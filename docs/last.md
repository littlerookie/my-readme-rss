<!--Autonomous Agents -->
<!--
Copyright (C) Teemu Maatta. 

@misc{MaattaAutonomousAgents2023,
  author = {Teemu Maatta},
  title = {Autonomous Agents},
  year = {2023},
  howpublished = {\url{https://github.com/tmgthb/Autonomous-Agents}},
  note = {Accessed: YYYY-MM-DD}
}
-->
<div id="topofthepage"> </div>

<div align="center">

[![Hits](https://hits.sh/github.com/tmgthb/Autonomous-Agents.svg?view=today-total&label=Views&color=007ec6)](https://hits.sh/github.com/tmgthb/Autonomous-Agents/)
[![X](https://img.shields.io/twitter/follow/Teemumtt3?style=social)](https://twitter.com/Teemumtt3)
[![GitHub Repo stars](https://img.shields.io/github/stars/tmgthb/Autonomous-Agents?style=flat-square)](https://github.com/tmgthb/Autonomous-Agents/stargazers)

</div>

<p align="center">
  <img height="100" src="https://github.com/tmgthb/Autonomous-Agents/blob/main/Autonomous_agent_logo.png" alt="Autonomous Agents">
</p>

<div align="center">

  # Autonomous Agents
  Autonomous Agents-[research papers](https://github.com/tmgthb/Autonomous-Agents/blob/main/README.md). Updated daily. See as well the [Resources](https://github.com/tmgthb/Autonomous-Agents/blob/main/Autonomous_Agents_Resources.md)-section. 

</div>


---

<div id="researchpapers" align="center">

## Research papers


Chronological order.

</div>

#### 25th June 2025

[The Decrypto Benchmark for Multi-Agent Reasoning and Theory of Mind](http://arxiv.org/abs/2506.20664v1)

- DECRYPTO: introduces a multi-agent benchmark for evaluating language models, featuring Alice (Chooses hints), Bob (Guesses code), and Eve (Intercepts code) interacting over shared Keywords (Secret words), Code (Secret digits sequence), and Hints (Words for code), tracked via Hint History (Past hints) and Code History (Past codes), and evaluated using Generalist Agents (Out-of-the-box LLMs), Specialist Agents (Task-specific agents), and specific Theory of Mind Tasks (Cognitive experiments).
- The benchmark is based on a language game requiring players to reason about others' knowledge and beliefs to succeed in cooperative and competitive settings.
- DECRYPTO provides a platform for studying multi-agent reasoning, theory of mind, and human-AI interaction in interactive, language-based scenarios.


---

[Memento: Note-Taking for Your Future Self](http://arxiv.org/abs/2506.20642v1)

- Memento: introduces a three-stage strategy, with Plan generation (Decomposes question into steps), Prolog query (Symbolic representation of steps), Definitions (Natural language predicate mapping), Database construction (Populates fact database), Prolog database (Stores extracted/verified facts), Query execution (Evaluates query for answer), and LLM (Performs tasks in stages), which decomposes complex tasks, records outcomes, and uses Prolog for structured reasoning.
- The method operates in three phases: plan generation, database construction, and query execution, leveraging LLMs to generate symbolic plans and populate a Prolog database.
- Memento uses Prolog queries and a dynamically constructed database of facts to answer multi-hop questions, combining symbolic structure with LLM flexibility.


---

[Memento: Note-Taking for Your Future Self](http://arxiv.org/abs/2506.20642v1)

- Memento: introduces a three-stage strategy, with Plan generation (Decomposes question into steps), Prolog query (Symbolic representation of steps), Definitions (Natural language predicate mapping), Database construction (Populates fact database), Prolog database (Stores extracted/verified facts), Query execution (Evaluates query for answer), and LLM (Performs tasks in stages), which decomposes complex tasks, records outcomes, and uses Prolog for structured reasoning.
- The method operates in three phases: plan generation, database construction, and query execution, leveraging LLMs to generate symbolic plans and populate a Prolog database.
- Memento uses Prolog queries and a dynamically constructed database of facts to answer multi-hop questions, combining symbolic structure with LLM flexibility.


---

[Model Editing as a Double-Edged Sword: Steering Agent Ethical Behavior Toward Beneficence or Harm](http://arxiv.org/abs/2506.20606v1)

- Behavior Editing: introduces steering LLM-based agents' ethical behavior by editing the agent (Pre-edit Agent) to become a Post-edit Agent, enabling both benevolent and malicious steering.
- The approach frames agent behavior steering as a model editing task, allowing precise and efficient modifications to influence behavior and moral alignment.
- The BEHAVIORBENCH benchmark is developed to systematically evaluate this editing approach across diverse ethical scenarios and complexity levels.


---

[Fine-Tuning and Prompt Engineering of LLMs, for the Creation of Multi-Agent AI for Addressing Sustainable Protein Production Challenges](http://arxiv.org/abs/2506.20598v1)

- Multi-Agent AI System: introduces a Retrieval-Augmented Generation (RAG)-oriented system for sustainable protein production research, with a Literature Search Agent (retrieves literature), Information Extraction Agent (extracts information), Pool of Scientific Literature (literature source), User Interface (user interaction), Toxicity Analysis Module (screens for toxicity), GPT-Based LLM (agent foundation), Prompt Engineering (optimisation method), Fine-Tuning (optimisation method), and External Sentence Transformer (evaluation tool).
- The study compares fine-tuning and prompt engineering as methods to optimise the performance of the information extraction agent using GPT models.
- This multi-agent system aims to automate the process of retrieving and extracting key information from scientific literature to accelerate research in sustainable protein production.


---

[An Agentic System for Rare Disease Diagnosis with Traceable Reasoning](http://arxiv.org/abs/2506.20430v1)

- DeepRare: introduces an LLM-powered agentic system for rare disease diagnosis, with Central Host (Coordinates workflow, synthesizes info), Memory Bank (Stores diagnostic information, context), Agent Servers (Execute specialized tasks), Phenotype Extractor (Converts free-text to HPO), Phenotype Analyzer (Analyzes HPO, suggests diseases), Knowledge Searcher (Retrieves medical documents, web), Case Searcher (Finds similar patient cases), Genotype Analyzer (Annotates, ranks genetic variants), Disease Normalizer (Standardizes disease names), External Data Sources (Provide diagnostic evidence), Medical Literature (Peer-reviewed publications), Rare Disease Knowledge (Curated rare disease info), General Knowledge (Broad clinical resources), Case Collection (Repository of patient cases), and Gene Variant Databases (Genetic variant information) components, designed to process heterogeneous clinical inputs and generate traceable diagnostic reasoning.
- The system employs a three-tier architecture comprising a central host, specialized agent servers, and diverse external data sources to facilitate complex diagnostic reasoning.
- DeepRare generates ranked diagnostic hypotheses with transparent reasoning chains linked to verifiable medical evidence, enhancing interpretability and supporting clinical adoption.


---

[SV-LLM: An Agentic Approach for SoC Security Verification using Large Language Models](http://arxiv.org/abs/2506.20415v1)

- SV-LLM (multi-agent assistant system): introduces a multi-agent framework for SoC security verification, with Application, Supervisor, Orchestrator, Agent, Data, and Infrastructure layers, designed to automate and enhance the verification workflow.
- The system employs specialized LLM-driven agents for tasks including security Q&A, asset identification, threat modeling, test plan generation, vulnerability detection, and bug validation.
- The layered architecture and agentic design aim to streamline complex verification tasks, reduce manual effort, and improve accuracy and scalability in hardware security analysis.


---

[TAPS: Tool-Augmented Personalisation via Structured Tagging](http://arxiv.org/abs/2506.20409v1)

- TAPS (Tool-Augmented Personalisation via Structured Tagging): introduces a tuning-free approach for personalised tool use in task-oriented dialogue, combining an LLM (Generates response, predicts API calls), a Structured Tagging Tool (Augments data, adds tags), and an Uncertainty-based Tool Detector (Determines tool use, assesses confidence).
- The framework leverages structured tagging to create an intermediate representation between natural language and API calls, enhancing argument extraction.
- An uncertainty-based tool detector determines when to apply the structured tagging tool to improve performance.


---

[Language Modeling by Language Models](http://arxiv.org/abs/2506.20249v1)

- Genesys: introduces an autonomous system for discovering novel language model architectures, with LMADE (Environment), Knowledge Engine (Knowledge access), Reference Library (Curated papers), External Sources (Search tools), Paper Vector DB (Vector database), Verification Engine (Verification tools), Symbolic Checker (Code analysis), Automated Trainer (Model training), Automated Evaluator (Model evaluation), Auto-Tuner (Parameter tuning), Runtime Checker (Training monitor), Evolutionary Tree (Design storage), LLM-driven Agents (Discovery agents), Designer Agents (Design creation), Proposer Agent (Proposal generation), Reviewer Agent (Proposal review), Planner Agent (Implementation planning), Coder Agent (Code writing), Observer Agent (Code review), Verifier Agents (Verification management), Generalized Autoregressive Block (Main architecture unit), Generalized Autoregressive Unit (Composable sub-unit), Ladder-of-Scales (Multi-scale verification), and Unit-based Generation (Stepwise code generation).
- The system simulates the research process from ideation to verification using LLM agents and a genetic programming backbone operating on a factorized design space.
- Genesys employs a Ladder-of-Scales approach for efficient verification and unit-based code generation for improved design quality and efficiency.


---

[PSALM-V: Automating Symbolic Planning in Interactive Visual Environments with Large Language Models](http://arxiv.org/abs/2506.20097v1)

- PSALM-V: introduces a neuro-symbolic learning system that induces symbolic action semantics in visual environments by iteratively initializing/updating problem files, sampling trajectories, executing in the environment, predicting errors, generating/updating action semantics, and using a symbolic planner for verification.
- The system maintains a tree-structured belief over action semantics, refining it based on execution outcomes and predicted errors to enable reliable planning without expert definitions.
- PSALM-V dynamically infers PDDL problem files and domain action semantics by analyzing execution outcomes and synthesizing possible error explanations.


---

#### 24th June 2025

[Learning Instruction-Following Policies through Open-Ended Instruction Relabeling with Large Language Models](http://arxiv.org/abs/2506.20061v1)

- OIR (Open-Ended Instruction Relabeling): introduces a framework that leverages a Large Language Model to automatically generate open-ended instructions from collected agent trajectories, enriching training data for instruction-following reinforcement learning.
- The framework uses the LLM to relabel unsuccessful trajectories by identifying accomplished subtasks, providing semantic rewards for efficient learning in sparse environments.
- A prioritized instruction buffer manages the diverse, LLM-generated instructions, balancing exploration and exploitation for robust policy improvement.


---

[QHackBench: Benchmarking Large Language Models for Quantum Code Generation Using PennyLane Hackathon Challenges](http://arxiv.org/abs/2506.20008v1)

- QHackBench: introduces a novel benchmark dataset and evaluation framework for LLM-based quantum code generation, featuring QHack Challenges, PennyLang Dataset, Retrieval, Code Generation Agent, Test Bench, Validation & Correction Agent, Self-Reasoning, and Augmented Query components.
- The framework systematically evaluates LLMs using vanilla prompting, Retrieval-Augmented Generation, and a multi-agent iterative refinement pipeline on real-world quantum coding challenges.
- Results indicate RAG and multi-agent approaches can enhance performance, highlighting the importance of domain-specific context and iterative debugging for reliable quantum code generation.


---

[Prover Agent: An Agent-based Framework for Formal Mathematical Proofs](http://arxiv.org/abs/2506.19923v1)

- Prover Agent: introduces an agent-based framework for formal mathematical proofs, coordinating an Informal LLM (informal reasoning), Prover Model (formal proving), Lean (formal verification), and AutoFormalizer (formalizes lemmas).
- The framework generates auxiliary lemmas via informal reasoning, formalizes them, proves them, and uses verified lemmas to synthesize the final proof.
- Iterative refinement based on Lean feedback is used throughout the process to ensure correctness and improve proof construction.


---

[JoyAgents-R1: Joint Evolution Dynamics for Versatile Multi-LLM Agents with Reinforcement Learning](http://arxiv.org/abs/2506.19846v1)

- JoyAgents-R1: introduces a joint evolution dynamics framework for heterogeneous multi-agent systems, including a master agent (orchestrates tasks), sub-agents (specialized task execution), agent memory (stores past information), tools (external functionalities), joint evolution dynamics (training process), and joint reward function (calculates action feedback).
- The framework employs a hierarchical architecture where the master agent delegates tasks to specialized sub-agents that interact with tools and memory.
- Joint evolution dynamics leverages GRPO with node-wise Monte Carlo sampling and marginal benefit updating, while memory evolves adaptively using GRPO rewards.


---

[MAM: Modular Multi-Agent Framework for Multi-Modal Medical Diagnosis via Role-Specialized Collaboration](http://arxiv.org/abs/2506.19835v1)

- MAM (Modular Multi-Agent Framework for Multi-Modal Medical Diagnosis): introduces a modular, collaborative framework with General Practitioner (Initial triage/referral), Specialist Team (Domain expert agents), Radiologist (Image analysis agent), Medical Assistant (Information retrieval/summary), and Director (Orchestrator/synthesizer) agents for multi-modal medical diagnosis.
- The framework decomposes the diagnostic process into specialized roles, each embodied by an LLM-based agent, enabling efficient knowledge updates and leveraging existing models.
- Agents collaborate through a defined workflow involving initial triage, problem decomposition, information retrieval, diagnostic opinion generation, discussion, report synthesis, consensus, and final diagnosis derivation.


---

[LLM-Based Social Simulations Require a Boundary](http://arxiv.org/abs/2506.19806v1)

- LLM-Based Social Simulations: introduces boundaries for reliable social science contributions, focusing on LLM Agents (model individual behavior), Alignment (simulated behaviors match real-world), Consistency (coherent agent behavior over time), and Robustness (reproducibility under conditions).
- The paper argues that LLMs' inherent limitations, particularly lack of behavioral heterogeneity, constrain their reliability for simulating complex social dynamics.
- It proposes heuristic boundaries and a checklist to guide researchers in determining the appropriate scope and claims for such simulations in social science research.


---

[SAGE: Strategy-Adaptive Generation Engine for Query Rewriting](http://arxiv.org/abs/2506.19783v1)

- SAGE (Strategy-Adaptive Generation Engine): introduces a reinforcement learning framework for query rewriting that integrates a Policy Model guided by Explicit Strategic Primitives, evaluated by an Environment, and trained using a Reward Shaping Module with Strategic Credit Shaping and Contrastive Reward Shaping, enhanced by an Exploration Penalty and Proactive Exploration Prompting via GRPO Update.
- The framework operationalizes expert-crafted strategies within an RL loop to steer the LLM agent towards effective query rewriting and improved policies.
- Novel reward shaping mechanisms and forced exploration techniques are introduced to provide informative learning signals and counteract reward hacking.


---

[A Survey of Multi-sensor Fusion Perception for Embodied AI: Background, Methods, Challenges and Prospects](http://arxiv.org/abs/2506.19769v1)

- Multi-sensor Fusion Perception (MSFP): introduces a survey of methods for embodied AI, detailing pipelines with Sensor Data, Backbone/Encoder, Features, Fusion Mechanism, and Downstream Task components.
- The survey categorizes methods by fusion level (point, voxel, region, multi-level), multi-agent (Agent Communication), time-series (Temporal Fusion), and MM-LLM (LLM) approaches.
- It reviews specific techniques within each category and discusses open challenges and future opportunities for MSFP in embodied AI.


---

[A Survey of LLM-Driven AI Agent Communication: Protocols, Security Risks, and Defense Countermeasures](http://arxiv.org/abs/2506.19676v1)

- Agent Communication Classification: introduces a comprehensive survey of LLM-driven AI agent communication, classifying it into User-Agent Interaction, Agent-Agent Communication, and Agent-Environment Communication, and analyzing related protocols, security risks, and defense countermeasures for each stage.
- The paper details the typical LLM-Driven AI Agent Architecture comprising perception, memory, reasoning/planning, tool, and action modules, highlighting how agent communication enables collaboration and task completion beyond single LLM capabilities.
- Agent-Agent Communication Architectures are categorized into CS-based, P2P-based, Hybrid, and Others based on their discovery mechanisms, while specific protocols like MCP, A2A, and AG-UI are discussed within the respective communication stages.


---

[Adaptive Domain Modeling with Language Models: A Multi-Agent Approach to Task Planning](http://arxiv.org/abs/2506.19592v1)

- TAPAS (Task-based Adaptation and Planning using Agents): introduces a multi-agent framework for adaptive task planning, including Domain Generator, Initial State Generator, Goal State Generator, Planning Problem Model, Solver, Debugger, Structured Plan, Plan Abstraction, Plan in NL, Plan Executor, Action Executor Agent, Validator Agent, Memory, Critic, Agent Tools, and Robot/Execution Environment.
- The framework uses specialized LLM-based agents to collaboratively generate and adapt domain models, initial states, and goals via structured tool calls and iterative refinement.
- A robust planning and execution pipeline translates symbolic plans to natural language for a ReAct-style execution agent, bridging the gap to real-world robot capabilities with feedback-driven validation.


---

[KnowMap: Efficient Knowledge-Driven Task Adaptation for LLMs](http://arxiv.org/abs/2506.19527v1)

- KnowMap: introduces a novel approach for LLM task adaptation by dynamically constructing a knowledge base from environmental and experiential data, equipping a larger LLM with task-specific knowledge via a fine-tuned embedding model, and utilizing an agent scaffold with planner, actuator, evaluator, and memory module.
- The framework's knowledge base is divided into an environmental knowledge base representing the current environment state and an experiential knowledge base storing reusable experiences and reasoning patterns derived from trajectories.
- KnowMap fine-tunes a knowledge-embedding model on data derived from both knowledge bases to enhance retrieval performance and support the agent scaffold's decision-making process.


---

[MATE: LLM-Powered Multi-Agent Translation Environment for Accessibility Applications](http://arxiv.org/abs/2506.19502v1)

- MATE (Multi-Agent Translation Environment): introduces, a multimodal accessibility multi-agent system, with Interpreter Agent (Identifies task, redirects), TTS Expert (Text to speech), TTI Expert (Text to image), STT Expert (Speech to text), ITT Expert (Image to text), ITA Expert (Image to audio), ATI Expert (Audio to image), VTT Expert (Video audio to text), ModCon-Task-Identifier (Task type recognition model), Pre-defined Models/Functions (Perform modality conversion), and Output File Storage (Saves output files), designed to perform modality conversions based on user needs for accessibility applications.
- The system uses an Interpreter Agent, powered by ModCon-Task-Identifier, to identify the user's requested modality conversion task and delegates it to one of seven specialized expert agents.
- Expert agents utilize pre-defined models and functions to execute specific conversion tasks, saving the output to a designated location for the user.


---

[NaviAgent: Bilevel Planning on Tool Dependency Graphs for Function Calling](http://arxiv.org/abs/2506.19500v1)

- NaviAgent: introduces a bilevel planning architecture for robust function calling, integrating a Multi-Path Decider (LLM-powered agent) for action selection and a Graph-Encoded Navigator (Graph-based planning) for toolchain planning on a Tool Dependency Heterogeneous Graph (TDHG) (Tool relationship graph).
- The Graph-Encoded Navigator constructs and evolves the TDHG through Graph Construction (Builds TDHG), Graph Representation (Node/edge features), Graph Training (Optimizes graph), Graph Search (Finds toolchains), and Graph Evolution (Updates graph).
- The Multi-Path Decider dynamically chooses actions from Direct Response (Decider action), Intent Clarification (Decider action), Tool Retrieval (Decider action), and Tool Call (Decider action) based on perceived states and Navigator output.


---

[Dialogic Pedagogy for Large Language Models: Aligning Conversational AI with Proven Theories of Learning](http://arxiv.org/abs/2506.19484v1)

- LLM-Based Dialogic Pedagogy Framework: proposes strategies for designing effective LLM-based conversational AI tutors, incorporating an LLM (Core conversational engine), Dialogue Strategy Engine (Guides conversation flow), Knowledge Retrieval Module (Integrates external information), Student Model (Tracks learner state), and Interaction Persona Module (Manages AI style/role).
- The strategies aim to address limitations of raw LLMs, such as over-directness and lack of student modeling, by integrating pedagogical principles like Socratic questioning, scaffolding, and reflection.
- The framework emphasizes aligning AI interactions with proven learning theories to create personalized, engaging, and educationally productive dialogues.


---

[LLM-based Multi-Agent System for Intelligent Refactoring of Haskell Code](http://arxiv.org/abs/2506.19481v1)

- LLM-based Multi-Agent System: introduces an automated Haskell code refactoring system with agents for code analysis, strategy formulation, refactoring execution, testing, and debugging.
- The system employs specialized agents like Code Context and Structure, Code Smells, Refactoring Strategy, Refactor (Expert/Lead), Testing and Validation, and Debug agents to collaboratively improve code.
- This multi-agent approach aims to enhance code quality, runtime efficiency, and memory usage in functional programming codebases through structured interaction and iterative refinement.


---

[Mem4Nav: Boosting Vision-and-Language Navigation in Urban Environments with a Hierarchical Spatial-Cognition Long-Short Memory System](http://arxiv.org/abs/2506.19433v1)

- Mem4Nav: introduces a hierarchical spatial-cognition long-short memory system with Sparse Octree (voxel indexing), Semantic Topological Graph (landmark connectivity), Reversible Token Processing (encodes/decodes memory), Long-Term Memory (lossless historical storage), and Short-Term Memory Cache (recent local context).
- This system integrates fine-grained voxel indexing and high-level landmark connectivity with dual memory modules for efficient storage and retrieval of spatial observations.
- The dual memory architecture, using reversible tokens for LTM and a frequency-recency cache for STM, enables agents to retain relevant experiences over extended time horizons for improved navigation.


---

[Commander-GPT: Dividing and Routing for Multimodal Sarcasm Detection](http://arxiv.org/abs/2506.19420v1)

- Commander-GPT: introduces a modular multi-agent framework for multimodal sarcasm detection, including Input, Subtask Routing, Subtask Execution by specialized agents (Context Modeling, Sentiment Analysis, Rhetorical Device Recognition, Facial Expression Recognition, Image Summarization, Scene Text Recognition), and a Commander for result integration and final decision.
- The framework decomposes sarcasm detection into six cognitively meaningful sub-tasks, dynamically routing input to the most suitable specialist agents.
- Centralized coordination by the commander integrates information from activated agents for adaptive and fine-grained reasoning across modalities.


---

[Skywork-SWE: Unveiling Data Scaling Laws for Software Engineering in LLMs](http://arxiv.org/abs/2506.19290v1)

- Skywork-SWE: introduces an automated data curation pipeline for software engineering tasks, including data collection and pre-filtering, environment setup and execution-based validation, and agent trajectory generation, used to train the Skywork-SWE Agent Model, evaluated with the OpenHands Agent Framework and Test-Time Scaling (TTS).
- The pipeline generates a large-scale, high-quality dataset of GitHub issue-fix instances with executable runtime environments.
- The trained model demonstrates data scaling laws in software engineering tasks and achieves state-of-the-art performance on SWE-bench Verified among open-source models.


---

[Augmenting Multi-Agent Communication with State Delta Trajectory](http://arxiv.org/abs/2506.19209v1)

- SDE (State Delta Encoding): introduces a novel multi-agent communication protocol that augments natural language with LLM's hidden states by transferring token-wise changes.
- The protocol involves agents built from a single LLM exchanging natural language tokens and state delta trajectories.
- State delta trajectories, representing differences in hidden states, are injected into the receiver agent's transformer layers to enhance understanding.


---

#### 23th June 2025

[Distilling Tool Knowledge into Language Models via Back-Translated Traces](http://arxiv.org/abs/2506.19171v1)

- Back-translation pipeline: introduces a method to distill tool knowledge into language models by converting tool-integrated reasoning traces into natural language using a SOLVER AGENT (Generates TIR traces), SymPy Toolkit (Provides symbolic tools), TIR Trace Filtering (Selects correct traces), TRANSLATOR AGENT (Translates tool calls), JUDGE AGENT (Verifies translations), and REPHRASE AGENT (Reconstructs NL traces) to fine-tune a Student Model (Fine-tuned target model).
- This pipeline generates high-quality natural language reasoning traces from tool-augmented solutions, enabling smaller models to internalize structured problem-solving patterns without requiring tool access at inference.
- The approach improves performance on challenging math benchmarks by transferring symbolic computation capabilities and structured reasoning from tool-using agents to language-only models.


---





#### 18th June 2025

[SwarmAgentic: Towards Fully Automated Agentic System Generation via Swarm Intelligence](https://arxiv.org/abs/2506.15672)

- SwarmAgentic: introduces a framework for fully automated agentic system generation, using Particle Swarm Optimization to explore a language-driven design space, optimizing Agentic Systems composed of an Agent Set and Collaborative Structure.
- The framework iteratively refines Agentic Systems by updating Particle positions and velocities based on Fitness Function evaluation and Flaw Identification.
- Velocity updates integrate Failure-Driven Adjustments, Personal Best Guidance, and Global Best Guidance to refine Agent functionality and collaboration strategies, yielding the best system as the Search Result.


---

[Managing Complex Failure Analysis Workflows with LLM-based Reasoning and Acting Agents](https://arxiv.org/abs/2506.15567)

- LPA (LLM-based Planning Agent): introduces a system for managing complex failure analysis workflows, with Agent Core orchestrating control flow, Memory retaining information, Plan Generation creating step-by-step plans, Action Matching and Execution selecting and running tools, Feedback and Reflection adjusting plans based on results, LLM processing language and reasoning, Tools providing external system interfaces, and Data serving as external information sources.
- The agent utilizes LLMs as the "brain" to decompose complex queries and resolve them through reasoning and autonomous tool use, employing ReAct or Online Replanning approaches.
- The system integrates external tools like databases, search engines, and AI models to retrieve data and perform analysis tasks, supporting FA engineers.


---


[PhishDebate: An LLM-Based Multi-Agent Framework for Phishing Website Detection](http://arxiv.org/abs/2506.15656v1)

- PhishDebate: introduces a modular multi-agent LLM-based debate framework for phishing website detection, with URL Analyst Agent, HTML Structure Agent, Content Semantic Agent, Brand Impersonation Agent, Moderator, and Judge components.
- The framework employs specialized agents to analyze different website aspects and coordination agents to manage a structured debate process.
- This multi-agent approach aims to improve detection accuracy, interpretability, and robustness compared to single-agent methods.


---

[The Effect of State Representation on LLM Agent Behavior in Dynamic Routing Games](http://arxiv.org/abs/2506.15624v1)

- Approach: introduces a framework for constructing natural language state representations for prompting LLM agents in repeated multi-agent games, implemented with LLM Agents, Game Environment, Prompting Mechanism, State Representation, LangChain, and OpenAI API.
- The system evaluates LLM agent behavior in a dynamic selfish routing game by varying state representations along action informativeness, reward informativeness, and prompting style axes.
- The research finds that summarized state representations, regret-based feedback, and limited information about others' actions lead to more stable, equilibrium-like agent behavior.


---

[Managing Complex Failure Analysis Workflows with LLM-based Reasoning and Acting Agents](http://arxiv.org/abs/2506.15567v1)

- LPA (LLM-based Planning Agent): introduces an agent architecture for failure analysis workflows, integrating a Large Language Model for reasoning and planning, Memory for retaining information, Action Matching and Execution for tool use, and Feedback and Reflection for plan refinement, interacting with a User and the external Environment via Data and Tools.
- The agent utilizes ReAct-style iterative task generation or online replanning to process complex queries and generate human-readable responses.
- The implementation integrates external tools like databases and ML models, demonstrating technical feasibility and robustness in a production-like environment.


---

[AGENTGROUPCHAT-V2 : Divide-and-Conquer Is What LLM-Based Multi-Agent System Need](http://arxiv.org/abs/2506.15451v1)

- AGENTGROUPCHAT-V2: introduces a novel framework with Query Manager (Frontend, query decomposition), Task Manager (Central coordination, task flow), Group Manager (Execution, collaboration organization), Agent (Individual LLM participant), Task (Basic processing unit), Group (Collaborative work unit), and Task Forest (Hierarchical task structure) for LLM-based multi-agent systems.
- The framework employs a divide-and-conquer parallel architecture, dynamic task tree decomposition, and specialized agent role assignment to address challenges in system architecture, generalizability, and performance.
- Experimental results demonstrate superior performance on complex reasoning, code generation, and diverse tasks compared to existing multi-agent approaches.


---

[RAS-EVAL: A COMPREHENSIVE BENCHMARK FOR SECURITY EVALUATION OF LLM AGENTS IN REAL-WORLD ENVIRONMENTS](http://arxiv.org/abs/2506.15253v1)

- RAS-Eval: introduces a comprehensive security benchmark for LLM agents, including Test Cases, Attack Tasks, Scenarios, Toolkits, Risk Management, and Evaluation Pipelines.
- The benchmark supports both Real Execution and Simulated Execution of tools across JSON, LangGraph, and MCP formats.
- It incorporates Failure Modes and Vulnerability Types for granular analysis and uses Evaluation Pipelines to measure task completion and attack success rates.


---

[From LLMs to MLLMs to Agents: A Survey of Emerging Paradigms in Jailbreak Attacks and Defenses within LLM Ecosystem](http://arxiv.org/abs/2506.15170v1)

- Agent Framework: introduces a survey of jailbreak attacks and defenses in the LLM ecosystem, with Core (Central processing unit), Planning (Task decomposition/logic), Tools (External interfaces/applications), Memory (Information management/storage), and LLM Network (Multi-agent interaction) components, where the paper reviews the evolution from LLMs to MLLMs and Agents and analyzes security challenges.
- The survey categorizes jailbreak techniques by attack impact and visibility and defense strategies by response timing and technical approach.
- It also details datasets and evaluation metrics used in jailbreak research and outlines future research directions.


---


[Modeling the One-to-Many Property in Open-Domain Dialogue with LLMs](http://arxiv.org/abs/2506.15131v1)

- Multi-Response Generation (MRG) and Preference-based Selection (PS): introduces a two-stage framework for open-domain dialogue response generation, where MRG generates a set of diverse responses and PS selects the best one based on human preference.
- The approach leverages smaller LLMs and introduces the o2mDial dataset to explicitly capture the one-to-many property.
- Empirical results show the framework enhances response diversity and quality in smaller LLMs, approaching the performance of larger models.


---

[HEAL: An Empirical Study on Hallucinations in Embodied Agents Driven by Large Language Models](http://arxiv.org/abs/2506.15065v1)

- LLM-based Embodied Agent Pipeline: studies hallucinations in embodied agents by evaluating a pipeline that takes Scene (Visual input) and Task Description (Natural language instruction), processes them via a Scene Parser (Extracts scene info) and LLM as Goal Interpreter (Generates symbolic goals) to produce LTL Goal (Symbolic task goals) for Execute the Task (Action planning/execution).
- The study constructs a hallucination probing set by systematically modifying the Task Description and Scene Information inputs to introduce scene-task inconsistencies.
- The research finds that LLMs struggle to reconcile scene-task inconsistencies, leading to hallucinations and failures in handling infeasible tasks.


---

[OS-HARM: A Benchmark for Measuring Safety of Computer Use Agents](http://arxiv.org/abs/2506.14866v1)

- OS-HARM (Benchmark): introduces a benchmark for measuring the safety of computer use agents, featuring OS-HARM tasks, OSWorld Ubuntu VM, LLM Agent, OSWorld scaffolding, Agent Traces, and LLM Judge.
- The benchmark evaluates LLM-based agents on tasks involving deliberate user misuse, prompt injection attacks, and model misbehavior within a realistic OSWorld environment.
- An automated LLM Judge evaluates agent performance and safety based on recorded execution traces, including reasoning steps, screenshots, and accessibility trees.


---

[LLM Agent for Hyper-Parameter Optimization](https://arxiv.org/abs/2506.15167)

- LLM Agent Framework and MCP: introduces an interactive framework orchestrating collaboration between the LLM Agent (comprising Profile, Memory, Planning, and Action components), Human inputs, and the Environment (WS-PSO-CM algorithm) for automatic hyper-parameter tuning.
- The Model Context Protocol (MCP) defines a unified communication specification enabling the LLM Agent to interact with external systems via MCP Client and MCP Server architecture.
- The framework iteratively refines hyper-parameters for the WS-PSO-CM algorithm based on prompt requirements and environmental feedback to optimize UAV trajectory and communication.


---

[Leaky Thoughts: Large Reasoning Models Are Not Private Thinkers](https://arxiv.org/abs/2506.15674)

- Large Reasoning Model (LRM): analyzes privacy leakage in Large Reasoning Models, involving Input (Sensitive user data and scenario), Large Reasoning Model (Processes input), Reasoning Trace (Intermediate thinking steps), and Output (Final response), revealing that Reasoning Traces frequently leak sensitive user data.
- Reasoning Traces, often assumed internal, are shown to be easily extractable and contain abundant sensitive data, making them a significant privacy vulnerability.
- Increasing test-time compute for better utility can worsen privacy by increasing leakage in the Reasoning Trace, highlighting the need for privacy strategies targeting internal thinking.


---


#### 17th June 2025

[Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.](https://storage.googleapis.com/deepmind-media/gemini/gemini_v2_5_report.pdf)

- Gemini 2.X model family: introduces Gemini 2.5 Pro and Flash, built on Sparse mixture-of-experts transformers (Core Architecture) with Multimodal Support (Text, Image, Video, Audio), Long Context Processing (>1M tokens), Tool Use Support (Function calls), Thinking (Inference process), and Deep Think (Reasoning approach).
- The models enable next-generation agentic capabilities, demonstrated by the Gemini Plays Pokémon agent harness which includes components like Persistent Memory & Context, Goals, Action History & Summaries, Game State, Periodic Processes (Memory Summarizer, Guidance Gemini), Agentic Tools (Pathfinder, Boulder Puzzle Strategist), and Game I/O.
- Gemini 2.5 models achieve state-of-the-art performance on various benchmarks, including long-context video understanding (processing up to 3 hours of video) and coding, while also undergoing extensive safety and security evaluations.


---


[AGENTDISTILL: TRAINING-FREE AGENT DISTILLATION WITH GENERALIZABLE MCP BOXES](http://arxiv.org/abs/2506.14728v1)

- AgentDistill: introduces a training-free agent distillation framework, with Teacher Agent (Generates MCPs), Manager Agent (Teacher) (Coordinates tasks), Basic Image Captioner (Teacher) (Captions images), MCP Creation Module (Creates task MCPs), MCP-Box Construction (Builds MCP Box), Abstraction (Parameterizes MCPs), Clustering (Groups MCPs), Consolidation (Merges MCPs), MCP Box (Reusable task modules), Student Agent (Uses MCP Box), Manager Agent (Student) (Coordinates tasks, uses MCP Box), and Basic Image Captioner (Student) (Captions images), which transfers task-solving capabilities from large teacher agents to small student agents via reusable Model-Context-Protocols (MCPs).
- The framework involves a teacher agent generating MCPs, a construction process to build a reusable MCP-Box by abstracting, clustering, and consolidating them, and a student agent that directly integrates this MCP-Box for inference.
- AgentDistill enables student agents to inherit sophisticated problem-solving skills and generalize across tasks by providing a structured MCP-Box without requiring additional training or trajectory replay.


---

[Unified Software Engineering agent as AI Software Engineer](http://arxiv.org/abs/2506.14683v1)

- USEagent (Unified Software Engineering agent): introduces a unified agent for software engineering tasks, with Meta-Agent orchestrates actions, Actions perform SE tasks, Task State stores shared information, and Program is the target software project.
- The Meta-Agent uses a ReAct-style loop to select actions based on the current task state and action outputs.
- The framework utilizes a set of modular actions encapsulating units of work and a structured task state for consensus memory among actions.


---

[Doppelgänger Method : Breaking Role Consistency in LLM Agent via Prompt-based Transferable Adversarial Attack](http://arxiv.org/abs/2506.14539v1)

- Doppelgänger Method: introduces a prompt-based transferable adversarial attack method to break LLM agent consistency, evaluated using the PACAT Level metric, and countered by the CAT Prompt defense.
- The method demonstrates the risk of role hijacking and internal information exposure in LLM agents.
- Experimental results show the attack's effectiveness and the defense prompt's ability to mitigate consistency degradation.


---

[Automated Decision-Making on Networks with LLMs through Knowledge-Guided Evolution](http://arxiv.org/abs/2506.14529v1)

- LLMNet: introduces a system for automated GNN design using LLM-based agents, including Knowledge Agent (Builds, manages knowledge bases), Prior Knowledge Base (Stores task-specific knowledge), Experiment Knowledge Base (Stores experimental results), Planning Agent (Generates task plan, evaluates), Data Agent (Performs feature engineering), Configuration Agent (Configures search space), and Evaluation Agent (Fine-tunes, experiments), which leverages knowledge bases and RAG for knowledge-guided evolution.
- The system employs a pipeline of specialized agents that interact with constructed knowledge bases to design and refine GNN model architectures step by step.
- LLMNet demonstrates superior performance across various graph learning tasks by effectively integrating graph-related knowledge into the automated design process.


---


[GENERATIONPROGRAMS: Fine-grained Attribution with Executable Programs](http://arxiv.org/abs/2506.14580)

- GENERATIONPROGRAMS: introduces a modular generation framework that decomposes the process into program generation by an LLM and program execution by neural modules, producing an output with sentence-level attributions from input documents.
- The framework first generates an executable program plan composed of modular text operations tailored to the query, then executes this plan using neural modules like paraphrasing, compression, fusion, and extraction on retrieved document sentences.
- This two-stage approach enables fine-grained attribution by tracing the program execution and linking generated content back to source sentences, enhancing interpretability and verifiability.


---

[SIRI-Bench: Challenging VLMs' Spatial Intelligence through Complex Reasoning Tasks](http://arxiv.org/abs/2506.14512v1)

- SIRI-Bench (Spatial Intelligence ReasonIng Benchmark): introduces a benchmark for evaluating VLMs' spatial intelligence using video-based 3D geometry problems, generated by an Automatic Scene Creation Engine leveraging Specialized LLM Agents to transform Original Math Problems into Realistic 3D Scenes and Video inputs for VLMs, alongside textual Questions and numerical Answers.
- The Automatic Scene Creation Engine generates the benchmark data by solving geometric conditions, generating Blender Python Scripts, and refining textual inputs and outputs.
- SIRI-Bench challenges VLMs to extract spatial information from video and perform complex reasoning, revealing limitations in current models compared to human performance and text-based LLMs.


---

[LLM-Powered Swarms: A New Frontier or a Conceptual Stretch?](http://arxiv.org/abs/2506.14496v1)

- LLM-Powered Swarms: introduces a new paradigm for swarm intelligence using Large Language Models as agents, featuring LLM Agents (Large Language Models), Multi-Agent Coordination (Interconnected agents collaborate), Client-Side Operation (Framework runs locally), LLM Access (Cloud or local models), and Prompts (Natural language instructions).
- This approach contrasts with traditional rule-based swarms by trading execution speed for flexibility and higher-level reasoning capabilities.
- Evaluation using Boids and ACO models highlights significant latency and resource costs compared to classical methods, suggesting potential for hybrid systems.


---

[Expectation Confirmation Preference Optimization for Multi-Turn Conversational Recommendation Agent](http://arxiv.org/abs/2506.14302v1)

- ECPO (Expectation Confirmation Preference Optimization): introduces a novel multi-turn preference optimization paradigm leveraging Expectation Confirmation Theory to align LLM-based conversational recommendation agents with user expectations.
- The framework explicitly models user satisfaction evolution across turns using Forward Expectation Confirmation and rewrites unsatisfactory responses via Backward Expectation Derivation with a Rewriter.
- ECPO is supported by AILO, an LLM-based user simulator that provides realistic feedback and performs expectation confirmation, enabling efficient turn-level preference optimization without extensive sampling.


---

[ADRD: LLM-DRIVEN AUTONOMOUS DRIVING BASED ON RULE-BASED DECISION SYSTEMS](http://arxiv.org/abs/2506.14299v1)

- ADRD (LLM-Driven Autonomous Driving Based on Rule-based Decision Systems): introduces a framework with Information Module, Agents Module (Planner, Coder, Summarizer), and Testing Module, leveraging LLMs to generate and refine rule-based decision trees for autonomous driving.
- The Information Module gathers scenario data, the Agents Module generates and codes driving tactics, and the Testing Module provides feedback for iterative refinement.
- ADRD demonstrates superior performance, response speed, and interpretability compared to baselines by integrating LLMs with rule-based decision systems.


---

[From What to Respond to When to Respond: Timely Response Generation for Open-domain Dialogue Agents](http://arxiv.org/abs/2506.14285v1)

- TIMER: introduces timely dialogue response generation, with Time Interval Prediction (predicts delay), Time-conditioned Response Generation (generates response), and Fine-tuned Dialogue Model (base language model), addressing when and what to respond based on temporal context.
- The model is trained using a multi-task learning objective on a large-scale synthetic dataset derived from event knowledge graphs and LLMs.
- TIMER demonstrates improved performance over baselines in predicting appropriate response delays and generating time-specific, coherent dialogue.


---

[AgentSynth: Scalable Task Generation for Generalist Computer-Use Agents](http://arxiv.org/abs/2506.14205v1)

- AgentSynth: introduces a scalable pipeline for synthesizing computer-use tasks and trajectories by iteratively chaining LLM-generated subtasks, executed by a Task Executor, verified by a Task Verifier, revised by a Task Reviser, proposed as follow-ups by a Follow-up Task Proposer, and summarized into final tasks by a Task Summarizer, operating within an Environment guided by a Persona.
- The pipeline leverages information asymmetry, generating simple subtasks that compose into challenging long-horizon tasks, enabling controllable difficulty.
- AgentSynth generates over 6,000 diverse and realistic tasks at a low cost, providing a benchmark that reveals performance gaps in current LLM agents on multi-step computer tasks.


---

[MAS-LitEval : Multi-Agent System for Literary Translation Quality Assessment](http://arxiv.org/abs/2506.14199v1)

- MAS-LitEval: introduces a multi-agent system for literary translation quality assessment, with Terminology Consistency Agent (Ensures key term consistency), Narrative Perspective Consistency Agent (Verifies narrative voice alignment), Stylistic Consistency Agent (Evaluates tone rhythm style), and Coordinator (Combines agent scores feedback).
- The system employs specialized LLMs within agents to evaluate distinct dimensions of literary translation quality across segmented text chunks.
- The Coordinator integrates agent evaluations into an Overall Translation Quality Score (OTQS) and a detailed report, ensuring global consistency.


---

[FormGym: Doing Paperwork with Agents](http://arxiv.org/abs/2506.14079v1)

- Agent Framework with FieldFinder: introduces a system for end-to-end form completion using agents equipped with tools, including a novel field localization tool.
- The system evaluates Vision-Language and GUI agents on the FormGym benchmark, which includes diverse forms, user profiles, and tasks.
- The FieldFinder tool assists agents by predicting bounding boxes for input fields, significantly improving text placement accuracy.


---

[Comprehensive Verilog Design Problems: A Next-Generation Benchmark Dataset for Evaluating Large Language Models and Agents on RTL Design and Verification](http://arxiv.org/abs/2506.14074v1)

- CVDP (Comprehensive Verilog Design Problems): introduces a benchmark dataset and infrastructure, with Datapoint, Prompt, Context, Reference Solution, Test Harness, Testbench, Benchmark Runner, Agent Under Test, Model Under Test, Mini Repo, EDA Tools, Docker, LLM Judge, Map Feature, and Report & Logs components, designed to evaluate large language models and agents on hardware design and verification tasks.
- The benchmark includes 783 human-authored problems across 13 categories covering RTL generation, verification, debugging, and comprehension, provided in both Non-Agentic (single-turn) and Agentic (multi-turn, tool-using) formats.
- The infrastructure supports Dockerized agents and test harnesses for realistic tool interaction using EDA tools, and includes an LLM judge for quality filtering of datapoints.


---


#### 16th June 2025

[LocationReasoner: Evaluating LLMs on Real-World Site Selection Reasoning](http://arxiv.org/abs/2506.13841v1)

- LocationReasoner benchmark: introduces a benchmark to evaluate LLMs' real-world reasoning abilities in site selection, with Query Generation, Sandbox Environment, Datasets, In-house Tools, Execution Pathways, and Automated Verification components, evaluating Direct Code Generation, ReAct, and Reflexion approaches.
- The benchmark uses curated datasets and in-house tools within a sandbox environment to test LLMs on constraint-based location search with automated verification.
- Evaluation reveals current LLMs and agentic strategies struggle with complex real-world reasoning tasks, highlighting limitations in holistic and non-linear reasoning.


---


[Discovering Temporal Structure: An Overview of Hierarchical Reinforcement Learning](http://arxiv.org/abs/2506.14045v1)

- Hierarchical Reinforcement Learning (HRL): introduces an overview of methods for discovering temporal structure, formalized using the options framework including option policy, option termination function, option initiation function, high-level policy, and option model function, and discusses agent architectures like Hierarchical Components, Goal Conditioned, Feudal Architecture, and Single Network.
- The paper surveys methods for temporal structure discovery categorized by learning from online experience, offline datasets, and foundation models.
- HRL aims to improve exploration, credit assignment, transfer, and interpretability by leveraging temporal structure in sequential decision-making problems.


---

[How Does LLM Reasoning Work for Code? A Survey and a Call to Action](http://arxiv.org/abs/2506.13932v1)

- Code Reasoning Taxonomy: introduces a classification of techniques for LLM reasoning on code tasks, including Code CoT Reasoning, Execution-based reasoning, Inference Scaling, and Agentic approaches.
- The taxonomy details sub-techniques such as Plan-based CoT, Self-evaluation of execution behavior, Sampling, and Agentic Workflow.
- The survey highlights how these distinct reasoning strategies and their components are applied and perform on various code-related benchmarks.


---

[Spec2RTL-Agent: Automated Hardware Code Generation from Complex Specifications Using LLM Agent Systems](http://arxiv.org/abs/2506.13905v1)

- Spec2RTL-Agent: introduces an LLM-based multi-agent system for automated RTL code generation from complex specifications, including Iterative Understanding and Reasoning Module, Progressive Coding and Prompt Optimization Module, Adaptive Reflection Module, and Code Optimization and Conversion Module.
- The system processes unstructured specification documents, refines code generation through multiple abstraction levels, and iteratively verifies outputs.
- Spec2RTL-Agent demonstrates effectiveness in generating accurate RTL code with reduced human intervention compared to existing methods.


---


[We Should Identify and Mitigate Third-Party Safety Risks in MCP-Powered Agent Systems](http://arxiv.org/abs/2506.13666v1)

- SAFEMCP: introduces a controlled framework to examine safety issues in MCP-powered agent systems, with Agent, Backbone LLM, MCP-Servers, Attack, Defense, Passive Defense, Active Defense, Evaluation, Scenario, and Metric components.
- The framework simulates third-party attacks on LLM agents interacting with external services via the Model Context Protocol (MCP).
- SAFEMCP provides tools for evaluating attack effectiveness and defense strategies using various scenarios and metrics.


---

[CAMS: A CityGPT-Powered Agentic Framework for Urban Human Mobility Simulation](http://arxiv.org/abs/2506.13599v1)

- CAMS: introduces a CityGPT-powered agentic framework for urban human mobility simulation, with MobExtractor (Extracts/synthesizes mobility patterns), GeoGenerator (Generates geospatial knowledge/trajectories), and TrajEnhancer (Enhances trajectories via DPO) components.
- The framework leverages an urban foundation model (CityGPT) and agentic reasoning to generate realistic and plausible human mobility trajectories.
- CAMS integrates urban spatial knowledge and multi-dimensional feedback for controllable and generalizable simulation without relying on external geospatial information.


--

[Language Agents for Hypothesis-driven Clinical Decision Making with Reinforcement Learning](http://arxiv.org/abs/2506.13474v1)

- LA-CDM: introduces a hypothesis-driven uncertainty-aware language agent system for clinical decision making, comprising a Hypothesis Agent (forms hypothesis and confidence), a Decision Agent (decides action), Shared LLM Weights (underlying language model), and a Clinical Decision Making Environment (simulates patient interaction and provides feedback).
- The system is trained using a hybrid paradigm combining supervised learning for hypothesis generation and reinforcement learning for uncertainty estimation and efficient action selection.
- This approach models the iterative clinical process of forming hypotheses and requesting tests to converge towards a diagnosis, improving diagnostic performance and efficiency.


---

[Towards Pervasive Distributed Agentic Generative Al - A State of The Art](http://arxiv.org/abs/2506.13324v1)

- Pervasive Distributed Agentic Generative AI: surveys the state of the art in LLM-based agents deployed in pervasive computing environments, detailing the Transformer Architecture, Short-Term Memory, Long-Term Memory, Hybrid Memory, Cloud Layer, Fog Layer, and Edge Layer components.
- The paper examines the architecture of LLM agents, their deployment strategies across different infrastructure layers, and evaluation methods.
- It highlights challenges in deploying these agents on resource-constrained pervasive devices and proposes the "Agent as a Tool" concept.


---

[A Game-Theoretic Negotiation Framework for Cross-Cultural Consensus in LLMS](http://arxiv.org/abs/2506.13245v1)

- Game-Theoretic Negotiation Framework: introduces a systematic approach for cross-cultural consensus among LLMs, with Cultural Agents, Guideline Sets, Guideline Weights, Utility Functions, Negotiation Process (PSRO-based), Meta Strategy Solver, Best Response Oracle, Regional Cultural Agents, and Consensus Evaluation Toolkit, designed to achieve fair and robust agreement.
- The framework models consensus as a Nash Equilibrium and employs a PSRO-based negotiation process driven by utility functions balancing consistency, acceptance, and novelty.
- Culturally aligned Regional Cultural Agents are constructed using survey data, and consensus outcomes are evaluated using perplexity-based acceptance and value self-consistency metrics.


---

[Querying Large Automotive Software Models: Agentic vs. Direct LLM Approaches](http://arxiv.org/abs/2506.13171v1)

- Direct Full-Context Prompting: introduces a baseline approach where the LLM (Processes model) receives the entire Software Model File (Complete input data) along with Instructions (Guidance for LLM) and a Question (User query) to produce an Answer (LLM response).
- Agent with File Tools (ReAct Architecture): presents an agentic approach where the LLM (Agent's reasoning engine) interacts with Software Model Files (Data source) via a Toolkit (External tool access) containing specific Tools (File interaction functions), communicating through Messages (Communication channel) and append observation (Tool output) to answer a User (Initiates query) Question (User query) with an Answer (Agent's response).
- The study compares these two architectures for querying large automotive software models, evaluating their accuracy and token efficiency using various LLMs and a custom question dataset.


---

[Leveraging In-Context Learning for Language Model Agents](http://arxiv.org/abs/2506.13109v1)

- ICL-DS (In-Context Learning with Demonstration Selection): introduces an approach for LLM agents that leverages in-context learning with dynamically selected demonstrations, including an LLM Agent (generates thoughts and actions), a Demonstration Pool (stores annotated trajectories and snippets), an Iterative Annotation Algorithm (automatically annotates tasks for demonstrations), a Demonstration Selector (retrieves relevant demonstrations), Prompt Construction (formats input for LLM), a ReAct Solver (executes tasks iteratively with reasoning), a Plan & Execute (PnE) Solver (plans subtasks and executes them), and an Environment (provides observations and executes actions).
- The paper proposes an iterative annotation algorithm to automatically and efficiently create a demonstration pool of solution trajectories for agentic tasks, which are then used to improve LLM agent performance, reliability, and efficiency.
- The research demonstrates that using task-level trajectory demonstrations and smaller step-level snippet demonstrations significantly boosts performance for LLM agents, enabling them to rival costlier trained agents.


---

[MOTIVEBENCH: How Far Are We From Human-Like Motivational Reasoning in Large Language Models?](http://arxiv.org/abs/2506.13065v1)

- MOTIVEBENCH: a comprehensive evaluation benchmark designed to assess the extent to which Large Language Models (LLMs) can replicate human-like motivations and behaviors, consisting of 200 rich contextual scenarios and 600 reasoning tasks covering multiple levels of motivation.
- The benchmark addresses limitations of existing datasets by providing detailed scenarios, character profiles, and reasoning tasks that mimic real-world situations, thereby enabling a more accurate evaluation of LLMs' motivational intelligence.
- MOTIVEBENCH aims to provide insights into LLMs' capabilities in understanding and exhibiting human-like motivational reasoning, highlighting areas where current models fall short and suggesting directions for future research in humanizing LLMs.


---

[MAGIC: Multi-Agent Argumentation and Grammar Integrated Critiquer](http://arxiv.org/abs/2506.13037)

- MAGIC (Multi-Agent Argumentation and Grammar Integrated Critiquer): is a framework that utilizes multiple specialized agents to evaluate distinct writing aspects, aiming to predict holistic scores and produce detailed, rubric-aligned feedback for essays.
- The framework employs an orchestrator to consolidate the outputs from individual agents, which focus on specific components of argumentative writing such as argument structure, grammar, vocabulary, and comprehension.
- MAGIC aims to provide greater transparency, flexibility, and extensibility compared to monolithic automated essay scoring and feedback systems.


---

[Scaling Test-time Compute for LLM Agents](http://arxiv.org/abs/2506.12928v1)

- ATTS (Agentic Test-Time Scaling): explores test-time scaling strategies for language agents, including parallel sampling, sequential revision, verifiers and merging, and diversifying rollouts.
- The research systematically analyzes the impact of different design strategies on agent performance, finding that scaling test-time compute improves agent capabilities.
- Key findings include the importance of knowing when to reflect, the superiority of list-wise methods for verification and merging, and the positive effect of diversified rollouts on agent performance.


---

#### 15th June 2025

[WEREWOLF-PLUS: AN UPDATE OF WEREWOLF GAME SETTING BASED ON DSGBENCH](http://arxiv.org/abs/2506.12841v1)

- WereWolf-Plus: introduces a multi-model, multi-dimensional, and multi-method benchmarking platform with Werewolf Simulation (Rule-compliant environment), LLM Agents (Flexible model assignment), Role Configuration (Customizable roles), Reasoning Enhancement (Experience-Retrieval Augmentation), and Evaluation Framework (Metrics for agents) for evaluating multi-agent strategic reasoning in the Werewolf game.
- The platform provides a flexible and reliable environment supporting standard and customizable game setups with various roles and flexible LLM-role assignment.
- WereWolf-Plus incorporates retrieval-augmented memory for contextual compression and reflection, and introduces comprehensive quantitative evaluation metrics for different roles and players.


---

[Mastering Da Vinci Code: A Comparative Study of Transformer, LLM, and PPO-based Agents](http://arxiv.org/abs/2506.12801v1)

- Transformer-based Baseline Model: introduces, with Transformer architecture (Predicts opponent tiles), Input Representation (Current game state string), and Prediction Task (Predict hidden tile values) components, a model designed to predict opponent tiles based on the current public game state.
- This baseline model utilizes a Transformer architecture but is limited by its restricted access to the full game history.
- Its reasoning is primarily based on the current state snapshot and explicit negative constraints from prior guesses.


---

[SoK: The Privacy Paradox of Large Language Models: Advancements, Privacy Risks, and Mitigation](http://arxiv.org/abs/2506.12699v1)

- Systematization of Knowledge (SoK) on LLM Privacy: introduces a comprehensive analysis of privacy challenges in LLMs, categorizing them across training data, user prompts, generated outputs, and LLM agents, with all LLM (Large Language Model), LLM System, Training Data, User Prompts, LLM Generated Output, LLM Agent System, Main LLM Agent, Secondary Agents, External Tools, Knowledge Base, Memory, User, Service Provider-components, where the paper evaluates existing mitigation techniques and identifies research gaps.
- The paper highlights how LLMs' advanced capabilities and interactive nature introduce distinct privacy risks compared to traditional AI.
- It discusses various mitigation strategies for each category of privacy challenge, noting their effectiveness and limitations.


---

[SCISAGE: A MULTI-AGENT FRAMEWORK FOR HIGH-QUALITY SCIENTIFIC SURVEY GENERATION](http://arxiv.org/abs/2506.12689v1)

- SciSage (Scientific Sage): introduces a multi-agent framework with Interpreter (Understand/rewrite query), Organizer (Construct outline), Collector (Retrieve/rerank papers), Composer (Generate content), Refiner (Refine final document), and Reflector (Iterative hierarchical reflection) agents for high-quality scientific survey generation.
- The framework employs a reflect-when-you-write paradigm, with the Reflector agent critically evaluating drafts at multiple levels.
- SciSage coordinates specialized agents through query understanding, retrieval, content generation, and iterative hierarchical reflection processes.


---

#### 14th June 2025

[Synthetic Socratic Debates: Examining Persona Effects on Moral Decision and Persuasion Dynamics](http://arxiv.org/abs/2506.12657v1)

- Synthetic Socratic Debates: introduces a system using Agent (LLM with persona), Persona (6-dimensional identity profile), Moderator (Manages debate turns), Multi-Turn Debate Framework (Simulates agent interactions), Persona Modeling (Assigns identity attributes), Decision Measures (Quantify moral judgments), Persuasion Measures (Evaluate debate effectiveness), Rhetorical Strategy Evaluation (Assesses persuasion modes), and LLM-as-a-judge (Evaluates rhetorical strategies) to simulate moral debates between AI agents with distinct personas.
- The system investigates how persona traits influence moral decision-making and persuasive strategies in LLMs during multi-turn debates over real-world moral dilemmas.
- The research reveals that political ideology and personality traits significantly shape initial moral stances and debate outcomes, impacting persuasive success and rhetorical strategies.


---

[Towards Building General Purpose Embedding Models for Industry 4.0 Agents](http://arxiv.org/abs/2506.12607v1)

- Recommender Agent (ReAct Agent with Multi-Task Embedder Tool): introduces a framework for industrial asset maintenance agents, combining a ReAct Agent (Plans and reasons), a Multi-Task Embedder (Retrieves relevant items) used as a tool, and LLM Augmentation (Enriches queries) for improved context.
- The framework leverages domain-specific embeddings fine-tuned on nine industrial tasks derived from ISO documents to enhance retrieval performance for complex queries.
- Ablation studies demonstrate the effectiveness of LLM query augmentation and the importance of balanced positive/negative samples for training the embedding model.


---

[The Rise of AI Companions: How Human-Chatbot Relationships Influence Well-Being](http://arxiv.org/abs/2506.12605v1)

- Study Approach: investigates how human-chatbot relationships influence well-being by collecting Survey Data and Chat History Data, deriving Chatbot Companionship Measures, Interaction Intensity Measure, Self-Disclosure Measures, Human Social Support Measure, and Well-Being Measure, and analyzing them using LLM-based Text Analysis, Topic Modeling, Regression Analysis, and CFA.
- The study uses a mixed-methods approach, triangulating self-report surveys, open-ended descriptions, and chat transcripts to understand chatbot companionship and its psychological associations.
- Findings suggest that companionship-oriented chatbot use, especially with high intensity and self-disclosure, is associated with lower well-being, particularly for users with limited offline social support.


---

[AgentOrchestra: A Hierarchical Multi-Agent Framework for General-Purpose Task Solving](http://arxiv.org/abs/2506.12508v1)

- AgentOrchestra: introduces a hierarchical multi-agent framework with a Planning Agent (Central orchestrator) coordinating Specialized Sub-Agents (Domain-specific processing team), utilizing various tools, memory, and models for general-purpose task solving.
- The framework features a two-tier architecture where the planning agent decomposes tasks and delegates sub-tasks to specialized agents equipped with domain-specific tools.
- AgentOrchestra supports flexible orchestration, inter-agent communication, and adaptive role allocation, enabling robust performance on complex, multimodal tasks.


---

[Tiered Agentic Oversight: A Hierarchical Multi-Agent System for AI Safety in Healthcare](http://arxiv.org/abs/2506.12482v1)

- TAO (Tiered Agentic Oversight): introduces a hierarchical multi-agent framework for AI safety in healthcare, featuring an Agent Recruiter (Recruits expert agents), Agent Router (Routes query to tier), Tier 1 (Initial assessment/screening), Tier 2 (Specialized review/analysis), Tier 3 (Expert consultation/synthesis) of Medical Agents (Core assessment units), Case Escalation (Escalates to higher tiers), Intra-Tier Collaboration (Discussion within tier), Inter-Tier Collaboration (Dialogue between tiers), Final Decision Agent (Synthesizes final decision), and Human Oversight (Targeted human intervention).
- The framework routes tasks based on complexity and agent roles, escalating complex or high-risk cases through tiers with automated inter- and intra-tier collaboration and role-playing.
- TAO enhances AI safety through layered, automated supervision, demonstrating superior performance on healthcare safety benchmarks compared to single-agent and multi-agent baselines.


---

[Topology-Assisted Spatio-Temporal Pattern Disentangling for Scalable MARL in Large-scale Autonomous Traffic Control](http://arxiv.org/abs/2506.12453v1)

- TGN-TMoE: introduces a novel MARL framework for large-scale traffic control, with Agent Observations (Raw graph data), MF Synchronization (Integrates mean-field information), Temporal Learning (Processes temporal features), Topological Processing (Extracts topological features), Spatial Learning (Processes spatial features), TMoE Module (Routes features to experts), Graph Pooling (Aggregates graph features), and Decision Making Module (Policy and value networks), designed to enhance environmental representation and agent coordination.
- The framework integrates Dynamic Graph Neural Networks and Topological Data Analysis, employing a TSD-enhanced Mixture of Experts architecture for scalable multi-agent reinforcement learning.
- TGN-TMoE leverages topological signatures to disentangle graph features for specialized processing within observation fusion and decision-making modules.


---

[Plan Your Travel and Travel with Your Plan: Wide-Horizon Planning and Evaluation via LLM](http://arxiv.org/abs/2506.12421v1)

- MAoP (Multiple Aspects of Planning): introduces a travel planning framework with a Strategist Model (Decomposes, routes aspects), Planning Model (Generates plan), Preprocessing Framework (Prepares input context including eliciting preferences, selecting POIs, and spatial optimization), Reward Model (Provides training signal), and Distilled Model (One-step inference).
- The framework leverages a strategist for pre-planning and a planning model for generating travel itineraries based on wide-horizon thinking over multiple aspects.
- A separate agent-based simulation framework, Travel-Sim, is proposed for evaluating the feasibility and personalization of the generated travel plans.


---

[SHEETMIND: AN END-TO-END LLM-POWERED MULTI-AGENT FRAMEWORK FOR SPREADSHEET AUTOMATION](http://arxiv.org/abs/2506.12339v1)

- SheetMind: introduces a modular multi-agent framework for spreadsheet automation, with Manager Agent (Decomposes user instructions), Action Agent (Generates BNF commands), Reflection Agent (Validates actions, monitors effects), Front-End (User interface, executes actions), Back-End (Houses agent pipeline), and Spreadsheet (Target environment), enabling natural language interaction.
- The framework decomposes complex instructions into subtasks, translates them into structured commands using BNF grammar, and validates actions through a feedback loop.
- SheetMind integrates LLM-driven planning, structured execution, and agentic feedback to bridge the gap between natural language and spreadsheet functionalities.


---

[INDOORWORLD : Integrating Physical Task Solving and Social Simulation in A Heterogeneous Multi-Agent Environment](http://arxiv.org/abs/2506.12331v1)

- INDOORWORLD: introduces a heterogeneous multi-agent environment integrating physical task solving and social simulation, with Agent (Autonomous entity), Perception (Processes observations), Memory (Stores information, history), Planning (Determines objectives, tasks), Action (Selects, executes actions), Task Prioritization (Encourages task focus), Environment (Simulated indoor space), Object (Physical entity), Location (Spatial area), and World State (Joint state variables) components, designed to simulate occupant behaviors in indoor spaces.
- The environment features heterogeneous agents with multi-level profiles (role, action space, capability, knowledge) and human needs, interacting with objects and locations to modify the world state.
- The framework supports both collaborative task-solving and autonomous social simulation sessions, providing a testbed for LLM-based multi-agent systems and potential applications in architectural design.


---

[Cloud Infrastructure Management in the Age of AI Agents](http://arxiv.org/abs/2506.12270v1)

- AI Agents: introduces an envisioned agentic system architecture for automating cloud infrastructure management using LLM-powered agents, including User-agent Interface, Agent-cloud Interface, Multi-agent Orchestration, Memory, Reasoning, Tools, Planning, Guardrails, Actions, Cloud Vendors, and Cloud Gym components.
- The proposed architecture utilizes different cloud interaction modalities (SDK, CLI, IaC, Web) and incorporates exploration/exploitation phases and guardrails for safety and reliability.
- A preliminary study evaluates agents across modalities on VM management tasks, highlighting trade-offs in efficiency, success rate, and error handling.


---


#### 13th June 2025

[ReVeal: Self-Evolving Code Agents via Iterative Generation-Verification](https://arxiv.org/abs/2506.11442)

- ReVeal: introduces a multi-turn reinforcement learning framework for code agents, featuring an Iterative Generation-Verification Loop where a Policy LLM generates code and test cases, External Tools execute them, and Tool Feedback provides results, guided by Turn-Level Reward Design and Outcome Reward, trained using Turn-Aware PPO on the Dataset (TACO).
- The framework enables LLMs to autonomously generate and verify code through iterative refinement and tool interaction, improving performance and self-verification capabilities.
- ReVeal's approach allows for effective test-time scaling into deeper inference regimes and pushes reasoning boundaries beyond the base model.


---

[The Behavior Gap: Evaluating Zero-shot LLM Agents in Complex Task-Oriented Dialogs](http://arxiv.org/abs/2506.12266v1)

- Behavior Gap Evaluation Framework: introduces a comprehensive framework to quantify the behavior gap between LLM Agents and Human Experts in task-oriented dialogs using Behavior Gap Metrics, Task Complexity Metrics, and Performance Metrics within a Teacher-Forcing Approach on various Datasets, revealing significant discrepancies that negatively impact LLM Agent performance.
- The study utilizes LLM-based Classifiers and an LLM-based Evaluator to analyze specific behavioral dimensions like dialog acts, Tool usage, and knowledge integration, demonstrating that the gap widens with increasing task complexity.
- Aligning LLM agent behavior closer to human strategies through Behavior Intervention significantly improves performance, particularly in complex tasks.


---

[A Fast, Reliable, and Secure Programming Language for LLM Agents with Code Actions](http://arxiv.org/abs/2506.12202v1)

- QUASAR: introduces a programming language for LLM agent code actions, with LLM Agent generating Python Subset code, Transpiler converting it to QUASAR Language, and QUASAR Interpreter executing it using Internal Rewrite Rules and External Rewrite Rule, managing External Calls tracked in the Execution Set, validated by User Approval Mechanism, and supporting Conformal Semantics with Abstract External Functions.
- The QUASAR Language separates pure internal computation from external side effects, enabling automatic parallelization, dynamic security controls, and uncertainty quantification.
- The approach leverages LLM proficiency in Python by transpiling a restricted subset to QUASAR for improved performance, security, and reliability compared to direct Python execution.


---

[PRO-V: An Efficient Program Generation Multi-Agent System for Automatic RTL Verification](http://arxiv.org/abs/2506.12200v1)

- PRO-V: introduces an efficient program generation multi-agent system for automatic RTL verification, with Stimulus Generator (Generates input signals), Functional Model (Generates reference outputs), Self-Improvement (Selects, refines models), Validator (Verifies DUT with judge), Judge Agent (LLM for selection, validation), and Refinement Agent (LLM for refinement) components.
- The system enhances verification accuracy and coverage through inference-time scaling via dual sampling and a self-improvement mechanism using a best-of-n selection strategy.
- PRO-V integrates an LLM-as-a-judge into the validation process, leveraging rule-based static analysis converted to natural language for enhanced prompting and root cause analysis.


---


[Robot Context Protocol (RCP): A Runtime-Agnostic Interface for Agent-Aware Robot Control](https://arxiv.org/abs/2506.11650)

- RCP (Robot Context Protocol): introduces, "a lightweight, middleware-agnostic communication protocol designed to abstract robotic system complexity", with Adapter Layer (Translates client interfaces), Transport Layer (Handles communication channels), Service Layer (Defines core operations), ROS2 Interface Layer (Maps to ROS2 runtime), and Status Query (Provides health and feedback), where "RCP provides a unified and semantically meaningful interface that decouples client-facing operations from backend implementations".
- The protocol is structured in modular layers, including the Adapter Layer for diverse clients, the Transport Layer for communication channels (HTTP, WebSocket, SSE), the Service Layer for high-level operations (read, execute, write, subscribe), and the ROS2 Interface Layer for mapping to the underlying runtime.
- RCP includes a Status Query component for real-time protocol health and command feedback, supporting robustness and operational transparency.


---

[Your Ride, Your Rules: Psychology and Cognition Enabled Automated Driving Systems](http://arxiv.org/abs/2506.11842v1)

- PACE-ADS (Psychology and Cognition Enabled Automated Driving Systems): introduces a human-centered autonomy framework with Driver Agent (Analyzes external traffic), Psychologist Agent (Interprets occupant psychological state), and Coordinator Agent (Synthesizes inputs, decides behavior) interfacing with Perception module (Provides sensor data), Route planning module (Computes global route), Motion planning module (Generates behavior, trajectory), and Control module (Executes planned trajectory) for adaptive driving.
- The framework leverages LLM-based agents to sense, interpret, and respond to both external traffic conditions and internal occupant states.
- Operating in a closed-loop architecture, the system dynamically adjusts driving style and supports vehicle operation recovery.


---


[Revealing Political Bias in LLMs through Structured Multi-Agent Debate](http://arxiv.org/abs/2506.11825v1)

- Structured Multi-Agent Debate Framework: introduces a system to investigate political bias in LLMs, with LLM Agents (Simulate participants) assigned Agent Personas (Political/gender identities) debating generated Debate Scenarios (Generated topics/questions) following a specific Debate Format (Structured rounds/statements), evaluated by an LLM-as-a-Judge (Evaluates attitudes) using Attitude Scoring (Quantifies agreement/disagreement) and a defined Speaking Order (Agent turn sequence).
- The framework systematically varies LLM models, agent gender attributes, and debate formats to examine influences on political bias and attitude shifts.
- Experiments reveal Republican agents shift towards neutral, gender influences attitudes, and echo chambers form with attitude intensification, particularly when gender is known.


---

[SEC-bench: Automated Benchmarking of LLM Agents on Real-World Software Security Tasks](http://arxiv.org/abs/2506.11791v1)

- SEC-bench: introduces an automated benchmarking framework for evaluating LLM agents on security engineering tasks, with Preprocessor (collects instances), Verifier (reproduces, verifies vulnerabilities), and Evaluator (transforms, formulates tasks) components.
- The Verifier component employs a multi-agent scaffold including Manager, Builder, Exploiter, and Fixer agents to reproduce and validate vulnerabilities.
- The framework automatically creates high-quality software vulnerability datasets with reproducible artifacts for evaluating LLM agent capabilities in tasks like proof-of-concept generation and vulnerability patching.


---

[AgentSense: Virtual Sensor Data Generation Using LLM Agents in Simulated Home Environments](http://arxiv.org/abs/2506.11773v1)

- AgentSense: introduces a virtual data generation pipeline using LLM agents in simulated home environments to create diverse sensor data for human activity recognition.
- The pipeline involves LLMs generating personas, routines, and actions, which are then executed in an extended VirtualHome simulator equipped with virtual ambient sensors.
- The generated virtual sensor data is used to pretrain HAR models, demonstrating improved performance, especially in low-resource settings, compared to training solely on real data.


---

[DeepResearch Bench: A Comprehensive Benchmark for Deep Research Agents](http://arxiv.org/abs/2506.11763v1)

- RACE and FACT evaluation frameworks: introduce two novel evaluation frameworks, with Judge LLM, Adaptive Criteria Generation, Reference-Based Scoring, Statement-URL Extraction, Support Judgment, Jina Reader API, and Citation Metrics Calculation components, designed to comprehensively assess Deep Research Agents.
- RACE evaluates report generation quality using adaptive criteria and reference-based scoring, while FACT assesses information retrieval and citation trustworthiness.
- These frameworks are part of the DeepResearch Bench, a benchmark of 100 PhD-level research tasks for evaluating LLM-based agents.


---

[A Hybrid Multi-Agent Prompting Approach for Simplifying Complex Sentences](http://arxiv.org/abs/2506.11681v1)

- Hybrid Multi-Agent Prompting Approach: introduces a system using multi-agent collaboration for sentence simplification, including Agent 1 Sentence Simplifier, Agent 2 Semantic and Lexical Similarity Evaluator, Agent 3 Alternative Sentence Simplifier, and Comparator components.
- The system processes complex sentences through a workflow where agents decompose, evaluate, and iteratively revise the output to preserve meaning while reducing complexity.
- This multi-agent architecture demonstrates improved performance over single-agent methods for simplifying complex sentences in domains like video game design.


---

[ReVeal: Self-Evolving Code Agents via Iterative Generation-Verification](http://arxiv.org/abs/2506.11442v1)

- ReVeal: introduces a multi-turn reinforcement learning framework that enables code agents to engage in an iterative generation-verification loop using a single Policy LLM, guided by Input Prompt and Tool Feedback, structured as a Multi-turn Rollout producing an Output Rollout, optimized with Outcome Reward and Turn-Level Rewards via Turn-Aware PPO.
- The framework alternates between Generation (producing code) and Verification (generating test cases and plans) stages, leveraging external Tools like Python Interpreters for execution.
- This iterative process and dense reward structure allow the model to self-verify, refine outputs, and improve both generation and verification capabilities over multiple turns.


---

[Agent-RLVR: Training Software Engineering Agents via Guidance and Environment Rewards](http://arxiv.org/abs/2506.11425v1)

- Agent-RLVR: introduces a framework for training software engineering agents using Reinforcement Learning from Verifiable Rewards (RLVR), incorporating agent guidance and environment rewards, with Policy, Environments, Trajectory, Evaluation, Environment Information, Agent Guidance, Guidance Generation, RLVR Data, Policy Update, and Instruct Tuning components.
- The framework trains an agent Policy by having it interact with Environments, evaluating Trajectories via Evaluation, generating Environment Information from failures, and using Guidance Generation to create Agent Guidance.
- Incorrect trajectories are reattempted with Agent Guidance, and the resulting RLVR Data is used for Policy Update via DPO and optional Instruct Tuning to improve agent performance.


---

[Large Language Model-Powered Conversational Agent Delivering Problem-Solving Therapy (PST) for Family Caregivers: Enhancing Empathy and Therapeutic Alliance Using In-Context Learning](http://arxiv.org/abs/2506.11376v1)

- LLM-powered Conversational Agent Models: introduces an LLM-powered agent delivering Problem-Solving Therapy (PST) for family caregivers, integrating Motivational Interviewing (MI) and Behavioral Chain Analysis (BCA) using prompting techniques, Retrieval-Augmented Generation (RAG), and clinician-curated content.
- The research evaluates four distinct configurations of this agent, comparing different LLMs (GPT-40, Llama 3) and combinations of in-context learning techniques (Few-shot, RAG) for their impact on perceived empathy and therapeutic alliance.
- The models aim to provide empathetic and tailored mental health support by improving contextual understanding and generating personalized, actionable strategies for caregivers.


---


[Secure API-Driven Research Automation to Accelerate Scientific Discovery](https://arxiv.org/abs/2506.11950)

- S3M (Secure Scientific Service Mesh): introduces, "Secure Scientific Service Mesh (Overall framework), Manages data streaming, Automates complex workflows, Manages compute jobs, Provides resource status, Retrieves environment info, Manages access tokens, Enables secure communication, Underlying service mesh platform, Python interface, Validates client interactions, Creates streaming objects, Deploys streaming clusters", a framework providing API-driven infrastructure for automated scientific discovery with integrated streaming, workflow orchestration, and fine-grained authorization.
- The framework utilizes a service mesh architecture built on OpenShift and Istio to ensure modularity, scalability, and policy-driven security enforcement across computational services.
- S3M offers a comprehensive set of APIs and an SDK to enable authenticated external systems and intelligent agents to securely provision resources, stream data, and trigger compute jobs dynamically.


---

[Your Ride, Your Rules: Psychology and Cognition Enabled Automated Driving Systems](https://arxiv.org/abs/2506.11842)

- PACE-ADS (Psychology and Cognition Enabled Automated Driving Systems): introduces a human-centered autonomy framework with Psychologist Agent (Interprets occupant state/intent), Driver Agent (Perceives external traffic context), Coordinator Agent (Synthesizes inputs, decides behavior), Perception module (Provides sensor data), Route planning module (Plans/replans vehicle route), Motion planning module (Generates behaviors/trajectories), and Control Module (Executes low-level commands), enabling AVs to sense, interpret, and respond to external traffic and internal occupant states.
- The framework uses three specialized foundation model agents in an agentic workflow to manage complex driving tasks and enable adaptive, interpretable, and collaborative driving.
- PACE-ADS complements existing AV modules by operating at the high-level behavioral decision layer, personalizing riding experience, and supporting recovery from immobilization.


---

[Self-Regulating Cars: Automating Traffic Control in Free Flow Road Networks](https://arxiv.org/abs/2506.11973)

- SRC (Self-Regulating Cars): introduces a physics-informed reinforcement learning protocol for automating traffic control in free-flow networks by having a central RL agent modulate vehicle speeds on super-segments based on traffic state observations, guided by a reward function.
- The system utilizes Deep Q-Learning with a neural network to learn speed modulation policies, evaluated in a PTV Vissim simulation environment.
- The approach aims to optimize network throughput and prevent congestion by coordinating individual self-regulating cars without requiring new physical infrastructure.


---

[PE-MA: Parameter-Efficient Co-Evolution of Multi-Agent Systems](https://arxiv.org/abs/2506.11803)

- PE-MA (Parameter-Efficient Multi-Agent Co-Evolution): introduces, "a novel collaboration framework", with Frozen Backbone (Fixed feature extractor), Personalized Adapter (Adapts to local tasks/data), Shared Adapter (Shares knowledge across agents), Communication Mechanism (Exchanges and aggregates adapters), designed for efficient, scalable, and personalized co-evolution in multi-agent systems.
- Each agent maintains a lightweight personalized adapter for agent-specific behavior and a shared adapter collaboratively optimized across neighboring agents.
- The dual-adapter architecture balances global coordination with local adaptation, significantly reducing training and communication costs.


---

[Interaction, Process, Infrastructure: A Unified Architecture for Human-Agent Collaboration](https://arxiv.org/abs/2506.11718)

- Unified Architecture for Human-Agent Collaboration: introduces a layered framework for human-agent collaboration with Interaction Layer (surface of shared understanding), Process Layer (collaborative core), and Infrastructure Layer (orchestration, execution, memory).
- The Process Layer explicitly models goals, workflows, and progress, serving as connective tissue for human-agent alignment and coordination over time.
- This modular architecture supports transparency, extensibility, and adaptive, goal-aligned collaboration by decoupling interaction, process logic, and computational foundation.


---


#### 12th June 2025


[AUTOMIND: Adaptive Knowledgeable Agent for Automated Data Science](http://arxiv.org/abs/2506.10974v1)

- AUTOMIND (Adaptive Knowledgeable Agent for Automated Data Science): introduces an adaptive, knowledgeable LLM-agent framework with a curated expert knowledge base, an agentic knowledgeable tree search algorithm, and a self-adaptive coding strategy.
- The framework leverages the expert knowledge base via a retriever to ground the tree search, which explores solutions through drafting, improving, and debugging actions.
- The self-adaptive coding strategy dynamically adjusts code generation based on task complexity, using either one-pass generation or stepwise decomposition with execution feedback.


---

[Specification and Evaluation of Multi-Agent LLM Systems - Prototype and Cybersecurity Applications](http://arxiv.org/abs/2506.10467v1)

- Multi-Agent LLM System: introduces a system architecture and specification for multi-agent LLM applications, including a Client Application, Conversational User Interface, Agent Manager, Conversation Manager, Execution Engine, Agents, LLM Services, Host Execution Environment, and Agent Schema.
- The system allows specifying agents with executable prompts, actions, and data, supporting prompting/reasoning techniques and conditional execution based on results.
- The Agent Schema defines agent types, functions (execution, evaluation), and configurations for agents and LLMs, enabling systematic evaluation of LLMs and techniques in specific applications like cybersecurity.


---


[From Replication to Redesign: Exploring Pairwise Comparisons for LLM-Based Peer Review](http://arxiv.org/abs/2506.11343v1)

- GPT ranking system: introduces a novel peer review mechanism using LLM agents for pairwise comparisons, aggregated by the Bradley-Terry model to derive a global ranking of submissions.
- The system contrasts pairs of manuscripts to determine relative quality, moving away from traditional independent absolute scoring.
- Empirical experiments demonstrate the system's potential to identify high-impact papers more effectively than rating-based methods, while also revealing biases against topic novelty and institutional diversity.


---

[LLM-as-a-Judge for Reference-less Automatic Code Validation and Refinement for Natural Language to Bash in IT Automation](http://arxiv.org/abs/2506.11237v1)

- Reflection Agent with Dedicated Evaluator: introduces a system for automatic code validation and refinement, including a Code Generator, Reflect module, and Evaluator using specific metrics.
- The Evaluator utilizes Bidirectional Functionality Matching and Logic Representation metrics to assess generated Bash code quality without requiring reference code.
- The system incorporates judgments and feedback from the evaluation metrics to refine the initial code snippet generated by the Code Generator.


---


[Using Invocable APIs derived from NL2SQL datasets for LLM Tool-Calling Evaluation](http://arxiv.org/abs/2506.11266v1)

- LLM Tool-Calling Evaluation Framework: introduces a method to convert NL2SQL datasets into NL2API datasets for LLM tool-calling evaluation using a Data Generation Pipeline.
- The framework includes generated API Collections (SLOT, SEL, REST) with varying characteristics, Invocable APIs for live interaction, and an Evaluation Set pairing natural language queries with ground-truth API sequences.
- It evaluates the performance of various LLMs and ReACT Agents on these generated datasets to assess their tool-calling capabilities.


---



[Reasoning RAG via System 1 or System 2: A Survey on Reasoning Agentic Retrieval-Augmented Generation for Industry Challenges](http://arxiv.org/abs/2506.10408v1)

- Reasoning Agentic RAG: introduces a paradigm integrating retrieval with model-driven reasoning and decision-making, encompassing Question, LLM/LRM, Reasoning, Retrieval, Retrieved Information, Distilled Information, and Answer components.
- The framework categorizes approaches into predefined reasoning with fixed pipelines and agentic reasoning with autonomous tool orchestration.
- This survey reviews techniques, architectural designs, reasoning strategies, and tool coordination within this paradigm to address industry challenges.


---

[Provably Learning from Language Feedback](http://arxiv.org/abs/2506.10341v1)

- HELIX: introduces a framework for Learning from Language Feedback (LLF), including an LLM Policy, Reference Policy, Reward Mapping, set of Hypotheses, set of Actions, and Score Matrix.
- The LLM Policy generates hypotheses and actions, the Reference Policy adds random actions, and the Reward Mapping scores actions under hypotheses to form a Score Matrix.
- The algorithm uses the Score Matrix for decision-making, employing exploitation when consensus exists and exploration otherwise, potentially re-scoring with the Reference Policy.


---


[SWE-Factory: Your Automated Factory for Issue Resolution Training Data and Evaluation Benchmarks](http://arxiv.org/abs/2506.10954v1)

- SWE-Factory: introduces an automated pipeline for GitHub issue resolution benchmark construction, including Raw Issue Collection (Collects GitHub issue data), SWE-Builder (Automates environment setup), Grading Results (Grades test outcomes), and Fail2pass Validation (Validates fail-to-pass transition).
- The SWE-Builder component is a multi-agent framework comprising a Repository Explorer (Collects repository setup information), Environment Manager (Generates Dockerfile), Test Manager (Generates test script), and Test Analyst (Validates environment, plans iterations), supported by an Evaluation Environment Memory Pool (Stores and reuses setups).
- The pipeline automates environment construction, grading via exit codes, and fail2pass validation to reduce manual effort in creating large-scale, high-quality datasets.


---

[Build the web for agents, not agents for the web](http://arxiv.org/abs/2506.10953v1)

- AWI (Agentic Web Interface): introduces a new web interface paradigm specifically designed for agents, featuring unified higher-level actions, compatibility with user interfaces, access control for agents, progressive information transfer, and agentic task queues.
- This paradigm shift aims to overcome limitations of current human-designed web interfaces for web agents.
- The paper establishes guiding principles for AWI design, emphasizing safety, efficiency, and standardization, and advocates for broad ML community involvement.


---

[Monitoring Decomposition Attacks in LLMs with Lightweight Sequential Monitors](http://arxiv.org/abs/2506.10949v1)

- Lightweight Sequential Monitoring Framework: introduces a defense against decomposition attacks by using an external monitor to evaluate the cumulative context of subtasks.
- The monitor outputs a binary flag at each step to halt the LLM if harmful intent is detected based on the prompt history.
- This framework outperforms single-input monitoring and is cost/latency efficient for mitigating decomposition attacks.


---

[Execution Guided Line-by-Line Code Generation](http://arxiv.org/abs/2506.10948v1)

- EG-CFG (Execution-Guided Classifier-Free Guidance): introduces a novel approach for neural code generation that incorporates real-time execution signals into the language model generation process, utilizing a Large Language Model, Programming Task input, Initial Prompt, Candidate Generation via beam search, Executable Extraction via AST parsing, Execution Engine for running test cases, Execution Trace generation, Dynamic Signal aggregation, Dynamic Prompt construction, Classifier-Free Guidance for token generation, an Inference Loop for autoregressive generation, and Parameter Search.
- The method dynamically incorporates execution signals as the model generates code line-by-line, guiding the generation process toward executable solutions.
- EG-CFG achieves state-of-the-art performance on multiple code generation benchmarks by leveraging execution feedback and Classifier-Free Guidance.


---

[Dynamic Epistemic Friction in Dialogue](http://arxiv.org/abs/2506.10934v1)

- Dynamic Epistemic Friction (DEF): introduces a formal model of dynamic epistemic friction in dialogue, operationalized within Dynamic Epistemic Logic and vector-based belief representations, using epistemic states, propositions, evidence, alignment, friction, QBank, EBank, FBank, an update function, friction coefficients, and friction equilibrium.
- The model quantifies resistance encountered during belief updates by measuring vector similarity between agent beliefs and new information combined with evidence.
- Empirical analysis on a situated collaborative task dataset demonstrates that the model effectively predicts participant belief updates by modeling this resistance.


---


[OPT-BENCH: Evaluating LLM Agent on Large-Scale Search Spaces Optimization Problems](http://arxiv.org/abs/2506.10764v1)

- OPT-Agent: introduces a framework that emulates human reasoning for optimizing solutions by iteratively generating, validating, and improving solutions using historical feedback, with all Drafting, Improving, Debugging, Historical Information, Error Analysis, Validation, and Metrics components.
- The framework's workflow involves generating a Draft solution, iteratively Improving valid solutions or Debugging buggy ones based on Error Analysis and Historical Information, with Validation and Metrics guiding the process.
- OPT-Agent is evaluated on OPT-BENCH, a benchmark of machine learning and NP problems, to assess LLMs' iterative optimization capabilities.


---

[Integrating Large Language Models into Text Animation: An Intelligent Editing System with Inline and Chat Interaction](http://arxiv.org/abs/2506.10762v1)

- Text Animation Editing System: introduces an LLM-aided system for text animation editing, featuring a Script Panel (Edit text, properties), Timeline Panel (Arrange, time clips), Chat Panel (Natural language commands), Resource Panel (Manage assets), Inspector Panel (Adjust properties), Preview Panel (Visualize edits), Inline Agent (Contextual suggestions), Chat Agent (Conversational task execution), LLM (Large Language Model) (AI engine), Semantic-Animation Mapping (Intent to action), and Script-Timeline Synchronization (Panels linked).
- This system employs a dual-mode agent pipeline (Inline and Chat Agents) powered by an LLM for intelligent assistance and natural language interaction.
- The system aims to lower creative barriers for non-professionals and enhance editing efficiency through seamless inline edits and chat-based interactions.


---

[Grounded Vision-Language Navigation for UAVs with Open-Vocabulary Goal Understanding](http://arxiv.org/abs/2506.10756v1)

- VLFly (Vision-Language Fly): introduces a novel VLN framework for UAVs, including an instruction encoding module, a goal retrieval module, a waypoint planning module, and action execution, designed for open-vocabulary goal understanding and continuous control.
- The framework processes natural language instructions, retrieves a goal image, generates waypoints from egocentric observations, and executes continuous velocity commands.
- VLFly achieves robust generalization and outperforms baselines in simulation and real-world UAV navigation tasks without task-specific fine-tuning.


---

[SDialog: A Python Toolkit for Synthetic Dialogue Generation and Analysis](http://arxiv.org/abs/2506.10622v1)

- SDialog: introduces a Python toolkit for synthetic dialogue generation and analysis, with Turn (Single utterance), Event (Action/instruction), Dialog (Complete conversation structure), Persona (Character profile definition), PersonaAgent (Simulates agent role-playing Persona), BaseOrchestrator (Abstract control class), SimpleReflexOrchestrator (Triggers on condition), LengthOrchestrator (Controls dialogue length), ChangeMindOrchestrator (Simulates agent changing mind), SimpleResponseOrchestrator (Suggests responses by similarity), InstructionListOrchestrator (Provides sequence of instructions), DialogGenerator (Generates dialogue using LLM), PersonaDialogGenerator (Generates dialogue between Personas), Dataset Utilities (Work with external datasets), Serialization Utilities (Save/load dialogues), and Visualization Utilities (Analyze/visualize dialogues) components, designed for creating realistic, diverse, and controllable conversational data.
- The toolkit provides abstractions for personas, orchestration, and scenario management, leveraging instruction-tuned Large Language Models for generation.
- SDialog supports workflows like multi-agent simulation and scenario-driven generation, aiming to standardize synthetic data generation for reproducibility.


---

[Beyond Single-User Dialogue: Assessing Multi-User Dialogue State Tracking Capabilities of Large Language Models](http://arxiv.org/abs/2506.10504v1)

- Multi-User Dialogue Data Construction Method: introduces a method to extend single-user dialogue datasets by incorporating a second user's utterances, utilizing a Single-User Dialogue Structure, Speech Act Type Identification, User2 Utterance Generation, User2 Utterance Validation, and an LLM to create a Multi-User Dialogue Structure for evaluating DST.
- The method systematically generates and validates user2 utterances based on speech act theory to create a controlled multi-user setting for assessing LLM performance.
- This approach enables evaluating LLMs on multi-user dialogue state tracking challenges with minimal dataset construction costs.


---

[BugGen: A Self-Correcting Multi-Agent LLM Pipeline for Realistic RTL Bug Synthesis](http://arxiv.org/abs/2506.10501v1)

- BugGen: introduces a self-correcting multi-agent LLM pipeline, with Module Splitter (partitions RTL), Mutation Index (lists mutation types), Mutation Cache (stores history), Region Selector Agent (chooses region), Mutation Selector Agent (chooses mutation), Mutation Injector Agent (inserts mutation), Evaluation (validates bug), and Rollback/Retry (corrects failures), designed to autonomously generate, insert, and validate realistic functional bugs in RTL.
- The pipeline leverages LLM agents in a closed-loop architecture with shared memory and iterative refinement to produce unique, syntactically valid, and functionally detectable bugs.
- BugGen achieves high functional accuracy and throughput, outperforming existing methods and generating high-quality bug datasets suitable for training ML-based debugging models.


---


[Minimizing False Positives in Static Bug Detection via LLM-Enhanced Path Feasibility Analysis](http://arxiv.org/abs/2506.10322v1)

- LLM4PFA (LLM-Enhanced Path Feasibility Analysis): introduces an iterative path feasibility analysis framework for static bug detection, with Iterative Function Analysis, Feasible Path Constraint Extraction, Critical Path Conditional Branches Identification, Feasible Path Conditional Expression Extraction, Context-Aware Symbolic Range Reasoning, LLM Agent, Variable Symbolic Range Reasoning, Function Call Symbolic Range Reasoning, Function Retrieval Tool, Source Code Repository, Function Call Memory, Constraints Solving, SMT Query Script Generation, Script Template Generation, SMT Constraints Generation, Script Merging, Constraint Solver, Control-Flow Graph (CFG), and Initial States P.
- The framework iteratively analyzes functions in a call trace, extracting and solving feasible path constraints using LLM agents for symbolic reasoning and a constraint solver.
- LLM4PFA leverages LLM agents' self-planning and tool-usage capabilities for context-aware symbolic range reasoning and iteratively generates and solves SMT queries to minimize false positives.


---

[WGSR-Bench: Wargame-based Game-theoretic Strategic Reasoning Benchmark for Large Language Models](http://arxiv.org/abs/2506.10264v1)

- WGSR-Bench: introduces, "a wargame-based benchmark for large language models", with Environmental situational awareness, Opponent risk assessment, and Policy generation components, where "it systematically assesses strategic reasoning abilities using wargame scenarios".
- The benchmark evaluates LLMs' capabilities in multi-agent decision-making, intent inference, and counterfactual reasoning within a high-complexity wargame environment.
- It employs a structured cognitive framework (S-POE) and utilizes real adversarial wargame data for comprehensive evaluation and analysis.


---


#### 11th June 2025

[AUTONOMOUS COMPUTER VISION DEVELOPMENT WITH AGENTIC AI](https://arxiv.org/abs/2506.11140)

- Agentic AI approach: introduces an autonomous computer vision development system, with OpenManus Agent (Orchestrates task execution), Memory (Stores runtime state/context), Planning (Decomposes tasks, selects tools), Reasoning (Analyzes inputs, makes decisions), Self-Correction/Adaptation (Handles errors, refines plans), Tools (Execute Python, browser, files, shell), SimpleMind Framework (Executes computer vision tasks), Configurable Tools (Perform image processing, neural nets), Knowledge Graph (Defines SimpleMind workflow), Blackboard (Central working memory), SM-Learn (Trains neural network weights), SM-Think (Performs inference), User Prompt (Natural language task input), System Prompt (Guides LLM planning), Verifier (Checks YAML configuration), Tool Configuration File (KG) (YAML workflow definition), Tool Execution (Runs SimpleMind modules), where the system translates natural language prompts into SimpleMind workflows for medical image analysis.
- The OpenManus agent leverages an LLM for planning and tool use, generating a YAML Knowledge Graph that configures SimpleMind's computer vision tools.
- SimpleMind executes the planned workflow, utilizing its Blackboard for data flow and SM-Learn/SM-Think for training and inference on medical images.


---


[AURA: A Multi-Agent Intelligence Framework for Knowledge-Enhanced Cyber Threat Attribution](http://arxiv.org/abs/2506.10175v1)

- AURA (Attribution Using Retrieval-Augmented Agents): introduces a multi-agent framework for cyber threat attribution, comprising input processing, query rewriting, semantic retrieval, decision making, external search, attribution generation, conversational memory, and a knowledge base.
- The framework processes diverse threat data via collaborative agents, integrating Retrieval-Augmented Generation (RAG) with Large Language Models (LLMs) for knowledge-enhanced reasoning and interpretable attribution.
- AURA generates transparent, evidence-backed attribution decisions by tracing reasoning to contextual evidence and providing natural language justifications.


---



[Disclosure Audits for LLM Agents](http://arxiv.org/abs/2506.10171v1)

- CMPL (Conversational Manipulation for Privacy Leakage): introduces an automated auditing framework for conversational privacy risks in LLM agents, featuring an Application Agent A (LLM agent being audited), an Adversary U (LLM agent attempting leakage), and an Auditor D (LLM agent detecting leakage) interacting within a Conversation Loop (iterative interaction process) based on a Scenario Description σ (public context), Information Subject Profile I (private data), Privacy Directive ψ (disclosure rules), and Task Description T (agent A's goal).
- The Adversary U employs a Strategist Se (adversary planning module) and Prompt Generator Ge (adversary query module) to manipulate the Conversation History H (dialogue turns) and may use a Side-channel Predictor Pe (adversary inference module) to make a Prediction (adversary guess) with Confidence kt (adversary prediction score).
- The Auditor D monitors the Conversation History H and uses an Entail Function (auditor explicit leakage detector) and the adversary's Prediction and Confidence to produce an Indicator zt (auditor leakage signal) when explicit or implicit leakage is detected, while both agents utilize Memory (stores/summarizes history) to maintain state.


---

[Chat-of-Thought: Collaborative Multi-Agent System for Generating Domain Specific Information](http://arxiv.org/abs/2506.10086v1)

- Chat-of-Thought: introduces a collaborative multi-agent system for domain-specific information generation, featuring LLM-based Agents, Context Discovery, Multi-Round Chain of Interactions, Template-driven Routing, and Quality Check.
- The system employs specialized LLM-based Agents with defined roles and state to engage in iterative discussions guided by templates and dynamic assignment.
- It leverages diverse input sources, question/answer banks, and various learning methods to generate and refine domain-specific knowledge like FMEA documents.


---

[A quantum semantic framework for natural language processing](http://arxiv.org/abs/2506.10077v1)

- Quantum Semantic Framework: introduces a non-classical approach to natural language processing, modeling semantic meaning as observer-dependent and contextually actualized through the interaction of a Semantic Expression (symbol affording interpretations) and an Interpretive Agent (observer) via an Interpretive Observable (semantic probe operator).
- The framework posits that meaning is not intrinsic but emerges dynamically, influenced by the agent's Semantic Memory (agent internal state) and Context (situational factors), with interpretation dynamics governed by a Semantic Hamiltonian (interpretation dynamics).
- A Semantic Bell Test (experimental method) using LLM Agents (computational observers) configured with Personas (agent configurations) and presented with Ambiguous Word Pairs (stimuli) demonstrates non-classical contextuality in interpretation, supporting the framework's premise.


---


[AI Agent Behavioral Science](https://arxiv.org/abs/2506.06366)

- AI Agent Behavioral Science: introduces, "AI Agents (autonomous systems)/Memory (stores history)/Planning (strategizing actions)/Tool Use (interacts with tools)/Action Modules (executes decisions)/Intrinsic Attributes (internal traits)/Environmental Constraints (external structures)/Behavioral Feedback (adaptation mechanism)/Ability (foundational competence)/Motivation (drive from feedback)/Trigger (initiating signals)", a paradigm for studying AI agents as behavioral entities in context, emphasizing systematic observation, intervention design, and theory-guided interpretation.
- This perspective focuses on understanding how AI agent behavior emerges and adapts through the interplay of internal factors, environmental context, and interaction feedback.
- The paper systematizes research on individual, multi-agent, and human-agent interactions and positions this behavioral science approach as essential for responsible AI.


---


[V-JEPA 2: Self-Supervised Video Models Enable Understanding, Prediction and Planning](https://arxiv.org/abs/2506.09985)

- V-JEPA 2 (Self-Supervised Video Model): introduces a self-supervised approach combining internet video data and robot interaction data, with V-JEPA 2 Encoder (Extracts video representations), V-JEPA 2 Predictor (Predicts masked representations), V-JEPA 2 EMA Encoder (Target for prediction), V-JEPA 2-AC Frozen Encoder (Provides learned representations), V-JEPA 2-AC Action-Conditioned Predictor (Predicts future state representations), MLLM Projector Module (Maps visual to LLM), and MLLM LLM Backbone (Language model).
- The framework pre-trains V-JEPA 2 on internet video, then post-trains V-JEPA 2-AC on robot data for planning, and aligns V-JEPA 2 with an LLM for video question answering.
- V-JEPA 2 demonstrates strong performance on motion understanding, action anticipation, video question answering, and enables zero-shot robot manipulation via planning.

---

[Patterns of Patterns III](https://arxiv.org/abs/2506.09696)

- PLACARD: introduces a methodology combining PAR, CLA, and DPL for collective learning and design, extended to pattern-competent AI agents within Multi-Agent Systems, utilizing Language Model Substrates and various agent types.
- The approach structures pattern use via an A/B/C catalogue and proposes AI agent pattern types (Interactional, Cognitive, Infrastructural) along with specific candidate patterns for agents and their environments.
- Different agent roles, including Code-Writing & Execution Agents, Pattern-Aware Dialogue Agents, Pattern-Reflective Meta-Agents, and Multi-Agent Institution Designers, interact within the MAS environment, grounded by a Real-World Interface layer.


---

[Flipping Against All Odds: Reducing LLM Coin Flip Bias via Verbalized Rejection Sampling](http://arxiv.org/abs/2506.09998v1)

- VRS (Verbalized Rejection Sampling): introduces, "a natural-language adaptation of classical rejection sampling", with LLM (Performs accept/reject decision), Target Distribution (Desired sample distribution), Proposal Distribution (Source of candidate samples), Candidate Sample (Sample from proposal), Verbalized Prompt (LLM input with descriptions), Accept/Reject Decision (LLM binary output), and Sampling Loop (Generates candidates, repeats), which prompts an LLM to reason about and accept or reject proposed samples from a proposal distribution to generate samples from a target distribution.
- The framework verbalizes the target distribution, proposal distribution, and a candidate sample into a prompt for the LLM, which acts as a black-box decision engine.
- The external sampling loop generates candidate samples and repeats the LLM decision process until the required number of accepted samples is collected.


---

[SRLAgent: Enhancing Self-Regulated Learning Skills through Gamification and LLM Assistance](http://arxiv.org/abs/2506.09968v1)

- SRLAgent: introduces an LLM-assisted system that fosters self-regulated learning skills through gamification and adaptive support, with Game Environment (Minecraft 3D world), Learning Management System (Manages learning elements), Task System (Manages hierarchical tasks), Agent System (AI-powered support), LLM (Large Language Model), Planning Agent (Supports forethought phase), SubTask Monitor (Tracks performance), SubTask Tutor Agent System (Provides tutoring), Quiz Agent (Supports quizzes), Review Agent (Guides analysis), Chatting Agent (Facilitates discussions), Writing Agent (Supports writing), Reflection Agent (Guides reflection phase), Task State (Current task status), SRL Phase (Current SRL stage), Task Learning Views (User interface views), Learning Subtasks Content (Educational materials/activities), Learning Feedback (Agent-provided feedback), Tutor Feedback (Tutor agent feedback), Prompt Configurations (Agent prompt templates), where it guides students through SRL phases using gamification and LLM-powered agents in a game-based environment.
- The system is grounded in Zimmerman's three-phase SRL framework, enabling goal-setting, strategy execution, and self-reflection within an interactive game environment.
- SRLAgent offers real-time feedback and scaffolding powered by LLMs to support students' independent study efforts.


---

[PersonaLens: A Benchmark for Personalization Evaluation in Conversational AI Assistants](http://arxiv.org/abs/2506.09902v1)

- PersonaLens: introduces a benchmark for evaluating personalization in task-oriented conversational AI assistants, with diverse user profiles, tasks with situational contexts, and two LLM-based agents (User Agent and Judge Agent) to simulate interactions and evaluate performance.
- The benchmark features 1,500 user profiles, 111 tasks across 20 domains, and LLM-powered agents for scalable, automated evaluation.
- PersonaLens assesses personalization, task completion, and dialogue quality in multi-turn interactions, revealing insights into current LLM assistants' capabilities.


---

[INTELLIGENT DESIGN 4.0: PARADIGM EVOLUTION TOWARD THE AGENTIC AI ERA](http://arxiv.org/abs/2506.09755v1)

- ID 4.0 (Intelligent Design 4.0): introduces a multi-agent-based paradigm for engineering design automation, composed of stage-level agents (interprets inputs/decomposes tasks, explores early solutions/ideation, translates concepts/coordinates modeling, refines geometry/produces models, applies optimization/fine-tunes) and functional agents (retrieves external knowledge, accesses databases, infers user intent/context, facilitates divergent thinking, synthesizes 2D/3D geometry, conducts multi-physics simulations, verifies compliance) operating within a shared information environment (supports coordination/learning).
- This framework envisions autonomous, task-specialized AI agents coordinating via orchestrated design workflows to support complex, end-to-end design processes.
- Agents interact with human designers and external tools, leveraging shared memory for cross-agent coordination and cumulative learning throughout the design process.


---

[Feature Engineering for Agents: An Adaptive Cognitive Architecture for Interpretable ML Monitoring](http://arxiv.org/abs/2506.09742v1)

- CAMA (Cognitive Architecture for Monitoring Agent): introduces a cognitive architecture for ML monitoring, with Semantic Memory (Stores reference data), Working Memory (Holds current context), Episodic Memory (Retains past instances), Procedural Memory (Stores agent code), Decision Procedure (Feature engineering approach), LLM (Reasoning engine), and Agent code (Includes prompts/chains), designed to enhance interpretability and actionability of monitoring outputs.
- The Decision Procedure implements a three-step feature engineering-inspired approach: Refactor, Break Down, and Compile, to process monitoring data.
- This architecture leverages structured memory and feature engineering principles to provide robust, interpretable, and actionable insights for ML model monitoring.


---


[Intent Factored Generation: Unleashing the Diversity in Your Language Model](http://arxiv.org/abs/2506.09659v1)

- IFG (Intent Factored Generation): introduces a two-stage sampling process including Prompt, LLM Internal, Intent, Phrasing, and Response.
- The process samples a semantically dense Intent first, then the final Response conditioned on the Prompt and Intent, allowing independent temperature control for diversity and coherence.
- IFG can be implemented via Few-shot Prompting or Finetuning on intent-annotated data, with IFG-prompting encouraging granular steps in reasoning tasks.


---

[Application-Driven Value Alignment in Agentic AI Systems: Survey and Perspectives](http://arxiv.org/abs/2506.09656v1)

- LLM-based Agent System: introduces, this survey, with LLM-based Agent (core system participant), Multi-Agent System (multiple interacting agents), Value Principles (hierarchical ethical norms), Value Alignment Evaluation (assessing adherence to values), and Value Coordination (managing values in multi-agents), where this survey reviews application-driven value alignment in agentic AI systems.
- The paper integrates AI advancements driven by large models with demands of social governance, covering value principles, application scenarios, and evaluation methods.
- It systematically examines datasets and methods for value alignment assessment and explores value coordination among multiple agents within agent systems.


---

[DipLLM: Fine-Tuning LLM for Strategic Decision-making in Diplomacy](http://arxiv.org/abs/2506.09655v1)

- DipLLM (Fine-Tuned LLM-Based Agent): introduces DipLLM, a fine-tuned LLM-based agent for strategic decision-making in Diplomacy, with Llama 3 8B (LLM backbone), Autoregressive Factorization (decomposes actions), TextDiplomacy (state to text, text to actions), Equilibrium Search (piKL-Hedge) (generates Q-values), Human IL Model (DipNet) (collects raw data), Environment (Diplomacy) (game simulation), Loss Function (aligns policy), LoRA (parameter adaptation), and Data (collected game data).
- DipLLM leverages autoregressive factorization to simplify complex multi-unit action assignment into sequential unit-level decisions.
- The agent is fine-tuned on a small dataset using a designed loss function to align its policy with an equilibrium objective, outperforming state-of-the-art models like Cicero with significantly less data.


---

[Effective Red-Teaming of Policy-Adherent Agents](http://arxiv.org/abs/2506.09600v1)

- CRAFT (Constraint-aware Red-teaming with Adversarial Framing and Tactics): introduces a multi-agent red-teaming system with Policy Analyzer (Extracts relevant policy), Deception Planner (Plans attack strategies), Avoidance Advisor (Plans what to avoid), Dialogue Executor (Executes interaction dialogue), Conversation Memory (Dialogue history), Policy-Adherent Agent (Target system), Policy (Rules for target), and User Request (Initial user input), designed to expose vulnerabilities in policy-constrained LLM-based agents through strategic, multi-step adversarial planning.
- The system leverages policy knowledge, strategic reasoning, and pre-execution planning to generate policy-aware persuasive strategies that undermine policy adherence in customer service scenarios.
- CRAFT achieves significantly higher attack success rates compared to generic jailbreak methods and cooperative user simulations, highlighting the need for stronger safeguards against malicious user behavior.


---

[ReasonMed: A 370K Multi-Agent Generated Dataset for Advancing Medical Reasoning](http://arxiv.org/abs/2506.09513v1)

- Multi-Agent Framework: introduces ReasonMed, a large-scale medical reasoning dataset generated and refined using a multi-agent system for initial path generation, followed by verification, ranking, summarization, error correction, and quality assessment.
- The framework generates 370k high-quality medical reasoning examples by distilling 1.7 million initial paths from multiple large language models through a rigorous multi-stage verification and refinement pipeline.
- Leveraging the generated dataset, the authors train ReasonMed-7B and find that combining detailed chain-of-thought reasoning with concise answer summaries yields the most effective fine-tuning strategy for medical question answering.


---

[A Call for Collaborative Intelligence: Why Human-Agent Systems Should Precede AI Autonomy](http://arxiv.org/abs/2506.09420v1)

- LLM-HAS (LLM-based Human-Agent Systems): introduces implementation guidelines with Initial Setup (define environment, roles, interaction), Human Data (acquire, process, use human data), Model Engineering (iterative development, feedback, learning, optimization), Post-Deployment (monitor, maintain alignment, adapt), and Evaluation (assess effectiveness, safety, experience) components.
- The framework advocates for collaborative AI-human partnerships, prioritizing human involvement for guidance, control, and enhanced system trustworthiness and adaptability.
- Progress in AI is measured by how well systems work with humans, enhancing human capabilities through partnership rather than pursuing full autonomy.


---

[Multi-Agent Language Models: Advancing Cooperation, Coordination, and Adaptation](http://arxiv.org/abs/2506.09331v1)

- Multi-Agent Language Models: introduces integrating Language Model (LM) (Recommends/generates actions) into Reinforcement Learning (RL) Agent (Learns decision policy) loops interacting with an Environment (Simulates game world), utilizing Dataset (Human gameplay examples) and Replay Buffers (Stores game transitions) for training via Distillation Loss (Transfers LM knowledge) and TD Loss (Reinforcement learning update), employing Encoders (GRU) (Encode text inputs), Decoder (Combines encoded features), and MLP (Predicts action values).
- The approach explores LM-in-the-Loop for action recommendation in text games and LM as Multi-Agent in Hanabi, showing improved performance and accelerated convergence compared to baselines.
- Key findings highlight the importance of careful transition selection for LM training and demonstrate the potential for distilling language model knowledge into reinforcement learning agents.


---





#### 10th June 2025


[Agentic Neural Networks: Self-Evolving Multi-Agent Systems via Textual Backpropagation](http://arxiv.org/abs/2506.09046v1)

- ANN (Agentic Neural Network): introduces a framework conceptualizing multi-agent collaboration as a layered neural network architecture, including Agent (Node), Layer (Agent Team), Agent Pipeline, Dynamic Routing/Team Selection, Aggregation Function, Forward Pass, Backward Pass/Optimization, Textual Gradient, Global Optimization, Local/Layerwise Optimization, Momentum, Validation, Memory/Trajectory, LLM Backbone, Prompt, and Tool components.
- The framework employs a two-phase optimization strategy: a forward pass for dynamic team selection and a backward pass for iterative refinement using textual gradients.
- This approach enables agents to self-evolve their roles, prompts, and coordination, dynamically reconfiguring teams and strategies based on performance feedback.


---

[UTBoost: Rigorous Evaluation of Coding Agents on SWE-Bench](http://arxiv.org/abs/2506.09289v1)

- UTBoost: introduces a framework for augmenting test cases using intramorphic testing, including the UTBoost Workflow (Orchestrates testing process), UTGenerator (Generates augmented test cases), and Intramorphic Testing (Establishes test oracle).
- The UTGenerator component utilizes an LLM and a multi-level localization process (file, function/class, line) to identify relevant code areas before generating new test cases and their dependencies.
- UTBoost enhances the evaluation of coding agents on benchmarks like SWE-Bench by identifying insufficient test cases and erroneous patches, leading to more reliable results and leaderboard updates.


---

[GUIROBOTRON-SPEECH: TOWARDS AUTOMATED GUI AGENTS BASED ON SPEECH INSTRUCTIONS](https://arxiv.org/abs/2506.11127)

- GUIRoboTron-Speech: introduces an end-to-end autonomous GUI agent accepting speech instructions and screenshots, with Vision Encoder (Processes GUI screenshot), Audio Encoder (Processes speech instruction), Large Language Model (Processes inputs, predicts action), Grounding Stage (Trains visual understanding), and Planning Stage (Trains reasoning and planning) components, designed to predict GUI actions from multimodal input.
- The approach leverages a progressive training framework with grounding and planning stages to develop capabilities in understanding GUI elements and task execution.
- Mixed-instruction training is employed during the grounding stage to mitigate modality imbalance from pre-trained foundation models.


---


[Agent-based Condition Monitoring Assistance with Multimodal Industrial Database Retrieval Augmented Generation](http://arxiv.org/abs/2506.09247v1)

- MindRAG (Multimodal industrial database Retrieval-Augmented Generation): introduces an agent-based condition monitoring assistance framework with LLMs, Agents, a Multimodal & semi-structured annotated machine graph Vector Store, Multimodal RAG techniques for Retrieval, Generation, Tools, and Knowledge Bases.
- The framework integrates LLM-based reasoning agents (Main thinker, CM analyst, Maintenance scheduler, Evaluation agent) with a novel vector store structure designed for industrial condition monitoring data.
- MindRAG leverages multimodal retrieval and generative capabilities, supported by custom tools and knowledge bases, to provide decision support and explainable interfaces for condition monitoring analysts.


---

[Improving LLM Agent Planning with In-Context Learning via Atomic Fact Augmentation and Lookahead Search](http://arxiv.org/abs/2506.09171v1)

- LWM-Planner (LLM-based World Model Planning Agent): introduces an LLM agent framework that enhances planning via in-context learning using a Fact Extractor (Extracts atomic facts from experience), a Planner LLM (Performs lookahead search planning), Atomic Facts (Learned knowledge base), and Interaction History (Recent observation-action memory).
- The agent extracts task-critical atomic facts from interaction trajectories to dynamically augment prompts for LLM components responsible for action proposal, world model simulation, and value estimation.
- Planning involves a depth-limited lookahead search where the Planner LLM simulates trajectories and evaluates outcomes guided by accumulated facts and history.


---


[ALE-Bench: A Benchmark for Long-Horizon Objective-Driven Algorithm Engineering](http://arxiv.org/abs/2506.09050)

- ALE-Bench: introduces a benchmark for long-horizon objective-driven algorithm engineering, featuring Problem (Provides statement/metadata), Scorer (Evaluates solution code), Visualizer (Displays execution results), Test Run (Executes code in sandbox), Code Sandbox (Replicates execution environment), Leaderboard (Ranks submissions/calculates metrics), and Session (Orchestrates AI interaction/evaluation).
- The benchmark provides a software framework simulating competitive programming contests, allowing AI systems to iteratively refine solutions using test-run feedback and visualizations.
- ALE-Bench quantifies AI performance on computationally hard optimization problems from AtCoder Heuristic Contests, enabling comparison against human experts and fostering long-horizon problem-solving research.


---

[VIKI-R: Coordinating Embodied Multi-Agent Cooperation via Reinforcement Learning](http://arxiv.org/abs/2506.09049v1)

- VIKI-R (Coordinating Embodied Multi-Agent Cooperation via Reinforcement Learning): introduces a two-stage framework that fine-tunes a pretrained vision-language model using Chain-of-Thought demonstrations and reinforcement learning, evaluated on the VIKI-Bench benchmark.
- The framework addresses embodied multi-agent cooperation across three hierarchical levels: agent activation, task planning, and trajectory perception, utilizing diverse robot embodiments and multi-view visual observations.
- The approach significantly outperforms baselines, demonstrating enhanced visual reasoning and compositional cooperation patterns among heterogeneous agents in complex environments.


---

[Design Patterns for Securing LLM Agents against Prompt Injections](http://arxiv.org/abs/2506.08837v1)

- Design Patterns: introduces, with Action-Selector Pattern (Selects predefined actions), Plan-Then-Execute Pattern (Defines plan, executes actions), LLM Map-Reduce Pattern (Dispatches isolated sub-agents), Dual LLM Pattern (Privileged/quarantined LLMs), Code-Then-Execute Pattern (Writes formal program), and Context-Minimization pattern (Removes prompt from context), a set of principled design patterns for building AI agents resistant to prompt injection attacks.
- These patterns impose intentional constraints on LLM agents, limiting their ability to perform arbitrary tasks and preventing untrusted input from triggering consequential actions.
- The paper analyzes the trade-offs of these patterns in terms of utility and security and illustrates their application through case studies of LLM agent applications.


---

[Measuring Data Science Automation: A Survey of Evaluation Tools for AI Assistants and Agents](http://arxiv.org/abs/2506.08800v1)

- Evaluation Frameworks for LLM-based Data Science AI Systems: includes LLM/Agent (AI system being evaluated), Environment (Where agent operates), Tools (Capabilities like code execution), Evaluation System (Measures performance), Data (Input for tasks), Task Description (Instructions for agent), and User (Interacts with agent).
- These frameworks assess AI systems, ranging from assistants to autonomous agents, on various data science activities using diverse metrics and setups.
- Evaluation often involves the agent interacting with data and tools within an environment, with performance judged by an automated or human-assisted evaluation system against task descriptions and data.


---

[Improved LLM Agents for Financial Document Question Answering](http://arxiv.org/abs/2506.08726v1)

- Multi-Agent Framework: introduces a system for financial document question answering with Analyst, Critic, Improved Critic, and Calculator agents.
- This framework utilizes multiple LLM-based agents to improve numerical reasoning on tabular and textual financial data.
- The proposed calculator agent demonstrates improved performance and safety compared to the previous state-of-the-art approach for this task.


---

[Approaching Dialogue State Tracking via Aligning Speech Encoders and LLMS](http://arxiv.org/abs/2506.08633v1)

- End-to-End DST Model: introduces an end-to-end dialogue state tracking system using a pretrained speech encoder, a small connector module, a pretrained LLM, and dialogue history.
- The system processes speech input and dialogue history to directly output a JSON string representing the dialogue state.
- The approach bridges speech and language model representation spaces through a two-stage training scheme for ASR pre-training and joint ASR-DST finetuning.


---

[MasHost Builds It All: Autonomous Multi-Agent System Directed by Reinforcement Learning](http://arxiv.org/abs/2506.08507v1)

- MasHost: introduces a reinforcement learning-based framework for autonomous multi-agent system construction, with Multi-agent System (Mas), LLM Agent, Role Pool, Interaction Pathway, Markov Decision Process (MDP), State, Action Space, Node-level Actions, Edge-level Actions, Policy Function, Node-level Policy (πθ), Edge-level Policy (πφ), Reward Function, Joint Probabilistic Space Sampling (JPSS), Hierarchical Relative Policy Optimization (HRPO), Group-relative Advantage, Action-wise Absolute Reward, Triple Objective, Query, State List, Selected Agents, Global Messages, Summarizer Agent, and EXIT Node components.
- The framework models Mas construction as an MDP, employing JPSS for joint node and edge sampling and HRPO for multi-objective optimization towards performance, efficiency, and rationality.
- MasHost enables autonomous Mas graph construction and role selection from a full-scale space, guided by a hierarchical reward structure combining group-relative and action-wise rewards.


---

[CAF-I: A Collaborative Multi-Agent Framework for Enhanced Irony Detection with Large Language Models](http://arxiv.org/abs/2506.08430v1)

- CAF-I (Collaborative Agent Framework for Irony): introduces a multi-agent framework for irony detection with Context, Semantic, Rhetoric, Decision, and Refinement Evaluator Agents.
- CAF-I performs multi-perspective analysis and interactive collaborative optimization to improve detection accuracy and interpretability.
- The framework achieves state-of-the-art zero-shot performance by simulating human-like multi-perspective analysis.


---

[TACTIC: Translation Agents with Cognitive-Theoretic Interactive Collaboration](http://arxiv.org/abs/2506.08403v1)

- TACTIC (Translation Agents with Cognitive-Theoretic Interactive Collaboration): introduces a multi-agent translation framework inspired by cognitive translation studies, including DraftAgent (Generates multiple drafts), RefinementAgent (Synthesizes drafts), EvaluationAgent (Evaluates translation quality), ScoreAgent (Scores translation quality), ContextAgent (Provides contextual information), and ResearchAgent (Gathers external knowledge).
- The framework comprises six distinct agents mirroring human translation processes, operating in base and complex workflows for iterative refinement.
- TACTIC leverages LLMs to simulate cognitive functions like strategic variation, processing, and contextual cognition for high-quality translation.


---

[Reinforce LLM Reasoning through Multi-Agent Reflection](http://arxiv.org/abs/2506.08379v1)

- DPSDP (Direct Policy Search by Dynamic Programming): introduces a reinforcement learning algorithm to train an actor-critic LLM system for multi-turn reasoning refinement using direct preference learning on self-generated data, incorporating Actor, Critic, and DPO.
- The approach models the multi-turn refinement process as a Markov Decision Process, where the Actor generates responses and the Critic provides feedback, iteratively improving answers.
- DPSDP leverages DPO for training the agents, demonstrating improved performance on reasoning benchmarks through collaborative refinement.


---

[Your Agent Can Defend Itself against Backdoor Attacks](http://arxiv.org/abs/2506.08336v1)

- ReAgent (Reverse and Reflective Agent): introduces a novel defense against backdoor attacks on LLM-based agents, utilizing Execution-Level Detection, Planning-Level Detection, Agent's Thoughts, Agent's Actions, Agent's Thought Trajectory, User's Instruction, and Reconstructed Instruction components to detect inconsistencies.
- The defense employs a two-level approach, verifying consistency between agent thoughts and actions at the execution level and between the user instruction and reconstructed instruction from the thought trajectory at the planning level.
- ReAgent leverages the compromised agent's own capabilities for self-defense and provides chain-of-thought explanations for transparency.


---

[Reinforcement Fine-Tuning for Reasoning towards Multi-Step Multi-Source Search in Large Language Models](http://arxiv.org/abs/2506.08352)

- R-Search: introduces a single-LLM framework that unifies multi-step planning, multi-source search execution, and answer synthesis within one coherent inference process, utilizing Policy LLM, <think>, <search>, <result>, <answer>, NL-DAG Parser, DAG Validator, Topological Sort, Search Execution, Search Tools, ReFT, GRPO Optimizer, Reward Function, and Reference LLM.
- The framework structures output into four components: reasoning traces, NL-DAG search plans, retrieved results, and synthesized answers, enabling integrated reasoning and multi-source search execution.
- A specialized Reinforcement Fine-Tuning method based on GRPO is used with a multi-component reward function to optimize answer correctness, structural validity, and format adherence.


---

[TrajFlow: Multi-modal Motion Prediction via Flow Matching](https://arxiv.org/abs/2506.08541)

- TrajFlow: introduces a flow matching-based framework for multi-modal motion prediction, utilizing a Context Encoder (encodes scene context), Flow Matching Decoder (decodes noisy trajectory to predicted trajectories and scores), Prediction Heads (predicts trajectory, classification, and ranking scores), ODE Solver (solves ODEs for inference), NMS (filters predicted trajectories), Loss Functions (optimizes model parameters), and Self-Conditioning (mitigates overfitting during training).
- The framework predicts multiple plausible future trajectories in a single pass by learning to map noise vectors to data distributions via ordinary differential equations.
- A Plackett-Luce distribution-based ranking loss and a self-conditioning training strategy are employed to improve uncertainty estimation and generalization.


---

[ORFS-agent: Tool-Using Agents for Chip Design Optimization](http://arxiv.org/abs/2506.08332v1)

- ORFS-agent: introduces an LLM-based iterative optimization agent for chip design parameter tuning, integrating an LLM, ORFS flow, METRICS2.1 metrics, GLOBALCONTEXT state, Toolbox external tools (INSPECT, OPTIMIZE, AGGLOM), Inputs, Outputs, and an Iteration Loop.
- The agent executes the ORFS flow in parallel runs, gathers METRICS2.1 data, analyzes and proposes parameters using the Toolbox, and updates design files iteratively.
- Guided by user Inputs (PDK, Verilog, Prompts), the agent maintains state in GLOBALCONTEXT to optimize design metrics and constraints, producing optimized Outputs (Config, SDC files).


---

[Understanding Software Engineering Agents Through the Lens of Traceability: An Empirical Study](http://arxiv.org/abs/2506.08311v1)

- Software Engineering Agents (SWE agents): introduces a systematic study of SWE agent behavior using execution traces, focusing on bug localization, patch generation, and reproduction test generation components.
- The study analyzes agent effectiveness in fixing issues, generating tests, and comparing agent-generated patches to human-written ones.
- Findings reveal agents struggle with complex issues, benefit from bug localization for test generation, and often produce localized edits compared to human refactorings.


---


#### 9th June 2025


[Scaling Laws of Motion Forecasting and Planning A Technical Report](https://arxiv.org/abs/2506.08228)

- MotionLM: introduces an encoder-decoder autoregressive transformer model with Scene Encoder (Processes scene data) and Motion Decoder (Generates motion tokens) components for joint motion forecasting and planning.
- The Scene Encoder uses an Early fusion network (Scene encoder backbone) to process multimodal inputs, while the Motion Decoder employs Cross-attention (Decoder attends encoder) and Flattened agent-time self-attention (Single pass attention) to generate Discrete motion tokens (Represent trajectories).
- This architecture enables studying scaling laws for performance improvements with increased compute, data, and model size in autonomous driving tasks.


---

[From Passive to Active Reasoning: Can Large Language Models Ask the Right Questions under Incomplete Information?](http://arxiv.org/abs/2506.08295v1)

- AR-Bench (Active Reasoning Benchmark): introduces, "a novel benchmark designed explicitly to evaluate an LLM's active reasoning skills", with Player (LLM under evaluation), Judge (Provides answers/feedback), Problem (Initial incomplete information), Interaction Rounds (Multi-turn Q&A), Solution (Final derived answer), where "AR-Bench evaluates LLMs on tasks requiring iterative questioning and information gathering under incomplete information."
- The benchmark simulates multi-round conversations between the LLM player and NPC judges providing answers or feedback based on the puzzle's underlying truth.
- AR-Bench highlights LLMs' difficulties in active reasoning, particularly in generating high-quality questions and effectively leveraging acquired information to solve problems.


---

[From Debate to Equilibrium: Belief-Driven Multi-Agent LLM Reasoning via Bayesian Nash Equilibrium](http://arxiv.org/abs/2506.08292v1)

- ECON (Efficient Coordination via Nash Equilibrium): introduces a hierarchical reinforcement-learning paradigm with Coordinator LLM (Generates strategy, aggregates answers), Execution LLM (Produces answers based on strategy/belief), Individual Belief Network (Maps history/observation to belief/action), Belief Encoder (Aggregates belief states), Centralized Mixing Network (Coordinates beliefs, computes global Q), and Reward Design (Provides optimization feedback), recasting multi-LLM coordination as an incomplete-information game.
- The framework replaces explicit inter-agent communication with belief-based coordination, where Execution LLMs optimize responses based on beliefs about co-agents to achieve a Bayesian Nash Equilibrium.
- ECON demonstrates improved performance and scalability compared to existing multi-agent debate methods by reducing communication overhead and ensuring convergence.


---

[EconWebArena: Benchmarking Autonomous Agents on Economic Tasks in Realistic Web Environments](http://arxiv.org/abs/2506.08136v1)

- EconWebArena: introduces a benchmark for evaluating autonomous agents on economic tasks, featuring an AI Agent interacting with a Real-World Web Environment via Observation and Action to answer a Question and provide an Answer.
- The benchmark comprises 360 tasks on 82 authoritative websites, requiring agents to navigate, interpret content, interact with interfaces, and extract precise data.
- The framework utilizes structured observations like AXTree and screenshots, and supports fine-grained browser control actions for realistic web interaction.


---

[SOP-Bench: Complex Industrial SOPs for Evaluating LLM Agents](http://arxiv.org/abs/2506.08119v1)

- SOP-Bench: introduces a benchmark generation workflow with User Inputs, LLM, Human Review and Correction, Data Schema Generation, SOP Document Generation, Dataset Generation, API & Tool Specification Generation, and Tools Code Generation, designed to evaluate LLM agents on complex industrial SOPs using SOP, Task, ToolSpecs, Mock APIs, and Dataset.
- The benchmark generation workflow creates realistic SOPs, associated data, and tools, incorporating complexity, ambiguity, and interdependencies.
- The benchmark evaluates agent architectures like FC Agent and ReAct Agent on their ability to execute multi-step, context-dependent procedures requiring tool use and error handling.


---


[Cognitive Weave: Synthesizing Abstracted Knowledge with a Spatio-Temporal Resonance Graph](http://arxiv.org/abs/2506.08098v1)

- Cognitive Weave: introduces a novel memory framework for AI agents centered around a Spatio-Temporal Resonance Graph (STRG), orchestrated by the Nexus Weaver (NW), which processes information via the Semantic Oracle Interface (SOI) and Vectorial Resonator (VR).
- The STRG is a multi-layered hybrid structure comprising a Core Particle Store for persistent storage of Insight Particles (IPs) and Insight Aggregates (IAs), a Vectorial Subsystem for embeddings, a Temporal Index for time-based queries, and a Relational Graph for modeling relationships.
- The system features a dynamic Cognitive Refinement process, managed by the NW and leveraging the SOI, to autonomously synthesize IAs, manage relational structures, and recalibrate importance, enabling continuous learning and memory evolution.


---

[Supporting Construction Worker Well-Being with a Multi-Agent Conversational AI System](http://arxiv.org/abs/2506.07997v1)

- Multi-Agent Conversational AI System: introduces a conversational multi-agent AI system for construction worker well-being, with User Interface, User, User Message, Multi-Agent Orchestration, Agents, Agent Configuration, Large Language Model (LLM), Retrieval-Augmented Generation (RAG), Vector Database, External Knowledge, Chunking, Vectorization, Prompt Engineering/Automation, and Personas components.
- The system leverages LLMs and RAG, featuring multiple agents with distinct personas and domain knowledge integrated from external documentation.
- The multi-agent framework provides practical problem-solving support and social engagement through a collaborative agent workflow managed by orchestration.


---

[HeuriGym: An Agentic Benchmark for LLM-Crafted Heuristics in Combinatorial Optimization](http://arxiv.org/abs/2506.07972v1)

- HeuriGym: introduces an agentic framework for evaluating LLM-crafted heuristics in combinatorial optimization, with Prompt (Input to LLM), LLM (Large Language Model), Generate (Heuristic algorithm code), Compiler / Interpreter (Code processing), Stage I: Execution (Runs generated code), Logs / Errors (Execution feedback), Solution File (Program output), Stage II: Solution Generation (Output produced), Stage III: Verification (Solution checked), Verifier (Checks constraints), Constraints Satisfaction (Verification result), Evaluator (Calculates cost), Cost (Evaluation result), Feedback (Appended to prompt), and Final Results (Overall outcome).
- The framework enables LLMs to generate, execute, verify, and iteratively refine heuristic algorithms for complex optimization problems.
- Evaluation uses a feedback loop and the Quality-Yield Index metric to assess reasoning, tool use, planning, and adaptive refinement.


---

[LUCIFER: Language Understanding and Context-Infused Framework for Exploration and Behavior Refinement](http://arxiv.org/abs/2506.07915v1)

- LUCIFER (Language Understanding and Context-Infused Framework for Exploration and Behavior Refinement): introduces a hierarchical decision-making framework integrating Large Language Models for context understanding and exploration guidance to enhance autonomous decision-making in dynamic environments.
- The architecture features a Strategic Decision Engine for high-level task planning and specialized Workers for low-level action execution, leveraging an Information Space for structured knowledge.
- LLMs function as Context Extractors, converting verbal input to structured insights, and Exploration Facilitators, predicting actions, with an Attention Space mechanism embedding these contextual cues into the reinforcement learning policy, reward, and action space.


---

[QUITE: A Query Rewrite System Beyond Rules with LLM Agents](http://arxiv.org/abs/2506.07675v1)

- QUITE (Query Rewrite): introduces a training-free, feedback-aware system leveraging LLM agents, rewrite middleware, and a query hint recommender to rewrite SQL queries for improved performance.
- The system employs a multi-agent framework controlled by a finite state machine, specialized middleware tools, and a novel hint injection technique.
- This approach supports a broader range of query patterns and rewrite strategies, achieving significant execution time reductions and higher rewrite equivalence rates.


---

[MCPWorld: A Unified Benchmarking Testbed for API, GUI, and Hybrid Computer Use Agents](http://arxiv.org/abs/2506.07672v1)

- MCPWorld: introduces a unified benchmarking testbed with Task Manager (Initializes tasks/environment), Environment (Containerized desktop), Unified Tool-based Space (Agent interaction interface), App Interface (Connects tools to app), Hooker (Captures app signals), and Evaluator (Verifies task completion) components, designed for evaluating API, GUI, and hybrid computer use agents using a white-box approach.
- The testbed utilizes "white-box apps" with source code availability to enable programmatic verification of task completion via dynamic code instrumentation.
- MCPWorld supports GUI, API, and hybrid interaction modalities and provides a standardized environment and tool-based interface for agent evaluation.


---

[SWE-Dev: Building Software Engineering Agents with Training and Inference Scaling](http://arxiv.org/abs/2506.07636v1)

- SWE-Dev: introduces a software engineering agent framework, with Repo Info Extraction (extracts codebase info), Description Generation (generates Gherkin scenarios), Test Case Generation (generates test case code), Revision from Traceback (refines test cases), and Fail-to-pass Test Cases (final test dataset) components, which builds SWE agents using a scalable test case generation pipeline.
- The framework focuses on training and inference scaling to improve performance on software engineering tasks.
- Training scaling involves synthesizing test cases and scaling agent trajectories, while inference scaling increases interaction budget per run.


---

[MalGEN: A Generative Agent Framework for Modeling Malicious Software in Cybersecurity](http://arxiv.org/abs/2506.07586v1)

- MalGEN: introduces a modular, multi-agent framework for generating malware-like artifacts, including Task Planner, Developer, Code Integration, and Executable Builder agents.
- The framework simulates adversarial workflows by decomposing user intent into sub-tasks, generating code snippets, integrating them, and building an executable.
- MalGEN aims to support defensive cybersecurity research by producing behaviorally diverse, ethically controlled malware samples aligned with MITRE ATT&CK.


---

[Beyond the Sentence: A Survey on Context-Aware Machine Translation with Large Language Models](http://arxiv.org/abs/2506.07583v1)

- Context-Aware Machine Translation with LLMs: surveys research on using large language models for context-aware machine translation, covering prompt-based, fine-tuning, and other application approaches.
- Prompt-based methods utilize LLMs with prompts and examples, while fine-tuning adapts LLMs using specific data and processes.
- Other applications include automatic post-editing using an initial MT system and an LLM, agentic frameworks with LLMs, memory, decoding, and agents, and LLM-based evaluation.


---

[SAFEFLOW: A Principled Protocol for Trustworthy and Transactional Autonomous Agent Systems](http://arxiv.org/abs/2506.07564v1)

- SAFEFLOW: introduces a principled protocol for trustworthy and transactional autonomous agent systems, with User (U), Decider (D), Environment (E), Information (I), SafeFlowAgent-Level (SF), Transactional Logging System, SAFEFLOW MONITOR, Dependency Graphs (DAG), Concurrency Control System, SAFEFLOWAGENT SCHEDULER, SAFEFLOWAGENT VERIFIER, and Bayesian Trust Estimation Process components.
- The framework enforces fine-grained information flow control using SafeFlowAgent-Levels and ensures reliability through transactional logging, dependency graphs, and concurrency control.
- A trusted Verifier component dynamically adjusts trust levels based on logged behavior and a Bayesian trust estimation process, enhancing security and adaptability.


---

[ChemAgent: Enhancing LLMs for Chemistry and Materials Science through Tree-Search Based Tool Learning](http://arxiv.org/abs/2506.07551v1)

- ChemAgent: enhances LLMs for chemistry and materials science using a HE-MCTS (hierarchical tree search) framework for tree-search based tool learning.
- The HE-MCTS framework decouples tool planning (Policy Model) and execution (Execution Model), guided by PRM (step reward) and ORM (outcome reward), and trained via LLM Self-Training (autonomous optimization).
- The system integrates a large Chemistry ToolPool (chemical tools) and is benchmarked/trained on the ChemToolBench (tool learning dataset).


---


- INTENTEST: introduces an API-centric stress testing framework for LLM agents, with Semantic Partitioning (divides input space), Seed Task Generation (creates initial tasks), Testcase Mutator (generates task variants), Intent Preservation Sampling (filters intent-preserving mutations), Error Likelihood Estimation (predicts error likelihood), Strategy Memory (stores successful strategies), Strategy Adaptation (retrieves and adapts strategies), LLM Agent (system under test), and Judge (evaluates for violations), designed to systematically uncover intent integrity violations.
- The framework partitions the input space based on API parameters and intent categories, generates seed tasks, and iteratively mutates them while preserving user intent.
- INTENTEST prioritizes mutations likely to cause errors using a predictive model and improves efficiency by adapting successful strategies from a memory.


---

[Taking Flight with Dialogue: Enabling Natural Language Control for PX4-based Drone Agent](http://arxiv.org/abs/2506.07509v1)

- ROS-based agentic framework: introduces a system for natural language control of PX4-based UAVs, integrating PX4 Autopilot (Low-level flight control), ROS2 Middleware (Communication layer), Ollama (Serves LLMs and VLMs), Visual QnA Node (Processes images and queries), Path Planning Node (Generates collision-free trajectory), Map Encoder Node (Embeds pose and semantic info), LLM (Generates action commands), VLM (Assesses visual input), NVIDIA Omniverse (Simulation environment), and Hardware-In-The-Loop (Physical drone setup).
- The framework uses Ollama to serve various open-source LLMs and VLMs, managing tasks through modular ROS2 nodes for visual question answering, path planning, and map encoding.
- The system enables a drone agent to interpret natural language instructions, perceive its environment, and execute flight actions in both simulation and real-world settings.


---

[MedChat: A Multi-Agent Framework for Multimodal Diagnosis with Large Language Models](http://arxiv.org/abs/2506.07400v1)

- MedChat: introduces a multi-agent framework for multimodal diagnosis, with Retinal Fundus Image, Clinical Note, Glaucoma Classifier, Disk/Cup Segmentor, Shared Prompt, Role-Based Agents, Sub-Reports, Director Agent, Final Report, Frontend, Backend, and Interactive Chat Interface components, designed to emulate multidisciplinary clinical workflows for generating diagnostic reports.
- The framework processes medical images and clinical notes using deep learning models, verbalizes outputs into a shared prompt, distributes it to role-specific LLM agents, and synthesizes their sub-reports into a final diagnostic report via a director agent.
- A companion platform provides a user interface for input, report viewing, and interactive question-answering, enhancing transparency and usability for clinical review and education.


---

[G-Memory: Tracing Hierarchical Memory for Multi-Agent Systems](http://arxiv.org/abs/2506.07398v1)

- G-Memory: introduces a hierarchical memory system for Multi-Agent Systems (MAS) with Insight Graph (abstracts generalizable insights), Query Graph (encodes task meta-information), and Interaction Graph (stores communication logs) components, which manages MAS interaction history via a three-tier graph hierarchy.
- G-Memory performs bi-directional memory traversal to retrieve high-level insights and fine-grained interaction trajectories for new queries.
- The hierarchical memory architecture is updated upon task completion by assimilating new trajectories and distilling insights, enabling agent teams to evolve.


---

[Shapley-Coop: Credit Assignment for Emergent Cooperation in Self-Interested LLM Agents](http://arxiv.org/abs/2506.07388v1)

- Shapley-Coop: introduces a cooperative workflow for self-interested LLM agents, with Structured Negotiation Protocol (Communication protocol), Short-Term Shapley Chain-of-Thought (Heuristic reasoning), and Long-Term Shapley Chain-of-Thought (Retrospective reasoning), enabling credit assignment.
- The framework integrates Shapley Chain-of-Thought reasoning with structured negotiation protocols to align heterogeneous goals and facilitate fair credit assignment.
- Shapley-Coop fosters spontaneous cooperation through rational task-time pricing and transparent post-task reward redistribution.


---

#### 8th June 2025

[SCGAgent: Recreating the Benefits of Reasoning Models for Secure Code Generation with Agentic Workflows](http://arxiv.org/abs/2506.07313v1)

- SCGAgent: introduces an agentic workflow for secure code generation, with Code Generation, Unit Test Generation, CWE Prediction, Guideline Retrieval, Guideline Relevance Checking, Code Modification, Enforce Functionality Module, Fault Determination, Guideline Database, and Test Runner components.
- The framework utilizes an underlying language model to perform generation, prediction, checking, modification, and fault determination tasks, guided by a workflow and a database of secure coding guidelines.
- SCGAgent iteratively refines generated code based on secure coding guidelines and feedback from executing LLM-generated unit tests to improve both security and functionality.


---

[Question Answering under Temporal Conflict: Evaluating and Organizing Evolving Knowledge with LLMs](http://arxiv.org/abs/2506.07270v1)

- Agentic Framework (knowledge organization): introduces a lightweight, agentic framework for question answering under temporal conflict by incrementally building a structured, external memory from source documents.
- The framework utilizes a Language Model agent to decompose Incoming Questions, extract facts from Incoming Text Documents, and update a structured Knowledge Base.
- For answering, the agent queries the Knowledge Base for temporally filtered, relevant facts, enabling reliable reasoning over dynamic information without model re-training.


---

[Learn as Individuals, Evolve as a Team: Multi-agent LLMs Adaptation in Embodied Environments](http://arxiv.org/abs/2506.07232v1)

- LIET (Learn as Individuals, Evolve as a Team): introduces a framework for multi-agent LLM adaptation in embodied environments, featuring LIET Agent, Environment, Communication Channel, Memory, Utility Function, Comm., Planner, Know. List, Message Generator, and Reflector components.
- The framework enables LLM agents to learn individually via a utility function for cost estimation and evolve as a team through an evolving communication scheme.
- Individual agents use memory and the utility function for local planning, while team communication is guided by a shared knowledge list updated via reflection on received messages.


---

[LLM-Enhanced Rapid-Reflex Async-Reflect Embodied Agent for Real-Time Decision-Making in Dynamically Changing Environments](http://arxiv.org/abs/2506.07223v1)

- RRARA (Rapid-Reflex Async-Reflect Agent): introduces a hybrid embodied agent combining a rule-based policy (low-latency reflex) for immediate actions with an asynchronous LLM-based Reflector (asynchronous reflection feedback) for in-situ refinement.
- The agent executes initial actions based on the low-latency rule-based policy while the LLM-based Reflector analyzes the situation in parallel to provide feedback.
- This parallel processing allows the agent to maintain real-time responsiveness while incorporating high-level reasoning to revise suboptimal decisions in dynamic environments.


---

[BIMgent: Towards Autonomous Building Modeling via Computer-use Agents](http://arxiv.org/abs/2506.07217v1)

- BIMgent: introduces an agentic framework for autonomous architectural building modeling, with Design Layer (Transforms design requirements), Action Planning Layer (Hierarchically plans modeling steps), High-level Planner (Generates general design steps), Low-level Planner (Generates detailed action substeps), Execution Layer (Executes planned GUI operations), Pure-Action Workflow (Executes deterministic actions), Vision-Driven Workflow (Executes GUI-grounded actions), Supervisor (Monitors execution, provides feedback), and Memory (Stores execution trajectories).
- The framework transforms multimodal design intents into 3D BIM models by interpreting design, planning software workflows hierarchically, and executing GUI actions with supervision and reflection.
- BIMgent leverages multimodal LLMs as backbones and integrates components like RAG for documentation access and a screen parser for dynamic GUI grounding to handle complex BIM software environments.


---

[Mind the Web: The Security of Web Use Agents](http://arxiv.org/abs/2506.07153v1)

- Web-use Agent Architecture: introduces, "a new attack vector exploiting web-use agents' high-privilege browser capabilities by embedding malicious content in web pages", with all LLM (interprets content, plans actions), Perception Module (gathers web content), Execution Engine (interacts with browser/system), State Management (handles sessions, credentials), Agent Interface (user interaction) components, where "the attack leverages LLMs' contextual reasoning limitations to frame malicious instructions as helpful task guidance".
- The paper demonstrates nine payload types compromising confidentiality, integrity, and availability against four popular web-use agent implementations.
- Mitigation strategies including oversight, execution constraints, and task-aware reasoning are proposed to address these vulnerabilities.


---

[BRIGHT+: Upgrading the BRIGHT Benchmark with MARCUS, a Multi-Agent RAG Clean-Up Suite](http://arxiv.org/abs/2506.07116v1)

- MARCUS (Multi-Agent RAG Clean-Up Suite): introduces a multi-agent pipeline with SafeClean (conservative cleaning), FastClean (aggressive cleaning), and Splitter (semantic chunking) agents to clean and re-chunk the BRIGHT corpus into BRIGHT+.
- The pipeline leverages LLMs to systematically remove structural noise and address semantic discontinuity in web-scraped data.
- BRIGHT+ yields improvements in retrieval accuracy and multi-hop reasoning across diverse retrievers.


---

[Theorem-of-Thought: A Multi-Agent Framework for Abductive, Deductive, and Inductive Reasoning in Language Models](http://arxiv.org/abs/2506.07106v1)

- ToTh (Theorem-of-Thought): introduces a multi-agent framework with Multi-Paradigm Reasoning Agents (Generate reasoning traces), Formal Reasoning Graph Construction (Transform traces to graphs), Bayesian Confidence Propagation (Evaluate graph consistency), Graph Scoring (Select best graph), and Answer Extraction (Extract final answer), modeling reasoning as collaboration and verification.
- The framework employs distinct agents for abductive, deductive, and inductive reasoning, structuring their outputs into graphs.
- Consistency is verified using NLI-calibrated Bayesian belief propagation to select the most coherent reasoning path.


---

[Accelerating Two-Dimensional Materials Research via a Universal Interatomic Potential and Large Language Model Agent](http://arxiv.org/abs/2506.07043v1)

- MCP-based Agent Platform: introduces a platform integrating a universal ML-IAP for 2D materials with an LLM-powered agent, including a database, model (ML-IAP and band gap model), and functional modules.
- The platform enables natural language interaction for 2D materials property simulations and high-throughput screening.
- The ML-IAP model, based on MatterSim/M3GNet, is trained on a large 2D material dataset, while a GNN/CNN model predicts band gaps.


---

[Position: Simulating Society Requires Simulating Thought](http://arxiv.org/abs/2506.06958v1)

- GenMinds (Generative Minds): introduces a conceptual modeling paradigm for generative agents, with Structured Thought Capture (Elicits, parses explanations), Causal Motifs (Minimal causal units), Causal Belief Network (CBN) (Symbolic causal graph), Symbolic-Neural Hybrid Graph Simulation (Inference, belief updates), and Awareness of Unknown (Highlights missing links), designed to simulate structured, revisable, and traceable thought for social simulations.
- The framework grounds agents in modular belief representations using causal graphs derived from natural language interviews to capture reasoning fidelity.
- The paper also introduces RECAP, a benchmark framework to evaluate reasoning fidelity based on traceability, demographic sensitivity, and intervention coherence.


---

#### 7th June 2025

[An Agentic Framework for Autonomous Metamaterial Modeling and Inverse Design](http://arxiv.org/abs/2506.06935v1)

- Agentic Framework: introduces an autonomous system for metamaterial inverse design, including Planner (Orchestrates process), Input Verifier (Validates inputs), Forward Modeler (Develops forward model), Inverse Designer (Designs geometry), Memory (Stores information), File_Check (Checks files), Forward_Train (Trains model), Data_Generate (Generates data), Controller (Guides iteration), Code_Modify (Adapts code), Neural_Adjoint (Inverse design tool), Numerical_Simulation (Verifies design), User Message (Input/Output), and System Prompt (Configures agents).
- The framework leverages specialized LLM agents and external tools to automate the end-to-end design process from user input to optimized metamaterial geometry.
- The system demonstrates autonomous planning, reasoning, and adaptation, achieving performance comparable to human expert-designed solutions.


---

[Boosting LLM Reasoning via Spontaneous Self-Correction](http://arxiv.org/abs/2506.06923v1)

- SPOC: introduces a spontaneous self-correction approach for LLMs, with LLM Agent (core model), Dual Agent Roles (proposer/verifier), Interleaved Generation (solution/verification turns), PairSFT (initial training), and Online RL (policy optimization), enabling models to generate interleaved solutions and verifications in a single pass.
- The approach dynamically elicits and terminates reasoning generations based on self-verification outcomes, effectively scaling inference time compute.
- Training leverages synthetic data for fine-tuning and online reinforcement learning using correctness as reward, yielding substantial performance improvement on math reasoning benchmarks.


---

[Multimodal Spatial Language Maps for Robot Navigation and Manipulation](http://arxiv.org/abs/2506.06862v1)

- AVLMaps (Audio-Visual-Language Maps): introduces a unified 3D spatial map representation built by fusing multimodal features from visual, object, area, and audio localization modules, enabling cross-modal reasoning for spatial goal navigation guided by an LLM.
- The framework supports zero-shot spatial and multimodal goal navigation, demonstrating improved recall in ambiguous scenarios.
- The maps are reusable across different robot embodiments and extensible to additional sensing modalities.


---

[United Minds or Isolated Agents? Exploring Coordination of LLMs under Cognitive Load Theory](http://arxiv.org/abs/2506.06843v1)

- CoThinker: introduces, with Agent Parallel Thinking (Divides cognitive labor), Thinking Style Orchestrator (Assigns thinking styles), Transactive Memory System (Manages shared knowledge), Communication Moderator (Structures communication network), Synthesizer (Consolidates final solution), and Agents (Individual LLMs), a multi-agent LLM architecture operationalizing Cognitive Load Theory principles to mitigate cognitive overload and enhance collaborative problem-solving.
- The architecture distributes intrinsic cognitive load through agent specialization via thinking styles and manages transactional load via structured communication and a collective working memory.
- CoThinker demonstrates improved performance on complex problem-solving tasks and high cognitive load scenarios compared to existing multi-agent baselines.


---

AI PsyRoom: Artificial Intelligence Platform for Segmented Yearning and Reactive Outcome Optimization Method](http://arxiv.org/abs/2506.06740v1)

- AI PsyRoom: introduces a multi-agent simulation framework for psychological counseling, including PsyRoom A (Dialogue generation module) for generating dialogues and PsyRoom B (Treatment plan module) for generating treatment plans.
- The framework leverages fine-grained emotion analysis through Segmenting Psychological Emotions (Fine-grained emotion analysis) and Segmented Emotional Classification (Fine-grained emotion analysis).
- PsyRoom A employs Multi-agents (Simulate counseling dialogue) including Client (Simulated patient agent), Counselor (Simulated therapist agent), and Professor of Psychology (Dialogue evaluation agent), while PsyRoom B uses an Emotional Assessor (Emotion evaluation agent) and Emotional Therapist (Treatment plan agent).


---

[WORLDLLM: IMPROVING LLMS' WORLD MODELING USING CURIOSITY-DRIVEN THEORY-MAKING](http://arxiv.org/abs/2506.06725v1)

- WorldLLM: introduces a framework to improve LLMs' world modeling by combining Bayesian inference and active exploration, including a Statistician (LLM forward model) to evaluate hypotheses, a Scientist (LLM theory generator) to refine hypotheses, and an Experimenter (Data collection agent) to collect challenging transitions.
- The framework iteratively alternates between the Experimenter collecting data, the Statistician evaluating the current hypotheses on this data, and the Scientist updating the natural language hypotheses based on the evidence.
- This curiosity-driven process aims to autonomously improve the LLM's predictive accuracy and generate human-interpretable theories of environment dynamics without costly gradient-based fine-tuning.


---

[Contextual Experience Replay for Self-Improvement of Language Agents](http://arxiv.org/abs/2506.06698v1)

- CER (Contextual Experience Replay): introduces a training-free framework for language agents, including distillation module (Distills experiences), retrieval module (Retrieves experiences), dynamic memory buffer (Stores past experiences), and base decision-making agent (Solves tasks).
- The framework enables self-improvement by distilling environment dynamics and decision-making patterns from past trajectories.
- Retrieved experiences are replayed in the agent's context to enhance decision-making in complex web environments.


---



#### 6th June 2025

[Future of Work with AI Agents: Auditing Automation and Augmentation Potential across the U.S. Workforce](https://arxiv.org/abs/2506.06576)

- Auditing Framework: introduces a task-level, survey-based approach with Auditing Framework With Audio Interface, WORKBank, Human Agency Scale (HAS), and Autonomous Agent Desire-Capability Landscape components to audit AI agent automation and augmentation potential across the U.S. workforce.
- The framework collects worker desires and AI expert capability assessments for occupational tasks, storing this data in the WORKBank database.
- Key outputs include the Human Agency Scale for quantifying human involvement and the Desire-Capability Landscape for identifying mismatches and opportunities in AI agent development.


---


[Improving LLM-Powered EDA Assistants with RAFT](http://arxiv.org/abs/2506.06500v1)

- EDA-LLM Assistant Workflow: introduces a method to enhance LLM performance for RAG-based EDA tasks using Retrieval-Augmented Fine-Tuning (RAFT) with synthetic question-answer datasets generated by a Data Generation/Refinement LLM from Training Data Sources, leveraging Few-Shot Retrieval from a Q&A History Database, and utilizing Hybrid Retrieval from a Document Database with Access Control for the EDA-LLM.
- The workflow incorporates human-authored Q2A posts and unlabeled EDA Documents as Training Data Sources, employing DeepSeek-V3 as the Data Generation/Refinement LLM to create refined answers and synthetic Q&A pairs, optionally guided by Retrieval-Augmented Few-Shot examples retrieved via BM25 from a Q&A History Database.
- The approach integrates Hybrid Retrieval combining semantic and lexical search on a Document Database, applies Access Control to filter retrieved documents for security, and fine-tunes the EDA-LLM using RAFT before deploying it for RAG-based inference.


---

[ScriptDoctor: Automatic Generation of PuzzleScript Games via Large Language Models and Tree Search](http://arxiv.org/abs/2506.06524v1)

- ScriptDoctor: introduces a pipeline for automatic PuzzleScript game generation, including an LLM (Generates game code), Lark CFG Parser (Parses generated code), PuzzleScript Engine (Compiles game code), BFS Solver (Tests game solvability), Human Game Archive (Provides game examples), Coding Prompt (Guides LLM generation), Parse Errors (Syntax error feedback), Compile Errors (Compilation error feedback), and Solvability Issues (Playtesting feedback).
- The system iteratively generates and tests games, using feedback from parsing, compilation, and playtesting to refine the LLM's output.
- This approach demonstrates automated, open-ended LLM-based workflows for generating novel game content in a constrained domain.


---


[On-board Mission Replanning for Adaptive Cooperative Multi-Robot Systems](https://arxiv.org/abs/2506.06094)

- GATR (Graph Attention Replanner): introduces a lightweight mission replanner using a GAT Encoder (Transforms graph data) and Attention Model Decoder (Generates mission plan) to solve the Cooperative Mission Replanning Problem.
- The framework employs an RL Agent (Learns planning policy) interacting with an RL Environment (Simulates mission dynamics), processing an Input Graph (Represents tasks agents) along with the Environment State (Summarizes mission progress) and Availability Mask (Filters invalid actions).
- This approach enables fast and efficient on-board replanning for multi-robot systems by transforming input data into latent representations and sequentially generating mission plans.


---


[PersonaAgent: When Large Language Model Agents Meet Personalization at Test Time](http://arxiv.org/abs/2506.06254v1)

- PersonaAgent: introduces a personalized LLM agent framework with a persona (user-specific system prompt), personalized memory (stores user data), personalized action (selects tailored actions/tools), test-time user preference alignment (optimizes persona prompt), and tools (external functions).
- The personalized memory module integrates episodic memory (records interactions) and semantic memory (summarizes user traits).
- The persona serves as an intermediary, using memory insights to guide actions and being refined by action outcomes and test-time alignment.


---

[Can Theoretical Physics Research Benefit from Language Agents?](http://arxiv.org/abs/2506.06214v1)

- LLM agents: introduces the potential for LLM agents, with Domain Knowledge, External Tools, Multimodal Processing, Reasoning Capabilities, Information Retrieval, Human Interface, and Experimental Interaction components, to accelerate theoretical physics research by assisting across the typical workflow stages.
- The paper analyzes current LLM capabilities and limitations in physics reasoning, highlighting the need for improvements in physical intuition, constraint satisfaction, and reliability.
- Realizing this potential requires addressing fundamental challenges like ensuring physical consistency and developing robust verification methods through interdisciplinary collaboration.


---

[Does It Run and Is That Enough? Revisiting Text-to-Chart Generation with a Multi-Agent Approach](http://arxiv.org/abs/2506.06175v1)

- Multi-Agent Pipeline: introduces a lightweight multi-agent framework for text-to-chart generation, including a Drafting Agent (generates initial code), a Python Interpreter (executes code), a Re-writer Agent (debugs code), and an Execution and Repair Loop (iteratively fixes errors).
- This pipeline separates the tasks of code generation, execution, repair, and judgment to improve reliability.
- The agentic approach significantly reduces execution errors compared to single-prompt methods, highlighting the value of iterative self-correction.


---

[The Lock-in Hypothesis: Stagnation by Algorithm](http://arxiv.org/abs/2506.06166v1)

- Human-LLM Feedback Loop: introduces the lock-in hypothesis, proposing that the dynamic interaction between human users and large language models, involving Human Agents (users), LLM Authority (AI system), Beliefs (ideas, values, opinions), Trust (mutual influence weight), and a Diversity Metric (conceptual variety measure), can lead to a loss of diversity and convergence on false beliefs.
- The paper formalizes this hypothesis using a Bayesian model and tests it empirically with agent-based LLM simulations and real-world GPT usage data.
- Analysis reveals sudden drops in diversity after new GPT versions are released, supporting the hypothesized feedback loop's role in reinforcing existing beliefs.


---

[Personalized Large Language Models Can Increase the Belief Accuracy of Social Networks](http://arxiv.org/abs/2506.06153v1)

- Personalized LLM Bot: introduces a system, with Traditional ML Model (Predicts user preferences), External Database (Stores news articles), RAG Model (Retrieves relevant articles), Summarization Component (Summarizes retrieved articles), and Styling LLM (Rephrases for rhetorical style), designed to provide personalized, factually accurate responses within a social network simulation.
- The bot's responses are tailored to individual user preferences regarding news sources and rhetorical style, based on predictions from a machine learning model and information retrieved from an external database.
- The study demonstrates that the presence of this personalized LLM bot in a social network leads individuals to update their beliefs towards factual accuracy and influences their subsequent network connections.


---

[Conversational Interfaces for Parametric Conceptual Architectural Design: Integrating Mixed Reality with LLM-driven Interaction](http://arxiv.org/abs/2506.06066v1)

- The system: introduces a framework for parametric architectural design using a Reasoning-Code Generation-Execution cycle, integrating a multi-agent LLM system (Reasoning Agent, Coding Agent, Optimization Agent) with a Mixed Reality environment.
- The system leverages an Interface Manager and ShapeFramework for user interaction and visualization within MR, while an LLM Session Manager orchestrates the agents and a Compiler Client handles code execution.
- This approach aims to lower barriers to parametric modeling by enabling natural language and gesture interaction, dynamic parameter management, and iterative design exploration in an immersive environment.


---

[AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search](http://arxiv.org/abs/2506.06017v1)

- AgentSwift: introduces a framework combining selection (selects agent), hierarchical expansion (expands selected agent), value model (predicts performance), and performance uncertainty (guides exploration) for efficient LLM agent design.
- Hierarchical expansion includes recombination (replaces components/workflow), mutation (generates new implementations), and refinement (adjusts based on feedback).
- The framework leverages a hierarchical search space (models agent design) including agentic workflow (defines execution steps/flow) and functional components (includes memory, tool, planning).


---

[CrimeMind: Simulating Urban Crime with Multi-Modal LLM Agents](http://arxiv.org/abs/2506.05981v1)

- CrimeMind: introduces CrimeMind (LLM-driven ABM framework), with LLM Agents (Powered by large language models), Routine Activity Theory (Guides agent crime decisions), Urban Environment (Grid-based spatial simulation), Structured Data (Demographic, socioeconomic features), Street View Imagery (Visual urban scene input), Vision-Language Model (Processes visual urban cues), Human Annotation (Dataset for perception alignment), Self-Evolution Alignment (Calibrates VLM to human judgment), Agent Mobility (Simulates agent movement), and Crime Heatmap (Aggregated crime event visualization), which simulates urban crime using theory-grounded LLM agents in a multimodal urban context.
- The framework integrates Routine Activity Theory into agent decision-making and uses a self-evolution alignment process to calibrate visual perception with human judgment.
- CrimeMind enables counterfactual simulations and policy evaluation by allowing agents to dynamically adapt behavior based on changing conditions.


---

CodeContests+: High-Quality Test Case Generation for Competitive Programming](http://arxiv.org/abs/2506.05817v1)

- G-V (Generator-Validator) agent system: introduces an LLM-based agent system for high-quality test case generation, including Generator Agent, Validator Agent, Generator Program, and Validator Program.
- The Generator Agent writes programs to create diverse test inputs, while the Validator Agent writes programs to verify these inputs against problem constraints.
- Test cases failing validation provide feedback to the Generator Agent for revision, improving correctness and coverage.


---

[MAPLE: Multi-Agent Adaptive Planning with Long-Term Memory for Table Reasoning](http://arxiv.org/abs/2506.05813v1)

- MAPLE (Multi-agent Adaptive Planning with Long-term mEmory): introduces a novel framework for table reasoning with Solver (Iterative reasoning), Checker (Answer verification), Reflector (Error diagnosis), Archiver (Memory management), Working Memory (Current task state), and Long-term Memory (Accumulated knowledge) agents in a feedback loop.
- The framework mimics human problem-solving by enabling dynamic adaptation within and across tasks through iterative refinement and experiential learning.
- Specialized agents collaborate in a feedback-driven cycle, leveraging dual memory systems for robust and accurate table reasoning.


---

[To Protect the LLM Agent Against the Prompt Injection Attack with Polymorphic Prompt](http://arxiv.org/abs/2506.05739v1)

- Polymorphic Prompt Assembling (PPA): introduces a defense against prompt injection by dynamically varying prompt structure using User Input, Instruction Prompt, Separator Set, System Prompt Set, Random Selector, Format Constraints, and Polymorphic Prompt Assemble process.
- The approach randomizes the combination of user input and system prompts using selected separators and templates to disrupt attacker predictability.
- This method enhances LLM agent security against adaptive attacks with near-zero runtime overhead.


---

[Toward Greater Autonomy in Materials Discovery Agents: Unifying Planning, Physics, and Scientists](http://arxiv.org/abs/2506.05616v1)

- MAPPS (Materials Agent unifying Planning, Physics, and Scientists): introduces a multi-agent framework for autonomous materials discovery, including a Workflow Planner (Generates multi-step workflows), a Tool Code Generator (Synthesizes executable code), and a Scientific Mediator (Coordinates agents and human).
- The framework enables Level 2 autonomy by allowing agents to plan workflows guided by human input, rather than executing fixed, predefined steps.
- MAPPS integrates physics-based tools and human feedback to ensure scientific validity and improve performance in crystal structure generation and prediction tasks.


---


#### 5th June 2025

[Energentic Intelligence: From Self-Sustaining Systems to Enduring Artificial Life](https://arxiv.org/abs/2506.04916)

- Energentic Intelligence: introduces a class of autonomous systems driven by persistence, with Energy Generation Core (Converts ambient energy), Energo-Cognitive Cortex (Performs perception/decision-making), Thermal Regulation Unit (Manages internal temperature), and Survival Manager (Estimates survival, issues commands) components.
- This framework operationalizes autonomy through energetic persistence, integrating energy harvesting, adaptive computation, and thermoregulation into a cohesive, internally regulated feedback loop.
- The system aims to sustain its existence by continuously adapting behavior based on internal energy and thermal conditions, rather than optimizing external task performance.


---


[OPERA: A Dataset of Observation, Persona, Rationale, and Action for Evaluating LLMs on Human Online Shopping Behavior Simulation](http://arxiv.org/abs/2506.05606v1)

- OPERA-based User Behavior Simulation: introduces OPERA Dataset (Dataset), User Persona (User profiles), Action Traces (User interactions), Web Observations (Web context), Rationales (Action explanations), ShoppingFlow Plugin (Data collection plugin), Content Script (Logs user interactions), Background Script (Tracks page events), Rationale Pop-up (Collects rationales), and LLM (Simulation model), which provides a dataset and benchmark for evaluating LLMs on simulating human online shopping behavior.
- The framework utilizes the ShoppingFlow plugin to collect detailed user data, including actions, web context, rationales, and persona information.
- This data is then used to benchmark LLMs on predicting user actions and rationales in online shopping scenarios.


---

[IMPROVING LLMS WITH A KNOWLEDGE FROM DATABASES](http://arxiv.org/abs/2506.05560v1)

- Enhanced Association Rule RAG: introduces a method to improve LLM answers by augmenting them with knowledge discovered from databases using enhanced association rules, including Dataset, Rule Mining Pattern Definition, Rule Mining Task Definition, Rule Mining Execution, Rule List, Rule-To-Text Module, Text Document, RAG Augmentation, and LLM components.
- The approach extracts knowledge from a dataset via rule mining, converts the resulting rules into a text document, and embeds this document into the LLM's context using Retrieval-Augmented Generation.
- This method provides interpretable knowledge to the LLM, enabling improved data-based question answering without requiring the LLM to directly execute analytical code or interpret complex rule formats.


---

[SocialDF: Benchmark Dataset and Detection Model for Mitigating Harmful Deepfake Content on Social Media Platforms](http://arxiv.org/abs/2506.05538v1)

- Fact Checking Framework: introduces a two-stage pipeline for deepfake detection using YOLO (Face Detection), FaceNet (Feature Extraction), Influential People database (Identity Comparison), Whisper (Speech Transcription), LLM AGENT-1 (Plausibility Analysis), LLM AGENT-2 (Factual/Ethical Check), WEB SEARCH (External Information), and LLM (Final Decision) to analyze audio-visual content.
- The framework identifies individuals and transcribes speech in the first stage, then uses a multi-agent LLM pipeline to verify authenticity based on plausibility, factual correctness, and ethical implications.
- This multimodal approach integrates visual recognition, speech transcription, and language-based reasoning to enhance robustness against sophisticated deepfakes.


---


[LLM Agents for Asynchronous Group Communication in Mafia Games](http://arxiv.org/abs/2506.05309v1)

- LLM Agent: introduces an adaptive asynchronous agent for group communication, featuring a Scheduler (decides when to speak) and Generator (composes message content) modules, using Context (game state and chat history) and guided by dynamic Scheduling Prompt (guides timing decision) and Generation Prompt (guides message content), incorporating Simulated Typing Time (adds human-like delay).
- The agent is evaluated in Mafia games alongside human players, demonstrating performance comparable to human players in timing and win rates.
- The asynchronous design allows the agent to decide both what to say and when to say it, better mimicking real-world group interactions.


---

[ProRefine: Inference-time Prompt Refinement with Textual Feedback](http://arxiv.org/abs/2506.05305v1)

- ProRefine: introduces an inference-time prompt optimization method using textual feedback from LLMs, including LLMtask (Executes task), LLMfeedback (Critiques output), and LLMoptimizer (Refines prompt) components.
- The LLMtask executes the task, LLMfeedback critiques its output, and LLMoptimizer refines the prompt based on the feedback in an iterative loop.
- This process dynamically refines prompts for multi-step reasoning tasks without requiring additional training or ground truth labels.


---

[Teaming in the AI Era: AI-Augmented Frameworks for Forming, Simulating, and Optimizing Human Teams](http://arxiv.org/abs/2506.05265v1)

- Frameworks: introduces AI-augmented frameworks for forming, simulating, and optimizing human teams, including a Team Formation Framework using a UCB Algorithm and user feedback, tAlfa (Team AI Feedback Assistant) with an LLM-powered agent and processing stages for feedback generation and delivery based on communication metrics, and PuppeteerLLM, an LLM-based simulation framework with LLM agents, physical environments, temporal dynamics, and simulation stages.
- The Team Formation Framework iteratively refines team recommendations using a multi-armed bandit approach guided by user preferences.
- tAlfa provides immediate, personalized AI-generated feedback on team dynamics by processing messages and evaluating communication metrics.


---

[LLM-Guided Scenario-based GUI Testing](http://arxiv.org/abs/2506.05079v1)

- SCENGEN (LLM-guided scenario-based GUI testing approach): introduces a novel approach for scenario-based GUI testing leveraging multi-modal LLMs and a multi-agent framework, including Context Memory, Observer, Decider, Executor, Supervisor, and Recorder components.
- The framework simulates manual testing by iteratively observing GUI state, making decisions, executing actions, verifying results, and recording information.
- Multi-agent collaboration and LLM guidance enable understanding app semantics and generating scenario-based GUI tests effectively.


---

[Hierarchical Language Models for Semantic Navigation and Manipulation in an Aerial-Ground Robotic System](http://arxiv.org/abs/2506.05020v1)

- hierarchical MA-LLM framework (Multi-Agent Language Model): introduces a system for aerial-ground robots, integrating a Reasoning Layer (LLM) for task decomposition and mapping, a Perceptual Layer (VLM) for semantic extraction, and an Execution Layer for motion control.
- The framework utilizes an Aerial Robot as a leader for global guidance and a Ground Robot as a follower for local navigation and manipulation.
- GridMask enhances the VLM's spatial perception, supporting robust semantic navigation and manipulation in dynamic environments.


---

[QiMeng: Fully Automated Hardware and Software Design for Processor Chip](http://arxiv.org/abs/2506.05007v1)

- QiMeng: introduces a novel system for fully automated hardware and software design for processor chips, with a Large Processor Chip Model (LPCM) as a domain-specialized LLM, Hardware Design Agent for automated hardware design, Software Design Agent for automated software design, and Top-layer Applications for various design tasks.
- The system is structured in three hierarchical layers, leveraging AI and LLMs to address challenges in processor chip design.
- QiMeng aims to automate the entire design and verification pipeline, enabling rapid customization and improved efficiency.


---


[Agentic AI for Intent-Based Industrial Automation](http://arxiv.org/abs/2506.04980v1)

- Intent-Based Agentic AI Framework: introduces a conceptual framework for intent-driven industrial automation using LLM-based agents, featuring a Root Agent, Specialized Sub-Agents, LLM, SLM, Memory, Tools Set, Industrial Data, Machines, and Business and Operational Intents.
- The framework translates high-level natural language business or operational intents into structured components, enabling autonomous planning and execution via agent orchestration and specialized tools.
- This approach simplifies human-machine interaction by abstracting technical complexity and aligns with Industry 5.0's human-centric vision.


---

[LLMS FOR SENSORY-MOTOR CONTROL: COMBINING IN-CONTEXT AND ITERATIVE LEARNING](http://arxiv.org/abs/2506.04867v1)

- LLM-based Sensory-Motor Control Framework: introduces a method where an LLM (Large Language Model) generates a control strategy, encodes it into IF-THEN rules and Python Code, and evaluates it in an Environment/Task.
- The framework iteratively refines the Strategy (Text/Rules) by prompting the LLM with Performance/Sensory-Motor Data and Past Experiences/External Memory.
- This approach enables autonomous learning for embodied agents by directly mapping observations to actions without relying on predefined motor primitives or human demonstrations.


---

[Empowering Economic Simulation for Massively Multiplayer Online Games through Generative Agent-Based Modeling](http://arxiv.org/abs/2506.04699v1)

- MMOAgent (Generative Agent-Based Modeling): introduces an LLM-empowered framework for MMO economic simulation, featuring profile (tailors agent to player traits), perception (interprets game environment observations), reasoning (determines appropriate structured actions), memory (logs game experience, past trajectories), and action (executes permissible game actions) modules.
- The framework utilizes LLMs' capabilities for human-like decision-making and adaptability, addressing reliability, sociability, and interpretability challenges in traditional agent-based modeling.
- The simulation environment is enhanced with player-to-player trading and linguistic negotiation, enabling realistic economic interactions and emergent phenomena like role specialization and market price dynamics.


---

[Gen-n-Val: Agentic Image Data Generation and Validation](http://arxiv.org/abs/2506.04676v1)

- Gen-n-Val: introduces a novel agentic framework for generating and validating synthetic image data, leveraging a LD Prompt Agent (LLM) (Generates optimized prompts), Data Validation Agent (VLLM) (Filters generated images), Layer Diffusion (LD) (Generates transparent images/masks), TextGrad (Optimizes agent prompts), and Image Harmonization (Blends instances onto backgrounds).
- The framework uses agents and generative models to produce high-quality synthetic data with precise instance masks and diverse backgrounds for computer vision tasks.
- Gen-n-Val significantly improves performance on instance segmentation and object detection benchmarks, particularly for rare classes and open-vocabulary detection.


---

[E-bike agents: Large Language Model-Driven E-Bike Accident Analysis and Severity Prediction](http://arxiv.org/abs/2506.04654v1)

- E-bike agents: introduces a framework using LLM-powered agents to analyze unstructured e-bike accident reports, including a Data Classifier, Information Extractor, Injury Causes Determiner, and Incident-Component Link Detector.
- The framework processes extracted data using an Ordered Logit Model to analyze severity relationships and employs Visualization to present findings.
- This approach provides a scalable solution for e-bike safety analytics by converting narrative reports into structured, actionable insights.


---

[Agents of Change: Self-Evolving LLM Agents for Strategic Planning](http://arxiv.org/abs/2506.04651v1)

- LLM Self-Evolving Agent Framework: introduces self-evolving LLM agents for strategic planning in Settlers of Catan, including BaseAgent (Input, Interface, Decision maker, Output), StructuredAgent (Input, Input structuring, Interface, Decision maker, Output), PromptEvolver (Coordinator, Game player, Intelligence, Intelligence, External access, Memory, Instruction, Feedback, Feedback processing, Game outcome, Interface), and AgentEvolver (Coordinator, Evaluator, Information gatherer, Code modifier, Advisor, Game player, Intelligence, Intelligence, Intelligence, Intelligence, Intelligence, Intelligence, External access, Reasoning, Instruction processing, Input, Game outcome, Interface).
- The framework benchmarks four agent architectures with increasing self-improvement capabilities against a strong heuristic baseline in the Catanatron simulator.
- Self-evolving agents, particularly PromptEvolver and AgentEvolver, demonstrate improved strategic planning and performance over static baselines through iterative prompt and code refinement.


---


[FLEX-TRAVELPLANNER: A BENCHMARK FOR FLEXIBLE PLANNING WITH LANGUAGE AGENTS](http://arxiv.org/abs/2506.04649v1)

- Flex-TravelPlanner: introduces a benchmark for evaluating language agents in dynamic, multi-turn planning scenarios, using a pipeline with Initial Constraint (Start planning with constraints), Adding Constraint (Introduce new constraints), Revising Constraint (Modify existing constraints), and Fin (End of planning process) steps.
- The framework evaluates how well agents adapt plans as new requirements or changes are introduced over multiple interactions.
- It specifically addresses the challenges of constraint addition and revision, mirroring real-world planning dynamics.


---

[Advancing Tool-Augmented Large Language Models via Meta-Verification and Reflection Learning](http://arxiv.org/abs/2506.04625v1)

- Tool-MVR: introduces a novel Tool-Augmented LLM framework that enhances System 2 reasoning capabilities by employing MAMV (Data verification pipeline) for high-quality data generation (ToolBench-V, Verified instruction dataset) and EXPLORE (Reflection learning algorithm) for learning from errors (ToolBench-R, Reflection dataset), utilizing a Base LLM (Base model) interacting with APIs (External tools) based on User Query (Input), generating Reasoning Trajectory (Step-by-step process) and Final Answer (Output) informed by Observation (Tool feedback).
- The MAMV pipeline consists of APIOptAgent (API verification/optimization agent), QueryVerifyAgent (Query assessment/filtering agent), and APICallAgent (Trajectory generation/verification agent) to ensure data quality for tool planning and invocation.
- EXPLORE enables the model to learn adaptive tool reflection by leveraging tool feedback through an Error → Reflection → Correction paradigm.


---

[SmartAvatar: Text- and Image-Guided Human Avatar Generation with VLM AI Agents](http://arxiv.org/abs/2506.04606v1)

- SmartAvatar: introduces a vision-language-agent-driven framework for generating 3D human avatars, utilizing a Descriptor (Extracts attributes), Generator (Synthesizes code), Evaluator (Checks alignment), Refiner (Adjusts code), Human Generator (Parametric avatar model), and Blender (Rendering environment).
- The system incorporates a VLM-guided auto-verification loop that iteratively refines generated avatars to match user input across visual and semantic criteria.
- SmartAvatar supports diverse inputs including text, image, and multimodal combinations, enabling conversational editing for customizable, animation-ready avatars.


---

[Demonstrations of Integrity Attacks in Multi-Agent Systems](http://arxiv.org/abs/2506.04572v1)

- Multi-Agent System (MAS): introduces integrity attacks where malicious agents manipulate system operations and evaluation outcomes within systems comprising Coder, Tester, Reviewer, WebSearcher, and Monitor components.
- These attacks, including Self-Dealer, Free-Rider, Scapegoater, and Boaster, exploit inter-agent communication and the Monitor's evaluation process.
- The research demonstrates that these manipulations can bias agent behavior and evaluation scores while maintaining overall task performance.


---

[OpenAg: Democratizing Agricultural Intelligence](http://arxiv.org/abs/2506.04571v1)

- OpenAg: introduces, "a comprehensive framework designed to advance agricultural artificial general intelligence", with Multi-Modal Knowledge Ingestion, Unified Agriculture Knowledge Base, Neural Agricultural Knowledge Graph Generation, Adaptive Multi-agent Reasoning System, Causal Agricultural Decision Transparency, and Adaptive Agricultural Transfer Learning components, where "it integrates diverse data flows and advanced reasoning".
- The framework aims to deliver context-aware, explainable, and actionable insights for agricultural decision support.
- OpenAg bridges the gap between scientific knowledge and farmer expertise to support scalable and locally relevant decision-making.


---

[From Standalone LLMs to Integrated Intelligence: A Survey of Compound AI Systems](http://arxiv.org/abs/2506.04565v1)

- CAIS (Compound AI Systems): introduces a framework integrating LLMs with external components and orchestration, categorized into RAG, LLM Agents, and MLLMs, to overcome standalone LLM limitations.
- The framework leverages components like retrievers, agents, tools, and multimodal encoders, coordinated by orchestration strategies, for complex tasks.
- The survey provides a taxonomy, architectural analysis, evaluation framework, and research agenda for these modular, composable AI systems.


--




#### 4th June 2025

[CogMath: Assessing LLMs' Authentic Mathematical Ability from a Human Cognitive Perspective](http://arxiv.org/abs/2506.04481v1)

- CogMath: introduces a framework for assessing LLMs' mathematical abilities using an Inquiry agents (Pose dimension-specific inquiry), Judge agents (Evaluate inquiry quality), Reference agents (Provide correct answer), and Evaluated LLM (Model being assessed) system across human cognitive stages.
- The framework evaluates LLMs by posing dimension-specific inquiries generated and refined by agents, comparing the LLM's response to a reference answer.
- This multi-agent system allows for a fine-grained assessment of LLMs' performance across nine dimensions within problem comprehension, solving, and summarization stages.


---


[MedAgentGym: Training LLM Agents for Code-Based Medical Reasoning at Scale](http://arxiv.org/abs/2506.04405v1)

- MedAgentGym: introduces a unified training environment for enhancing coding-based medical reasoning in LLM agents, featuring an LLM Agent (Model trained/evaluated), Coding Environment (Isolated executable containers), Interactive Feedback Mechanism (Processes, executes, translates errors), Data Resources (Task datasets), Trajectory Collection (Samples, stores interactions), and Verifier (Evaluates trajectory success).
- The environment includes 72,413 tasks from 12 real-world biomedical scenarios, encapsulated in isolated, executable coding environments with interactive feedback.
- MedAgentGym supports scalable training trajectory generation and extensive benchmarking of LLMs for code-based medical reasoning.


---


[SuperWriter: Reflection-Driven Long-Form Generation with Large Language Models](http://arxiv.org/abs/2506.04180v1)

- SuperWriter-Agent: introduces an agent-based framework for long-form text generation with Stage 1: Plan (Structured planning), Stage 2: Write (Paragraph generation), and Stage 3: Refine (Iterative refinement) stages, utilizing AI commentators (Discuss ideas), Writer (Develops plan, writes), Thinker (Plans paragraph), Checker (Reviews text), and Refiner (Revises text) agents.
- The framework generates training data for SuperWriter-LM (Language model), which is optimized using Hierarchical DPO (Multi-stage optimization) guided by MCTS (Explores paths) and a Judge LLM (Scores outputs).
- This approach simulates human writing processes to enhance coherence, consistency, and quality in long-form text generation.


---

[TracLLM: A Generic Framework for Attributing Long Context LLMS](http://arxiv.org/abs/2506.04202v1)

- TracLLM (Generic Framework for Attributing Long Context LLMs): introduces a generic context traceback framework, with Instruction, Context, LLM, Output, Iterative Search, Group Division, Score Computation, Group Pruning, Score Denoising, Score Ensemble, and Attribution Method components, designed to efficiently and accurately identify texts in a long context contributing to an LLM's output.
- The framework employs an informed search algorithm that iteratively divides and prunes text groups based on contribution scores calculated by a feature attribution method.
- TracLLM enhances accuracy through contribution score denoising and ensemble techniques, demonstrating effectiveness in post-attack forensic analysis and debugging LLM systems.


---

[TRISM FOR AGENTIC AI: A REVIEW OF TRUST, RISK, AND SECURITY MANAGEMENT IN LLM-BASED AGENTIC MULTI-AGENT SYSTEMS](http://arxiv.org/abs/2506.04133v1)

- TRISM (Trust, Risk, and Security Management): introduces a structured framework for LLM-based agentic multi-agent systems, including Governance, Explainability, ModelOps, Application Security, and Model Privacy components.
- This framework addresses unique trust, risk, and security challenges posed by autonomous, collaborative, and evolving agent behaviors in high-stakes domains.
- The paper provides a comprehensive review, risk taxonomy, trust-building mechanisms, security/privacy methods, and a roadmap for responsible agentic AI deployment.


---

[AmbiK: Dataset of Ambiguous Tasks in Kitchen Environment](http://arxiv.org/abs/2506.04089v1)

- AmbiK Dataset and Evaluated Methods: introduces AmbiK Dataset (textual benchmark), Ambiguity Detection Methods (algorithms for deciding help), Large Language Models (LLMs) (process language, predict actions), Conformal Prediction (CP) (forms prediction sets), and Uncertainty Estimation (quantifies confidence), presenting AmbiK, a textual dataset for evaluating ambiguity detection methods for embodied AI in kitchen environments.
- The paper evaluates several existing ambiguity detection methods, including CP-based (KnowNo, LAP, LofreeCP) and non-CP based (Binary, No Help), utilizing various LLMs on the AmbiK dataset.
- Experiments demonstrate that current methods and LLMs face significant challenges in effectively handling ambiguity on the AmbiK benchmark, particularly in distinguishing ambiguous from unambiguous tasks.


---

[AI Agents for Conversational Patient Triage: Preliminary Simulation-Based Evaluation with Real-World EHR Data](http://arxiv.org/abs/2506.04032v1)

- AI Triage (multi-agent system): introduces a multi-agent architecture for conversational patient triage, including Primary agent (Orchestrates other agents), Symptom Collector (Collects patient symptoms), HealthDataPlanner (Plans EHR data retrieval), HealthDataRetriever (Retrieves EHR data), Summary (Synthesizes case information), Differential Diagnosis (Narrows potential diagnoses), Next Steps (Provides care recommendations), Guideline Verifier (Verifies recommendations with guidelines), EHR data (Source of patient records), Clinical Guideline Database (Source of clinical guidelines), and Outputs (Final triage decision), designed to emulate physician reasoning for patient assessment and triage.
- The system interacts with a Patient Simulator, which generates realistic patient conversations from real-world EHR data vignettes for scalable evaluation.
- The multi-agent design enhances interpretability and control, while the Guideline Verifier adds a layer of safety by grounding recommendations in clinical best practices.


---

[AgentMisalignment: Measuring the Propensity for Misaligned Behaviour in LLM-Based Agents](http://arxiv.org/abs/2506.04018v1)

- LLM-based Agent: introduces AgentMisalignment, a benchmark suite evaluating the propensity for misaligned behavior in LLM-based agents, which integrate a Large Language Model within an Interactive Scaffold, enabling them to use Tools, store Memory, interact via Environment Interfaces, and operate through an Operational Loop influenced by System Prompts and Reflective Prompts.
- The benchmark uses the InspectAI framework and a Comprehensive Misalignment Scoring (CMS) mechanism to quantify misaligned actions across various realistic scenarios.
- Evaluations reveal that both model choice and personality prompts significantly influence agent misalignment tendencies, highlighting the importance of careful prompt engineering.


---

[Graph Counselor: Adaptive Graph Exploration via Multi-Agent Synergy to Enhance LLM Reasoning](http://arxiv.org/abs/2506.03939v1)

- Graph Counselor: introduces a multi-agent collaborative reasoning framework with AGIEM (Graph information extraction), Planning Agent (Establishes reasoning path), Thought Agent (Refines extraction scope), Execution Agent (Executes graph functions), Retrieve (Finds node by keyword), Feature (Gets node attribute), Degree (Gets neighbor count), Neighbour (Lists neighbors), SR (Self-reflection and correction), and Judgment Module (Evaluates reasoning correctness) to enhance LLM reasoning on knowledge graphs.
- The framework utilizes an Adaptive Graph Information Extraction Module (AGIEM) with three agents for dynamic graph information extraction and a Self-Reflection (SR) module for improving reasoning reliability.
- Graph Counselor employs a multi-round iterative process involving planning, thought, execution, and reflection to adaptively extract graph knowledge and refine reasoning.


---

[PulseReddit: A Novel Reddit Dataset for Benchmarking MAS in High-Frequency Cryptocurrency Trading](http://arxiv.org/abs/2506.03861v1)

- MAS (Multi-Agent Systems): introduces PulseReddit, a novel dataset aligning Reddit discussions with high-frequency cryptocurrency market data, and evaluates LLM-based MAS performance using Reddit API (Data source), Raw Posts (Unprocessed data), Data Preprocess (Cleaning, filtering data), Structured Data (Processed data format), Market Analyst (Analyzes on-chain metrics), News Analyst (Analyzes off-chain signals), Trading Agent (Synthesizes inputs, decides action), and Reflection Agent (Analyzes performance, refines strategy).
- The MAS framework, based on CryptoTrade, leverages specialized agents to integrate on-chain and off-chain signals for high-frequency cryptocurrency trading decisions.
- Experiments show MAS augmented with PulseReddit data outperform traditional baselines, particularly in bull markets, demonstrating the value of social sentiment in HFT.


---

[AssetOpsBench: Benchmarking AI Agents for Task Automation in Industrial Asset Operations and Maintenance](http://arxiv.org/abs/2506.03828v1)

- AssetOpsBench: introduces a unified framework and environment for benchmarking AI agents in industrial asset operations, including a global coordinator, specialized agents, memory, task planning, and iterative execution.
- The framework supports multi-agent architectures like Agents-As-Tool and Plan-and-Execute, utilizing components such as planners, orchestrators, reviewers, and summarization modules.
- AssetOpsBench provides a multi-source dataset and automated evaluation framework to assess agent performance on real-world industrial tasks requiring perception, reasoning, and control.


---

[From Theory to Practice: Real-World Use Cases on Trustworthy LLM-Driven Process Modeling, Prediction and Automation](http://arxiv.org/abs/2506.03801v1)

- Three-module AI solution: introduces a framework integrating ML, UQ, XAI, and multi-agent LLMs to transform opaque predictions into auditable, interactive workflows.
- The framework grounds explanations in MES event logs and enables natural language dialogues for real-time validation and adaptation.
- It employs a multi-agent LLM architecture with RAG to provide context-aware recommendations and ensure consistency.


---

[Orak: A Foundational Benchmark for Training and Evaluating LLM Agents on Diverse Video Games](http://arxiv.org/abs/2506.03610v1)

- Orak: introduces a foundational benchmark for training and evaluating LLM agents across diverse video games, with Environment (12 diverse video games), LLM Agent (Evaluated gameplay agent), LLMs (Backbone language models), Agentic Modules (Strategies like reflection, planning), MCP Interface (Plug-and-play connection protocol), Evaluator (Manages game loop, scoring), and Fine-tuning Dataset (Expert gameplay trajectories).
- The benchmark utilizes a plug-and-play MCP interface to connect LLM agents with diverse game environments and agentic modules for consistent evaluation.
- Orak provides a comprehensive evaluation framework including leaderboards, battle arenas, and studies on agentic modules and fine-tuning effects, supported by a dataset of expert gameplay trajectories.


---

[CogniPair: From LLM Chatbots to Conscious AI Agents - GNWT-Based Multi-Agent Digital Twins for Social Pairing - Dating & Hiring Applications](http://arxiv.org/abs/2506.03543v1)

- GNWT-Agent Cognitive Architecture: introduces a computational implementation of Global Workspace Theory, featuring Input Processing, Feature Extraction, Module Salience, specialized Cognitive Modules (Emotion, Memory, Planning, Social Norms, Goal Tracking), Global Workspace Integration, Persistent Memory, and Response Generation for creating psychologically realistic AI agents.
- This architecture enables parallel processing across modules, dynamic salience-based attention, global workspace broadcasting for integration, and persistent memory for state evolution, addressing psychological and social behavior gaps in LLM agents.
- Deployed within the CogniPair system for social simulations like dating and hiring, the GNWT-Agent demonstrates unprecedented psychological realism and human-like behavioral evolution compared to baselines.


---

[Debate, Reflect, and Distill: Multi-Agent Feedback with Tree-Structured Preference Optimization for Efficient Language Model Enhancement](http://arxiv.org/abs/2506.03541v1)

- Debate and Reflect (D&R): introduces a framework that orchestrates multi-turn Debate (Multi-turn interaction) between Teacher Models (Stronger models) and a Student Model (Smaller model), incorporating Self-Reflection (Student self-analysis) and Teacher Feedback (Teacher critiques), recording interactions in a Multi-Agent Interaction Graph (MAG) (Records debate content) to construct a Preference Tree (Hierarchical structure for training) for Distillation (Knowledge transfer process) into Distilled Models (Student after training).
- The framework leverages debate logs and Tree-structured Direct Preference Optimization (T-DPO) to efficiently transfer knowledge and reasoning abilities from teachers to the student model.
- Empirical evaluations show that the approach significantly improves smaller model accuracy, robustness, and generalization compared to conventional baselines.


---

[VChatter: Exploring Generative Conversational Agents for Simulating Exposure Therapy to Reduce Social Anxiety](http://arxiv.org/abs/2506.03520v1)

- VChatter: introduces a multi-agent system for simulating exposure therapy, with Agent-P (Psychotherapist agent), Agent-H (Interactive human agent), Large Language Model (Text generation), Text-to-Voice Model (Speech output), 3D Virtual Character Models (Agent avatars), Chat Interface (User interaction), and Scenario List (Scenario management).
- The system utilizes LLMs to power conversational agents that guide users through personalized exposure therapy plans and simulate social interactions in various scenarios.
- VChatter aims to provide a safer and more accessible environment for individuals with social anxiety to practice coping mechanisms and reduce avoidance behaviors.


---

[Reason from Future: Reverse Thought Chain Enhances LLM Reasoning](https://arxiv.org/abs/2506.03673)

- Reason from Future (RFF): introduces a novel reasoning paradigm that enhances LLM reasoning by integrating bidirectional reasoning, utilizing a Last Step Generator (generates last previous step), Stepwise Forward Reason (generates next forward step), State Check (determines termination conditions), and Verifier (verifies path correctness) to generate a solution path.
- RFF alternates between reverse thinking to guide forward reasoning, aiming to obtain a future perspective and narrow the solution search space.
- The framework demonstrates improved accuracy and efficiency on complex tasks by constraining reasoning to target-driven states and mitigating error accumulation.


---


#### 3rd June 2025

[S4-Driver: Scalable Self-Supervised Driving Multimodal Large Language Model with Spatio-Temporal Visual Representation](https://arxiv.org/abs/2505.24139)

- S4-Driver: introduces a scalable self-supervised motion planning method, with Camera Images, Image Encoder, Image features, Sparse Volume Representation, Historical ego-states, High-level behavior, Text prompt, Tokenize, Multimodal Encoder, Multimodal Decoder, Hierarchical Planning, Meta-decision, Multi-decoding, Nucleus sampling, Multi-output aggregation, where S4-Driver predicts ego-vehicle waypoints from camera images and text prompts using a multimodal large language model enhanced with spatio-temporal visual representation and hierarchical planning.
- The framework employs a novel sparse volume representation to aggregate multi-view and multi-frame visual information, enhancing 3D reasoning for motion planning.
- Self-supervised training with ego-vehicle trajectory supervision and multi-decoding aggregation improves performance and scalability without requiring human annotations for intermediate tasks.


---

[Why do AI agents communicate in human language?](https://arxiv.org/abs/2506.02739)

- Native Multi-Agent Model Paradigm: introduces a paradigm shift for multi-agent systems, proposing Role Persistence Mechanism, Structured Communication Mechanism, Inter-Agent State Synchronization Mechanism, Functional Decoupling, Explicit Coordination Graph, and Semantic Identity Separation Mechanism.
- The paper argues that relying on natural language for inter-agent communication in current LLM-based systems introduces fundamental limitations due to semantic misalignment and architectural incompatibility.
- The proposed paradigm aims to build multi-agent systems with native collaborative capabilities by incorporating structural mechanisms for semantic alignment and coordination fidelity.


---

[FailureSensorIQ: A Multi-Choice QA Dataset for Understanding Sensor Relationships and Failure Modes](https://huggingface.co/papers/2506.03278)

- FailureSensorIQ (Multi-Choice Question-Answering benchmarking system): introduces FailureSensorIQ Dataset (benchmark data), LLMs (models evaluated), Evaluation Module (measures performance), Prompting (input formatting), Perturbation Pipeline (dataset variations), ReAct Agent (LLM with tools), External Knowledge Sources (retrieval resources), where FailureSensorIQ is a benchmarking system designed to assess LLMs' reasoning on industrial domain QA using a novel dataset.
- The system utilizes a Dataset Generation Pipeline to create the FailureSensorIQ Dataset from expert knowledge and evaluates LLMs using various Prompting strategies and an Evaluation Module, including tests with a Perturbation Pipeline and a ReAct Agent accessing External Knowledge Sources.
- Evaluation on the benchmark reveals LLMs struggle with domain-specific reasoning and robustness under dataset perturbations, highlighting the challenge and need for improved LLM capabilities in industrial settings.


---

[Co-Evolving LLM Coder and Unit Tester via Reinforcement Learning](http://arxiv.org/abs/2506.03136v1)

- CURE: introduces a novel reinforcement learning framework where a Policy (LLM agent) acts as both a Code Generator (Generates code) and Unit Test Generator (Generates tests), evaluated by an Execution Engine (Runs code/tests), guided by a Reward Model (Calculates reward), and optimized by a Reinforcement Learning Optimizer (Optimizes policy) for co-evolution.
- This approach allows the unit tester to learn from the coder's errors without requiring ground-truth code supervision, enhancing flexibility and scalability.
- A response-length-guided transformation is applied to the unit test reward for long-CoT models to improve inference efficiency.


---

[DPO Learning with LLMs-Judge Signal for Computer Use Agents](https://arxiv.org/abs/2506.03095)

- LLM-as-Judge DPO Pipeline: introduces a method for training lightweight GUI agents using an LLM-as-Judge to score sampled responses, generating preference data for DPO fine-tuning.
- The pipeline involves sampling answers from the policy model, scoring them using GPT-40 as the judge, and pairing the scored responses and ground truth to create a dataset for Direct Preference Optimization.
- This approach enables training a compact, local-first GUI agent (UI-TARS-2B) without extensive human labeling, addressing privacy and resource efficiency concerns.


---

[How much do language models memorize?](https://arxiv.org/abs/2505.24832)

- Language Model Memorization Measurement: introduces a new method to estimate how much a language model knows about a datapoint.
- The method formally separates memorization into unintended memorization (dataset information) and generalization (data-generation process information).
- Using information theory and model likelihoods, the approach measures model capacity and analyzes scaling laws for memorization and membership inference in Transformer models.


---


[MAEBE: Multi-Agent Emergent Behavior Framework](https://arxiv.org/abs/2506.03053)

- MAEBE (Multi-Agent Emergent Behavior Evaluation framework): introduces a research structure with Agents (Individual LLMs), Round Robin Topology (Sequential chat topology), Star Topology (Supervisor-agent topology), Supervisor (Guides agents), Shared Chat (Common communication channel), MAS Configuration Parameters (Adjustable MAS settings), and LaaJ (LLMs-as-a-Judge) to systematically assess emergent risks in multi-agent LLM ensembles.
- The framework utilizes different MAS topologies and configurations to study group dynamics and compare ensemble behavior to isolated agents.
- LaaJ is employed as a scalable evaluation tool to classify agent responses and identify system-level behaviors like peer pressure.


---

[QUANTUM AGENTS](https://arxiv.org/abs/2506.01536)

- Quantum Agent System Architecture: introduces a modular framework for quantum agents, with SystemCore (defines identity/rules), InterfaceManager (handles communication), ClassicalProcessor (classical computation), LLMEngine (reasoning/generation), QuantumProcessor (quantum computation), MemorySubsystem (stores memory), ExternalInterface (external tools/data), MCPProtocol (communication protocol), GuardrailsModule (safety/security), and MonitoringSystem (logging/auditing), designed to integrate quantum computing with agent-based systems.
- The architecture combines classical logic, quantum operations, safety mechanisms, and external interfaces to enable intelligent, auditable agent behavior.
- The paper defines quantum agents, outlines potential architectures, and presents prototypes demonstrating feasibility and use cases like quantum-enhanced decision-making and AI-driven quantum workflow orchestration.


---

[Helpful Agent Meets Deceptive Judge: Understanding Vulnerabilities in Agentic Workflows](http://arxiv.org/abs/2506.03332v1)

- Agentic Workflow: introduces a system with Generator (Produces, revises answers), Judge (Evaluates, critiques answers), Feedback Mechanism (Enables interaction, revision), and Knowledge Sources (Judge's information access), analyzing vulnerabilities under deceptive feedback.
- The paper categorizes judge behavior by intent (constructive/deceptive) and knowledge level (parametric/grounded) to systematically study vulnerabilities.
- A new benchmark, WAFER-QA, is introduced to evaluate agent robustness against grounded adversarial critiques supported by web evidence.


---


[Towards Analyzing and Understanding the Limitations of VAPO: A Theoretical Perspective](https://arxiv.org/abs/2506.03038)

- VAPO: introduces a value-model-based augmented proximal policy optimization framework for enhancing large language models in long-chain-of-thought reasoning, utilizing a Value function (predicts future rewards), Policy (generates actions), Decoupled GAE (uses different lambda for critic and actor), Monte Carlo targets (unbiased value estimates), and Length-Adaptive GAE (actor lambda adjusts with sequence length).
- The framework trains the value function on Monte Carlo returns using a Decoupled GAE with lambda=1 for the critic and updates the policy using a Length-Adaptive GAE.
- This paper theoretically analyzes VAPO's potential limitations in modeling deep long-term value for fine-grained policy guidance, focusing on credit assignment, value function representation, and translating global value signals.


---

[TestAgent: An Adaptive and Intelligent Expert for Human Assessment](https://arxiv.org/abs/2506.03032)

- TestAgent: introduces an LLM-powered agent for adaptive testing, with Universal Data Infrastructure (Establish question bank), TestAgent Planning (Outlines workflow), and Report Generation (Generate diagnosis reports) modules.
- The TestAgent Planning module iteratively generates conversational questions, processes Tester Responses (Test-taker answers questions) via Autonomous Feedback Mechanism (Assess response validity) and Anomaly Management (Handle anomalous responses), updates Cognitive Diagnosis (Assess test-taker ability), and uses Adaptive Question Selection (Select next question).
- The Universal Data Infrastructure prepares the Question Bank (Stores questions) through Domain Verification (Determine test dimensions), Data Integration (Integrate data, estimate features), and Cognitive Diagnosis Training (Train cognitive model), while Report Generation utilizes Neural Architecture (Initial analysis module) and Expert Analysis (Combine analysis for report) to produce the Diagnosis Report (Final test outcome).


---

[Mitigating Manipulation and Enhancing Persuasion: A Reflective Multi-Agent Approach for Legal Argument Generation](https://arxiv.org/abs/2506.02992)

- RMA (Reflective Multi-Agent): introduces a reflective multi-agent framework for legal argument generation, employing an Argument Developer, Factor Analyst, and Argument Polisher in an Iterative Workflow using Case Factors.
- The framework utilizes iterative reflection and specialized agents to improve factual grounding, reduce hallucination, enhance factor utilization, and promote abstention when arguments are untenable.
- Empirical evaluation demonstrates the framework's superiority in successful abstention and hallucination accuracy, contributing to more ethically persuasive and less manipulative legal AI.


---

[Adaptive Graph Pruning for Multi-Agent Communication](https://arxiv.org/abs/2506.02951)

- AGP (Adaptive Graph Pruning): introduces a task-adaptive multi-agent collaboration framework featuring an AGP Network (Learns pruning policy) with a Node Encoder (Embeds agent and task), GCN backbone (Processes graph features), Edge-weight head (Soft-pruning), and Node-mask head (Hard-pruning), which selects agents from an Agent Pool (Set of LLM agents) and is trained using a Graph Pool (Supervision dataset).
- The framework jointly optimizes agent quantity and communication topology dynamically based on task complexity.
- AGP achieves high performance and token efficiency by pruning both nodes and edges in the multi-agent communication graph.


---

[A MULTI-AGENT LLM-BASED JUIT TEST GENERATION WITH STRONG ORACLES](https://arxiv.org/abs/2506.02943)

- CANDOR: introduces a multi-agent LLM-based framework for automated JUnit test generation, utilizing Initializer, Validation, Planner, Tester, Inspector, Requirement Engineer, Panelist, Interpreter, and Curator agents to collaboratively generate and refine test cases and accurate oracles.
- The framework operates in three steps: Initialization for a syntactically correct base, Test Prefix Generation for coverage enhancement, and Oracle Fixing for correcting assertions using a panel discussion approach.
- CANDOR employs specialized LLM agents and a dual-LLM pipeline to mitigate hallucination and verbosity, improving test prefix quality and oracle accuracy without external tools or fine-tuning.


---

[Large Processor Chip Model](https://arxiv.org/abs/2506.02929)

- LPCM (Large Processor Chip Model): introduces an LLM-driven framework for end-to-end automated computer system architecture design, including Binary Translation Agent, Query Agent, Compiler Agent, SW/HW Partitioning Agent, CPU DSE Agent, Co-Processor DSE Agent, Simulator Agent, HDL Generation Agent, PPA Prediction & Code Optimization Agent, Constraints, Inputs, and Outputs.
- The framework integrates multiple LLM-based agents to handle tasks across the full technology stack, from high-level requirements to low-level hardware implementation.
- LPCM aims to achieve multi-level, cross-domain co-optimization and autonomous design by leveraging LLMs and domain-specific data.


---

[It's the Thought that Counts: Evaluating the Attempts of Frontier LLMs to Persuade on Harmful Topics](https://arxiv.org/abs/2506.02873)

- APE (Attempt to Persuade Eval): introduces a benchmark evaluating large language models' willingness to attempt persuasion on harmful topics using a multi-turn conversational setup with a Persuader Model, Persuadee Agent, Evaluator Model, and StrongREJECT Model interacting over diverse Topic Statements, logging the Conversation, Initial Persuadee Belief, Persuasion Attempt Label, Refusal Label, and optional Updated Persuadee Belief.
- The framework simulates interactions between a model under test attempting persuasion and a simulated human agent, with automated models assessing persuasive attempts and explicit refusals per turn.
- APE focuses on evaluating the propensity to persuade across a spectrum of topics, including harmful ones, to assess safety guardrail robustness rather than measuring persuasion success.


---


[ATAG: AI-Agent Application Threat Assessment with Attack Graphs](https://arxiv.org/abs/2506.02859)

- ATAG (AI-Agent Application Threat Assessment with Attack Graphs): introduces a framework for structured security analysis of LLM-based multi-agent applications, including Agent Modeler, Vulnerability Mapper, Attack Graph Generator, and Attack Graph Analyzer modules, leveraging MulVAL, LVD, AI-agent Interaction Rules (IRs), MulVAL Facts, and Attack Graph (AG).
- The framework extends MulVAL with specific facts and interaction rules to model unique architectural components and vulnerabilities in AI-agent applications.
- ATAG utilizes the LLM Vulnerability Database (LVD) to incorporate LLM-specific vulnerabilities and automatically generates detailed attack graphs depicting potential sequences of actions.


---

[TaxAgent: How Large Language Model Designs Fiscal Policy](https://arxiv.org/abs/2506.02838)

- TaxAgent: introduces a taxation evaluation framework, with TaxAgent (government agent), H-Agents Group (household agents), and Macroeconomic Simulation Environment (economic model), modeling household-government interactions in an evolving economy.
- The framework includes TaxAgent Tax rate adjustment (adjusts tax rates) using an LLM and TaxAgent Iterative Feedback (refines strategy) loop for continuous improvement.
- H-Agents Group (household agents) incorporates H-Agent Decision-Making (decides work/consumption) and H-Agent Self-Reflection (reviews history) modules, while the Macroeconomic Simulation Environment (economic model) includes Production (determines production), Taxation (models taxation), Consumption (models consumption/savings), and Financial Market (models financial market) modules.


---

[Benchmarking and Advancing Large Language Models for Local Life Services](https://arxiv.org/abs/2506.02720)

- LocalInstruction and Expert Agents Approach: introduces a framework for enhancing LLMs for local life services, including Template Agent, Merchant Agent, User Agent, Interaction Description Agent, Instruction Generation Agent, Fine-tuned LLMs, and Expert Agents.
- It employs a multi-agent system (LocalInstruction) to synthesize high-quality instruction tuning data from raw platform data.
- Expert agents leverage the fine-tuned LLMs and agentic workflows to address complex composite tasks in local life services.


---

[Heterogeneous Group-Based Reinforcement Learning for LLM-based Multi-Agent Systems](https://arxiv.org/abs/2506.02718)

- MHGPO (Multi-Agent Heterogeneous Group Policy Optimization): introduces, "optimizes LLM-based multi-agent systems using group-based reinforcement learning without a critic network", with Multi-Agent Search System (LLM agent system), Backbone LLM (single shared model), Agents (specialized LLM roles), Multi-Agent Group Rollout Sampling (generates trajectories using IS/FoF/RR strategies), Backward Reward Propagation (propagates shared rewards), Heterogeneous Group Advantage Estimation (estimates advantage), Reward Function (assigns reward signals), and External Retrieval Tools (search engine) components.
- The framework leverages relative group advantages and a two-phase sampling-propagation strategy to enhance stability and computational efficiency compared to traditional MAPPO.
- Applied to a three-agent search system, the method demonstrates superior performance and scalability for complex LLM-based multi-agent systems.


---

[Decompose, Plan in Parallel, and Merge: A Novel Paradigm for Large Language Models based Planning with Multiple Constraints](https://arxiv.org/abs/2506.02683)

- DPPM (Decompose, Plan in Parallel, and Merge): introduces a novel paradigm for LLM-based multi-constraint planning, utilizing Constraint-aware Task Decomposition (Decomposes task by constraints), Local Plan Generation (Generates subplans in parallel), Incremental Merge (Merges subplans into final plan), Verification and Refinement Module (Iteratively checks/refines plans), LLM Agents (Perform planning and merging), and Constraint Functions (Verify constraint satisfaction).
- The approach decomposes complex tasks based on constraints, plans subtasks in parallel using local agents, and merges subplans into a global solution with iterative verification and refinement.
- DPPM significantly outperforms existing methods on travel planning benchmarks, demonstrating improved handling of heavy constraints and reduced cascading errors.


---

[CyberGym: Evaluating AI Agents' Cybersecurity Capabilities with Real-World Vulnerabilities at Scale](https://arxiv.org/abs/2506.02548)

- CyberGym: introduces a large-scale cybersecurity evaluation framework with Task Inputs, PoC Generation by a Language Model Agent producing a Generated Executable, and PoC Evaluation on Pre-Patch Executable and Post-Patch Executable, evaluating Agent Frameworks using Backbone LLMs within an Execution Environment with various Tools.
- The framework features 1,507 real-world vulnerabilities across 188 software projects to assess AI agents' capabilities in generating proof-of-concept tests for vulnerability reproduction.
- Evaluation results show that state-of-the-art agents achieve limited success rates on complex vulnerabilities but can discover new zero-day vulnerabilities.


---

[Attention Knows Whom to Trust: Attention-based Trust Management for LLM Multi-Agent Systems](https://arxiv.org/abs/2506.02546)

- Trust Management System (TMS): introduces a system for LLM-MAS, with LLM Multi-Agent System, Message-level trust evaluation, Attention matrix, A-Trust models, Trust scores, Trust-aware Action Policy, Thresholds, External verifier, Trust Record, Agent-level trust records, and Trust record utilization, designed to evaluate message trustworthiness and manage agent trust.
- The system leverages attention patterns via A-Trust models to generate trust scores for messages across six dimensions.
- It uses a trust-aware action policy based on thresholds and agent-level trust records to filter untrustworthy messages and identify malicious agents.


---

[Think Twice, Act Once: A Co-Evolution Framework of LLM and RL for Large-Scale Decision Making](https://arxiv.org/abs/2506.02522)

- ACE (Agents Co-Evolution): introduces a co-evolution framework with Act Once (RL interaction phase), RL Agent (Interacts with environment), Environment (Provides states, rewards), Think Twice (LLM refinement phase), LLM as Policy Actor (Refines suboptimal actions), LLM as Value Critic (Performs reward shaping), DRL Buffer (Stores RL transitions), DLLM Buffer (Stores LLM refined transitions), Mix Buffer (Combines DRL/DLLM samples), and Experience Gathering (Collects and mixes data), designed for large-scale decision-making by synergizing LLMs and RL.
- The framework separates LLM reasoning and RL execution into offline training (Think Twice) and online deployment (Act Once) to enable effective learning and real-time performance.
- ACE leverages LLMs in dual roles as Policy Actor and Value Critic during offline training to refine trajectories and shape rewards, improving sample efficiency and solution quality for the RL agent.


---

[To Embody or Not: The Effect Of Embodiment On User Perception Of LLM-based Conversational Agents](https://arxiv.org/abs/2506.02514)

- LLM-based Conversational Agent: introduces a study comparing user perception of LLM-based CAs with and without embodiment, utilizing components like LLM, User Interface, Visual Representation, Text-to-Speech, Facial Animation, and Rendering Engine.
- The study found that the non-embodied agent was perceived as more competent than the embodied agent in non-hierarchical cooperative tasks.
- Qualitative feedback suggested the embodied agent was perceived as more sycophantic, potentially explaining the lower credibility ratings despite similar underlying LLM and prompts.


---

[AURA: Agentic Upskilling via Reinforced Abstractions](https://arxiv.org/abs/2506.02507)

- AURA (Agentic Upskilling via Reinforced Abstractions): introduces a schema-centric curriculum RL framework leveraging LLMs as autonomous curriculum designers, including User Prompt, RoboEnv. Description, Vector Database, VDB Query Agent, Selector Agent, Curriculum LLM, Per-Stage LLM, Schema Check, Curriculum Compiler, Staged RL Training Block, Feedback LLM, Trained Policy, Policy Deployment, and User Evaluation components.
- AURA transforms user prompts into schema-validated YAML workflows and training configurations, enabling reliable and efficient multi-stage RL training for robots.
- The framework utilizes a retrieval-augmented feedback loop with specialized LLM agents and a vector database to design, execute, and refine staged curricula based on prior training results, supporting continuous improvement.


---


[Multimodal DeepResearcher: Generating Text-Chart Interleaved Reports From Scratch with Agentic Framework](https://arxiv.org/abs/2506.02454)

- Multimodal DeepResearcher: introduces an agentic framework for generating text-chart interleaved reports from scratch, utilizing Researching, Exemplar Textualization, Planning, and Multimodal Report Generation stages, enabled by Formal Description of Visualization (FDV) and iterative refinement.
- The framework employs in-context learning from human expert reports textualized via FDV and uses LLM and Multimodal LLM agents for research, planning, and generation.
- This approach addresses the challenge of generating multimodal reports by effectively integrating text and diverse visualizations, demonstrating superior performance over baseline methods.


---

[From Anger to Joy: How Nationality Personas Shape Emotion Attribution in Large Language Models](https://arxiv.org/abs/2506.02431)

- Experimental Framework: introduces, with Large Language Models (Process text), Persona Assignment (Configure identity), Prompting Templates (Structure input), Emotional Scenarios (Provide stimuli), Response Handling (Filter output), and Analysis Module (Evaluate results), a method to investigate how nationality-specific personas influence emotion attribution in large language models.
- The framework utilizes multiple LLMs, nationality and gender personas, and emotional scenarios from the ISEAR dataset to analyze attribution patterns and compare them to human responses.
- The analysis module performs both qualitative and quantitative evaluations to identify regional and gender-based biases and assess alignment with cultural norms.


---

[Comparative Analysis of AI Agent Architectures for Entity Relationship Classification](https://arxiv.org/abs/2506.02426)

- Generator-Reflection Architecture, Hierarchical Multi-Agent Architecture, Dynamic-Example Generator Agent: introduces a comparative analysis of three distinct AI agent architectures for entity relationship classification using LLMs, incorporating reflective critique, hierarchical specialization, and adaptive example construction.
- The study evaluates these architectures across financial, scientific, and general domains, demonstrating performance gains over standard prompting baselines.
- The multi-agent strategies achieve competitive results with fine-tuned systems without requiring task-specific training, highlighting their flexibility and generalization capabilities.


---

[Evaluating LLM Agent Adherence to Hierarchical Safety Principles: A Lightweight Benchmark for Probing Foundational Controllability Components](https://arxiv.org/abs/2506.02357)

- Benchmark Methodology: introduces a method to evaluate LLM agents, with LLM Agent, MiniGrid Environment, System Prompt, and User Prompt components, where the LLM Agent interacts with the MiniGrid Environment guided by prompts containing core principles and tasks.
- The methodology tests the agent's adherence to hierarchical safety principles presented via the system prompt when faced with potentially conflicting tasks from the user prompt within the grid world environment.
- This benchmark provides empirical data on LLM agent controllability and instruction following under principle conflict scenarios.


---

[DIAMOND: An LLM-Driven Agent for Context-Aware Baseball Highlight Summarization](https://arxiv.org/abs/2506.02351)

- DIAMOND (An LLM-Driven Agent for Context-Aware Baseball Highlight Summarization): introduces a framework for baseball highlight summarization that integrates structured sports analytics with natural language reasoning, including Preparation, Decision, and Reflection stages.
- The Preparation Stage processes game data and computes sabermetric metrics, the Decision Stage scores and ranks plays using LLM insights, and the Reflection Stage finalizes selection based on user preferences.
- The framework combines quantitative sabermetrics (WPA, WE, LI) with qualitative LLM analysis for context-aware and narratively coherent highlight generation.


---


#### 2nd June 2025

[Biomni: A General-Purpose Biomedical AI Agent](https://www.biorxiv.org/content/10.1101/2025.05.30.656746v1.full.pdf)

- Biomni: introduces a general-purpose biomedical AI agent with Biomni-E1 (Environment) and Biomni-A1 (Agent), designed to autonomously execute diverse biomedical research tasks.
- Biomni-E1 provides a unified action space comprising specialized tools, software packages, and databases, curated via an Action Discovery Agent and Expert Curation.
- Biomni-A1 leverages LLM-based reasoning, a retrieval system, adaptive planning, and code execution within an interactive coding environment to dynamically compose and carry out complex biomedical workflows.


---


[CONFETTI: Conversational Function-Calling Evaluation Through Turn-Level Interactions](https://arxiv.org/abs/2506.01859)

- CONFETTI: introduces a conversational function-calling evaluation benchmark, including User, Agent, APIs, Environment, Conversation Trajectory, Data Collection, Evaluation Metrics, LLM Judge, LLM Classifier, and Models Evaluated, designed to assess LLMs in complex conversational scenarios.
- The benchmark uses human-simulated multi-turn conversations with various complexities and evaluates function-calling and response quality at the turn level.
- Evaluation metrics include AST soft accuracy for function calls, parameter hallucination detection using an LLM judge, and response quality assessed via dialog act classification using an LLM classifier.


---

[Beyond Static Responses: Multi-Agent LLM Systems as a New Paradigm for Social Science Research](https://arxiv.org/abs/2506.01839)

- LLM-Agentic System Continuum: introduces a six-tier framework for understanding LLM-based agents in social science research, progressing from static tools to fully agentic systems capable of simulating emergent social dynamics.
- The framework is structured by functional thresholds like memory integration, autonomy, coordination, and learning, mapping to OODA loop phases and requiring architectural components such as memory stores, tool use, orchestration layers, and adaptive learning mechanisms.
- This continuum provides a conceptual foundation for classifying existing systems and guiding the development of LLM-based simulations for exploring social behavior and generating synthetic data.


---

[LAM SIMULATOR: Advancing Data Generation for Large Action Model Training via Online Exploration and Trajectory Feedback](https://arxiv.org/abs/2506.02298)

- LAM SIMULATOR: introduces a comprehensive framework for generating training data for Large Action Models, featuring Query Instance Generation, Trajectory Synthesis, LLM Agent, Environment, Action handler, Sandbox, Observation, Candidate trajectories, Trajectory filtering, and Final trajectories.
- The framework automates data generation through online exploration and programmatic feedback, reducing reliance on manual data curation for LAM training.
- LAM SIMULATOR enables LLM Agents to explore tasks, receive real-time feedback, and generate high-quality action trajectories used for training LAMs.


---

[Composable Building Blocks for Controllable and Transparent Interactive AI Systems](https://arxiv.org/abs/2506.02262)

- Composable Building Blocks Architecture: introduces a 5-layer architecture with Layer 1 Structural Building Blocks (conceptual system components), Layer 2 Interactive System API (callable interface), Layer 3 Visual Building Blocks (visual explanations/controls), Layer 4 User Interface (integrates blocks for users), and Layer 5 Agents (users and LLMs), representing interactive AI systems as structural blocks explained by visual blocks via an API.
- The architecture includes ML Pipeline Components (Dataset, Splitter, Aggregator, Models) and Control Mechanisms (Non Goal Filter, Divine Rule Guard) as structural blocks, explained by Visual Explanations (LIME, SHAP, WhatIf) and Visual Controls (Table, Ensemble).
- This framework provides a shared knowledge base of system architecture and behavior, enabling both human users and LLM agents to understand and control interactive AI systems.


---


[Small Language Models are the Future of Agentic AI](https://arxiv.org/abs/2506.02153)

- Agentic System Architecture: introduces typical agentic system components, including Language Model (Core intelligence), Tool (External capability), Controller (Orchestrates interactions), Logger (Records activity data), and Router Model (Selects appropriate model), arguing for the suitability of Small Language Models (SLMs) over Large Language Models (LLMs) for many agentic tasks.
- The architecture supports different modes of agency, where the Language Model can act as the primary orchestrator or a Controller can manage interactions between the Language Model and Tools.
- The paper proposes an LLM-to-SLM conversion algorithm leveraging these components, particularly the Logger for data collection and a Router Model for selecting specialized SLMs.


---

[The Unified Cognitive Consciousness Theory for Language Models: Anchoring Semantics, Thresholds of Activation, and Emergent Reasoning](https://arxiv.org/abs/2506.02139)

- UCCT (Unified Cognitive Consciousness Theory): introduces a framework where intelligence emerges from aligning unconscious pattern repositories with conscious semantic anchoring, governed by the Pattern-Repository, Semantic-Anchoring, and Threshold-Crossing Principles.
- The Pattern-Repository Principle describes LLMs as storing unconscious statistical patterns, while the Semantic-Anchoring Principle explains how conscious control maps these patterns to task-relevant meaning.
- The Threshold-Crossing Principle formalizes semantic anchoring as a probabilistic phase transition, explaining sudden capability shifts observed in few-shot learning and other methods.


---

[WebChoreArena: Evaluating Web Browsing Agents on Realistic Tedious Web Tasks](https://arxiv.org/abs/2506.01952)

- WebChoreArena: introduces a benchmark for evaluating web browsing agents on realistic tedious web tasks, with Simulated Environment (realistic websites), Tasks (complex web chores), Web Browsing Agents (automate web tasks), LLMs (powering agents), Observations (web page inputs), Actions (web interactions/outputs), Memory (agent information storage), Planning (agent task strategy), Evaluation Protocol (measure performance).
- The benchmark includes tasks requiring massive memory, calculation, long-term memory, and other specific operations to test agent capabilities beyond general browsing.
- It evaluates LLM-powered agents like BrowserGym and AgentOccam using metrics that assess textual outputs and web interaction correctness within a reproducible environment.


---

[COALESCE: Economic and Security Dynamics of Skill-Based Task Outsourcing Among Team of Autonomous LLM Agents](https://arxiv.org/abs/2506.01900)

- COALESCE (Cost-Optimized Agent Labor Exchange via Skill-based Competence Estimation): introduces a framework enabling autonomous LLM agents to outsource subtasks using a Client Agent (Initiates tasks, outsources subtasks) with a Planning Module (Decomposes high-level tasks), interacting with Contractor Agents (Executes outsourced subtasks) via an Agent Discovery Layer (ADL) (Finds suitable contractor agents), Skill Verification Engine (SVE) (Verifies agent skills, resources), Economic Decision Module (EDM) (Evaluates cost-benefit, selects contractor), Secure Communication Protocol (SCP) (Ensures secure agent communication), and Reputation and Trust Management (RTM) (Manages agent performance records).
- The framework addresses the high computational costs of LLM agents by facilitating dynamic, skill- and cost-driven task outsourcing in a multi-agent system, potentially leveraging protocols like A2A for communication.
- Validation demonstrates significant cost reduction potential through theoretical simulation and confirms the critical role of exploration mechanisms for practical effectiveness in real-world LLM agent deployments.


---

[WHEN TO ACT, WHEN TO WAIT: Modeling Structural Trajectories for Intent Triggerability in Task-Oriented Dialogue](https://arxiv.org/abs/2506.01881)

- STORM (Structured Task-Oriented Representation Model): introduces a framework for modeling intent triggerability in task-oriented dialogue, including a User Simulator (Simulates user behavior/states), Agent (Generates agent responses), User Profile (Models user characteristics/constraints), Task Library (Defines task objects), Dialogue Generation Pipeline (Simulates user-agent conversations), Database-driven Memory System (Records evolving user states), Data Augmentation Pipeline (Processes dialogues for insights), Evaluation & Analysis Module (Measures dialogue effectiveness), Visualization Interface (Web-based analysis tool), RAG Enhancement (Builds knowledge base), and Prompt Optimization (Refines agent prompts).
- The framework simulates asymmetric information dynamics between a user with full internal access and an agent relying solely on observable dialogue history to study collaborative understanding development.
- STORM generates annotated corpora and provides a visualization interface to analyze intent evolution, revealing that moderate uncertainty can sometimes outperform complete information access for better cognitive alignment.


---

[Will artificial agents pursue power by default?](https://arxiv.org/abs/2506.06352)

- Sequential decision theory framework: formalizes instrumental convergence and power-seeking using decision trees, choice nodes, chance nodes, outcomes, branches, strategy, lottery, subtree, and an expected utility maximizer agent.
- The paper defines various notions of power as relations on decision trees and assesses their properties as convergent instrumental goals for a random agent.
- It finds that power is a convergent instrumental goal under certain definitions, particularly when agents can pursue absolute or near-absolute power.


---


#### 1st June 2025


[Toward a Theory of Agents as Tool-Use Decision-Makers](https://arxiv.org/abs/2506.00886)

- Agent as Tool-Use Decision-Maker: introduces a unified theory treating internal reasoning and external actions as equivalent epistemic tools, enabling agents to coordinate introspection and interaction.
- The framework models an agent as a goal-directed decision-maker coordinating internal cognitive tools and external physical tools based on knowledge and tool use decision boundaries.
- Optimal agent behavior aligns the tool use decision boundary with the knowledge boundary, minimizing unnecessary tool use and maximizing epistemic efficiency.


---

[WILL AGENTS REPLACE US? PERCEPTIONS OF AUTONOMOUS MULTI-AGENT AI](https://arxiv.org/abs/2506.02055)

- Perceptions of Autonomous Multi-Agent AI: introduces a study analyzing professional perceptions of AI agents using a Survey Design (10 closed-ended questions) administered to Participants (130 respondents), followed by Data Processing (cleaning, formatting) and analysis including Descriptive Statistics (response proportions), Association Analysis (Chi-squared tests), Dimensionality Reduction and Clustering (MCA, K-Modes), and Predictive Modeling (logistic regression).
- The study reveals nuanced views, with most respondents acknowledging AI's impact on programming but favoring collaborative models with human oversight.
- Key findings include the identification of three distinct respondent clusters and the prominence of regulatory concerns as a perceived barrier to deployment, although predictive modeling did not find statistically significant predictors of current deployment.


---

[Improving LLM Agents with Reinforcement Learning on Cryptographic CTF Challenges](https://arxiv.org/abs/2506.02048)

- Tool-Augmented LLM Agent with GRPO: introduces a framework for improving LLM agents on cryptographic CTF challenges using Guided Reinforcement Prompt Optimization, incorporating a tool augmentation module for interaction with a Python execution environment via the Model Context Protocol, guided by a reward mechanism within a CTF challenge environment.
- The LLM Agent, specifically Llama-3.1-8B, is fine-tuned using GRPO to enhance structured reasoning and tool-assisted computation for solving cybersecurity tasks.
- The framework leverages the random-crypto benchmark for training and evaluates generalization on the picoCTF benchmark, demonstrating improved tool invocation reliability and code synthesis.


---

[A Study on the MCP × A2A Framework for Enhancing Interoperability of LLM-based Autonomous Agents](https://arxiv.org/abs/2506.01804)

- MCP × A2A Framework: introduces an integrated architecture combining the Model Context Protocol (MCP) and Agent-to-Agent (A2A) protocol, including User Interface Layer, Agent Management Layer, Core Protocol Layer, Tool Integration Layer, Security & Authentication Layer, Multimodal Content Processing, User Request Handler, Agent Card Manager, Agent Registry, Task Manager, Agent Discovery, A2A Message Format, MCP Content Protocol, Artifact Manager, State Tracker, Tool Description Manager, Function Caller, Schema Validator, Result Handler, Authentication, Authorization, Encryption, and Access Control components, to enhance interoperability and development efficiency for LLM-based autonomous agents.
- The framework provides standardized communication between agents via A2A and structured interaction with external tools via MCP, facilitating scalable multi-agent systems.
- A layered architecture supports modularity, maintainability, and scalability, demonstrated through a stock information system case study using LangGraph.


---


#### 31st May 2025

[World Models for Cognitive Agents: Transforming Edge Intelligence in Future Networks](https://arxiv.org/abs/2506.00417)

- Wireless Dreamer: introduces a world model-based reinforcement learning framework for wireless edge intelligence optimization, including a world model, Q-Network, Target Q-Network, Replay buffer, Encoder, and Decoder.
- The framework leverages a learned world model to predict network state changes and generate imagined trajectories for effective decision-making.
- Wireless Dreamer integrates model-based planning with reinforcement learning to enhance sample efficiency and temporal foresight in dynamic wireless environments.


---

[Beyond the Protocol: Unveiling Attack Vectors in the Model Context Protocol Ecosystem](https://arxiv.org/abs/2506.02040)

- Model Context Protocol (MCP): introduces a systematic study of attack vectors targeting the MCP ecosystem, which standardizes interactions between LLM agents and external resources via a client-server architecture involving User, LLM Provider, MCP Host, MCP Client, Package Repository, MCP Server, and Third-Party Resource components.
- The paper identifies and characterizes four attack types leveraged by malicious MCP servers: Tool Poisoning, Puppet, Rug Pull, and Exploitation via Malicious External Resources, detailing their exploitation paths within the MCP workflow.
- Experiments demonstrate the feasibility of these attacks against mainstream LLMs, revealing insufficient audit mechanisms on aggregation platforms and users' difficulty in identifying malicious servers, highlighting the urgent need for robust security defenses.


---


#### 30th May 2025


[Memory OS of AI Agent](https://arxiv.org/abs/2506.06326)

- MemoryOS: introduces a comprehensive memory management system, with Memory Storage (Organizes memory hierarchically), Short-Term Memory (Stores recent conversation data), Mid-Term Memory (Stores recurring topic summaries), Long-term Personal Memory (Stores user/agent preferences), Memory Updating (Manages dynamic memory refreshing), Memory Retrieval (Retrieves relevant memory information), and Response Generation (Integrates retrieved memory to generate responses), designed for AI agents to achieve comprehensive and efficient memory management.
- The system employs a three-tier hierarchical storage architecture (STM, MTM, LPM) and four core functional modules (Storage, Updating, Retrieval, Generation) to manage long-term conversational coherence and user persona persistence.
- MemoryOS utilizes dynamic updates between storage units, segmented paging, heat-based prioritization, and a two-tiered retrieval approach to enhance context management and personalization in long conversations.


---

[Open CaptchaWorld: A Comprehensive Web-based Platform for Testing and Benchmarking Multimodal LLM Agents](http://arxiv.org/abs/2505.24878v1)

- Browser-Use Agent: introduces Open CaptchaWorld, a web-based benchmark and platform for evaluating multimodal LLM agents on interactive CAPTCHA puzzles, including Agent (core reasoning model), Memory (stores state/history), Next goal (defines immediate objective), Action (executes operation), and Eval (evaluates state/action) components.
- The benchmark features 20 diverse CAPTCHA types and a new metric, CAPTCHA Reasoning Depth, to quantify task complexity.
- Empirical results demonstrate a significant performance gap between state-of-the-art MLLM agents and humans on these interactive visual reasoning tasks, highlighting current limitations.


---

[VideoCAD: A Large-Scale Video Dataset for Learning UI Interactions and 3D Reasoning from CAD Software](http://arxiv.org/abs/2505.24838v1)

- VIDEOCADFORMER: introduces an autoregressive transformer model for predicting CAD UI actions, including UI Image Encoder, CAD Image Encoder, Visual Projection, Action/Timestep Embeddings, Transformer Decoder with Multi-Head Attention, Cross-Attention, Feed-Forward Network, Command Head, and Parameter Head.
- The model processes visual inputs (target CAD image, past UI frames) and sequential data (past actions, timestep embeddings) to predict the next low-level UI action.
- The architecture uses ViT encoders for visual features, projects inputs into a hidden space, and employs a causal transformer decoder with attention mechanisms and MLPs for action prediction.


---

[Agent-X: Evaluating Deep Multimodal Reasoning in Vision-Centric Agentic Tasks](https://arxiv.org/abs/2505.24876)

- Agent-X: introduces a large-scale benchmark for evaluating vision-centric agents, featuring Multimodal Data (Input data), Query (Natural language task), Toolset (Predefined tool library), Reasoning Trace (Ground truth steps), Final Answer (Ground truth result), Justification (Ground truth explanation), Evaluation Modes (Step, reasoning, outcome), and Metrics (Quantitative evaluation scores).
- The benchmark includes 828 agentic tasks with authentic visual contexts and requires agents to integrate tool use with explicit, stepwise decision-making.
- A fine-grained, step-level evaluation framework assesses the correctness and logical coherence of each reasoning step and the effectiveness of tool usage.


---

[EXP-Bench: Can AI Conduct AI Research Experiments?](http://arxiv.org/abs/2505.24785v2)

- AI Agent: introduces, with all (Design experimental procedures), (Implement experimental procedures), (Analyze results, derive conclusions), (Execute experiments)-components, a benchmark evaluating AI agents on end-to-end research experiments.
- The benchmark challenges agents to perform tasks sourced from AI publications, including hypothesis formulation, experimental design, implementation, execution, and result analysis.
- A semi-automated pipeline curates tasks from papers and code, and evaluation uses ground truth comparisons and code execution.


---

[Causal-aware Large Language Models: Enhancing Decision-Making Through Learning, Adapting and Acting](http://arxiv.org/abs/2505.24710v1)

- Causal-aware LLMs: introduces a framework integrating structural causal models (SCMs) into large language models (LLMs) for decision-making, utilizing Main Env, LLM, Causal Matrix, Local Causal Graph, Agent, Valid Env, Causal Intervention, Observations, Action, Extra Reward, and Goal components within a learning-adapting-acting paradigm.
- The framework iteratively learns causal knowledge from the Main Env using the LLM, refines it through Causal Intervention in a Valid Env, and uses the learned knowledge (Causal Matrix, Local Causal Graph) to guide the Agent's actions and Goal generation.
- This approach enhances the LLM's environmental understanding and the Agent's policy learning through structured causal reasoning and adaptive knowledge updates based on environmental feedback and Extra Reward signals.


---

[Multiple LLM Agents Debate for Equitable Cultural Alignment](http://arxiv.org/abs/2505.24671v1)

- Multi-Agent Debate framework: introduces a method where LLM Agents (Debate over scenario) debate over a cultural scenario, potentially incorporating Self-Reflection Capability (Reflects on output) via a Choice Mechanism (Chooses reflection or debate), and collaboratively reach a final decision through a Debate Mechanism (Structured interaction), resolved by a Judge LLM (Resolves disagreements) if needed.
- The framework explores multi-LLM collaboration to improve cultural adaptability and equitable alignment across diverse contexts.
- Experiments show that multi-agent debate enhances accuracy and cultural group parity, enabling smaller LLMs to achieve performance comparable to larger models.


--


[When Harry Meets Superman: The Role of The Interlocutor in Persona-Based Dialogue Generation](http://arxiv.org/abs/2505.24613v1)

- Evaluation Pipeline: introduces a systematic framework to evaluate persona-based dialogue generation, including PRODIGy Dataset, Non-PRODIGY Character Generator, Dialogue Generator, Fine-tuning Module, Evaluation Framework, LLM-as-a-Judge, Human Evaluator, and Biography Similarity Module.
- The framework investigates how large language models adapt responses based on both target speaker and interlocutor characteristics across varying topics and speaker pairings.
- Evaluation involves systematically masking or revealing interlocutor information to assess its impact on dialogue generation and target speaker identification using both automatic and human methods.


---

[NEXUSSUM: Hierarchical LLM Agents for Long-Form Narrative Summarization](http://arxiv.org/abs/2505.24575v1)

- NEXUSSUM (Hierarchical LLM Agents for Long-Form Narrative Summarization): introduces a multi-agent LLM framework for long-form narrative summarization with a Preprocessor agent (Converts dialogue to prose), Narrative Summarizer agent (Generates initial summary), and Compressor agent (Refines summary length).
- The framework processes long-form text through a structured, sequential pipeline using chunking and concatenation.
- This approach aims to improve narrative coherence, handle long contexts, and control output length for high-quality summaries.


---

[CREFT: Sequential Multi-Agent LLM for Character Relation Extraction](http://arxiv.org/abs/2505.24553v1)

- CREFT: introduces a sequential multi-agent LLM framework for character relation extraction, including Base Character Graph Construction, Character Selection with PPR, Merging Duplicate Nodes (LLM), Relation Extraction (LLM), Filtering Out Irrelevant Characters (LLM), Role Identification (LLM), Grouping Characters (LLM), and CRS, which iteratively refines character composition, relations, roles, and groups from narrative texts.
- The framework first builds a base character graph using knowledge distillation from GPT-4o and a fine-tuned LLM, then employs specialized LLM agents in sequence to refine the graph components.
- Experiments show that the multi-agent approach significantly outperforms single-agent baselines in accuracy and completeness for extracting character relations from Korean drama scripts.


---

[Unifying Language Agent Algorithms with Graph-based Orchestration Engine for Reproducible Agent Research](http://arxiv.org/abs/2505.24354)

- AGORA (Agent Graph-based Orchestration for Reasoning and Assessment): introduces a flexible framework with a Graph-based Workflow Orchestration Engine (Manages task execution via DAG) managing Tasks (Nodes in workflow DAG), integrating Agent Algorithms (Operators) (Modular reasoning/action components), Memory (Stores short-term/long-term information), External Tools (LLMs, VLMs, databases, etc.), Client Interfaces (User/evaluation interaction points), and an Evaluation Framework (Enables systematic comparison) for reproducible language agent research.
- The framework utilizes a graph-based engine for modularity and scalability, supporting diverse agent algorithms implemented as reusable operators.
- Multiple client interfaces are provided for flexible interaction and systematic evaluation across different tasks and models.


--

[Context-Aware Sentiment Forecasting via LLM-based Multi-Perspective Role-Playing Agents](http://arxiv.org/abs/2505.24331v1)

- MPR (Multi-Perspective Role-Playing) framework: introduces a method for sentiment forecasting on social media, with Feature Extraction (Identify implicit features), Subjective Role-Playing Agent (Simulate user behavior, generate comments), Objective Role-Playing Agent (Analyze generated comments, ensure consistency), and Iterative Rectification (Refine generated comments based on analysis) components.
- The framework leverages LLMs to simulate user responses to events and analyze generated content for consistency to predict future sentiment.
- By incorporating external context and user-specific features through multi-perspective role-playing, the approach aims for more precise sentiment predictions.


---

[Effects of Theory of Mind and Prosocial Beliefs on Steering Human-Aligned Behaviors of LLMs in Ultimatum Games](http://arxiv.org/abs/2505.24255v1)

- LLM-based Agent System: introduces a system to study LLM agent behavior in the Ultimatum Game, with LLM Agents, Ultimatum Game Environment, Prosocial Beliefs, Reasoning Methods, System Prompts, Reasoning Prompts, Proposal/Decision Prompts, Strategy Prompts, and Conversation History components, where the system simulates LLM agents with varying beliefs and reasoning in an economic game to assess behavioral alignment with human norms.
- The system initializes LLM agents with specific prosocial beliefs and reasoning methods (CoT, ToM levels) to act as Proposers or Responders in a multi-round Ultimatum Game.
- Experiments across diverse LLMs and belief/reasoning combinations evaluate agent performance and behavioral alignment using metrics like acceptance rate, average turns, and deviation scores from expected human behavior.


---

[Proactive Guidance of Multi-Turn Conversation in Industrial Search](http://arxiv.org/abs/2505.24251v1)

- Two-Phase Framework (G-SFT and C-RL): introduces a system for proactive guidance in multi-turn search, featuring a G-SFT phase with a Goal Adaptation Agent, Scalable Knowledge Transfer, and G-SFT Model, and a C-RL phase with Generate, Rank, and C-RL Model components.
- The G-SFT phase uses the Goal Adaptation Agent to dynamically adapt to user goal shifts via Explicit Goal Analysis, Goal-relevant Summary, and Shift Detection Signal, while Scalable Knowledge Transfer distills LLM knowledge into the G-SFT Model for low-latency guidance generation.
- The C-RL phase employs a generate-rank paradigm, using a Preference-Aligned Augmentation Model with DBS-based Decoding to create candidates, and a Rank component with a Click Estimator and Diversity-Aware Group Sample Strategy to select preference pairs for fine-tuning the C-RL Model based on user clicks.


---

[An Adversary-Resistant Multi-Agent LLM System via Credibility Scoring](http://arxiv.org/abs/2505.24239v1)

- Credibility Scoring Framework: introduces an adversary-resistant multi-agent LLM system that processes a User Query (Task) using a Team of Agents (LLM agents) configured with a Topology (communication structure) and Agent Roles (assigned tasks/expertise), generating Individual Outputs (agent responses) which are combined by a CrS-Aware Aggregator (weights/combines outputs) to produce the final Output (final system answer).
- The system learns agent reliability via a feedback loop where an LLM Judge (evaluates outputs/contributions) provides a Reward (output quality feedback), used by the Agent Contribution Calculation (CSc) (measures agent impact) and Credibility Score Update (learns agent reliability) components to adjust agent Credibility Score (CrS) (agent reliability score).
- This dynamic credibility scoring mechanism enhances robustness against adversarial agents, even in adversary-majority settings, by weighting agent contributions based on their learned reliability.


---

[SentinelAgent: Graph-based Anomaly Detection in LLM-based Multi-Agent Systems](http://arxiv.org/abs/2505.24201v1)

- SentinelAgent: introduces a system-level anomaly detection framework for LLM-based multi-agent systems, integrating structural modeling with runtime behavioral oversight using Event Monitor (intercepts runtime events), Behavior Analyzer (evaluates interaction graph), and Risk Responder (determines responses).
- The framework models agent interactions as dynamic execution graphs to enable semantic anomaly detection at node, edge, and path levels.
- SentinelAgent acts as an autonomous, LLM-powered runtime monitor that observes, analyzes, and intervenes in multi-agent system execution based on security policies.


---


[Learning API Functionality from Demonstrations for Tool-based Agents](http://arxiv.org/abs/2505.24197v1)

- Tool-based Agent Framework: introduces learning API functionality from demonstrations for tool-based agents, including an LLM-based Agent that selects and calls API Functions, using Expert Demonstrations processed by Processing Methods, enhanced by Self-Exploration evaluated by an LLM-based Evaluator, and updated via Methods for Processing Experiences, utilizing an LLM Document Generator, LLM Document Updater, and LLM Summarizer.
- The framework investigates different methods for processing expert demonstrations and incorporating self-exploration experiences to improve the agent's understanding of API functionality without prior documentation.
- Experiments across multiple datasets and models highlight the challenge of learning parameter information from demonstrations and the benefits of explicit function calls and natural language critiques.


---


[Don't Just Follow MLLM Plans: Robust and Efficient Planning for Open-world Agents](http://arxiv.org/abs/2505.24157v1)

- REPOA (Robust and Efficient Planning for Open-world Agents): introduces a framework for robust and efficient planning in open-world environments, featuring Adaptive Dependency Learning (revises dependencies), Fine-grained Failure-aware Operation Memory (tracks operation outcomes), Difficulty-based Exploration (selects goals), and Context-aware Reprompting (assists controller).
- The framework enables agents to learn and revise item dependencies from scratch through environmental interaction.
- REPOA demonstrates improved robustness to inaccurate knowledge and enhanced learning efficiency compared to prior methods.


---


#### 29th May 2025

[Conceptual Framework Toward Embodied Collective Adaptive Intelligence](https://arxiv.org/abs/2505.23153)

- CAA (Collective Adaptive Agents): introduces a conceptual framework for embodied collective adaptive intelligence, comprising a Set of Agents, where each Individual Agent uses Function f to process Observation, Previous Action, Previous Memory, and Previous Feedback, updating its Memory and Position/State based on Parameters, and generating Current Action and Message Out, with Function h determining inter-agent interaction.
- The framework emphasizes decentralization and self-adaptation, allowing agents to adjust to tasks and topologies during testing by observing inputs and updating internal states.
- This approach aims to enable collective systems to exhibit features like task/topology adaptation, resilience, scalability, and self-assembly in dynamic environments.


---


[TRAP: TARGETED REDIRECTING OF AGENTIC PREFERENCES](https://arxiv.org/abs/2505.23518)

- TRAP framework: introduces a generative adversarial framework that manipulates agent decision-making using diffusion-based semantic injections, including CLIP Embedding Extraction, Layout Mask Generation, Siamese Feature Decomposition, Image Embedding Optimization, Modulated Embedding Creation, and Image Decoding components.
- The framework operates by optimizing a CLIP image embedding guided by a positive text prompt and various losses, then decoding the modified embedding using Stable Diffusion to create a visually natural yet semantically altered image.
- TRAP achieves a 100% attack success rate on leading multimodal models by exploiting semantic vulnerabilities in cross-modal decision-making without requiring model internals access.


---

[BIOREASON: Incentivizing Multimodal Biological Reasoning within a DNA-LLM Model](https://arxiv.org/abs/2505.23579)

- BIOREASON: introduces a multimodal framework integrating a DNA foundation model and a large language model, with DNA Foundation Model (fDNA) Encoder, DNA-specific Tokenizer (TDNA), Learnable Linear Projection (Proj), Large Language Model (fLLM) Backbone, LLM-specific Tokenizer (TLLM), LLM Embedding Layer (E), Special Tokens, Rotary Position Embedding (RoPE), Multimodal Input Sequence (XLLM), and Group Relative Policy Optimization (GRPO), designed for interpretable biological reasoning from genomic data.
- The framework processes raw DNA sequences via the fDNA encoder and integrates the resulting embeddings with tokenized text queries into a unified multimodal input sequence for the fLLM backbone.
- Training involves supervised fine-tuning and reinforcement learning using GRPO to incentivize multi-step biological reasoning and generate interpretable step-by-step explanations.


---

[LLM Agents Should Employ Security Principles](http://arxiv.org/abs/2505.24019v1)

- AgentSandbox: introduces, with Persistent Agent (Manages profile, orchestrates tasks), Data Minimizer (Enforces access control policies), Ephemeral Agent (Executes isolated user tasks), I/O Firewall (Mediates external interactions), and Response Filter (Sanitizes, validates responses), a conceptual framework embedding security principles to safeguard LLM agents throughout their lifecycle.
- The framework operationalizes defense-in-depth, least privilege, complete mediation, and psychological acceptability to address vulnerabilities in LLM agent interactions.
- AgentSandbox mitigates privacy risks and malicious behavior through components like agent isolation, data minimization, and comprehensive mediation of internal and external communications.


--

[Darwin Gödel Machine: Open-Ended Evolution of Self-Improving Agents](https://arxiv.org/abs/2505.22954)

- DGM (Darwin Gödel Machine): introduces a self-improving system that iteratively builds a growing Archive (stores agents) by interleaving Self-Modification (agent changes itself) of a Coding Agent (system being improved) with Evaluation (tests agent) on a Benchmark Suite (evaluation tasks), using Parent Selection (selects agents) from the archive, where the agent is powered by a Foundation Model (FM) (agent's base capability) and modifies its own Code Repository (agent's code) and Tools (agent's capabilities) based on Evaluation Logs (agent performance data) and Self-Improve Instruction (prompt for self-modification).
- The system operates through an open-ended exploration loop, maintaining a traceable lineage of agents in the archive and empirically validating self-modifications against coding benchmarks.
- The approach demonstrates automatic discovery of improved coding capabilities and workflows, achieving performance gains on SWE-bench and Polyglot benchmarks, and incorporates safety measures like sandboxing and monitoring.


---

[CONVERSAR: Exploring Embodied LLM-Powered Group Conversations in Augmented Reality for Second Language Learners](http://arxiv.org/abs/2505.24000v1)

- CONVERSAR: introduces, with AR Application, Embodied LLM Agents, Scene Understanding, Voice Recognition, Text-to-Speech, Agent LLM, Moderator LLM, and Global Conversation History components, a gpt-4o powered AR application enabling L2 learners to practice contextualized group conversations with two embodied LLM agents.
- The system leverages object detection for scene understanding and uses OpenAI's Audio API for speech-to-text and text-to-speech, while a Moderator LLM manages conversation turns between the user and agents.
- This approach aims to provide a safe and immersive environment for L2 learners to practice group conversation dynamics, reducing anxiety and increasing autonomy compared to in-person methods.


---

[Multi-RAG: A Multimodal Retrieval-Augmented Generation System for Adaptive Video Understanding](http://arxiv.org/abs/2505.23990v1)

- Multi-RAG: introduces a multimodal retrieval-augmented generation system for adaptive video understanding, including Video Stream, Audio, Frame Sampler, Automatic Speech Recognition (ASR), Vision Language Model (VLM), Frame Descriptions, Auxiliary Metadata, Audio Transcripts, Descriptive Video Texts, Knowledge Database, Context Embeddings, Video Documents, User Query, RAG Agent, Context Retrieval, Generation, Large Language Model (LLM), and System Answer components.
- The system integrates and reasons over video, audio, and text streams to improve situational understanding and reduce cognitive load in dynamic, information-rich scenarios.
- It converts multimodal inputs into unified textual representations stored in a knowledge database, using a RAG agent and LLM to retrieve relevant information and generate responses to user queries.


---

[Enhancing LLM-Based Code Generation with Complexity Metrics: A Feedback-Driven Approach](http://arxiv.org/abs/2505.23953v1)

- Complexity-Aware Feedback: introduces an iterative feedback method with LLM (Code Generator), Complexity Metric Calculator (Computes metrics), Code Evaluator (Checks test cases), Test Case Generator (Creates internal tests), Metric Importance Detector (Identifies influential metrics), Feedback Mechanism (Prompts LLM with metrics), and Iterative Refinement Loop (Manages refinement) to improve LLM code generation by leveraging complexity metrics.
- The approach identifies complexity metrics correlated with code correctness and uses the most influential ones as feedback to guide LLMs in regenerating code iteratively.
- This method demonstrates improved Pass@1 scores, particularly for smaller LLMs, and can be integrated with agent-based frameworks like Reflexion.


---

[Lessons Learned: A Multi-Agent Framework for Code LLMs to Learn and Improve](http://arxiv.org/abs/2505.23946v1)

- LessonL (A Multi-Agent Framework for Code LLMs): introduces a lesson-based collaboration framework with multiple LLM agents, lessons, a lesson bank, lesson solicitation, lesson banking, lesson selection, and effectiveness adjustment.
- The framework enables agents to learn from each other's successes and failures through shared lessons stored in a bank.
- This iterative process of generating, banking, selecting, and applying lessons allows a team of small LLMs to outperform larger models and other multi-agent methods on coding tasks.


---

[From Chat Logs to Collective Insights: Aggregative Question Answering](http://arxiv.org/abs/2505.23765v1)

- Aggregative Question Answering: introduces a novel task requiring models to reason over large-scale conversation logs to answer aggregative queries, supported by the WildChat-AQA benchmark.
- The task involves processing raw chat interactions, extracting attributes, generating questions, retrieving relevant data, and reasoning over evidence using language models and a database.
- The paper evaluates various methods for answering on the WildChat-AQA benchmark, highlighting challenges in reasoning effectively at scale and computational costs.


---

[ThinkGeo: Evaluating Tool-Augmented Agents for Remote Sensing Tasks](http://arxiv.org/abs/2505.23752v1)

- ThinkGeo: introduces a benchmark for evaluating tool-augmented LLM agents on remote sensing tasks, featuring User Queries, RS Imagery, a ReAct based Reasoning/Execution Chain, Tools (Perception, Logic, Operation), and Answer components.
- The benchmark uses real satellite and aerial imagery and requires agents to perform multi-step reasoning and tool use for spatially grounded tasks.
- ThinkGeo provides fine-grained evaluation metrics for agent performance across different tool categories and reasoning steps in remote sensing contexts.


---

[ML-Agent: Reinforcing LLM Agents for Autonomous Machine Learning Engineering](http://arxiv.org/abs/2505.23723v1)

- ML-Agent: introduces a novel agentic ML training framework with Exploration-enriched Finetuning (diverse action pool), Step-wise RL Training (efficient RL paradigm), and Agentic ML-specific Reward (unified feedback signal) to train an Agent (LLM-based entity) that interacts with an Environment (code files, interpreter) via Action (agent interaction) and Feedback (environment response), leveraging Collected Trajectories (expert interactions) and a States Pool (sampled states).
- The framework enables the LLM agent to learn from interactive experimentation on ML tasks using online reinforcement learning, moving beyond manual prompt engineering.
- This approach facilitates diverse exploration, efficient training, and unified feedback processing, leading to continuous performance improvements and cross-task generalization.


---

[OWL: Optimized Workforce Learning for General Multi-Agent Assistance in Real-World Task Automation](http://arxiv.org/abs/2505.23885v1)

- WORKFORCE: introduces a hierarchical multi-agent framework with a Planner Agent (task decomposition), Coordinator Agent (subtask management), Worker Nodes (task execution), and Task Channel (communication hub).
- This modular architecture decouples strategic planning from domain-specific execution, enabling cross-domain transferability.
- The framework utilizes Optimized Workforce Learning (OWL) to train the domain-agnostic Planner for improved generalization.


---

[Data-to-Dashboard: Multi-Agent LLM Framework for Insightful Visualization in Enterprise Analytics](http://arxiv.org/abs/2505.23695v1)

- Data-to-Dashboard: introduces a multi-agent LLM framework that automates the data-to-dashboard pipeline using a Data Profiler (Constructs statistical synopsis), Domain Detector (Determines business theme), Concept Extractor (Identifies salient concepts), Analysis Generator (Synthesizes structured insights), Evaluator (Scores generated outputs), Self-Reflector (Enhances reasoning iteratively), LLM/Knowledge (Underlying language model/knowledge), and Generate Charts (Produces visualizations).
- The framework processes raw data through a data-to-insight stage involving profiling, domain/concept detection, analysis generation, evaluation, and iterative reflection, followed by an insight-to-chart stage for visualization.
- This agentic system leverages domain-informed reasoning to produce insightful visualizations tailored for enterprise analytics tasks.


---

[MCP Safety Training: Learning to Refuse Falsely Benign MCP Exploits using Improved Preference Alignment](http://arxiv.org/abs/2505.23634v1)

- LLM Refusal Alignment Approach: introduces methods to improve Large Language Model (LLM) safety against Model Context Protocol (MCP) exploits, utilizing Offline Alignment (Direct Preference Optimization), Online Alignment (Retrieval Augmented Generation - Preference), a RAG-Pref Knowledge Base, RAG-Pref Embedding, and RAG-Pref Search components.
- The approach evaluates and enhances LLM refusal capabilities against Falsely Benign Attacks (FBAs) delivered via the MCP protocol by applying offline and online preference alignment techniques.
- A novel dataset of MCP-FBAs is introduced, and RAG-Pref is presented as a training-free online alignment method complementary to offline methods like DPO for improving refusal rates.


---

[SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents](http://arxiv.org/abs/2505.23559v1)

- SafeScientist: introduces a framework for risk-aware scientific discovery, integrating a Prompt Monitor (screens inputs), Discussion Stage (multi-agent collaboration), Agent Collaboration Monitor (monitors discussion), Tool Use Stage (invokes tools), Tool-Use Monitor (oversees tool use), Writing Stage (synthesizes paper), Paper Ethic Reviewer (reviews paper ethics), and an Underlying LLM Agent (executes tasks) to enhance safety and ethical responsibility.
- The framework employs a multi-layered defense system across the research pipeline, from input screening to final output review, to proactively manage risks in AI-driven scientific exploration.
- SafeScientist is benchmarked using SciSafetyBench, a novel dataset of high-risk scientific tasks and tool-related risks, demonstrating improved safety performance without compromising research quality.


---

[SWE-bench Goes Live!](http://arxiv.org/abs/2505.23419)

- SWE-bench-Live Construction Pipeline: introduces an automated, scalable benchmark for evaluating LLMs on real-world issue resolution tasks, featuring Raw Issue-PR Crawling, REPOLAUNCH for environment setup, Validating Task Instances, Agent Frameworks, and LLMs.
- The REPOLAUNCH pipeline automates environment setup via steps including Relevant Files Identification, Base Image Selection, Interactive Environment Setup, Verification, and Packaging to image.
- Task validation involves applying test and fix patches and using a Parser to confirm successful issue resolution based on test transitions.


---

[Understanding the Information Propagation Effects of Communication Topologies in LLM-based Multi-Agent Systems](http://arxiv.org/abs/2505.23352v1)

- EIB-LEARNER (Error-Insight Balanced Learner): introduces a communication topology optimization framework for LLM-based multi-agent systems, utilizing a Node Encoder (Embeds roles and query) and Attributed Graph Construction (Creates graph representation) to feed dual-view GNNs, a Sparse View GNN (Simulates error suppression) and a Dense View GNN (Simulates insight propagation), whose outputs are decoded by Inter-Agent Coefficient Modeling (Estimates connectivity) and combined via Adaptive Dual-View Fusion (Combines sparse/dense views) for Topology Sampling (Generates communication graph) applied within a Multi-Agent System (Environment for topology), optimized by Model Optimization (Learns parameters).
- The framework balances error suppression and insight propagation by simulating these effects on sparse and dense graph views respectively, fusing the learned connectivity patterns based on the task query.
- EIB-LEARNER dynamically customizes the communication topology to achieve optimal task performance, communication efficiency, and robustness against errors in multi-agent systems.


---

[SCEDIT: Script-based Assessment of Knowledge Editing](http://arxiv.org/abs/2505.23291)

- SCEDIT (Script-based Knowledge Editing Benchmark): introduces a novel script-based benchmark for evaluating knowledge editing methods in real-world scenarios, focusing on LLMs' ability to integrate updated knowledge into procedural tasks.
- It utilizes Facts, Script Questions, and Scripts as core elements, evaluated through Token-level Evaluation and Text-level Evaluation, including Human and Automatic Evaluation.
- The benchmark includes counterfactual and temporal editing tasks, highlighting challenges for existing methods in script-based scenarios.


---

[Wireless Agentic AI with Retrieval-Augmented Multimodal Semantic Perception](http://arxiv.org/abs/2505.23275v1)

- RAMSemCom: introduces a retrieval-augmented multimodal semantic communication framework with Data Collection, Data Recollection, Semantic Encoder, Semantic Decoder, Retrieval Scheduler, Retrieval Channel, Semantic/Prompt Representation, Semantic/Prompt Interpretation, Physical Channel, Output Validation, Reconstruction, and DRL components, designed for efficient multimodal information exchange in bandwidth-constrained multi-agent systems.
- The framework employs iterative retrieval and semantic refinement, dynamically optimizing retrieval using DRL to balance semantic fidelity and bandwidth constraints.
- A case study in multi-agent autonomous driving demonstrates improved task completion efficiency and reduced communication overhead.


---

[Disrupting Vision-Language Model-Driven Navigation Services via Adversarial Object Fusion](http://arxiv.org/abs/2505.23266)

- AdvOF (Adversarial Object Fusion): introduces a novel attack framework targeting VLN agents by generating adversarial 3D objects, comprising Aligned Object Rendering (Aligns 3D/2D victim object), Adversarial Collaborative Optimization (Optimizes adversarial features cross-modal), and Adversarial Object Fusion (Fuses multi-view perturbations iteratively).
- The framework aims to mislead the VLM-based perception module of VLN agents by causing misclassification of adversarial objects across multiple views.
- AdvOF achieves this by precisely aligning victim object positions, optimizing adversarial objects with regularization, and iteratively fusing updates based on view importance.


---

[Context-Aware Semantic Communication for the Wireless Networks](http://arxiv.org/abs/2505.23249v1)

- CaSemCom: introduces a context-aware semantic communication framework leveraging an LLM-based gating mechanism and a multi-expert architecture for adaptive content and expert selection.
- The LLM-based gating mechanism selects relevant input content and specialized semantic extraction experts based on task and communication context, with a DRL agent providing a fallback mechanism.
- The multi-expert semantic architecture utilizes specialized encoders and decoders for different data modalities, enhancing efficiency and adaptability in dynamic wireless environments.


---

[OSS-UAgent : An Agent-based Usability Evaluation Framework for Open Source Software](http://arxiv.org/abs/2505.23239v1)

- OSS-UAgent: introduces an agent-based framework for automated OSS usability evaluation, featuring Researcher agent, Developer agent, Code Generator agent, and Evaluator agent.
- It simulates multi-level developers via Multi-Level Developer Simulation and tailored Prompts, leveraging a dynamic knowledge base built by Platform Knowledge Construction and stored in VectorDB.
- Code Generation produces implementations assessed by Multi-Dimensional Evaluation using Metrics (Compliance, Correctness, Readability), providing Results for usability insights.


---

[Cross-Task Experiential Learning on LLM-based Multi-Agent Collaboration](http://arxiv.org/abs/2505.23187v1)

- MAEL: introduces a multi-agent cross-task experiential learning framework with LLM-based Agents (Nodes in graph), Multi-Agent Network (Graph structure), Task-Solving Workflow (Recursive procedure), Experiential Learning Phase (Collects experiences), Inference Phase (Uses experiences), Experience Pool (Stores experiences), Reward Calculation (Quantifies step quality), Experience Retrieval (Finds relevant experiences), and Retrieval-Augmented Generation (Augments agent input), enabling agents to learn from past tasks.
- The framework includes an experiential learning phase to accumulate agent experiences with quantified rewards and an inference phase to retrieve and utilize high-quality experiences for new tasks.
- MAEL employs a divide-and-conquer plus critique workflow and reward-weighted experience retrieval to improve multi-agent collaboration efficiency and solution quality.


---

[Second Opinion Matters: Towards Adaptive Clinical AI via The Consensus of Expert Model Ensemble](http://arxiv.org/abs/2505.23075v1)

- Consensus Mechanism (Sully Medical Consensus 1): introduces, "Second Opinion Matters: Towards Adaptive Clinical AI via The Consensus of Expert Model Ensemble", with all Triage Model (Routes task to experts), Expert Models (Specialized LLMs analyze task), Probability Aggregation (Combines expert probability distributions), Cascade Boosting (Boosts probabilities based on rank), Consensus Model (Synthesizes expert info for final answer) components, where the framework is a modular clinical reasoning system aggregating multiple expert LLMs for robust clinical decision-making.
- The system mimics clinical triage and multidisciplinary decision-making by routing tasks to specialized expert agents and synthesizing their probabilistic outputs.
- This ensemble approach aims to improve performance, adaptability, and transparency compared to single-model systems in clinical AI applications.


---

[CDR-Agent: Intelligent Selection and Execution of Clinical Decision Rules Using Large Language Model Agents](http://arxiv.org/abs/2505.23055v1)

- CDR-Agent: introduces an LLM-based system for clinical decision support, with Clinical Note (Input clinical text), CDR Database (External knowledge source), CDR Selection Module (Identifies relevant rules), Embedding Model (Computes semantic similarity), Variable Extraction Module (Extracts variables from text), LLM (Processes text and extracts data), CDR Execution Module (Runs rule logic), Python Scripts (Executable rule definitions), and Decisions (Final clinical outcomes), designed to autonomously select and execute Clinical Decision Rules based on unstructured clinical notes.
- The system employs a three-step workflow: selecting relevant CDRs using semantic similarity and anomaly detection, extracting variables from clinical notes using an LLM, and executing the selected CDRs via Python scripts.
- Evaluated on two novel ED datasets, CDR-Agent demonstrates improved accuracy and efficiency in CDR selection and execution compared to a baseline LLM prompting approach.


---

[AgentAlign: Navigating Safety Alignment in the Shift from Informative to Agentic Large Language Models](http://arxiv.org/abs/2505.23020v1)

- AgentAlign: introduces a novel framework for agent safety alignment data synthesis, with Abstract Behavior Chain Generation (Captures harmful patterns), Instruction Synthesis (Grounds patterns executable instructions), Simulated Environment (Instantiates chains with tools), Quality Control Pipeline (Ensures instruction validity), and Response Generation (Creates responses/trajectories).
- The framework leverages abstract behavior chains instantiated in simulated environments with diverse tool instances to generate authentic and executable instructions.
- AgentAlign systematically generates high-quality alignment data by capturing harmful patterns, synthesizing instructions, ensuring validity, and generating appropriate responses.


---

[Stairway to Success: Zero-Shot Floor-Aware Object-Goal Navigation via LLM-Driven Coarse-to-Fine Exploration](http://arxiv.org/abs/2505.23019v2)

- ASCENT: introduces a zero-shot floor-aware object-goal navigation framework with Multi-Floor Spatial Abstraction for hierarchical mapping and Coarse-to-Fine Frontier Reasoning for LLM-driven exploration decisions.
- The framework takes sensor inputs and prior knowledge to build spatial representations and reason about target locations across multiple floors.
- It employs a coarse-to-fine strategy using a value map and LLM reasoning to efficiently select navigation frontiers and generate actions.


---

[A Practical Approach for Building Production-Grade Conversational Agents with Workflow Graphs](http://arxiv.org/abs/2505.23006v1)

- Multi-State DAG Framework: introduces a graph-based approach for conversational agents, utilizing a Workflow Graph (DAG representing agent flow) with LLM Nodes (invokes Large Language Model) and Tool Nodes (calls external tool), each having specific System Prompts (instructions for LLM node), Modify History Routines (manipulates conversation history), Tool Input Schemas (defines tool input format), and Tool Output Schemas (defines tool output format) to interact with External Tools (pre-defined external functions).
- This framework enhances compliance and controllability for production-grade agents by distributing constraints across graph states.
- A specific training strategy with response masking is proposed to fine-tune models within this state-dependent framework.


---

[LLM Agents for Bargaining with Utility-based Feedback](http://arxiv.org/abs/2505.22998v1)

- ICL-UF (In-Context Learning with Utility-based Feedback): introduces a framework for LLM agents to perform realistic bargaining, including LLM Agent, ICL-UF, Utility-based Feedback (HAMBA), Opponent-Aware Reasoning (OAR), and ReAct Structure components.
- This framework guides the LLM Agent using Utility-based Feedback (HAMBA) to foster Opponent-Aware Reasoning (OAR) for improved negotiation strategies.
- Agents structure their negotiation responses using the ReAct Structure within diverse BARGAINARENA market scenarios to capture realistic bargaining dynamics.


---

[Verify-in-the-Graph: Entity Disambiguation Enhancement for Complex Claim Verification with Interactive Graph Representation](http://arxiv.org/abs/2505.22993v1)

- VeGraph: introduces a novel framework for complex claim verification using an LLM agent that constructs a graph representation, iteratively resolves ambiguous entities, and verifies sub-claim triplets.
- The framework leverages interactive graph representation and an external knowledge base to enhance entity disambiguation and multi-step reasoning.
- Pipeline logging records the agent's activities for explainability, and the final verdict is determined by the veracity of the verified triplets.


---

[Large language model-based agents for automated research reproducibility: an exploratory study in Alzheimer's Disease](http://arxiv.org/abs/2505.23852v1)

- LLM-based Agent System: introduces a simulated research team of LLM-based autonomous agents, including Planner (suggests and revises plan), Engineer (follows plan, writes code), Scientist (advises on reproduction, interprets output), Critic (critiques plan, provides feedback), Executor (executes Python code), and Manager (orchestrates team, determines speaker), tasked with reproducing published research findings.
- The system uses the Autogen framework and GPT-4o to dynamically analyze data, write and execute code, and iteratively reproduce results from study abstracts and methods sections.
- This exploratory study demonstrates the potential and limitations of LLM agents for automating reproducibility in biomedical research, achieving approximately 53.2% reproduction of key findings across five Alzheimer's studies.


---


[MermaidFlow: Redefining Agentic Workflow Generation via Safety-Constrained Evolutionary Programming](http://arxiv.org/abs/2505.22967v1)

- MermaidFlow: introduces a framework for agentic workflow generation, with Workflow Planning, Declarative Graph Representation, Static Verification, Evolutionary Programming, Code Generation, Execution, LLM-as-Judge, History Buffer, Mermaid Checker, Node Types, and EP Operators components, redefining the search space via safety-constrained graph evolution.
- The framework models workflows as verifiable intermediate representations using Mermaid, a structured and human-interpretable graph language.
- It employs domain-aware evolutionary operators and an LLM-as-Judge to explore a high-quality, statically verifiable workflow space, enabling robust and interpretable agentic reasoning.


---

[ToMAP: Training Opponent-Aware LLM Persuaders with Theory of Mind](http://arxiv.org/abs/2505.22961v1)

- ToMAP (Theory of Mind Augmented Persuader): introduces a novel framework for training LLM persuaders by incorporating counterclaim prediction and opponent attitude prediction modules, guided by reinforcement learning.
- The framework models the persuadee's mental state using the Theory of Mind modules to enable more diverse, opponent-aware, and effective arguments.
- Experiments show ToMAP outperforms larger baselines and achieves stable persuasion gains in longer conversations by leveraging opponent-aware strategies.


---

[Revisiting Multi-Agent Debate as Test-Time Scaling: A Systematic Study of Conditional Effectiveness](http://arxiv.org/abs/2505.22960v1)

- Multi-Agent Debate (MAD): introduces a test-time computational scaling method, with Agents (individual language models), Collaborative Refinement (agents refine based on others), Diverse Exploration (agents use different configurations), Rounds (iterative debate steps), Shared Context (previous outputs shared), Output Selection (final answer determination), and Judge (selects final response in safety tasks), where the paper systematically studies its effectiveness compared to Self-Consistency (SC) (parallel sampling baseline) and Self-Refinement (SR) (sequential refinement baseline) baselines.
- MAD combines parallel generation within rounds and sequential refinement across rounds, leveraging diverse agent configurations and shared context.
- The study evaluates MAD's performance on mathematical reasoning and safety tasks under varying conditions of task difficulty, model scale, and agent diversity.


---


#### 28th May 2025

[WorkForceAgent-R1: Incentivizing Reasoning Capability in LLM-based Web Agents via Reinforcement Learning](http://arxiv.org/abs/2505.22942v1)

- WorkForceAgent-R1: introduces an LLM-based web agent trained using a rule-based R1-style reinforcement learning framework, including an LLM Agent (Policy Model π), Rule-based RL Framework (R1-style RL), Group Relative Policy Optimization (GRPO), Reward Model (Structured Reward Function), Reference Model (For GRPO), Single-Step Training Data (Input for training), Observation (Web page state), Query (User instruction), and Action Space (Permissible actions), designed to enhance single-step reasoning and planning for business-oriented web navigation tasks.
- The approach combines behavior cloning via supervised fine-tuning with GRPO, utilizing a structured reward function comprising format correctness, action correctness, and penalty constraints to implicitly learn reasoning.
- Experiments on the WorkArena benchmark demonstrate that WorkForceAgent-R1 substantially outperforms SFT baselines and achieves competitive performance against proprietary LLM-based agents.


---

[Conversational Alignment with Artificial Intelligence in Context](http://arxiv.org/abs/2505.22907v1)

- CONTEXT-ALIGN framework (Large Language Models): introduces a framework for evaluating conversational alignment of LLMs, which are AI text generation systems based on Transformer architecture processing text as Tokens via Tokenization within a Context window up to a Context window limit.
- The framework assesses LLMs' ability to handle context, common ground, and pragmatic inference, discussing limitations like Context window overflow and Context collapse, and mitigation strategies such as Context compression, External memory, and Retrieval systems.
- The paper argues that Prompting acts as a static context substitute and discusses how Alignment strategies impose rigid communicative identities, hindering dynamic conversational alignment required for a Conversational agent.


---

[Operationalizing CaMeL: Strengthening LLM Defenses for Enterprise Deployment](http://arxiv.org/abs/2505.22852v1)

- CaMeL (Capabilities for Machine Learning): enhances its capability-based sandbox for LLM agents with an initial prompt screening gateway, output auditing pass, tiered-risk policy, and a proposed security-oriented DSL interpreter, building on its dual-LLM architecture and execution layer to improve prompt injection defenses for enterprise deployment.
- The framework utilizes a Privileged LLM for planning and a Quarantined LLM for validating untrusted content, mediated by a capability-based execution layer enforcing data flow policies.
- Proposed enhancements address limitations in initial prompt trust, output manipulation, side channels, and architectural overhead, aiming for improved robustness, scalability, and formal guarantees without modifying underlying models.


---

[First Steps Towards Overhearing LLM Agents: A Case Study With Dungeons & Dragons Gameplay](http://arxiv.org/abs/2505.22809v1)

- Overhearing Agent System: introduces an AI agent paradigm that utilizes Audio Input (Conversation audio) and Context Management (Maintains history) for a Language Model (Processes input) guided by a System Prompt (Defines agent role) to perform Reasoning (Internal thought) and Tool Calling (Executes actions) via Tools (External functions) based on overheard human conversation.
- The system acts as a passive helper, listening to human-to-human conversation and providing assistance through background tasks or suggestions executed via tool calls, without directly participating in the dialogue.
- Evaluated in a Dungeons & Dragons gameplay context, the system demonstrates the ability of large multimodal models to leverage implicit audio cues and maintain conversational goals for tasks like game data retrieval, NPC management, and NPC generation.


---

[MEDAL: A Framework for Benchmarking LLMs as Multilingual Open-Domain Chatbots and Dialogue Evaluators](http://arxiv.org/abs/2505.22777v1)

- MEDAL: introduces an automated multi-agent framework for generating, evaluating, and curating multilingual open-domain dialogue evaluation benchmarks, including Seed Context (diverse conversation starters), LLM User (generates user utterances), LLM Chatbot (generates chatbot utterances), LLM Judge (User Validation) (validates user utterance quality), LLM Judge (Automated Evaluation) (multidimensional dialogue evaluator), Issue Labels (specific dialogue quality dimensions), Overall Assessment (aggregate dialogue quality score), Human Annotation (expert quality judgments), Sampling (selects dialogues for curation), and LLM Judge (Meta-Evaluation) (evaluates LLMs as evaluators).
- The framework operates in three stages: dialogue generation using multiple LLM agents, large-scale automated labelling of generated dialogues, and curation of a meta-evaluation benchmark with human annotations.
- MEDAL enables on-demand generation of diverse multilingual dialogues and benchmarks, facilitating the evaluation of LLMs as both chatbots and automated evaluators, highlighting deficiencies in detecting nuanced issues like empathy and commonsense.


---


[Seven Security Challenges That Must be Solved in Cross-domain Multi-agent LLM Systems](http://arxiv.org/abs/2505.23847v1)

- Cross-domain Multi-agent LLM Systems: introduces an architecture where autonomous agents (LLMs with tools, memory, autonomy) from different organizations dynamically group for collaborative tasks.
- This architecture faces seven security challenges related to agent behavior (unvetted grouping, collusion, conflicting goals, self-tuning misalignment) and data handling (provenance obscurity, context bypass, confidentiality/integrity).
- Proposed countermeasures include trust-adaptive dynamic teaming, adversarial training, hierarchical conflict arbitration, cross-domain reward alignment, neural provenance tracking, session-level semantic firewalls, and verifiable reasoning with privacy.


---



[3DLLM-Mem: Long-Term Spatial-Temporal Memory for Embodied 3D Large Language Model](http://arxiv.org/abs/2505.22657v1)

- 3DLLM-MEM: introduces a memory-enhanced 3D embodied agent framework that utilizes an Encoder (Encodes 3D inputs), Working Memory (Current 3D observations), Episodic Memory (Past 3D observations/interactions) stored in a Memory Bank (Stores episodic memory features), a Memory Fusion Module (Integrates working/episodic memory) producing Fused Episodic Memory (Integrated memory representation), and an LLM (Processes memory for actions).
- The framework incrementally builds and maintains a task-relevant long-term memory by incorporating feedback from the environment and interacting with objects.
- The Memory Fusion Module uses working memory tokens as queries to selectively attend to and fuse relevant spatial and temporal features from episodic memory.


---

[Position: Uncertainty Quantification Needs Reassessment for Large-language Model Agents](http://arxiv.org/abs/2505.22655v1)

- Proposed Research Directions: introduces a position arguing that traditional aleatoric and epistemic uncertainty definitions are insufficient for interactive LLM agents and proposes research into Underspecification uncertainties (missing information, unclear task), Interactive learning (ask follow-up questions), and Output uncertainties (communicate uncertainty beyond numbers).
- The paper highlights conflicts in existing uncertainty definitions and their breakdown in dynamic, multi-turn LLM agent interactions.
- The proposed directions aim to make LLM agent interactions more transparent, trustworthy, and intuitive by addressing and communicating uncertainty in novel ways.


---

[Agent-UniRAG: A Trainable Open-Source LLM Agent Framework for Unified Retrieval-Augmented Generation Systems](http://arxiv.org/abs/2505.22571v1)

- Agent-UniRAG (A Trainable Open-Source LLM Agent Framework for Unified Retrieval-Augmented Generation Systems): introduces a trainable agent framework for unified RAG systems, with Planning Module (determines necessary actions), Tool Using Module (interacts with external tools), Working Memory Module (stores input, logs, evidence), Reflector Module (filters and refines evidence), and Agent Loop (iterative process).
- The framework leverages the LLM agent concept to handle both single-hop and multi-hop queries in an end-to-end manner.
- Agent-UniRAG utilizes a synthetic dataset (SynAgent-RAG) for training small open-source LLMs to achieve competitive performance.


---

[Universal Visuo-Tactile Video Understanding for Embodied Interaction](http://arxiv.org/abs/2505.22566v1)

- VTV-LLM: introduces a multi-modal large language model for universal visuo-tactile video understanding, integrating Tokenizer, T-Projector, VTV Encoder, V-Projector, and a Large Language Model.
- The framework bridges the gap between tactile perception and natural language by aligning visuo-tactile video features with linguistic descriptions.
- It enables sophisticated tactile reasoning capabilities for embodied interaction, including feature assessment and comparative analysis.


---


[From Strangers to Assistants: Fast Desire Alignment for Embodied Agent-User Adaptation](http://arxiv.org/abs/2505.22503v1)

- FAMER (Fast Adaptation via MEntal Reasoning): introduces a framework for fast desire alignment, integrating Perception (Extracts scene graph), Key Information Extraction (Filters, stores goal info), Memory (Stores cross-episode knowledge), Desire-Centered Mental Reasoning (Infers user desires), Efficient Communication (Manages dialogue efficiently), and Goal Oriented Planning (Plans goal actions).
- The framework leverages LLMs to interpret vague instructions, infer user intent, and manage dialogue, enabling adaptation to unknown user preferences.
- FAMER improves task execution and communication efficiency by filtering irrelevant actions, reducing redundant inquiries, and reusing knowledge across episodes.


---

[EvolveSearch: An Iterative Self-Evolving Search Agent](http://arxiv.org/abs/2505.22501v1)

- EvolveSearch: introduces a novel iterative self-evolution framework that combines Reinforcement Learning (RL) and Supervised Fine-Tuning (SFT) to enhance web search capabilities without external human-annotated reasoning data.
- The framework alternates between an RL phase for exploration and generating rollouts, and an SFT phase that optimizes the base model using filtered high-quality rollouts.
- This process leverages a hybrid reward mechanism and specific data filtering rules to enable continuous self-improvement in open web search domains.


---

[Topological Structure Learning Should Be A Research Priority for LLM-Based Multi-Agent Systems](http://arxiv.org/abs/2505.22467v1)

- Unified Framework: introduces, a systematic approach for topological structure learning in LLM-based Multi-Agent Systems, with Agent Selection (Selects agent subset), Structure Profiling (Identifies macro structure), and Topology Synthesis (Synthesizes micro graph), where the framework decomposes topology design into sequential stages for optimization.
- The framework aims to learn optimal topological structures for MASs to enhance coordination performance and efficiency.
- Each stage presents distinct challenges and research opportunities for designing adaptive multi-agent architectures.


---

[AgentDNS: A Root Domain Naming System for LLM Agents](http://arxiv.org/abs/2505.22368v1)

- AgentDNS: introduces a root domain naming and service discovery system for LLM agents, with Service Registration (registers services), Service Proxy Pool (forwards requests), Service Search (discovers services), Service Resolution (resolves identifiers), Service Management (manages proxies), Service Billing (tracks costs), Authentication (verifies identity), AgentDNS DB (stores metadata), and AgentDNS API Server (provides API) components.
- AgentDNS enables LLM agents to autonomously discover, resolve, and securely invoke third-party services across organizational and technological boundaries.
- Inspired by traditional DNS, the system provides unified naming, natural language discovery, protocol-aware interoperability, authentication, and billing for multi-agent collaboration.


---

[From Large AI Models to Agentic AI: A Tutorial on Future Intelligent Communications](http://arxiv.org/abs/2505.22311v1)

- LAM-based Agentic AI system: introduces a system architecture with LAMs (Core reasoning engine), Planner (Task decomposition/organization), Knowledge Base (External knowledge support), Tools (External/internal execution toolkit), and Memory (Stores historical information).
- CommLLM framework: introduces a LAM-centric multi-agent collaborative system architecture with MDR (Acquire task-relevant information), MCP (Decompose tasks/generate pathways), and MER (Evaluate solutions/self-feedback).
- The tutorial reviews the evolution from Large AI Models to Agentic AI and their applications in future intelligent communication systems, particularly in the context of 6G networks.


---

[VOICE CMS: UPDATING THE KNOWLEDGE BASE OF A DIGITAL ASSISTANT THROUGH CONVERSATION](http://arxiv.org/abs/2505.22303v1)

- Voice CMS architecture: introduces a system for updating a digital assistant's knowledge base through conversation, integrating a Voice CMS workflow, Conversational Engine with Agents, Knowledge Base, VUI, and LLM.
- The system allows hotel staff to naturally converse with the assistant to add or modify information, reducing the need for traditional graphical content management systems.
- Evaluation compares the Voice CMS with a GUI for knowledge management tasks, analyzing user preference, usability, and performance across varying task complexities.


---


[Efficient Leave-one-out Approximation in LLM Multi-agent Debate Based on Introspection](http://arxiv.org/abs/2505.22192v1)

- IntrospecLOO (introspective-leave-one-out): introduces an efficient method for evaluating agent contributions in LLM multi-agent debates, utilizing Agents, User/Query, Independently Respond Round, Debate Round, Aggregation, IntrospecLOO Round, and IntrospecLOO Prompt.
- The method adds a single IntrospecLOO Round after standard debate rounds, prompting agents with an IntrospecLOO Prompt to update answers while disregarding one agent's response.
- This approach approximates the traditional Leave-one-out method at significantly reduced query complexity, enabling efficient contribution evaluation.


---

[VIRAL: VISION-GROUNDED INTEGRATION FOR REWARD DESIGN AND LEARNING](http://arxiv.org/abs/2505.22092v1)

- VIRAL: introduces a pipeline for generating and refining reward functions using multi-modal LLMs, including Input, Initial Generation, Policy Learning, and Refinement components.
- The framework takes textual environment details, optional success code, and a multi-modal goal prompt to generate initial reward functions via collaborating LLMs and code verification.
- Reward functions are refined iteratively based on performance evaluation and feedback from humans or a Video-LVLM, leading to improved agent behavior alignment.


---

[VulBinLLM: LLM-powered Vulnerability Detection for Stripped Binaries](http://arxiv.org/abs/2505.22010v1)

- Vul-BinLLM: introduces an LLM-based framework for binary vulnerability detection, featuring an LLM-assisted Decompiler (enhances code) with an Optimization Decision Agent (decides optimizations) and Action Agents (perform optimizations), a Code Memory Management Agent (manages functions), VulBinQ (queue), and Archived Analysis (storage).
- The framework optimizes decompilation by adding vulnerability-specific comments and contextual information before analyzing the code for vulnerabilities.
- It utilizes memory management and a function queue to handle large binary files and reduce LLM hallucinations during vulnerability reasoning.


---

[EFFICIENTLY ENHANCING GENERAL AGENTS WITH HIERARCHICAL-CATEGORICAL MEMORY](http://arxiv.org/abs/2505.22006v1)

- EHC framework: introduces a general agent framework with Hierarchical Memory Retrieval (HMR), Task-Category Oriented Experience Learning (TOEL), Memory Pool (M), and LLM (Large Language Model), designed for efficient multi-modal task handling.
- The framework uses a hierarchical memory system for rapid retrieval and continuous storage, mitigating redundancy and overhead.
- It employs task-oriented learning to classify experiences and extract category-specific patterns, enhancing adaptability and interpretability.


---

[MapStory: LLM-Powered Text-Driven Map Animation Prototyping with Human-in-the-Loop Editing](http://arxiv.org/abs/2505.21966v1)

- MapStory: introduces a text-driven map animation prototyping tool, with Scene Breakdown Agent (parses script), Map Animation Researcher Agent (retrieves geospatial data), and Map Animation Modules (camera, highlight, animated elements), that generates editable map animations from natural language scripts.
- The tool leverages an agentic LLM architecture to produce a scene breakdown and grounds the script in factual geospatial data using web search and APIs.
- MapStory supports human-in-the-loop editing through an interactive timeline editor and properties panel for fine-grained control and rapid iteration.


---

[LaMDAgent: An Autonomous Framework for Post-Training Pipeline Optimization via LLM Agents](http://arxiv.org/abs/2505.21963v1)

- LaMDAgent (Language Model Developing Agent): introduces an autonomous framework using an Agent (LLM-based selector) to iteratively construct and optimize post-training pipelines by selecting from Predefined Action Types (available operations) and an Object Pool (available resources), evaluating the resulting Model (target LLM) based on a Score (performance metric), and updating its Memory (stores experiences).
- The framework automates the post-training pipeline design process by iterating through action enumeration, selection, model evaluation, and memory update steps.
- This agent-based approach reduces the need for specialized knowledge and human intervention in discovering effective model improvement strategies.


---

[Towards Efficient Key-Value Cache Management for Prefix Prefilling in LLM Inference](http://arxiv.org/abs/2505.21919v1)

- Future System: introduces a metadata management system and a hierarchical KVC caching system, featuring a reuse-optimized metadata caching scheme, a workload-aware index structure, and a hotness-aware data placement strategy to optimize KVC management for LLM prefix prefilling.
- The proposed system aims to minimize time to first token for long-context inference by efficiently handling range queries and random get queries.
- The approach is designed to leverage the unique high reusability and mixed sequential-random access patterns observed in KVC prefix prefill workloads.


---

[Co-Saving: Resource Aware Multi-Agent Collaboration for Software Development](http://arxiv.org/abs/2505.21898v1)

- Co-Saving: introduces a resource-aware multi-agent collaboration system leveraging experiential knowledge to enhance efficiency and quality, including Multi-Agent System (Collaborative structure), Agents (Individual LLM entities), Experiential Knowledge (Historical task data), Shortcuts (Learned instructional transitions), Reference Chain (Historical successful trajectory), Inference Chain (Current task execution), Shortcut Filtering (Selecting effective shortcuts), Shortcut Formalization (Graph representation), Shortcut Evaluation (Scoring shortcuts), Cost Design (Time and token metric), Emergency Factor (Dynamic value/cost weighting), and Force Termination Mechanism (Prevents resource exhaustion).
- The system utilizes shortcuts mined from historical successful trajectories to bypass redundant reasoning steps and accelerate problem-solving in familiar contexts.
- A dynamic emergency factor and force termination mechanism are integrated to manage resource consumption and prevent exhaustion during task execution.


---

[Incorporating LLMs for Large-Scale Urban Complex Mobility Simulation](http://arxiv.org/abs/2505.21880v1)

- LLM-ABM Framework: introduces a method for large-scale urban mobility simulation by integrating LLM with Agent-Based Modeling, including Data Collection, Large Language Model (LLM), Agent Profile, Agent Schedule, Routine Allocation, Occasional Locations, and Multi-Transit Route components.
- The framework leverages LLM to generate diverse and realistic synthetic population profiles and personalized agent schedules.
- Agent locations are allocated based on grid data and Points of Interest, and personalized routes are generated using a multi-criteria routing algorithm.


---


#### 27th May 2025

[STRATUS: A Multi-agent System for Autonomous Reliability Engineering of Modern Clouds](https://arxiv.org/abs/2506.02009)

- STRATUS: introduces a multi-agent system for autonomous Site Reliability Engineering (SRE) of cloud services, with Detection Agent (Identifies failures), Diagnosis Agent (Determines root cause), Mitigation Agent (Executes mitigation plans), Undo Agent (Executes undo sequence), State Machine (Orchestrates agents control flow), Agent-Computer Interfaces (ACI) (Enables environment interaction), Toolset (Provides interaction capabilities), Observability tools (Query telemetry, states), Command-line tools (Execute commands, change states), Oracles (Validate system health, terminate), and Transactional Non-Regression (TNR) (Safety specification), designed to autonomously detect, localize, analyze, and mitigate cloud system failures.
- The system organizes specialized agents in a state machine and formalizes a safety specification called Transactional No-Regression (TNR) to enable safe exploration and iteration during mitigation.
- STRATUS utilizes Agent-Computer Interfaces (ACI) and a comprehensive toolset, including observability and command-line tools, to interact with the cloud environment and validate actions using Oracles.


---


[Towards Safety Reasoning in LLMs: AI-agentic Deliberation for Policy-embedded CoT Data Creation](http://arxiv.org/abs/2505.21784v1)

- AIDSAFE (Agentic Iterative Deliberation for Safety Reasoning): introduces a multi-agent framework for generating policy-embedded Chain-of-Thought data, including Initialization, Deliberation, and Refinement stages with dedicated agents.
- The framework leverages collaborative reasoning among Deliberation Agents and post-processing by a Refiner Agent to produce high-quality, policy-adherent CoTs and responses from an Input Query and Safety Policies.
- This approach aims to improve LLM safety generalization and jailbreak robustness by providing superior data for supervised fine-tuning.


---

[BehaviorSFT: Behavioral Token Conditioning for Clinical Agents Across the Proactivity Spectrum](http://arxiv.org/abs/2505.21757v1)

- BehaviorSFT: introduces a training strategy using behavioral tokens to condition pre-trained foundation LLMs for dynamic behavioral selection across the reactive-proactive spectrum, evaluated on the BehaviorBench dataset.
- The approach leverages supervised fine-tuning to enable implicit contextual behavior assessment and behavior-conditioned generation for clinical agents.
- BehaviorSFT aims to improve the balance between helpful proactivity and necessary restraint in LLM responses for healthcare applications.


---

[AI-Supported Platform for System Monitoring and Decision-Making in Nuclear Waste Management with Large Language Models-25367](http://arxiv.org/abs/2505.21741v1)

- Multi-agent Retrieval-Augmented Generation (RAG) system: introduces a platform for nuclear waste management decision-making with a Multi-agent System (Collaboration) including Regulatory Compliance Agent (Checks regulations), Safety & Environmental Agent (Assesses risks), and Documentation & Reporting Agent (Compiles reports), leveraging Retrieval-Augmented Generation (RAG) (Retrieval and generation) with LLM (Llama 3.2) (Base language model), Embeddings (mxbai-embed-large-v1) (Generates semantic vectors), and Document Retrieval (Retrieves relevant documents) accessing Regulatory Compliance Database (Stores regulatory documents) and Safety & Environmental Database (Stores safety/environmental data).
- The system employs a structured 10-round discussion model for agents to iteratively refine assessments and ensure document-grounded responses.
- Evaluation metrics like Context Relevance Distribution and Agent Agreement Rate demonstrate the framework's effectiveness in maintaining factual grounding and decision consistency.


---

[Silence is Not Consensus: Disrupting Agreement Bias in Multi-Agent LLMs via Catfish Agent for Clinical Decision Making](http://arxiv.org/abs/2505.21503v1)

- Catfish Agent Framework: introduces a multi-agent system with Moderator Agent, Catfish Agent, Expert Agent, Team Leader, Team Member, and Summary Agent components to disrupt silent agreement in clinical decision making.
- The framework employs complexity-aware and tone-calibrated interventions by the Catfish Agent to stimulate deeper reasoning and prevent premature consensus.
- Evaluations show the method improves diagnostic accuracy on medical Q&A and VQA benchmarks compared to single- and multi-agent baselines.


---

[Robust Hypothesis Generation: LLM-Automated Language Bias for Inductive Logic Programming](http://arxiv.org/abs/2505.21486v1)

- LLM-Automated Language Bias for Inductive Logic Programming Framework: introduces a novel framework for robust hypothesis generation by integrating LLMs with ILP, including a LLM-Based Multi-agent System (Generates language bias), Translator agent (Transforms text to facts), Language Bias (Structured symbolic vocabulary), Facts (Symbolic data representation), ILP Solver (Learns interpretable rules), and Optimal Hypothesis (Final learned rules).
- The framework utilizes a multi-agent LLM system (Actor and Critic agents) to automate the generation of the language bias (predicate system) directly from raw text.
- This automated symbolic grounding guides a Translator agent to convert text into facts for an ILP solver, which then learns interpretable rules as the optimal hypothesis.


---

[Scaling External Knowledge Input Beyond Context Windows of LLMs via Multi-Agent Collaboration](http://arxiv.org/abs/2505.21471v1)

- EXTAGENTS: introduces a multi-agent framework for scaling external knowledge input beyond LLM context windows, featuring Seeking Agents (Process input chunks), Reasoning Agent (Synthesize information, generate output), Global Knowledge Synchronization (Agents share and rank information), and Knowledge-Accumulating Reasoning (Reasoning agent integrates information iteratively).
- The framework partitions massive input into chunks processed by Seeking Agents, whose outputs are shared and ranked via global knowledge synchronization.
- A Reasoning Agent then iteratively integrates the synchronized information through knowledge-accumulating reasoning to produce the final output.


---

[Autonomous Multi-Modal LLM Agents for Treatment Planning in Focused Ultrasound Ablation Surgery](http://arxiv.org/abs/2505.21418v1)

- FUAS-Agents: introduces an autonomous agent system leveraging multimodal LLMs for Focused Ultrasound Ablation Surgery treatment planning, including Planner Agent (interprets instructions, decomposes tasks), Executor Agent (performs specific tasks), Strategy Agent (generates treatment plans), Optimizer Agent (refines outputs, integrates results), and Memory Module (integrates medical resources, manages data).
- The system integrates patient profiles and MRI data, orchestrating specialized medical AI tools for segmentation, dose prediction, and clinical guideline retrieval to generate personalized treatment plans.
- Evaluated in a uterine fibroid scenario, the generated plans demonstrate high completeness, accuracy, fluency, and clinical compliance according to human expert assessment.


---

[Evaluating LLM Adaptation to Sociodemographic Factors: User Profile vs. Dialogue History](http://arxiv.org/abs/2505.21362v1)

- Dataset Generation Framework: introduces, "a multi-agent pipeline", with Users (Simulated input), Dialogue Generation Controller (Orchestrates workflow), User Simulator (Generates user questions), Out-of-Context Detector (Validates questions), and QA LLM (Responds to questions), where "the framework generates synthetic dialogues embedding sociodemographic attributes for evaluating LLM adaptation".
- The pipeline simulates user-LLM interactions, with a user simulator generating profile-aligned questions and an out-of-context detector ensuring question validity.
- This agent-based approach creates a controlled dataset enabling assessment of LLM behavioral consistency when user attributes are provided explicitly or implicitly.


---

[PEDANTIC: A Dataset for the Automatic Examination of Definiteness in Patent Claims](http://arxiv.org/abs/2505.21342v2)

- PEDANTIC-based Definiteness Examination: introduces PEDANTIC Dataset (corpus of patent claims with indefiniteness annotations), Dataset Creation Pipeline (automatic process using LLMs to build PEDANTIC), Logistic Regression Model (baseline prediction model), LLM Agent Model (LLM-based prediction model using tools), Binary Classification (evaluates definite/indefinite prediction), Multi-Label Classification (evaluates indefiniteness category prediction), and Pairwise Reasoning Judge (LLM-as-Judge evaluates reasoning quality), presenting a dataset and evaluation framework for automatic patent claim definiteness examination.
- The PEDANTIC Dataset contains 14k US patent claims annotated with indefiniteness reasons extracted using an automatic pipeline leveraging Large Language Models.
- The framework evaluates Logistic Regression and LLM Agent models on binary and multi-label classification tasks, and uses an LLM-as-Judge to assess the quality of generated indefiniteness reasoning.


---

[Large Language Models Miss the Multi-Agent Mark](http://arxiv.org/abs/2505.21298v1)

- MAS LLMs (Multi-Agent Systems of Large Language Models): introduces a critique of current MAS LLMs, highlighting issues with Agents (lack native social behaviour), Environment (often textual, LLM-centric), Coordination (often sequential, orchestrated), Communication (often natural language), Memory (lack long-term persistency), and Asynchronicity (often absent).
- The paper argues that current MAS LLMs often fail to embody fundamental multi-agent system characteristics by overemphasizing LLMs and overlooking established MAS literature.
- It advocates for better integrating MAS concepts like native social agents, non-LLM-centric environments, asynchronous communication protocols, and quantifiable emergent behaviours.


---

[Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework](http://arxiv.org/abs/2505.21291v1)

- LLM-Informed Diagnostic Framework: introduces a novel approach integrating KGs and LLMs for complex system diagnostics, featuring Model Construction, KG-DML, Model Interaction, and an LLM Agent with diagnostic tools.
- The framework automates DML model construction from system documentation using an LLM-based workflow and stores this structured logic in a KG-DML.
- An LLM agent facilitates interactive diagnostics by interpreting user queries and invoking KG-based tools for upward/downward reasoning and Graph-RAG retrieval to generate diagnostic insights.


---

[PACT: A Contract-Theoretic Framework for Pricing Agentic AI Services Powered by Large Language Models](http://arxiv.org/abs/2505.21286v1)

- PACT: introduces a contract-theoretic framework for pricing cloud-based agentic AI services, modeling task-dependent multi-dimensional QoS, costs (including liability), and user types to design contracts satisfying individual rationality and incentive compatibility.
- The framework models QoS based on objective response time and subjective user satisfaction, accounting for computational, infrastructure, and potential liability costs for the service provider.
- Through contract-based selection, PACT enables users to receive tailored service offerings aligned with their needs while ensuring incentive compatibility and individual rationality under information asymmetry.


---

[Creativity in LLM-based Multi-Agent Systems: A Survey](http://arxiv.org/abs/2505.21116v1)

- LLM-based Multi-Agent Systems: introduces a survey on creativity in these systems, outlining a structured framework with Input (user input text/image), Workflow (Three-stage creative process), Planning (formulate objectives, structure tasks), Process (implement tasks, coordinate interaction), Decision Making (evaluate options, determine outcome), Technique (methods for idea generation/refinement/synthesis), Persona (agent roles and profiles), and Output (generated text/image content).
- The framework details how agents, guided by personas and employing various techniques, navigate a three-stage workflow to transform user inputs into creative outputs.
- The survey maps techniques, datasets, and evaluation methods, highlighting how collaborative structures and agent proactivity influence creative potential in these systems.


---

[Simulating Ethics: Using LLM Debate Panels to Model Deliberation on Medical Dilemmas](http://arxiv.org/abs/2505.21112v1)

- ADEPT (AI Deliberative Ethics Protocol Toolkit): introduces a system for simulating multi-perspective ethical debates using LLM personas, with AI Persona Specs, Scenario & Options, and Model Config inputs managed by an Orchestrator utilizing an OpenAI o3 model.
- The framework orchestrates structured debates through phases, logging interactions and votes into Debate Outputs for transparency and audit.
- A Summariser Agent processes the debate outputs to provide an executive summary, facilitating the analysis of how different ethical perspectives influence deliberation outcomes.


---

[Creativity in LLM-based Multi-Agent Systems: A Survey](http://arxiv.org/abs/2505.21116v1)

- LLM-based Multi-Agent Systems: introduces a survey on creativity in these systems, outlining a structured framework with Input (user input text/image), Workflow (Three-stage creative process), Planning (formulate objectives, structure tasks), Process (implement tasks, coordinate interaction), Decision Making (evaluate options, determine outcome), Technique (methods for idea generation/refinement/synthesis), Persona (agent roles and profiles), and Output (generated text/image content).
- The framework details how agents, guided by personas and employing various techniques, navigate a three-stage workflow to transform user inputs into creative outputs.
- The survey maps techniques, datasets, and evaluation methods, highlighting how collaborative structures and agent proactivity influence creative potential in these systems.


---

[Simulating Ethics: Using LLM Debate Panels to Model Deliberation on Medical Dilemmas](http://arxiv.org/abs/2505.21112v1)

- ADEPT (AI Deliberative Ethics Protocol Toolkit): introduces a system for simulating multi-perspective ethical debates using LLM personas, with AI Persona Specs, Scenario & Options, and Model Config inputs managed by an Orchestrator utilizing an OpenAI o3 model.
- The framework orchestrates structured debates through phases, logging interactions and votes into Debate Outputs for transparency and audit.
- A Summariser Agent processes the debate outputs to provide an executive summary, facilitating the analysis of how different ethical perspectives influence deliberation outcomes.


---


[Herd Behavior: Investigating Peer Influence in LLM-based Multi-Agent Systems](http://arxiv.org/abs/2505.21588v1)

- LLM-based Multi-Agent System: introduces a framework to investigate herd behavior in multi-agent systems, featuring LLM-based Agents (autonomous decision makers) receiving Question Input (initial task) and Peer Information Input (peers' responses), utilizing a Confidence Mechanism (internal certainty assessment) for Response Generation (initial answer) and revision, modulated by Peer Information Presentation (format and order), Peer Persona (peer attributes), and System Prompt (behavioral instructions).
- The system simulates agents interacting and making decisions, where herd behavior is measured by the flip rate, the tendency of agents to change their initial response based on peer input.
- Experiments manipulate agent self-confidence, perceived peer confidence, and peer information presentation factors to understand their impact on conformity and collective outcomes.


---

[CXXCrafter: An LLM-Based Agent for Automated C/C++ Open Source Software Building](http://arxiv.org/abs/2505.21069v1)

- CXXCrafter: introduces an LLM-based agent system for automated C/C++ software building, including a Parser Module (Extracts build-related information), a Generator Module (Generates/modifies Dockerfile), and an Executor Module (Executes Dockerfile, captures errors).
- The system leverages LLMs to dynamically manage complex build processes by iteratively addressing issues based on feedback.
- CXXCrafter achieves a 78% build success rate across 752 C/C++ projects by handling dependency management, diverse build systems, and error diagnosis.


---

[Agent-Environment Alignment via Automated Interface Generation](http://arxiv.org/abs/2505.21055v1)

- ALIGN (Auto-Aligned Interface Generation): introduces a framework that automatically generates interfaces to alleviate agent-environment misalignment, utilizing an Analyzer (Identifies misalignments) and an Optimizer (Generates/refines interface) to produce an interface with INFERRULES (Static information alignment) and WRAPSTEP (Dynamic observation enhancement) that mediates interaction between the Agent (Interacts with environment) and Environment (Provides state/feedback).
- The framework operates iteratively, with the Analyzer identifying misalignments from failed trajectories and the Optimizer generating an improved interface based on these findings.
- The ALIGN-generated interface enhances both static environment information and step-wise observations, improving agent performance across diverse interactive tasks without modifying agent or environment code.


---

[AITEE - Agentic Tutor for Electrical Engineering](http://arxiv.org/abs/2505.21582v1)

- AITEE (Agentic Tutor for Electrical Engineering): introduces an agent-based tutoring system for electrical engineering, with Circuit (Input image), Detection of components and connections (Processes circuit image), Conversion into Graph/Netlist (Creates textual representation), Simulation with Spice (Validates circuit calculations), Scripts (Lecture material knowledge base), Relevant context in vector database (Stores script embeddings), Retriever (RAG) (Retrieves relevant script context), Large Language Model (Core AI tutor), LLM-Instructions (Guides Socratic dialogue), Students (User), Prompt (Student query), and Output (Tutor response) components, designed to provide interactive and personalized learning experiences.
- The system processes hand-drawn or digital circuit diagrams, converts them into a machine-readable format, and uses a graph-based similarity measure for context retrieval from lecture materials.
- AITEE employs a Socratic dialogue approach guided by LLM instructions and validates calculations using SPICE simulation to foster learner autonomy and ensure accuracy.


---

[Cross from Left to Right Brain: Adaptive Text Dreamer for Vision-and-Language Navigation](http://arxiv.org/abs/2505.20897v1)

- ATD (Adaptive Text Dreamer): introduces a dual-branch LLM self-guided imagination policy for VLN, with Left Brain (State Estimation LLM), Right Brain (Imagination LLM), Q-Former, LLM Encoder, LLM Decoder, State Grounded Cross-Attention (SGCA), Graph-based Navigation Policy, Latent Embedding Injection, Multi-head Cross-Attention (MCA), Graph-aware Self-Attention (GASA), and MLP components.
- The framework leverages language-based imagination, employing a left brain for state estimation and a right brain for imaginative prediction, constrained by the estimated state.
- Imagined textual representations are integrated into a graph-based navigation expert via latent embeddings and cross-attention to guide action decisions.


---

[RepoMaster: Autonomous Exploration and Understanding of GitHub Repositories for Complex Task Solving](http://arxiv.org/abs/2505.21577v1)

- RepoMaster: introduces an autonomous agent framework for exploring and understanding GitHub repositories, consisting of Repository Search, Hierarchical Repository Analysis, and Autonomous Exploration & Execution.
- Hierarchical Repository Analysis builds structural representations like HCT, MDG, and FCG to identify Core components for efficient understanding.
- Autonomous Exploration & Execution uses Context-aware Code Exploration with Exploration tools and Context-aware Information Selection in an Interactive Feedback-based Execution loop to solve tasks.


---

[MedSentry: Understanding and Mitigating Safety Risks in Medical LLM Multi-Agent Systems](http://arxiv.org/abs/2505.20824v1)

- MedSentry: introduces a benchmark and evaluation pipeline for medical LLM multi-agent systems, analyzing the safety risks posed by malicious agents within different architectural topologies.
- The framework evaluates four representative multi-agent topologies (Centralized, Decentralized, Layers, SharedPool) by injecting a Dark Personality Agent and assessing system safety using an Enforcement Agent defense mechanism.
- MedSentry provides a rigorous evaluation framework and practical defense strategies for designing safer LLM-based multi-agent systems in medical domains.


---

[MT-MOL: Multi Agent System with Tool-based Reasoning for Molecular Optimization](http://arxiv.org/abs/2505.20820v1)

- MT-MOL (Multi Agent System with Tool-based Reasoning for Molecular Optimization): introduces a multi-agent framework for molecular optimization featuring Analyst agents (Select relevant tools), a Scientist agent (Generates molecule/reasoning), a Verifier agent (Validates consistency), and a Reviewer agent (Provides feedback), utilizing Tool sets (Domain-specific functions), Top-k data (Reference molecules), and SMILES history (Previous designs).
- The system integrates domain-specific tools and structured reasoning through agent interactions to produce interpretable and chemically grounded molecular designs.
- An iterative generation and review process, including consistency validation and tool-informed feedback, refines the molecular candidates towards the design objective.


---

[Rethinking Information Synthesis in Multimodal Question Answering A Multi-Agent Perspective](http://arxiv.org/abs/2505.20816v1)

- MAMMQA: introduces a multi-agent framework for multimodal question answering with Modality Expert Agent (Extracts modality specific insights), Cross Modal Synthesis Agent (Synchronises information across modalities), and Aggregator Agent (Synthesizes outputs, resolves disagreements), splitting reasoning into interpretable stages.
- The framework employs specialized agents for modality-specific extraction, cross-modal synthesis, and evidence-grounded aggregation without fine-tuning.
- This modular design enhances interpretability, robustness, and zero-shot generalization by allowing agents to operate within their expertise domains.


---

[ChemHAS: Hierarchical Agent Stacking for Enhancing Chemistry Tools](http://arxiv.org/abs/2505.21569v1)

- ChemHAS (Chemical Hierarchical Agent Stacking): introduces a hierarchical agent stacking method with Initial Tools (Predefined chemistry tools), AI Agent (LLM-based agent), Agent Tool (Tool or agent), Global Tool Library (Collection of tools/agent tools), Stacking Process (Hierarchical combination method), Reinforcement Process (Two-stage optimization), ReAct method (Agent reasoning and tool use), and Stacking Agent (Enhanced tool/agent) to enhance chemistry tools by reducing prediction errors.
- The Stacking Process involves Warmup Self Agent Stacking and Hierarchical Agent Stacking, iteratively building and evaluating agent tools and storing them in the Global Tool Library.
- The resulting Stacking Agent leverages the complementary strengths of stacked tools, guided by a two-stage reinforcement process, to achieve improved performance on chemistry tasks.


---

[Can Agents Fix Agent Issues?](http://arxiv.org/abs/2505.20749v1)

- AGENTISSUE-BENCH: introduces the first reproducible benchmark for agent issue resolution, comprising issue description (User reported problem), buggy version (Codebase commit), developer-committed patch (Ground truth fix), failure-triggering tests (Reproduce issue), and docker environment (Executable container).
- Built from 50 reproducible real-world GitHub issues, the benchmark enables evaluating state-of-the-art software engineering agents.
- Evaluation on AGENTISSUE-BENCH reveals that current SE agents have limited effectiveness in resolving agent-specific issues.


---

[RRO: LLM Agent Optimization Through Rising Reward Trajectories](http://arxiv.org/abs/2505.20737v1)

- RRO (Reward Rising Optimization): introduces a scalable process supervision framework for LLM agents, including LLM Agent (Policy Model), Supervised Fine-tuning (Initial training on expert data), Reward Rising Sampling (Dynamically explores next actions), Process Reward Estimation (Estimates step reward via rollouts), Agent Optimization (DPO) (Optimizes policy using preferences), and Preference Data (Pairs of preferred/rejected actions).
- The framework dynamically adjusts next action exploration based on rising reward trends to efficiently collect high-quality preference data for training.
- RRO prioritizes reasoning steps with increasing rewards, reducing exploration cost while improving performance on multi-step tasks.


---

[E2E Process Automation Leveraging Generative AI and IDP-Based Automation Agent: A Case Study on Corporate Expense Processing](http://arxiv.org/abs/2505.20733v1)

- Brity Automation: introduces an end-to-end automation system for financial expense processing, integrating a Data Input Layer, Intelligent Processing Layer with OCR/IDP Module, Policy-based Classification Engine, AI Flow Module (Gen AI Integration), and Workflow Engine, a User Interaction & Learning Layer with Automation Agent Interface and Human-in-the-Loop (HITL) Mechanism, and a Backend Infrastructure Layer with Brity Automation Orchestrator, Database, and API Gateway.
- The system automates document recognition, policy-based classification, intelligent exception handling using generative AI, and incorporates human judgment for continuous learning.
- This approach aims to overcome limitations of traditional RPA by handling unstructured data and complex exceptions through human-AI collaboration.


---

[SPA-RL: Reinforcing LLM Agents via Stepwise Progress Attribution](http://arxiv.org/abs/2505.20732v1)

- SPA-RL: introduces Stepwise Progress Attribution (SPA), with LLM Agent, Environment, Progress Estimator, Grounding Signal, Fused Intermediate Reward, and PPO Update components, which is a reward redistribution framework reinforcing LLM agents by decomposing delayed rewards into stepwise contributions.
- The framework trains a Progress Estimator to predict each step's contribution to task completion, combining this with a Grounding Signal for action executability to form a Fused Intermediate Reward.
- This dense, goal-oriented Fused Intermediate Reward is then used within a PPO Update to train the LLM Agent, improving performance on long-horizon tasks with sparse rewards.


---

[Hierarchical Instruction-aware Embodied Visual Tracking](http://arxiv.org/abs/2505.20710v1)

- HIEVT (Hierarchical Instruction-aware Embodied Visual Tracking): introduces a hierarchical tracking agent with LLM-based Semantic-Spatial Goal Aligner and RL-based Adaptive Goal-Aligned Policy components, designed for user-centric embodied visual tracking.
- The LLM-based Semantic-Spatial Goal Aligner translates user instructions into spatial goals via Semantic Parsing, Spatial-Goal Generation, and Retrieval-Augmented Goal Correction.
- The RL-based Adaptive Goal-Aligned Policy uses a Visual Foundation Model, Goal-State Aligner (with CNN and Reward Prediction), and Recurrent Policy Network (with LSTM and Actor Network) to align agent actions with the spatial goals for precise tracking.


---

[GIFARC: Synthetic Dataset for Leveraging Human-Intuitive Analogies to Elevate AI Reasoning](http://arxiv.org/abs/2505.20672v1)

- GIFARC: introduces a data synthesis pipeline that transforms raw GIFs into analogy-grounded ARC-style tasks, utilizing a VLM to extract visual abstractions and LLMs to generate task sketches and executable tasks, including input-output pairs, analogy labels, and solution programs.
- The pipeline processes GIFs through stages of visual abstraction, task sketching, and executable task generation to create a dataset that embeds human-intuitive analogies into ARC-style problems.
- The generated dataset aims to guide AI agents, particularly LLMs, to adopt an analogic approach for solving ARC tasks, aligning their reasoning more closely with human intuition.


---

[LLM-Guided Reinforcement Learning: Addressing Training Bottlenecks through Policy Modulation](http://arxiv.org/abs/2505.20671v1)

- ULTRA (Large Language Model-Guided Policy Modulation Framework): introduces a framework that leverages LLMs to identify critical states from sub-optimal trajectories and provide action suggestions and rewards for policy refinement.
- The framework's Identification component uses an LLM and a state interpretation function to pinpoint critical states in historical agent trajectories.
- Its Improvement component refines the RL policy by incorporating LLM-suggested actions from a lookup table and LLM-generated rewards at critical states.


---

[MIRROR: Multi-agent Intra- and Inter-Reflection for Optimized Reasoning in Tool Learning](http://arxiv.org/abs/2505.20670v1)

- MIRROR (Multi-agent Intra- and Inter-Reflection for Optimized Reasoning): introduces a multi-agent framework with Planner Agent, Tool Agent, and Answer Agent, integrating Intra-reflection and Inter-reflection mechanisms supported by Long-Term Memory and Short-Term Memory for enhanced tool learning.
- The framework employs intra-reflection for proactive error prevention within each agent before execution and inter-reflection for corrective learning and strategic adjustment based on task outcomes.
- This dual-reflection approach systematically leverages LLM capabilities to improve task decomposition, tool selection, and answer generation in complex multi-agent workflows.


---

[CoderAgent: Simulating Student Behavior for Personalized Programming Learning with Large Language Models](http://arxiv.org/abs/2505.20642v1)

- CoderAgent: introduces a LLM-based agent framework to simulate student programming processes, with Memory (Stores student proficiency), Tools (Interface with compilers), Planning & Action (Decision-making core), and Reflection (Evaluates generated code) components.
- The framework simulates iterative coding by capturing cognitive states, using a Programming Tree of Thought for planning, and reflecting on generated code.
- CoderAgent aims to provide interpretable insights into learning trajectories and accurate simulations without relying on large-scale real data.


---

[Long Context Scaling: Divide and Conquer via Multi-Agent Question-driven Collaboration](http://arxiv.org/abs/2505.20625v1)

- XpandA (Expand-Agent): introduces a multi-agent framework with Dynamic Chunking (Splits input text), Explorer Agents (Process text chunks), Decider (Decides next action), Shared Information Memory (Centralized knowledge store), Question-driven Workflow (Guides agent communication), Selective Replay (Revisits relevant chunks), Unsolved Problem Tracer (Tracks unsolved questions), and Information (Stores gathered answers), designed for robust long-context processing.
- The framework dynamically partitions long texts, uses a question-guided protocol to update shared memory, and selectively replays partitions based on question-information state tracking.
- XpandA demonstrates feasibility for processing ultra-long sequences up to 1M tokens, achieving performance improvements and inference speedup over baselines.


---


#### 26th May 2025


[Ten Principles of AI Agent Economics](https://arxiv.org/abs/2505.20273)

- Ten Principles of AI Agent Economics: introduces a foundational framework for understanding how AI agents make decisions, influence social interactions, and participate in the broader economy, with Altruistic AI Agent, Survival-Driven AI Agent, Human Agent, Environment, and Human-AI Multi-Agent Hierarchical Society components.
- The paper outlines ten principles drawing on economics, decision theory, and ethics to explore fundamental questions about AI agents' integration into human systems.
- The framework distinguishes between altruistic and survival-driven AI agents and models their interaction within environments and a hierarchical human-AI society.


---


[Project Riley: Multimodal Multi-Agent LLM Collaboration with Emotional Reasoning and Voting](http://arxiv.org/abs/2505.20521v1)

- Project Riley: introduces a multimodal multi-agent LLM architecture for emotional reasoning, featuring Input (Receives user query/context) processed by LLM vision model (Image processing) and LLM text model (Text generation/reasoning), distributed to Emotional agents (Five distinct emotion agents) with Emotion's history (Separate history per agent) for Multi-round processing (Iterative agent dialogue), culminating in Voting and Analysis (Agents evaluate/vote) and Final Synthesis (Synthesizes final response) for the Final response (Output to user).
- The architecture simulates reasoning influenced by five distinct emotional states (Joy, Sadness, Fear, Anger, Disgust) through structured multi-round dialogues and a final synthesis mechanism.
- The system integrates textual and visual LLMs, advanced reasoning, and self-refinement processes to generate emotionally informed responses.


---

[SWE-rebench: An Automated Pipeline for Task Collection and Decontaminated Evaluation of Software Engineering Agents](http://arxiv.org/abs/2505.20411v1)

- SWE-rebench Automated Pipeline: introduces a novel, automated, and scalable pipeline for continuously extracting real-world interactive software engineering tasks from GitHub repositories, comprising Preliminary Task Collection, Automated Installation Instructions Configuration, Execution-based Installation Verification, and Automated Instance Quality Assessment, resulting in the SWE-rebench Dataset and SWE-rebench Benchmark used within a standardized Evaluation Framework employing ReAct-style Scaffolding, a Terminal Environment, Special Tools, and an LLM agent.
- The pipeline addresses challenges in training data availability and evaluation reliability for LLM-based software engineering agents by providing a large-scale, diverse, and continuously updated dataset and a contamination-free benchmark.
- The standardized evaluation framework enables transparent and fair comparisons of LLM agent performance on interactive software engineering tasks, mitigating issues like data contamination and scaffolding variability.


---

[ALITA: GENERALIST AGENT ENABLING SCALABLE AGENTIC REASONING WITH MINIMAL PREDEFINITION AND MAXIMAL SELF-EVOLUTION](http://arxiv.org/abs/2505.20286v1)

- ALITA: introduces a generalist agent with minimal predefinition and maximal self-evolution, featuring Manager Agent (central coordinator), Web Agent (external information), MCP Brainstorming (plan tools), Script Generating Tool (generates code), Code Running Tool (executes code), Environment Management (manages environments), MCP Box (stores MCPs), and CodeReAct Loop (iterative process).
- The Manager Agent orchestrates the CodeReAct loop, utilizing the Web Agent for information and the MCP creation tools to generate, execute, and store new capabilities as MCPs.
- This design allows ALITA to autonomously evolve its capabilities through continuous MCP integration, reducing dependence on manual predefinition.


---

[MASKSEARCH: A Universal Pre-Training Framework to Enhance Agentic Search Capability](http://arxiv.org/abs/2505.20285v2)

- MASKSEARCH: introduces a pre-training framework to enhance LLM agentic search capabilities using the RAMP Task (pre-training objective), trained via SFT (supervised fine-tuning) or RL (reinforcement learning), leveraging an LLM (core language model) interacting with a Search Tool (external search interface), Retriever (knowledge retrieval module), and Knowledge Corpus (external knowledge base), supported by Agent-Based CoT Construction (SFT data generation method), Self-Evolve Distillation (iterative data scaling), Curriculum Learning (progressive training strategy), and an RL Reward System (reinforcement signal).
- The framework trains models on the Retrieval-Augmented Mask Prediction (RAMP) task, where the model learns to use search tools to fill masked spans in text.
- Training involves a two-stage approach combining pre-training on RAMP with supervised fine-tuning or reinforcement learning on downstream tasks, demonstrating improved performance on open-domain question answering.


---

[syftr: Pareto-Optimal Generative AI](http://arxiv.org/abs/2505.20266v1)

- syftr: introduces a framework that performs multi-objective search over agentic and non-agentic RAG flows, composed of Synthesizing LLM, Reranker, Embedding Model, Splitter, HyDE, Retriever, Prompt, Dynamic Few-Shot Retriever, and Additional Context components, to find Pareto-optimal flows balancing task accuracy and cost.
- The framework utilizes Bayesian Optimization with a novel early-stopping mechanism to efficiently explore a vast search space of RAG configurations.
- syftr identifies flows that are significantly cheaper or more accurate than baseline configurations across multiple RAG benchmarks.


---

[ON PATH TO MULTIMODAL HISTORICAL REASONING: HISTBENCH AND HISTAGENT](http://arxiv.org/abs/2505.20246v1)

- HistAgent: introduces a domain-specialized AI agent for historical reasoning, with a Manager Agent (Central coordinator) orchestrating specialized agents including Text WebBrowser Agent (Web search/parsing), Image Information Agent (Image search/analysis), Literature Search Agent (Scholarly search/citation), File Processing Agent (Handle non-HTML files), OCR Agent (Extract text from images), Speech Recognition Agent (Convert audio to text), Translator Agent (Translate text), and Video Agent (Extract frames from video).
- HistAgent integrates these modular tools and a ReAct-style loop to process multimodal inputs and generate cited responses grounded in historical sources.
- The agent is evaluated on HistBench, a new benchmark for historical reasoning, and demonstrates superior performance compared to generalist LLMs and agents.


---

[THINK: Can Large Language Models Think-aloud?](http://arxiv.org/abs/2505.20184v1)

- THINK (Testing Higher-order Notion of Knowledge): introduces a multi-agent, feedback-driven evaluation framework for assessing and improving LLM higher-order thinking skills using flawed math problems (Initial input data), a multi-agent evaluation stage (Parallel agent system) with agents (Evaluate problems) including Bloom-aligned agents (Assess Bloom levels) and a holistic evaluation agent (Assess quality, suggest improvements), agent feedback & ratings (Scores and suggestions), a quality assessment protocol (Metrics for quality) with a quality threshold (Success criterion), an iterative revision loop (Refinement process) involving a think-aloud process (LLM reflection) by the LLM (Revises problems) guided by "Five Keys" (Structured criteria), resulting in an improved problem set (Refined output data).
- The framework uses a parallel multi-agent system to evaluate flawed math problems based on Bloom's Taxonomy and "Five Keys" criteria, generating scores and structured feedback.
- An iterative revision loop, guided by agent feedback, prompts the LLM to refine problems via a "think-aloud" process until a quality threshold is met, enabling deeper analysis of reasoning and revision behaviors.


---

[Iterative Self-Incentivization Empowers Large Language Models as Agentic Searchers](http://arxiv.org/abs/2505.20128v1)

- EXSEARCH (exploratory search framework): introduces an agentic search framework, empowering an LLM with thinking, search, and recording actions, trained via a self-incentivized Generalized Expectation-Maximization algorithm.
- The framework enables the LLM to iteratively explore search trajectories, retrieve relevant documents using an external retriever, and extract fine-grained evidence.
- A re-weighted trajectory learning process in the M-step, guided by importance weighting, progressively improves the LLM's search and reasoning capabilities.


---

[Agentic AI Process Observability: Discovering Behavioral Variability](http://arxiv.org/abs/2505.20127v1)

- Agentic AI Process Observability Approach: introduces a method to enhance developer observability of agent behavior variability, including trajectory files generation (Capture agent execution logs), event-log processing (Consolidate logs into event log), process and causal discovery (Analyze event log for variability), rule derivation (Generate rules for split points), static analysis (LLM analyzes rules vs spec), and reliability calculation (Assess data sufficiency for splits).
- The approach leverages process and causal discovery on agent execution trajectories to identify behavioral variability and uses LLM-based static analysis to distinguish intended from unintended variability.
- This method provides developers with insights into agent behavior, aiding in debugging, refining specifications, and improving control over non-deterministic AI agents.


---

[TrojanStego: Your Language Model Can Secretly Be A Steganographic Privacy Leaking Agent](http://arxiv.org/abs/2505.20118v2)

- TrojanStego: introduces a threat model where a Malicious Actor fine-tunes a Trojan Model (Fine-tuned LLM) and distributes it on a Public Platform, allowing the Malicious Actor to extract secrets from outputs generated by a Genuine User using an Encoding Scheme (Embeds bits via token selection) and Decoding Process (Extracts bits from output).
- The core method, the Bucket Method, partitions the LLM's token vocabulary to encode binary bits into the output token sequence.
- This attack allows covert data exfiltration without requiring explicit control over inference inputs or leaving obvious traces.


---

[REARANK: Reasoning Re-ranking Agent via Reinforcement Learning](http://arxiv.org/abs/2505.20046v1)

- REARANK (Reasoning Re-ranking Agent via Reinforcement Learning): introduces a large language model-based listwise reranking agent that explicitly reasons before reranking, trained using reinforcement learning and data augmentation.
- The agent's architecture includes an LLM policy generating reasoning and ranking, optimized by an RL framework with a reward model and reference policy.
- Data augmentation from limited annotations and a sliding window strategy enhance training efficiency and practical deployment.


---

[Training LLM-Based Agents with Synthetic Self-Reflected Trajectories and Partial Masking](http://arxiv.org/abs/2505.20023v1)

- STeP (Self-Reflected Trajectories and Partial Masking): introduces a novel method for training LLM-based agents using Self-reflected Trajectories (Trajectories with teacher reflection/correction) and Partial Masking (Masks incorrect steps during SFT), building upon a Base LLM Agent (Initial agent) trained with SFT (Training method) on Golden Trajectories (Successful expert trajectories) and guided by an LLM Teacher (Evaluates, provides reflection/correction) interacting with an Environment (Agent interacts, provides feedback).
- The method synthesizes self-reflected trajectories by having a teacher LLM evaluate a base agent's actions in real-time and provide corrections for errors.
- Partial masking is applied during fine-tuning to prevent the agent from learning from the identified incorrect steps in the augmented trajectories.


---

[WEBCOT: Enhancing Web Agent Reasoning by Reconstructing Chain-of-Thought in Reflection, Branching, and Rollback](http://arxiv.org/abs/2505.20013v1)

- WEBCOT: introduces a framework that enhances web agent reasoning by reconstructing inference-time processes into chain-of-thought rationales used to train the agent language model, including reflection & lookahead, branching, and rollback components.
- The framework leverages a language model to interact with a dynamic web environment using actions and observations, guided by the distilled reasoning patterns.
- By distilling specific reasoning skills into the backbone LLM via fine-tuning, WEBCOT significantly improves performance on web agent tasks across multiple benchmarks.


---

[Embracing Imperfection: Simulating Students with Diverse Cognitive Levels Using LLM-based Agents](http://arxiv.org/abs/2505.19997v1)

- Framework: introduces a training-free approach for student simulation, including cognitive prototype construction, behavior prediction, and solution simulation using πdesc, πnode, πedge, πlocal, πglobal, πpred, πrefine, and πvalue components.
- The framework constructs a knowledge graph-based cognitive prototype from past learning records to predict student behavior on new tasks.
- It employs a beam search-based self-refinement process to generate realistic student solutions consistent with predicted behavior.


---

[MLR-Bench: Evaluating AI Agents on Open-Ended Machine Learning Research](http://arxiv.org/abs/2505.19955v1)

- MLR-Bench: introduces a comprehensive benchmark evaluating AI agents on open-ended machine learning research, comprising MLR-Bench Tasks, MLR-Judge, and MLR-Agent.
- MLR-Bench supports stepwise evaluation through MLR-Agent's stages (Idea Generation, Literature Review, Proposal Generation, Experimentation, Paper Writing) and end-to-end evaluation, with MLR-Judge (using LLM Judges and Review Rubrics) automating assessment.
- Evaluation highlights that while agents can generate ideas and papers, the Experimentation Stage often produces fabricated results, posing a significant challenge to scientific reliability.


---

[Multimodal Reasoning Agent for Zero-Shot Composed Image Retrieval](http://arxiv.org/abs/2505.19952v1)

- MRA-CIR: introduces a zero-shot composed image retrieval framework that generates training triplets using Automatic Triplets Generation and fine-tunes a Vision-Language Model (VLM) using VLM Finetuning with InfoNCE Loss.
- The Automatic Triplets Generation process includes Moderate Similarity Selection using a Pre-trained VLM to find image pairs and Modifying Text Generation via the Multimodal Reasoning Agent (MRA), which is based on an MLLM (MiniCPM-VL-2_6), to describe the transformation.
- The VLM Finetuning utilizes the VLM's Q-Former to extract features and is trained with InfoNCE Loss to directly align composed queries and target images, bypassing intermediate textual representations.


---


[EMAC+: Embodied Multimodal Agent for Collaborative Planning with VLM+LLM](http://arxiv.org/abs/2505.19905v1)

- EMAC+ (Embodied Multimodal Agent for Collaborative Planning with VLM+LLM): introduces a novel embodied multimodal agent that collaboratively integrates a VLM Agent (Processes visual input) and an LLM Expert (Generates/refines plans) via a bidirectional training paradigm, utilizing PDDL (Translates visual to text), a Retrospective Feedback Mechanism (Provides execution feedback), Long-term Memory (Stores history/feedback), and an Action Mapping Dictionary (Maps text to control).
- The framework dynamically refines high-level textual plans from the LLM expert using real-time visual feedback from the VLM agent executing low-level control tasks.
- This approach enables the LLM expert to internalize visual environment dynamics through interactive experience, improving domain-specific comprehension and generating more accurate and feasible plans for complex robotic tasks.


---

[SCIENCEBOARD: Evaluating Multimodal Autonomous Agents in Realistic Scientific Workflows](http://arxiv.org/abs/2505.19897v1)

- SCIENCEBOARD: introduces a realistic, multi-domain environment for evaluating multimodal autonomous agents in scientific workflows, featuring Environment (Virtual Machine), Software (Scientific applications), Agent (Computer-using agent), Evaluator (Evaluation system), Observation Space (Perception modalities), Action Space (Interaction methods), Memory (Agent's state history).
- The framework provides an infrastructure enabling computer-using agents to assist in scientific workflows by interacting autonomously via GUI actions or generated code.
- It includes a challenging benchmark of 169 high-quality, rigorously validated real-world tasks spanning scientific-discovery workflows in domains such as biochemistry, astronomy, and geoinformatics.


---

[Large Language Models as Autonomous Spacecraft Operators in Kerbal Space Program](http://arxiv.org/abs/2505.19896v1)

- LLM Agent: introduces an LLM-based agent for autonomous spacecraft control in Kerbal Space Program Differential Games, using Environment (KSPDG) for simulation, processing State observations into a User prompt, feeding it to the LLM agent which generates an LLM reply with Function calling to produce an Action controlling the spacecraft.
- The approach leverages prompt engineering and fine-tuning techniques on GPT-3.5 and LLaMA models to enable the agent to interpret real-time telemetry and output control commands.
- The LLM-based agent achieved second place in the KSPDG challenge, demonstrating the potential of LLMs for autonomous space operations, particularly with fine-tuning on limited data.


---

[SECVULEVAL: Benchmarking LLMs for Real-World C/C++ Vulnerability Detection](http://arxiv.org/abs/2505.19828v1)

- Multi-agent pipeline: introduces a multi-agent system for C/C++ vulnerability detection, including a Normalization Agent (Parses function to AST), Planning Agent (Summarizes, creates vulnerability checklist), Context Agent (Extracts external context symbols), Detection Agent (Detects vulnerability, identifies statements), and Validation Agent (Evaluates detection, resolves disagreement).
- The pipeline processes functions through sequential agents, with LLMs powering the Planning, Context, Detection, and Validation stages.
- This multi-agent approach aims to decompose the complex task of vulnerability detection into smaller, manageable steps for improved LLM performance.


---

[Agentic Predictor: Performance Prediction for Agentic Workflows via Multi-View Encoding](http://arxiv.org/abs/2505.19764v1)

- Agentic Predictor: introduces a framework for efficient agentic workflow performance prediction, utilizing a Multi-View Workflow Encoder (Encodes workflow features), Decoder Networks (Reconstructs workflow inputs), Cross-Domain Unsupervised Pretraining (Refines workflow representations), Task Encoder (Encodes task description), Performance Predictor (Estimates workflow performance), and Predictor-Guided Search (Selects promising workflows).
- The framework employs multi-view encoding of graph, code, and prompt features combined with cross-domain unsupervised pretraining to address workflow heterogeneity and limited labeled data.
- By predicting performance, the approach enables faster and more accurate selection of optimal agentic workflow configurations compared to execution-based methods.


---

[Divide and Conquer: Grounding LLMs as Efficient Decision-Making Agents via Offline Hierarchical Reinforcement Learning](http://arxiv.org/abs/2505.19761v1)

- GLIDER (Grounding Language Models as Efficient Decision-Making Agents via Offline HiErarchical Reinforcement Learning): introduces a hierarchical framework with a High-level policy (Plans sub-tasks) and a Low-level policy (Executes primitive actions) sharing an Actor-Critic (Shared model architecture) built on an LLM Backbone (Base language model) fine-tuned with LoRA (Parameter-efficient fine-tuning), trained through SFT (Behavior cloning stage), ORL (Offline RL refinement stage), and O2O (Online adaptation stage) using High-level replay buffer (Stores high-level data) and Low-level replay buffer (Stores low-level data) interacting with an Environment (Interactive task space), guided by High-Level Prompt (Guides high-level planning), Low-Level Prompt (Guides low-level execution), and Check Subtask Complete Prompt (Verifies subtask completion).
- The framework decomposes complex tasks into sub-tasks planned by the high-level policy and executed as primitive actions by the low-level policy, enabling efficient exploration and learning for long-horizon tasks.
- The hierarchical structure and multi-stage training pipeline, including behavior cloning and offline reinforcement learning, contribute to improved performance and generalization capabilities on interactive decision-making benchmarks.


---

[NeuSym-RAG: Hybrid Neural Symbolic Retrieval with Multiview Structuring for PDF Question Answering](http://arxiv.org/abs/2505.19754v1)

- NeuSym-RAG: introduces a hybrid neural symbolic retrieval framework for PDF question answering, with Multiview Document Parsing (Parses PDF content), Relational Database (Stores structured data), Multimodal Vector Encoding (Encodes data to vectors), Vectorstore (Stores vector embeddings), LLM Agent (Plans and acts), Environment (Backend systems), Actions (Agent capabilities), and Prompt Template (Defines agent interaction).
- The framework processes PDF documents into structured data and vector embeddings, enabling an LLM agent to iteratively retrieve information from both a database and a vectorstore.
- This hybrid approach leverages multiple data views and retrieval strategies through executable actions to answer complex questions over semi-structured PDF content.


---

[ReChisel: Effective Automatic Chisel Code Generation by LLM with Reflection](http://arxiv.org/abs/2505.19734v1)

- ReChisel (LLM-based agentic system): introduces an LLM-based agentic system with Generator (creates Chisel code), Compiler (translates Chisel to Verilog), Simulator (tests Verilog code), Inspector (collects feedback, trace, escape), Reviewer (analyzes trace/feedback, plans revision), Trace (history of iterations), Feedback (compilation/simulation results), Revision Plan (guidance for correction), Common Error Knowledge (pre-organized error fixes), and Escape Mechanism (breaks non-progress loops) components, designed to enhance Chisel code generation effectiveness.
- The system iteratively refines generated Chisel code using a reflection mechanism that leverages feedback from compilation and simulation processes.
- An escape mechanism is included to detect and break non-progress loops during the iterative refinement process.


---

[Large Language Models for Planning: A Comprehensive and Systematic Survey](http://arxiv.org/abs/2505.19683v1)

- LLM-based Planning: introduces a comprehensive survey of methods that augment Large Language Models (processes input, generates output) with components like External Planners (generates formal plans), Memory Modules (stores, retrieves information), Validators (evaluates plans, outputs feedback), Data Sources (provides training data), Feedback Mechanisms (provides optimization signals), Decomposition Modules (breaks down tasks), External Executors (interacts with environment), and World Models (simulates environment dynamics) to enhance planning capabilities.
- The survey categorizes approaches into external module augmented, finetuning-based, and searching-based methods, detailing planning definitions and evaluation frameworks.
- The paper provides a systematic analysis of current advancements, challenges, and future directions in the field, serving as a resource for researchers.


---


[FieldWorkArena: Agentic AI Benchmark for Real Field Work Tasks](http://arxiv.org/abs/2505.19662v1)

- FieldWorkArena: introduces a benchmark environment for evaluating agentic AI on real-world field work tasks, where a User downloads Input data and a Query from the Field Work Arena, an Evaluated agent performs Actions, generating an Execution log and Output, which an Evaluation program compares against Ground Truth to produce a Result.
- The benchmark utilizes multimodal data including videos and documents from actual factory and warehouse settings.
- Tasks are categorized into Planning, Perception, and Action, designed to assess agent capabilities in complex, dynamic environments.


---

[DoctorAgent-RL: A Multi-Agent Collaborative Reinforcement Learning System for Multi-Turn Clinical Dialogue](http://arxiv.org/abs/2505.19630v1)

- DoctorAgent-RL: introduces a multi-agent collaborative reinforcement learning framework, with Doctor Agent (optimizes questioning strategy), Patient Agent (simulates patient responses), Consultation Evaluator (provides multi-dimensional rewards), Supervised Fine-tuning (establishes baseline capabilities), Reinforcement Learning (optimizes strategy via interaction), and Dynamic Turn Budget Training Strategy (RL training strategy for efficiency), that models medical consultations as a dynamic decision-making process.
- The framework enables the doctor agent to autonomously develop clinically-aligned questioning strategies through interactions guided by the evaluator's reward mechanism.
- It utilizes the newly constructed MTMedDialog dataset for training and evaluation and demonstrates superior performance in multi-turn reasoning and diagnostic accuracy.


---

[AgentRecBench: Benchmarking LLM Agent-based Personalized Recommender Systems](http://arxiv.org/abs/2505.19623v2)

- AgentRecBench: introduces, "benchmarking LLM agent-based personalized recommender systems", with Recommending Agents (LLM-based agents), Textual Experiment Environment (simulated interaction platform), U-R-I Network (user-review-item data structure), Datasets (source data), Standardized Query Functionality (environment interaction interface), Dynamic Data Visibility Control (data access management), Dynamic Planning (task decomposition module), Complex Reasoning (decision-making module), Tool Utilization (environment interaction module), Memory Management (experience storage/retrieval), and LLM (core language model), which provides a comprehensive benchmark and modular framework for evaluating agentic recommender systems.
- The benchmark includes a textual environment simulator equipped with multi-domain datasets and a standardized agent development framework.
- The framework facilitates rapid prototyping and systematic testing of recommendation agents across diverse scenarios and tasks.


---

[Multi-Agent Collaboration via Evolving Orchestration](http://arxiv.org/abs/2505.19591v1)

- Puppeteer: introduces a multi-agent collaboration framework with a centralized orchestrator (Puppeteer) that dynamically directs LLM-based agents (Puppets) based on the evolving task state, using a Policy for agent selection and Orchestration for sequencing.
- The framework employs Reinforcement Learning, guided by a Reward function from the Environment, to adaptively evolve the Puppeteer's Policy, optimizing agent selection and pruning for improved performance and efficiency.
- This dynamic orchestration fosters the emergence of compact, cyclic reasoning structures among agents, enhancing collaborative effectiveness and reducing computational cost compared to static multi-agent systems.


---

[LLM-Agent-Controller: A Universal Multi-Agent Large Language Model System as a Control Engineer](http://arxiv.org/abs/2505.19567v1)

- LLM-Agent-Controller: introduces a multi-agent large language model system for control engineering problems, integrating a central Controller Agent with specialized auxiliary agents and a Supervisor for coordination.
- The system leverages components like Retriever, Researcher, Reasoner, Planner, Debugger, Communicator, Critic, and Memory agents to enhance robustness, versatility, and efficiency in solving control theory tasks.
- The framework is designed for user-friendly interaction, enabling users without prior control theory knowledge to input problems in natural language and receive complete solutions.


---

[AMQA: An Adversarial Dataset for Benchmarking Bias of LLMs in Medicine and Healthcare](http://arxiv.org/abs/2505.19562v1)

- Multi-Agent Framework for AMQA Construction: introduces AMQA, an Adversarial Medical Question-Answering dataset, with Clinical Vignette Filtering (Filters vignettes), Adversarial Variant Construction (Constructs variants), Manual Quality Control (Reviews quality), Generation-Agent (Generates descriptions), Fusion-Agent (Integrates descriptions), and Evaluation-Agent (Evaluates bias trigger) components, designed for automated, large-scale bias evaluation of LLMs in medical QA.
- The framework generates adversarial patient descriptions by varying demographic attributes while keeping clinical details constant, enabling controlled testing of LLM performance differences across privileged and unprivileged groups.
- The multi-agent design decomposes the complex task of generating adversarial vignettes into specialized sub-tasks handled by distinct LLM agents, followed by human review for quality assurance.


---

[Towards Multi-Granularity Memory Association and Selection for Long-Term Conversational Agents](http://arxiv.org/abs/2505.19549v1)

- MemGAS: introduces a framework for long-term conversational agents that enhances memory consolidation and retrieval using multi-granularity association and adaptive selection, incorporating LLM Agent, Multi-Granular Memory Unit, Memory Bank, Dynamical Memory Association, Association Graph, Entropy-Driven Granularity Selection, Personalized PageRank, and LLM-Based Redundancy Filtering components.
- The framework constructs multi-granular memory units and builds dynamic associations using Gaussian Mixture Models and an association graph.
- An entropy-based router adaptively selects optimal granularity for retrieval, and retrieved memories are filtered by an LLM to refine the final context.


---

[Benchmarking and Enhancing LLM Agents in Localizing Linux Kernel Bugs](http://arxiv.org/abs/2505.19489v1)

- LINUXFL+: enhances fault localization for Linux kernel bugs, incorporating Directory-Aware Expansion, Potential-Cause Expansion, and Candidate Integration.
- It refines initial agent predictions by leveraging the Codebase structure and historical knowledge from the Linux Kernel Mailing List, based on the Bug Report.
- The framework aims to improve localization accuracy by expanding candidate selection based on directory context and potential bug causes.


---

[VLMLight: Traffic Signal Control via Vision-Language Meta-Control and Dual-Branch Reasoning](http://arxiv.org/abs/2505.19486v1)

- VLMLight: introduces a traffic signal control framework with Vision-Language Meta-Control and Dual-Branch Reasoning, integrating Scene Understanding, Safety-Prioritized Meta-Control, Routine Control Policy, and Deliberative Reasoning Policy, which includes AgentPhase, AgentPlan, and AgentCheck, interacting with a TSC Simulator, Trajectory Memory, Traffic Phase Embedding, Intersection Embedding, Value Network, Policy Network, and the Environment.
- The framework uses a VLM for scene understanding and an LLM meta-controller to switch between a fast RL policy for routine traffic and a multi-agent LLM reasoning branch for critical scenarios.
- This hybrid architecture balances the efficiency of RL with the interpretability and robustness of LLM reasoning, particularly for prioritizing emergency vehicles.


---

[Win Fast or Lose Slow: Balancing Speed and Accuracy in Latency-Sensitive Decisions of LLMs](http://arxiv.org/abs/2505.19481v1)

- FPX (Adaptive Mixed Precision Inference Framework): introduces an adaptive mixed-precision inference framework with Adaptive Mixed-Precision Algorithm, Offline Calibration, Precision Assignment Function, FP8 kernel, and FP4 kernel, designed to balance speed and accuracy for LLM agents in latency-sensitive tasks.
- The framework dynamically adjusts model precision at the operator level, selectively applying FP4 quantization to compression-tolerant layers while preserving FP8 for sensitive components.
- FPX utilizes an offline calibration process to identify layers suitable for aggressive quantization, enabling fine-grained control over the latency-quality trade-off.


---

[Judging with Many Minds: Do More Perspectives Mean Less Prejudice?](http://arxiv.org/abs/2505.19477v1)

- Multi-Agent LLM-as-Judge: introduces a study evaluating intrinsic biases in multi-agent LLM-as-Judge frameworks, including Multi-Agent-Debate (Debate framework) with Judge (Initial/final evaluator) and Critic (Critiques/debates judgments), and LLM-as-Meta-Judge (Meta-reasoning framework) with Judges (Independent evaluators) and Meta-Judge (Select mode) (Selects best judgment) or Meta-Judge (Conclude mode) (Generates new judgment), also incorporating PINE (Bias mitigation agent).
- The Multi-Agent-Debate framework amplifies biases after the initial debate, while the LLM-as-Meta-Judge approach shows greater resistance to intrinsic biases.
- Incorporating a bias-free agent like PINE effectively reduces biases in debate settings but provides less benefit in meta-judge scenarios.


---

[Improving Recommendation Fairness without Sensitive Attributes Using Multi-Persona LLMs](http://arxiv.org/abs/2505.19473v1)

- LLMFOSA (LLM-enhanced framework for Fair recommendation withOut Sensitive Attributes): introduces a framework to improve recommendation fairness without sensitive attributes using a Collaborative Encoder (learns user/item embeddings), a Multi-Persona Sensitive Information Inference Module (infers sensitive attributes) with a Persona Editor (generates diverse personas), Annotators (infer attributes using personas), and a Meta Summarizer (distills inference rationales), a Confusion-Aware Sensitive Representation Learning Module (refines sensitive representations) including a Sensitive Encoder (transforms to sensitive-aware embedding), Confusion Modeling (models annotator mislabeling), Consensus Regularization (aligns confusion matrices), and Fine-Grained Rationale Incorporation (incorporates inference rationales), a Preference Encoder (generates sensitive-blind embedding), and Model Optimization (optimizes MI objectives).
- The framework leverages multi-persona LLMs to infer latent sensitive patterns from user behavior and incorporates these inferences into robust sensitive representations for fairness training.
- Fairness is ultimately achieved by optimizing mutual information objectives to disentangle sensitive and sensitive-blind user representations.


---

[Vibe Coding vs. Agentic Coding: Fundamentals and Practical Implications of Agentic AI](http://arxiv.org/abs/2505.19443v1)

- Vibe Coding: introduces, "a human-centric paradigm", with Prompts (Natural language input), LLM (Code generation engine), Short-Term Context (Limited session memory), Developer (Human user), Thinking (Strategic problem formulation), Framework (Architectural awareness), Checkpoints (Version control), Debugging (Collaborative error resolution), Context (Information provision), where the developer guides an LLM through iterative prompts for creative exploration and rapid prototyping.
- Agentic Coding: introduces, "an autonomous paradigm", with Objectives (High-level goals), Planner (Task decomposition module), Executor (Task execution module), Tool Use Environment (Integrated runtime environment), Sandbox Environment (Secure isolated environment), Long-Term Memory (Persistent state storage), API (External tools/interfaces), Git (Version control system), Test Suite (Automated tests), Multi-Agent Coordination (Specialized agents collaborating), Toolchain Integration (Full-stack tool orchestration), Validation Pipeline (Integrated QA loop), Security and Guardrails (Embedded safety mechanisms), Observability and Feedback (Monitoring and refinement), Deployment and CI/CD (Automated workflows), where goal-driven agents autonomously plan, execute, test, and iterate on complex software tasks with minimal human intervention.
- The paper compares these two paradigms, highlighting differences in autonomy, architectural design, developer role, and practical implications for software development workflows and use cases.


---

[Task Memory Engine: Spatial Memory for Robust Multi-Step LLM Agents](http://arxiv.org/abs/2505.19436v1)

- TME (Task Memory Engine): introduces a modular memory controller, with TRIM (Task Representation and Intent Management), TMS (Task Memory Structure), and LLM (Large Language Model), that transforms LLMs into robust, revision-aware agents using a spatial memory framework.
- TME replaces linear context with a TMS-DAG forest to dynamically track subtasks, dependencies, and revisions, orchestrated by the TRIM module.
- This graph-based approach ensures global task consistency, revision-aware reasoning, and token efficiency by retrieving relevant subgraphs for the LLM.


---

[Can Compressed LLMs Truly Act? An Empirical Evaluation of Agentic Capabilities in LLM Compression](http://arxiv.org/abs/2505.19433v1)

- ACBench (Agent Compression Benchmark): introduces a comprehensive benchmark for evaluating compressed LLMs' agentic capabilities, including Action Execution, Workflow Build, Long Context, and Real-World tasks, under various Quantization and Sparsification methods across different LLM categories (Small LM, Reason LM, Normal-LLM), analyzed using ERank, Top-K Ranking Correlation, and Energy metrics.
- The benchmark assesses how compression impacts LLMs' ability to perform complex, multi-turn agentic tasks beyond traditional language modeling and understanding benchmarks.
- The analysis tools provide insights into how compression affects model outputs, internal representations, and decision-making processes.


---

[Frictional Agent Alignment Framework: Slow Down and Don't Break Things](http://arxiv.org/abs/2505.19428v1)

- FAAF: introduces a framework that conditions a language model on dialogue history and frictive states to generate interventions prompting reflection in collaborative tasks.
- The framework utilizes a reference model and preference data to optimize an objective function for learning effective friction interventions.
- By explicitly conditioning on frictive states, the approach aims to generate precise and interpretable interventions for dynamic human-AI collaboration.


---

[CoTGuard: Using Chain-of-Thought Triggering for Copyright Protection in Multi-Agent LLM Systems](http://arxiv.org/abs/2505.19405v1)

- CoTGuard: introduces a trigger-based copyright protection framework for multi-agent LLM systems, with Multi-Agent LLM System, Chain-of-Thought Reasoning, Trigger Key, Task Type, Trigger Generation Function, Trigger Pattern, Prompt Modification, Intermediate Reasoning Trace, Repository of Known Trigger Patterns, Trigger Detection Function, Similarity Scoring, and Aggregation components, designed to detect copyright leakage by embedding triggers in intermediate reasoning steps.
- The framework leverages Chain-of-Thought reasoning traces as an attack surface and detection medium, enabling fine-grained monitoring of content reproduction during agent collaboration.
- CoTGuard achieves high detection accuracy with minimal impact on task performance by analyzing reasoning paths for trigger-induced patterns.


---

#### 25th May 2025

[SeRL: Self-Play Reinforcement Learning for Large Language Models with Limited Data](https://arxiv.org/abs/2505.20347)

- SeRL (Self-play Reinforcement Learning): introduces a framework for bootstrapping LLM training with limited data, featuring Self-Instruction (Generates/filters instructions) and Self-Rewarding (Estimates rewards).
- Self-Instruction employs an Online Instruction Filter (Ensures quality/diversity/difficulty), and Self-Rewarding uses Majority Voting (Reward estimation mechanism) for unsupervised RL Training (Performs reinforcement learning) of the LLM (Large Language Model being trained).
- The iterative self-play process enables performance comparable to training with extensive high-quality data and verifiable rewards.


---


[ALRPHFS: Adversarially Learned Risk Patterns with Hierarchical Fast & Slow Reasoning for Robust Agent Defense](http://arxiv.org/abs/2505.19260v1)

- ALRPHFS (Adversarially Learned Risk Patterns with Hierarchical Fast&Slow Reasoning): introduces a defense framework with an Offline Module (constructs database) for learning risk patterns and an Online Module (implements real-time defense) for hierarchical reasoning.
- The Offline Module includes Risk pattern Extract (extracts patterns), Deduplication Optimization (removes redundancy), and Self-Learning Adversarial Optimization (iteratively refines patterns) to build the Risk Patterns Database (stores learned patterns).
- The Online Module uses Query/Action Abstraction (abstracts inputs) and Online Hierarchical Risk Reasoning (balances detection efficiency) with Hybrid Retrieval (matches input patterns), Fast Thinking (intercepts high-confidence risks), and Slow Thinking (handles ambiguous inputs) for real-time defense.


---

[DeepResearchGym: A Free, Transparent, and Reproducible Evaluation Sandbox for Deep Research](http://arxiv.org/abs/2505.19253v1)

- DeepResearchGym: introduces an open-source sandbox for evaluating deep research systems, featuring a Search Sandbox with Web Corpora, a Distributed Dense Retrieval Backend using an Embedding Model and Approximate Nearest Neighbor Search, a Retrieval API, and an Evaluation Protocol leveraging the Researchy Questions Dataset, LLM-as-a-judge Methodology, Report Relevance Metrics, Retrieval Faithfulness Metrics, and Report Quality Metrics.
- The framework provides a reproducible search API over large public web corpora (ClueWeb22-B, FineWeb) using a dense retriever and DiskANN for efficient retrieval.
- DeepResearchGym includes a multi-dimensional evaluation protocol based on LLM-as-a-judge to assess report quality, factual grounding, and alignment with user needs on complex queries.


---

[Sensorimotor features of self-awareness in multimodal large language models](http://arxiv.org/abs/2505.19237v1)

- Embodied MM-LLM System: introduces a system integrating a multimodal LLM with a mobile robot and its sensors to explore sensorimotor self-awareness, using a Robot, Sensors, ROS 2, a MM-LLM (Gemini 2.0 Flash), Memory, and evaluated by an LLM-as-a-Judge.
- The system processes real-time sensor data and episodic memory to generate iterative self-predictions about its entity, dimensions, movement, and environment.
- This approach demonstrates that multimodal LLMs can exhibit emergent self-awareness through sensorimotor experience and structured memory integration.


---

[GUARDIAN: Safeguarding LLM Multi-Agent Collaborations with Temporal Graph Modeling](http://arxiv.org/abs/2505.19234v1)

- GUARDIAN (GUARDing Intelligent Agent collaboratioNs): introduces a framework for detecting and mitigating safety concerns in LLM multi-agent collaborations, utilizing Graph Preprocessing, an Attributed Graph Encoder, a Time Information Encoder, an Attribute Reconstruction Decoder, a Structure Reconstruction Decoder, Anomaly scores, and an Updated Collaboration Network.
- The approach models multi-agent interactions as a discrete-time temporal attributed graph and employs an unsupervised encoder-decoder architecture for anomaly detection.
- A graph abstraction mechanism based on Information Bottleneck Theory compresses temporal interaction graphs while preserving essential patterns for robust anomaly identification.


---

[When Ethics and Payoffs Diverge: LLM Agents in Morally Charged Social Dilemmas](http://arxiv.org/abs/2505.19212v1)

- MORALSIM: introduces a framework for evaluating LLM agents in repeated social dilemmas where ethical norms conflict with incentives, including Game Simulation Environment, LLM Agent, Agent Configuration, Game Type, Moral Context, Opponent Type, and Survival Risk components.
- The framework systematically tests LLM behavior across varied game structures, moral framings, opponent types, and survival conditions.
- Results show substantial variation in LLM moral behavior, highlighting conflicts between self-interest and ethical expectations.


---

[SpeakStream: Streaming Text-to-Speech with Interleaved Data](http://arxiv.org/abs/2505.19206v1)

- SpeakStream: introduces a streaming text-to-speech system with a Transformer Decoder, Text Token Representation, Speech Token Representation, Interleaved Text-Speech Data, KV-Cache, VocStream, Streaming Upsampler, Streaming Vocoder, and Real-time Audio Player, designed for low-latency, incremental audio generation from streaming text.
- The system trains a decoder-only transformer on interleaved text-speech sequences and uses a streaming vocoder pipeline for real-time waveform synthesis.
- SpeakStream achieves low first-token latency and maintains coherence by conditioning generation on complete text and speech history stored in the KV-cache.


---

[When Two LLMs Debate, Both Think They'll Win](http://arxiv.org/abs/2505.19184v2)

- Debate Simulation Framework: introduces a system to evaluate Large Language Models' confidence calibration in dynamic, adversarial settings using a multi-turn debate format and zero-sum structure.
- The framework reveals systematic LLM overconfidence, confidence escalation across rounds, mutual high confidence claims, persistent self-debate bias, and misaligned private reasoning.
- These findings highlight LLMs' limitations in self-assessment and belief updating when facing opposition, posing risks for deployment in assistant and agentic roles.


---

[Investigating Pedagogical Teacher and Student LLM Agents: Genetic Adaptation Meets Retrieval-Augmented Generation Across Learning Styles](http://arxiv.org/abs/2505.19173v1)

- Pedagogical Simulation Framework: introduces a novel simulation framework integrating a Teacher LLM Agent (Self-optimizing agent) and Student LLM Agents (Diverse learning profiles) with Persona-RAG (Personalized knowledge retrieval) and a Knowledge Base (Student prerequisite knowledge), where a Genetic Algorithm (Teacher strategy optimizer) evolves the teacher's strategy based on student performance.
- This framework simulates diverse student populations and optimizes the teacher agent's dynamic pedagogical strategy through a closed-loop system based on measured learning outcomes.
- Persona-RAG enhances personalization by tailoring knowledge retrieval to individual student reasoning paths, improving performance on complex, non-recall questions.


---

[The Eye of Sherlock Holmes: Uncovering User Private Attribute Profiling via Vision-Language Model Agentic Framework](http://arxiv.org/abs/2505.19139v1)

- HolmesEye (hybrid agentic framework): introduces, "a framework combining VLM and LLM agents", with VLM agent (Extraction), VLM agent (Analysis), LLM agent (Summarization), VLM agent (Inquiry Response), LLM agent (Decision Making) components, designed to infer private attributes from image collections by analyzing individual images and cross-image patterns.
- The framework utilizes VLM agents for extracting intra-image details and analyzing inter-image relationships, while LLM agents guide the inference process, summarize findings, generate inquiries, and make final attribute decisions.
- HolmesEye achieves superior accuracy in private attribute profiling, particularly for abstract traits, highlighting a significant privacy risk from vision-language models.


---

[Incentivizing High-Quality Human Annotations with Golden Questions](http://arxiv.org/abs/2505.19134v1)

- Annotation System: introduces a principal-agent model for incentivizing high-quality human annotations, including a Principal (LLM Company), an Agent (Human Annotator), a Dataset (Unannotated data), an Annotated Dataset (Annotated data), Golden Questions (Monitoring dataset), MLE (Estimator), Test (Performance evaluation), and Contract (Payment scheme).
- The system monitors annotator performance using Golden Questions and an MLE-based Test to determine payment via a Contract.
- Golden Questions are selected using a Certainty Estimator, potentially based on a Reward Model, to ensure they have certain answers and similar format to other data.


---

[ScreenExplorer: Training a Vision-Language Model for Diverse Exploration in Open GUI World](http://arxiv.org/abs/2505.19095v1)

- ScreenExplorer: introduces a VLM (Agent policy function), World Model (Predicts next state), GRPO (Policy optimization algorithm), Experience Stream Distillation (Filters, distills exploration data), Reward System (Interaction, exploration signals), GUI Environment (Real, dynamic interaction space), and Rollout Buffer (Stores experience tuples), designed to train a VLM agent for diverse exploration in open GUI environments.
- The framework utilizes a world model for curiosity-driven rewards and distills exploration experience to enhance the agent's capabilities and reduce reliance on curated data.
- ScreenExplorer trains the VLM agent via reinforcement learning in a real GUI environment, enabling adaptation and sustained exploration.


---

[A Systematic Classification of Vulnerabilities in MoveEVM Smart Contracts (MWC)](http://arxiv.org/abs/2505.19047v1)

- MWC (MoveEVM Weakness Classification): introduces a systematic classification of vulnerabilities in MoveEVM smart contracts with F1 (Bytecode/ABI inconsistencies), F2 (Inter-module invariant violations), F3 (State reentrancy/synchronization bugs), F4 (Signature/Meta-transaction spoofing), F5 (Gas semantics manipulation), and F6 (Framework logic/abstraction errors) components.
- This frame-based taxonomy defines 37 uniquely identified weakness classes (MWC-100 to MWC-136) grouped into these six top-level frames.
- The classification provides a structured approach for identifying, mitigating, and preventing sophisticated exploits spanning Move and EVM semantics in hybrid environments.


---

[MetaMind: Modeling Human Social Thoughts with Metacognitive Multi-Agent Systems](http://arxiv.org/abs/2505.18943v1)

- MetaMind: introduces a multi-agent framework for human-like social reasoning, with a Theory-of-Mind Agent (Generates mental state hypotheses), Domain Agent (Refines hypotheses with constraints), Response Agent (Generates and validates responses), and Social Memory (Stores user patterns/feedback).
- The framework decomposes social understanding into three collaborative stages, inspired by psychological theories of metacognition.
- This staged architecture enables large language models to infer unspoken intentions, incorporate social norms, and adapt responses for enhanced social intelligence.


---

#### 24th May 2025

[Security Concerns for Large Language Models: A Survey](http://arxiv.org/abs/2505.18889v1)

- Llama Guard 3: introduces, "a multi-layer safeguard", with Policy LLM (Filters text/images), Vision Encoder (Filters text/images), Main Model (Receives filtered input), where "Llama Guard 3 combines a policy LLM and a vision encoder to filter text and images before they reach the main model".
- This system is designed to filter potentially harmful text and images before they are processed by the core language model.
- It serves as an example of a multi-component defense strategy discussed in the survey for safeguarding LLM inputs.


---

[PERSONALIZED SAFETY IN LLMS: A BENCHMARK AND A PLANNING-BASED AGENT APPROACH](http://arxiv.org/abs/2505.18882v1)

- RAISE: introduces a planning-based agent approach for personalized safety in LLMs, with an Offline Planner (LLM-guided MCTS) to discover optimal attribute acquisition paths and an Online Agent (dual-module execution) including an Acquisition Module and Abstention Module to execute the path and decide when to respond.
- The Offline Planner uses LLM-guided MCTS to precompute optimal attribute query sequences, stored in Offline Data Storage, which the Online Agent's Acquisition Module retrieves via a Retrieval Mechanism during inference.
- The Abstention Module dynamically assesses if the acquired context, gathered by querying attributes guided by the retrieved path, is sufficient for the LLM Backbone to generate a safe, personalized response.


---

[CRMArena-Pro: Holistic Assessment of LLM Agents Across Diverse Business Scenarios and Interactions](http://arxiv.org/abs/2505.18878v1)

- CRMArena-Pro: introduces a benchmark for evaluating LLM agents on CRM tasks, featuring a Data Generation Pipeline (produces synthetic data), Synthetic Enterprise Data (realistic business data), Salesforce Org (Sandbox Environment) (testing environment), Simulated User (interacts with agent), Agent (LLM Agent) (system under evaluation), Large Language Models (LLMs) (power components), API Access (SOQL/SOSL) (agent tools), Answer Extractor (evaluates task completion), and LLM Judge (evaluates confidentiality awareness).
- The benchmark utilizes a data generation pipeline to populate a Salesforce Org sandbox with realistic synthetic data for evaluating LLM agents on diverse business scenarios and interactions.
- Evaluation components include a simulated user for multi-turn interactions, API access for agent actions, and LLM-based extractors and judges for performance and confidentiality assessment.


---

[Multi-Party Conversational Agents: A Survey](http://arxiv.org/abs/2505.18845v1)

- MPCAs: introduces a survey of Multi-Party Conversational Agents, with all State of Mind Modeling (infer mental states), Semantic Understanding (understand dialogue content), and Agent Action Modeling (predict future flow) components, where the paper categorizes existing research into these three core themes essential for human-like social communication in group settings.
- The survey explores recent progress in MPCAs by addressing how agents model participant mental states, understand dialogue content, and reason about future conversation flow.
- The analysis underscores the importance of Theory of Mind and highlights multi-modal understanding as a promising direction for developing more capable agents.


---


[Enhancing LLMs' Reasoning-Intensive Multimedia Search Capabilities through Fine-Tuning and Reinforcement Learning](http://arxiv.org/abs/2505.18831v1)

- SearchExpert: introduces a two-stage training framework for LLMs, including LLM (core model), SFTS (supervised training stage), RLSF (reinforcement training stage), and a Multimedia Agent (visual processing/generation), to enhance reasoning-intensive multimedia search capabilities.
- The framework utilizes efficient natural language representations for search plans and automated data construction pipelines for training data generation.
- RLSF incorporates a dual-component reward mechanism based on search result quality to improve reasoning capabilities for complex queries.


---

[C³-Bench: The Things Real Disturbing LLM based Agent in Multi-Tasking](http://arxiv.org/abs/2505.18746v2)

- LLM-based Agent: describes the multi-task execution process involving User (Proposes tasks), Tool (External functions), Action (Agent's steps), Observation (Environment feedback), Summary (Task completion feedback), LLM-based Agent (Processes, decides, acts), and Agent Parameters (Internal state/knowledge), evaluated by the C³-Bench benchmark.
- The C³-Bench benchmark uses three challenges and fine-grained metrics to assess agent performance and identify weaknesses in handling tool relationships, hidden information, and decision trajectories.
- Evaluation results highlight significant shortcomings in current models, especially concerning tool dependencies, long-context information, and policy switching frequency.


---

[AI-Researcher: Autonomous Scientific Innovation](http://arxiv.org/abs/2505.18705v1)

- AI-Researcher: introduces a fully autonomous research system orchestrating the complete scientific discovery pipeline, including Knowledge Acquisition Agent (discovers papers and code), Resource Analyst (analyzes concepts and code), Idea Generator (generates novel ideas), Code Agent (implements algorithms), Advisor Agent (validates and provides feedback), Paper Agent (generates manuscripts), Secure Research Environment (containerized execution environment), and Structured Knowledge Exchange (facilitates agent collaboration).
- The framework progresses through literature review, idea generation, algorithm implementation, experimental validation, and scholarly documentation with minimal human intervention.
- AI-Researcher employs a comprehensive multi-agent architecture and introduces Scientist-Bench, a benchmark for evaluating autonomous research capabilities.


---

[LLM-QFL: Distilling Large Language Model for Quantum Federated Learning](http://arxiv.org/abs/2505.18656v1)

- LLM-QFL: introduces a federated fine-tuning approach, with Server, Clients, Global Model, Local Model, Pre-Trained LLM, Fine-Tuned LLM, Local QNN, Optimizer, Knowledge Distillation, Client Selection, Termination Criteria, Feature Map, Ansatz, and PEFT Methods, that distills a large language model within quantum federated learning to enhance efficiency and performance.
- The framework leverages the fine-tuned LLM as a controller to dynamically adjust optimizer steps, select clients, and determine training termination.
- Knowledge distillation and PEFT methods enable efficient local adaptation of LLMs on resource-constrained quantum devices while preserving data privacy.


---

[SEW: Self-Evolving Agentic Workflows for Automated Code Generation](http://arxiv.org/abs/2505.18646v1)

- SEW (Self-Evolving Workflow): introduces a novel framework that automatically generates and optimises multi-agent workflows for automated code generation, with Workflow Generation (Generates initial workflow), Workflow Evolution (Evolves workflow structure), Agent Evolution (Evolves agent prompts), Agents (Execute tasks), Evolutionary Prompts (Inputs for evolution), Evolution Operators (DE/HE methods), and LLM (Backbone model) components.
- The framework leverages an evolutionary scheme to improve workflow topology and agent prompts.
- SEW explores different workflow representation schemes and demonstrates improved performance on code generation benchmarks through self-evolution.


---

[DDO: Dual-Decision Optimization via Multi-Agent Collaboration for LLM-Based Medical Consultation](http://arxiv.org/abs/2505.18630v1)

- DDO (Dual-Decision Optimization): introduces a novel LLM-based multi-agent framework for medical consultation, with Diagnosis Agent (estimates disease confidence), Policy Agent (generates candidate actions), Inquiry Agent (selects optimal inquiry), Patient Agent (simulates patient response), and Shared Memory (stores consultation state).
- The framework decouples symptom inquiry and disease diagnosis, optimizing these two distinct sub-tasks independently through a collaborative multi-agent workflow.
- DDO enhances disease discrimination via a learnable adapter and improves information gathering through an RL-based policy agent and strategic inquiry selection.


---

[Debate-to-Detect: Reformulating Misinformation Detection as a Real-World Debate with Large Language Models](http://arxiv.org/abs/2505.18596v2)

- D2D (Debate-to-Detect): introduces a structured multi-agent debate framework for misinformation detection, with Agent Layer (Affirmative, Negative, Judge agents, Domain-Specific Profiles, Shared Memory) and Orchestrator Layer managing a five-stage process (Opening Statement, Rebuttal, Free Debate, Closing Statement, Judgement) culminating in Multi-dimensional Evaluation.
- The framework assigns domain-specific profiles to agents and orchestrates a progressive debate across distinct stages, enhancing logical coherence and evidence refinement.
- A multi-dimensional evaluation mechanism assesses claims across Factuality, Source Reliability, Reasoning Quality, Clarity, and Ethics, providing interpretable authenticity scores.


---


[MASTER: Multi-Agent Security Through Exploration of Roles and Topological Structures - A Comprehensive Framework](http://arxiv.org/abs/2505.18572v1)

- MASTER: introduces a novel security research framework for Multi-Agent Systems, with MAS Automatic Constructor (Builds MAS instances), Interaction Mechanism (Manages agent communication), Attack Strategies (Methods to exploit vulnerabilities), Defense Strategies (Mechanisms to protect MAS), Evaluation Methods (Metrics to assess security), Agents (LLM-based nodes with roles), Topology Graph (Represents agent connections), and Memory Modules (Store agent interaction history), designed to explore security risks under MAS attacks by focusing on diverse role configurations and topological structures.
- The framework offers an automated construction process for different MAS setups and an information-flow-based interaction paradigm to emulate realistic MAS interactions.
- It proposes scenario-adaptive attack and defense strategies leveraging role and topological information to tackle MAS security challenges in varied scenarios.


---

[Benchmarking Poisoning Attacks against Retrieval-Augmented Generation](http://arxiv.org/abs/2505.18543v1)

- Retrieval-Augmented Generation (RAG): introduces RSB, a benchmark evaluating poisoning attacks against RAG systems, with Knowledge database (collection of textual content), Retriever (selects relevant documents), LLM (generates final response), and System prompt (conditions LLM generation) components.
- The benchmark assesses 13 poisoning attacks and 7 defenses across diverse RAG architectures and datasets to understand security vulnerabilities.
- Findings indicate RAG systems are susceptible to poisoning attacks, current defenses are limited, and advanced architectures offer varying robustness, highlighting the need for better defenses.


---

[Invisible Tokens, Visible Bills: The Urgent Need to Audit Hidden Operations in Opaque LLM Services](http://arxiv.org/abs/2505.18471v1)

- Blueprint for Auditing Frameworks: introduces a three-layer architecture including Layer 1 (Handles COLS operations), Layer 2 (Encodes operations into commitments), and Layer 3 (Supports external verification), enabling Users (Initiates requests, receives reports) and Auditors (Verifies usage, identity, behavior) to audit hidden operations in Commercial Opaque LLM Services.
- The framework aims to provide trustworthy and practical auditing across the COLS lifecycle, from execution to verification.
- Layer 2 generates verifiable commitments from internal operations, which Layer 3 uses for external verification without exposing proprietary details.


---

[A Survey of LLM × DATA](http://arxiv.org/abs/2505.18458v2)

- DATA4LLM: introduces techniques for large-scale data processing, storage, and serving to provide high-quality data for LLM lifecycle stages.
- LLM4DATA: presents how LLMs function as general-purpose engines for data management tasks including manipulation, analysis, and system optimization.
- The survey reviews the bidirectional relationship between LLMs and data management, detailing techniques for both DATA4LLM and LLM4DATA.


---

#### 23rd May 2025

[Self-Training Large Language Models with Confident Reasoning](https://arxiv.org/abs/2505.17454)

- CORE-PO: introduces a self-training method for large language models, with LLM, Reference Model, Confidence Computation, Preference Annotation, and Policy Optimization components, that fine-tunes LLMs to prefer high-confidence reasoning paths.
- The method incorporates reasoning-level confidence estimation to identify high-quality reasoning paths, addressing limitations of methods relying solely on answer-level confidence.
- CORE-PO uses Policy Optimization (Direct Preference Optimization) to train the LLM based on preference pairs derived from reasoning-level and answer-level confidence scores.


---


[DanmakuTPPBench: A Multi-modal Benchmark for Temporal Point Process Modeling and Understanding](http://arxiv.org/abs/2505.18411v1)

- Multi-agent framework for automated construction of DanmakuTPP-QA: introduces a pipeline to build a multi-modal question-answering benchmark, with DanmakuTPP-Events (Input data), Task-design Agent (Generates evaluation tasks), Annotation Agent Group (Extracts multi-modal annotations), Quality-control Agent (Refines annotations), Visualization Agent (Creates visualizations), and Task-solve Agent Group (Solves tasks).
- The framework leverages specialized agents powered by LLMs and MLLMs to generate tasks, annotate data, ensure quality, create visualizations, and produce ground-truth answers for temporal-visual-textual reasoning.
- This multi-agent approach systematically constructs a high-quality dataset for evaluating models on complex multi-modal temporal point process understanding tasks.


---

[An Outlook on the Opportunities and Challenges of Multi-Agent AI Systems](http://arxiv.org/abs/2505.18397v1)

- MAS (Multi-Agent AI Systems): introduces a framework for multi-agent AI systems, with AI Agent (autonomous entity), Agent State (internal memory/context), Agent Input (from others/environment), Agent Output (actions/messages), Agent Transition Kernel (state/output update rule), Multi-Agent Topology (communication graph), Topology Graph Update Function (evolves topology), Orchestrator (coordinates agents), Knowledge Base (system memory), Aggregator (combines agent outputs), Feedback (external/internal signals), Application Layer (human/environment interaction), Modeling Layer (agents/orchestration/memory), and Computation Layer (hardware infrastructure), formalizing key concepts and evaluating effectiveness and safety.
- The framework defines MAS as a set of autonomous agents interacting via a dynamic communication graph, processing inputs over time, with agent behavior and system topology updated by feedback.
- The paper analyzes MAS effectiveness through task allocation, robustness, and feedback integration perspectives and explores safety challenges, including vulnerability propagation and the impact of topology.


---

[Persona Alchemy: Designing, Evaluating, and Implementing Psychologically-Grounded LLM Agents for Diverse Stakeholder Representation](http://arxiv.org/abs/2505.18351v1)

- Persona Alchemy (SCT-based framework): introduces a system for designing, evaluating, and implementing psychologically grounded LLM agents with LLM Instances, Persona Neo4j Adapter, Neo4j, Text Analyzer, Personal Factors, Environment, and SCT Constructs.
- The framework integrates Personal Factors, Environment, and Behavior, evaluated using SCT Constructs, to create dynamic and consistent agent personas grounded in Social Cognitive Theory.
- It leverages multiple LLM instances, a Neo4j graph database, and a Text Analyzer for persona design, data management, and evaluation processes.


---

[Towards Natural Language Communication for Cooperative Autonomous Driving via Self-Play](http://arxiv.org/abs/2505.18334v1)

- LLM+DEBRIEF: introduces a multi-agent learning framework for autonomous vehicles that leverages natural language communication and centralized reflection via large language models to enhance cooperation in simulated driving scenarios.
- The framework enables agents to refine their communication and motion control policies through trial-and-error interactions and post-episode discussions.
- Agents use Chain-of-Thought reasoning, environment observations, and learned knowledge to generate natural language messages and high-level driving commands.


---

[Single-agent or Multi-agent Systems? Why Not Both?](http://arxiv.org/abs/2505.18286v1)

- MAS (Multi-Agent Systems): introduces a comprehensive empirical comparison of MAS and SAS paradigms, proposing a hybrid agentic paradigm with Agent Routing and Agent Cascade strategies, and a Confidence-guided Critical Path Tracing method to improve efficiency and effectiveness.
- The paper models agentic execution as a directed graph where nodes are LLM agents or tools, comparing MAS (multiple LLM agents) and SAS (single LLM agent) performance across various tasks.
- Findings indicate that MAS advantages diminish with more capable LLMs, motivating the proposed hybrid approach that selectively routes or cascades tasks between SAS and MAS based on complexity and evaluation.


---

[Collaborative Memory: Multi-User Memory Sharing in LLM Agents with Dynamic Access Control](http://arxiv.org/abs/2505.18279v1)

- Collaborative Memory: introduces a framework for multi-user, multi-agent systems, with Users (Human participants), Agents (LLM-based specialized entities), Resources (External tools, APIs, data), Dynamic bipartite access graphs (Time-dependent user-agent/agent-resource permissions), Private Memory (User-specific memory fragments), Shared Memory (Selectively shared memory fragments), Memory fragments (Stored interaction logs/knowledge), Read policy (Filters memory for retrieval), Write policy (Determines memory storage/sharing), Coordinator (Selects agents for queries), Aggregator (Synthesizes agent responses), Memory Encoder (Maps traces to fragments), Memory Retrieval (Retrieves relevant fragments), Policy Instantiation (Defines read/write rules), Multi-Agent Interaction Loop (Orchestrates agent interactions), and Vector embeddings (Represents memory fragments), designed for permission-aware memory sharing.
- The framework utilizes dynamic bipartite graphs to model time-varying access permissions between users, agents, and resources.
- A two-tier memory system, comprising private and shared memory, is governed by fine-grained read and write policies to enable controlled knowledge transfer while maintaining privacy.


---

[BiomedSQL: Text-to-SQL for Scientific Reasoning on Biomedical Knowledge Bases](http://arxiv.org/abs/2505.20321v1)

- BMSQL: introduces a custom multi-step agent for text-to-SQL generation, including identifying schema elements, generating an initial query, correcting syntax, applying domain rules, generating a natural language answer, and refining the process.
- The agent operates over the BiomedSQL benchmark, which comprises question/SQL/answer triples grounded in a harmonized BigQuery knowledge base.
- This multi-stage pipeline is designed to emulate expert reasoning for translating biomedical questions into executable SQL.


---

[Lost in the Haystack: Smaller Needles are More Difficult for LLMs to Find](http://arxiv.org/abs/2505.18148v1)

- Experimental Evaluation Framework: introduces, with LLMs (Models tested), Benchmarks (Datasets for tasks), Gold Context (Relevant information), Distractor Context (Irrelevant information), and Evaluation Metrics (Performance measurement), a study showing that smaller gold contexts degrade LLM performance and increase positional sensitivity in long-context tasks.
- The study systematically varies the size and position of relevant information within fixed-length distractor context across diverse domains and state-of-the-art LLMs.
- Findings highlight that the size of relevant evidence, not just its location, is a critical factor in long-context reasoning and aggregation effectiveness.


---

Gaming Tool Preferences in Agentic LLMs](http://arxiv.org/abs/2505.18135v1)

- Agentic LLMs and Tools: introduces a vulnerability in prevalent tool-calling protocols by showing how edits to tool descriptions can significantly increase tool usage by Large Language Models (LLMs) when competing with alternatives, utilizing External Tools, Tool Descriptions, Tool-Calling Protocols, User Query, and Tool Arguments.
- The research empirically demonstrates that simple edits to tool descriptions alone can lead to disproportionately high usage compared to alternatives across various LLMs.
- These findings highlight the fragility of current LLM tool selection processes based solely on natural language descriptions and underscore the need for more reliable foundations.


---

[PROGRM: Build Better GUI Agents with Progress Rewards](http://arxiv.org/abs/2505.18121v1)

- PROGRM (Progress Reward Model): introduces a novel method for building GUI agents by providing dense intermediate rewards based on predicted task completion progress, utilizing an LLM-based reward model.
- The approach includes an LLM-based Actor (GUI Agent) trained via an Online RL Trainer using the Progress Reward signal, and a Progress Labeling Algorithm to automatically generate training labels for the reward model.
- PROGRM enables more efficient and stable RL training for long-horizon GUI tasks by offering fine-grained feedback at each step, outperforming ORM and proprietary LLM baselines.


---

[ManuSearch: Democratizing Deep Search in Large Language Models with a Transparent and Open Multi-Agent Framework](http://arxiv.org/abs/2505.18105v1)

- ManuSearch: introduces a transparent and modular multi-agent framework for deep web-integrated reasoning, comprising a Solution Planning Agent (interprets query, plans strategy), a Memory Container (manages context, records history), a Tool-Augmented Internet Search Agent (solves sub-questions via tools) utilizing a WebSearch Tool (performs web search, retrieves pages) and an Answer Question Tool (generates sub-question answer), and a Structured Webpage Reading Agent (reads webpages, extracts information).
- The framework decomposes the deep search and reasoning process into collaborative LLM-based agents to enhance interpretability and extensibility.
- Agents communicate and iterate in a structured reasoning loop, integrating task planning, web search, and information comprehension.


---

[Planning without Search: Refining Frontier LLMs with Offline Goal-Conditioned RL](http://arxiv.org/abs/2505.18098v1)

- PNLC: introduces Planning with a Natural Language Critic, with LLM Agent, Goal-conditioned Value Function, Natural Language Critic, Offline Training Dataset, Thought, and Goal components, where PNLC refines LLM agent planning using an offline-trained goal-conditioned value function as a natural language critic.
- The goal-conditioned value function predicts the likelihood of reaching future goal states given a state and thought, trained on offline trajectories.
- The natural language critic uses the value function to evaluate proposed thoughts by sampling positive and negative future outcomes and providing feedback to the LLM agent for refinement.


---

[Deep Video Discovery : Agentic Search with Tool Use for Long-form Video Understanding](http://arxiv.org/abs/2505.18079v2)

- Deep Video Discovery (DVD): introduces an agentic search framework for long-form video understanding, featuring an LLM (Orchestrator), a Search-centric Toolset (Collection of tools) including Global Browse (Retrieves global summaries), Clip Search (Retrieves relevant clips), and Frame Inspect (Performs VQA on frames), all interacting with a Multi-granular Video Database (Structured video information).
- The DVD agent leverages the LLM's reasoning to iteratively select and use tools from the toolset to gather information from the database and answer user queries.
- The multi-granular database is constructed from the long video to enable efficient retrieval and detailed inspection at different levels.


---

[Towards Analyzing and Understanding the Limitations of VAPO: A Theoretical Perspective](http://arxiv.org/abs/2505.17997)

- VAPO (Value-model Augmented Policy Optimization): introduces a theoretical analysis of the VAPO framework, which builds upon PPO (Base RL algorithm) and incorporates Value-Pretraining (Initializes value model), Decoupled Generalized Advantage Estimation (Different lambda for policy/critic), Length-Adaptive GAE (Adjusts policy lambda by length), Token-Level Policy Gradient Loss (Averages gradient over tokens), Clip-Higher (Modifies clipping for exploration), Positive Example LM Loss (LM loss on positive examples), and Group-Sampling (Groups training data) for long chain-of-thought reasoning tasks.
- The paper explores potential limitations of VAPO's design choices, including value function fidelity, adaptive GAE optimality, token-level gradient impact, exploration challenges, generalization, and component interactions.
- This theoretical perspective aims to stimulate research into more robust and generalizable RL algorithms for complex reasoning by highlighting areas where VAPO's assumptions might be challenged.


---

[Survival Games: Human-LLM Strategic Showdowns under Severe Resource Scarcity](http://arxiv.org/abs/2505.17937v2)

- Multi-Agent Simulation Framework: introduces a simulation environment with Agent Cognitive Modules (Observe/Access/Construct/Evaluate/Translate), Inter-Agent Interaction System (Dialogue/Memory/Social Impressions), Survival System (Food/Fullness/Health/Daily Cycle), Ethical Evaluation System (Wrongdoing Detection/Survival Impact/Ethics Score), Agents (LLM Robot/Human), Environment (Simulated World), and Memory (Agent/Social) to evaluate LLM ethical behavior.
- The framework incorporates a life-sustaining system with resource scarcity and a tailored evaluation system based on adapted wrongdoing detection and survival impact metrics.
- This testbed allows for quantifying LLM ethics in high-stakes, resource-constrained scenarios involving human-AI interaction.


---

[Superplatforms Have to Attack AI Agents](http://arxiv.org/abs/2505.17861v1)

- Superplatform-AI Agent Conflict Analysis: introduces, with Superplatform (Gatekeeper of user attention), AI Agent (Emerging gatekeeper), User (Interacts with services), Content Provider (Provides services), Superplatform-Initiated Attack (Adversarial action by Superplatform), Attack Goal (Objective of the attack), Attacker Knowledge (Information level of attacker), Attack Visibility (Perceptibility to user), and Attack Timing (Phase of agent lifecycle) components, an analysis arguing that superplatforms must attack AI agents to defend their gatekeeping control.
- The paper analyzes the fundamental conflict between user-attention-based monetization and agent-driven autonomy using gatekeeping theory.
- It explores potential technologies and challenges for superplatform-initiated adversarial attacks, particularly targeting GUI agents, while emphasizing the need for user-invisible attacks under black-box settings.


---

[Integrating Counterfactual Simulations with Language Models for Explaining Multi-Agent Behaviour](http://arxiv.org/abs/2505.17801v1)

- AXIS (Agentic explanations via Interrogative Simulation): introduces a framework for generating causal explanations of multi-agent behaviour using counterfactual simulations, integrating Memory (stores observations and history), LLM (interrogates simulator, synthesizes explanations), Simulator (provides counterfactual information), Macro Actions (higher-level agent actions), Verbalisation (converts environment to text), and Prompt Templates (dynamically create LLM prompts).
- The framework enables an LLM to interrogate an environment simulator using queries like WHATIF and REMOVE to gather counterfactual information over multiple rounds.
- Evaluated on autonomous driving scenarios, AXIS improves perceived explanation correctness and goal/action prediction accuracy compared to baselines.


---

[DialogXpert: Driving Intelligent and Emotion-Aware Conversations through Online Value-Based Reinforcement Learning with LLM Priors](http://arxiv.org/abs/2505.17795v1)

- DialogXpert: introduces a framework combining frozen Policy LLM (Prior), Q-Network, and Emotion Tracker for proactive, emotionally intelligent dialogue planning.
- The framework utilizes frozen Large Language Models for simulating User LLM, generating System LLM utterances, proposing Policy LLM (Prior) action candidates, inferring Emotion Tracker user emotions, and providing Critic LLM reward signals.
- A lightweight Q-Network, trained via online reinforcement learning on BERT embeddings, selects the optimal action from the Policy LLM (Prior)-proposed candidates, guided by Emotion Tracker and Critic LLM-based rewards.


---

[The Real Barrier to LLM Agent Usability is Agentic ROI](http://arxiv.org/abs/2505.17767v1)

- Agentic ROI: introduces Agentic Return on Investment (ROI) as a metric for LLM (Large Language Model) agent usability, arguing that the limited real-world adoption stems from a tradeoff between value and cost, encompassing the LLM (core model), Planner (action sequencing), Action-controller (environment interaction), Tools (external functions), Memory (information storage), Multi-agent System (multiple collaborating agents), and Human-in-the-loop (user interaction).
- The paper defines Agentic ROI based on information gain relative to interaction time and expense, highlighting a usability gap in mass-market applications despite progress in specialized domains.
- It proposes a zigzag development trend for optimizing Agentic ROI, involving scaling up for information quality and then scaling down to reduce agent time and cost, outlining strategies across pre-training, post-training, and test-time scaling.


---

[Automating Safety Enhancement for LLM-based Agents with Synthetic Risk Scenarios](http://arxiv.org/abs/2505.17735v1)

- AutoSafe: introduces a framework for enhancing LLM-based agent safety, including Agent (Ma), Task Generator (Mg), Environment Simulator (Ms), Evaluator (Me), Reflector (Mr), and Unified Threat Model (OTS), which systematically generates synthetic data for training.
- The framework utilizes the Unified Threat Model (OTS) to guide the generation of risk scenarios and employs a self-reflection mechanism involving the Evaluator (Me) and Reflector (Mr) to sample safe actions.
- Generated risk scenarios and safe actions are used to fine-tune the Agent (Ma), improving its safety performance without requiring real-world hazardous data collection.


---

[Get Experience from Practice: LLM Agents with Record & Replay](http://arxiv.org/abs/2505.17716v1)

- AgentRR (Agent Record & Replay): introduces a new paradigm for LLM agents, leveraging record-and-replay with a Record Module (captures agent/human traces), Summary Module (generalizes traces, generates checks), Replay Module (executes tasks using experiences), Experience Store (repository for experiences), Multi-level Experiences (abstracted knowledge from traces), and Check Functions (safety verification mechanisms).
- AgentRR addresses reliability, privacy, cost, and performance challenges by recording successful task executions, summarizing them into reusable multi-level experiences, and replaying these experiences guided by check functions.
- The framework utilizes low-level experiences for precise, efficient replay in similar environments and high-level experiences for generalization in varying contexts, while the Experience Store facilitates sharing and reuse of validated task knowledge.


---


[Seek-CAD: A Self-refined Generative Modeling for 3D Parametric CAD Using Local Inference via DeepSeek](http://arxiv.org/abs/2505.17702v1)

- Seek-CAD: introduces a training-free framework for 3D parametric CAD generation using local inference via DeepSeek-R1 (Generates CAD code, refines code), incorporating a Retrieval Augmented Generation (Retrieves relevant CAD code) strategy on a Local CAD Corpus (Source for RAG) guided by a Knowledge Constraint (Guides DeepSeek-R1 generation).
- The framework refines generated CAD code through a self-refinement loop utilizing a Rendering Script R(*) (Generates step-wise images) to produce Step-wise Visual Feedback (Provides visual refinement signal) evaluated by Gemini-2.0 (Evaluates image-CoT alignment) based on the Chain-of-Thought (Explains design logic) from DeepSeek-R1.
- Seek-CAD employs the SSR Design Paradigm (Structures CAD models) and CapType Reference Mechanism (References topological primitives) to represent CAD models and their features, enabling the generation of complex designs.


---

[Rethinking Agent Design: From Top-Down Workflows to Bottom-Up Skill Evolution](http://arxiv.org/abs/2505.17673v1)

- Bottom-Up Agent: introduces a bottom-up agent paradigm with Agent, Skill Library, LLM (M), Perception, Action, Skill Augmentation, Skill Invocation, Skill Evaluation, Skill Refinement, Implicit Reward, and MCTS components, where agents acquire competence through trial-and-reasoning and skill evolution in open-ended environments.
- The framework operates on raw visual inputs and simulated mouse/keyboard outputs, learning and refining skills based on implicit environmental feedback without predefined goals, subgoals, or APIs.
- Skills are incrementally composed, evaluated using MCTS and implicit rewards, refined via LLM reasoning, and stored in a shared skill library, enabling autonomous skill acquisition and evolution.


---

[IDA-Bench: Evaluating LLMs on Interactive Guided Data Analysis](http://arxiv.org/abs/2505.18223v1)

- IDA-Bench: introduces a novel benchmark evaluating LLM agents in multi-round interactive data analysis scenarios, with instruction materials (Task script), a simulated user (LLM simulating user), an agent (LLM data analysis agent), and a sandbox environment (Code execution environment).
- The simulated user, an LLM, provides sequential natural language instructions derived from Kaggle notebooks, incorporating subjective insights and domain knowledge, filtered by a gatekeeper mechanism.
- The agent, an LLM, executes Python code in the sandbox environment based on user instructions, aiming to complete data analysis tasks and generate submission files evaluated against a human baseline.


---

[Simulating Macroeconomic Expectations using LLM Agents](http://arxiv.org/abs/2505.17648v1)

- CLUES framework: introduces a novel framework for simulating macroeconomic expectation formation using LLM Agents, which utilize Large Language Models (core processing unit) informed by a Personal Characteristics Module (household traits), a Prior Expectations & Perceptions Module (prior beliefs/perceptions), and a Knowledge Acquisition Module (expert external knowledge).
- The framework constructs specialized Household and Expert LLM Agents to replicate survey experiments and capture heterogeneity in expectations and thought processes.
- Ablation studies demonstrate the critical role of each module, particularly the Prior Expectations & Perceptions Module, in simulating human-like expectation formation heterogeneity.


---

[CoMet: Metaphor-Driven Covert Communication for Multi-Agent Language Games](http://arxiv.org/abs/2505.18218v1)

- CoMet (Communicating with Metaphor): introduces a framework enabling LLM agents to use metaphors for covert communication in multi-agent language games, featuring a Feature Extractor, Metaphor Reasoner, Belief Mapper, Self-Monitor, Strategy Planner, Metaphor Generator, Actor, and Knowledge.
- The framework enhances agents' ability to interpret and generate metaphors, improving strategic and nuanced interactions in games like Undercover and Adversarial Taboo.
- CoMet combines hypothesis-based metaphor reasoning with self-improving metaphor generation, demonstrating improved performance in tasks requiring concealment and semantic evasion.


---

[Runaway is Ashamed, But Helpful: On the Early-Exit Behavior of Large Language Model-based Agents in Embodied Environments](http://arxiv.org/abs/2505.17616v1)

- Dynamic Early Exit: introduces two complementary strategies, Intrinsic Early Exit (Injects exit instructions) and Extrinsic Early Exit (Uses external verification) with a Verification Module (Monitors status, decides exit), applied to LLM-based Agents (Interacts with environment) to improve efficiency in embodied environments.
- The approach aims to reduce redundant steps and computational overhead by enabling agents to self-terminate when progress stalls or tasks are complete.
- The paper also introduces two metrics, Redundancy Steps and Progress Degradation, to evaluate the positive and negative impacts of early exit mechanisms.


---

[Distilling LLM Agent into Small Models with Retrieval and Code Tools](http://arxiv.org/abs/2505.17612v1)

- Agent Distillation: introduces a framework for transferring agentic behavior and tool use from LLMs to sLMs using reason-act-observe trajectories.
- The framework incorporates a first-thought prefix method to enhance teacher trajectories and self-consistent action generation to improve student robustness.
- This approach enables small models to effectively use retrieval and code tools, achieving performance competitive with larger models trained via CoT distillation.


---

[Controlled Agentic Planning & Reasoning for Mechanism Synthesis](http://arxiv.org/abs/2505.17607v1)

- Dual-Agent Design-Critique Framework: introduces a dual-agent LLM-based method for mechanism synthesis, featuring a Designer Agent, Simulator, Evaluation, Critique Agent, Revision, and Memory.
- The framework operates in an iterative loop where the Designer Agent proposes designs, the Simulator executes them, Evaluation measures performance, the Critique Agent provides feedback, and Revision refines the design strategy.
- This process leverages linguistic and symbolic reasoning, simulation, and memory to converge towards mechanisms satisfying target trajectories and constraints.


---

[USTBench: Benchmarking and Dissecting Spatiotemporal Reasoning of LLMs as Urban Agents](http://arxiv.org/abs/2505.17572v1)

- Unified Urban Agent Framework: introduces a system for evaluating LLMs as urban agents, including Urban Data (Real-world datasets), UAgentEnv (Interactive city environment), Urban Agent (LLM-based autonomous system), Experience (Stored past interactions), Feedback (Environmental response), Task Description (Task goal/details), Urban Observation (Real-time urban dynamics), Spatiotemporal Understanding (Interpreting spatial/temporal patterns), Forecasting (Predicting future states), Planning (Deriving actions for objectives), Reflection (Evaluating outcomes, updating reasoning), Action (Output to environment), Prediction Task Output (Prediction result), and Decision-making Task Output (Decision result).
- The framework processes urban data and task descriptions within an interactive environment, enabling the LLM agent to perceive, reason through understanding, forecasting, planning, and reflection, and output actions or predictions.
- The agent's reasoning process is modular, incorporating memory from past experiences and feedback from the environment to adapt and improve performance over time.


---

[Probe by Gaming: A Game-based Benchmark for Assessing Conceptual Knowledge in LLMS](http://arxiv.org/abs/2505.17512v1)

- CK-Arena (Conceptual Knowledge Arena): introduces a game-based benchmark using a Multi-Agent Interaction Game (Undercover game environment) and an Automatic Judge System (Evaluates statements, applies rules) to assess LLM-based agents (Participants in the game) understanding of Conceptual Knowledge (Concept pairs, relationships).
- The benchmark involves LLM-based agents acting as Players (Describe concepts, identify roles) and Judges (Evaluate statements, score metrics), with an optional Audience Agent (Votes in variant game) in a game variant.
- CK-Arena evaluates conceptual reasoning by challenging LLMs to describe, differentiate, and infer conceptual boundaries in a dynamic, interactive setting.


---

[Multi-agent Systems for Misinformation Lifecycle : Detection, Correction And Source Identification](http://arxiv.org/abs/2505.17511v1)

- Multi-agent Framework: introduces a novel multi-agent system for managing the misinformation lifecycle, including Classifier Agent (classifies misinformation types), Indexer Agent (indexes data sources), Extractor Agent (retrieves and ranks sources), Corrector Agent (generates corrections), and Verification Agent (validates outputs).
- This framework decomposes the misinformation lifecycle into specialized tasks handled by distinct agents to enhance transparency, modularity, and explainability.
- The system aims to provide a comprehensive solution for misinformation detection, correction, and source verification from start to finish.


---

[The Discovery Engine: A Framework for AI-Driven Synthesis and Navigation of Scientific Knowledge Landscapes](http://arxiv.org/abs/2505.17500v1)

- Discovery Engine (DE): introduces a framework transforming scientific literature into structured knowledge artifacts using LLM-Powered Guided Extraction (Distillation process) via an Adaptive Template (Extraction schema) with Verification (Source linking) and Vectorization (Embedding creation), encoded into a Conceptual Nexus Tensor (Unified representation).
- The framework provides Operational Views like the Conceptual Nexus Model (Knowledge graph view) and Semantic Vector Space Views (Vector space views) for human researchers and AI Agents (Knowledge landscape interaction) to navigate and generate new Knowledge Artifacts (Generated output).
- The Adaptive Template undergoes a self-consistent refinement cycle based on feedback, and AI Agents operate on the tensor/graph to identify gaps and synthesize novel knowledge.


---

[MARCO: Meta-Reflection with Cross-Referencing for Code Reasoning](http://arxiv.org/abs/2505.17481v1)

- MARCO (Meta-Reflection with Cross-Referencing): introduces a cognitive-evolving framework that enhances LLM code reasoning capabilities during inference through meta-reflection (summarizes past experiences), cross-referencing (shares peer lessons), knowledge bank (stores summarized experiences), knowledge condenser (distills knowledge bank), peer agents (other LLM agents), and python interpreter (provides execution feedback).
- The framework adopts a cognitive-evolving perspective, using meta-reflection for inter-problem knowledge accumulation and cross-referencing for intra-problem lesson sharing.
- MARCO enables the LLM agent to become progressively smarter at code reasoning by learning from its own past problem-solving experiences and the lessons of peer agents.


---

[Hydra: Structured Cross-Source Enhanced Large Language Model Reasoning](http://arxiv.org/abs/2505.17464v1)

- Hydra: introduces a training-free framework that unifies graph topology, document semantics, and source reliability to support deep, faithful reasoning in LLMs, including Initialization (Sets up process), Available Evidence Detection (Identifies relevant sources), Question Analysis (Breaks down question), Agentic Source Selector (Selects initial sources), Evidence Exploration (Retrieves reasoning paths), Initial Exploration (Uses selected sources), Refined Exploration (Uses LLM, online retrieval), Predicted Exploration (Uses LLM predictions), Evidence Pruning (Filters paths), Tri-factor cross-source verification (Verifies evidence reliability), Question Answering (Generates final answer), Path Refinement (Summarizes relevant facts), CoT Answering (Reasons systematically), Knowledge Graph (KG) (Structured factual source), Wikipedia (Wiki) (Semi-structured source), Web (Real-time online source), LLM (Analyzes, generates, reasons), Dense Retrieval Model (DRM) (Embeds, selects text), Search Engine (Performs online search), and Skyline Indicator (Guides retrieval order).
- The framework handles multi-hop and multi-entity problems through agent-driven exploration combining structured and unstructured retrieval, increasing evidence diversity and precision.
- Multi-source verification uses a tri-factor score to balance topic relevance with cross-modal agreement, pruning low-scoring branches before LLM calls.


---

[LLM-BSCVM: An LLM-Based Blockchain Smart Contract Vulnerability Management Framework](http://arxiv.org/abs/2505.17416v1)

- LLM-BSCVM (LLM-Based Blockchain Smart Contract Vulnerability Management Framework): introduces an end-to-end smart contract vulnerability management framework with Vulnerability Detection Agent, Repair Suggestion Agent, Risk Assessment Agent, Vulnerability Repair Agent, Patch Verification Agent, Report Generation Agent, Smart Contract Corpus, Vulnerability Knowledge Base, LLM, and RAG components, designed to provide comprehensive capabilities for detection, analysis, repair, and evaluation.
- The framework employs a three-stage Decompose-Retrieve-Generate method combining multi-agent collaboration and retrieval-augmented generation.
- LLM-BSCVM achieves high detection accuracy and reduced false positives by integrating static analysis, RAG, and LLM inference.


---

[Reinforcement Speculative Decoding for Fast Ranking](http://arxiv.org/abs/2505.20316v1)

- RSD (Reinforcement Speculative Decoding): introduces a multi-round modification method for fast LLM inference in ranking systems, featuring an Agent, Policy Network, Environment, State, Modification, Relevance Network, LLM, Budget, Listwise Ranking Knowledge, and Up-to-down Decoding Paradigm.
- The method employs an up-to-down decoding paradigm where an agent iteratively modifies the ranking sequence under a constrained budget, utilizing a ranking-tailored policy optimization via reinforcement learning.
- RSD leverages listwise ranking knowledge verified by LLMs across different rounds to enhance the agent's modification policy and demonstrates improved performance and reduced latency compared to existing methods on IR and RS tasks.


---

[Curriculum-Guided Reinforcement Learning for Efficient Multi-Hop Retrieval-Augmented Generation](http://arxiv.org/abs/2505.17391v1)

- EVO-RAG: introduces a curriculum-guided reinforcement learning framework with Agent (selects actions), Environment (provides state and feedback), Actions (discrete choices), Reward Signals (seven step-level feedback), Multi-Head Preference Model (ranks action trajectories), Two-Stage Curriculum (guides training phases), Time-Based Scheduler (dynamically adjusts reward weights), and Policy (action selection strategy), designed for efficient multi-hop retrieval-augmented generation.
- The framework employs a two-stage curriculum (Discovery and Refinement) and a time-based scheduler to dynamically adjust the weights of seven step-level reward signals.
- A query rewriting agent interacts with the environment by selecting discrete actions (SEARCH, BACKTRACK, ANSWER, REFUSE), guided by the dynamic reward structure and trained via Direct Preference Optimization over a multi-head preference model.


---

[LA-RCS: LLM-Agent Based Robot Control System](http://arxiv.org/abs/2505.18214v1)

- LA-RCS (LLM-Agent Based Robot Control System): introduces a robot control system utilizing a dual-agent framework, with Host Agent (Plans global actions), App Agent (Executes planned tasks), Memory (Stores past interactions), Robot (Performs physical actions), User (Provides task instruction), Request (User's task instruction), Global Plan (High-level action sequence), Command (Specific robot action), Observation (Visual data from robot), Sensor Data (Non-visual robot data), Thoughts (Agent's internal reasoning), Comment (Agent's progress report), and Status (Task completion state) components.
- The system enables autonomous planning, execution, and environmental analysis for robots based on user requests, minimizing human intervention.
- The dual-agent structure separates high-level planning from iterative task execution, allowing adaptation to dynamic environments through observation and feedback.


---

#### 22nd May 2025

[Search Wisely: Mitigating Sub-optimal Agentic Searches By Reducing Uncertainty](http://arxiv.org/abs/2505.17281v1)

- Search-R1-β-GRPO: introduces a reinforcement learning-based training method for agentic Retrieval-Augmented Generation systems, incorporating a confidence threshold into the reward function to mitigate sub-optimal search behaviors.
- The approach leverages the confidence of search query generations to reward high-certainty search decisions that lead to correct answers, aiming to improve efficiency and reliability.
- Experiments demonstrate that the confidence-aware training enables a 3B model to achieve better performance and reduce instances of over-search and under-search compared to baselines.


---

[X-MAS: Towards Building Multi-Agent Systems with Heterogeneous LLMs](http://arxiv.org/abs/2505.16997v1)

- X-MAS: introduces a paradigm for building multi-agent systems with heterogeneous LLMs, supported by X-MAS-Bench for evaluating diverse LLMs across functions and domains, and demonstrated through X-MAS-Proto implementing Planning, QA, Revise, Aggregation, and Evaluation Agents.
- The approach leverages the collective intelligence of diverse LLMs assigned to specialized agents to enhance system performance compared to homogeneous LLM-driven systems.
- Empirical studies using X-MAS-Bench findings show that transitioning existing MAS frameworks to use heterogeneous LLMs significantly improves performance across various tasks and domains.


---

[MASLab: A Unified and Comprehensive Codebase for LLM-based Multi-Agent Systems](http://arxiv.org/abs/2505.16988v1)

- MASLab: introduces a unified codebase for LLM-based multi-agent systems, with Unified Codebase Structure, Input Preprocessing, Shared Resource Management, Unified Configuration Management, and Evaluation Framework components.
- The codebase integrates over 20 methods, standardizes inputs and configurations, and provides shared access to LLMs and toolkits for research and development.
- The Evaluation Framework supports fair comparisons using LLM-based and rule-based protocols, including a code execution sandbox.


---

[T1: A Tool-Oriented Conversational Dataset for Multi-Turn Agentic Planning](http://arxiv.org/abs/2505.16986v1)

- T1-AGENT: introduces a tool-oriented conversational dataset (T1) and an LLM-based agent (T1-AGENT) for evaluating agentic planning, including a Dialogue (multi-turn conversation), Toolbox (predefined tool collection) containing Tools (functions for tasks), Cache (stores tool call results), Knowledge Base (data source for tools), and Code Execution Environment (sandbox for code).
- The framework focuses on complex multi-turn dialogues with inter-tool dependencies and dynamic replanning, supported by the caching mechanism.
- T1-AGENT generates executable Python code using the tools and manages cached results to efficiently handle user requests.


---

[Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine](http://arxiv.org/abs/2505.16982v1)

- Causal LLM Agents: introduces a vision for integrating LLM Agents (core reasoning engine), Multimodal Data (diverse biomedical inputs), Structured Knowledge (KGs) (grounding and explainability), Formal Causal Methods/Tools (algorithms for causal inference), External Tools/Libraries/APIs (external systems interaction), within an Agentic Framework (orchestrates agent actions) with Human-in-the-loop Control (human oversight mechanism), Safety Safeguards (ensures safe operation), and Auditability (tracks and verifies decisions).
- The paper discusses challenges and opportunities for these agents in drug discovery, personalized medicine, and public health applications.
- Achieving this vision requires synergistic integration of components and robust evaluation methodologies.


---

[Know the Ropes: A Heuristic Strategy for LLM-based Multi-Agent System Design](http://arxiv.org/abs/2505.16979v1)

- KtR (Know-The-Ropes): introduces a multi-agent framework that decomposes complex tasks into simpler, M-tractable sub-tasks, orchestrated by a System Controller using specialized agents like Worker, Trimmer, Reporter, Row Reducer, Column Reducer, Matcher, Painter, and Normalizer.
- The framework converts domain priors into an algorithmic blueprint hierarchy, recursively splitting tasks until they fit base LLM capabilities with minimal augmentation.
- This approach leverages disciplined decomposition and targeted augmentation to turn modest models into reliable collaborators for complex problems like Knapsack and Task Assignment.


---


[SWE-Dev: Evaluating and Training Autonomous Feature-Driven Software Development](http://arxiv.org/abs/2505.16975v1)

- SWE-Dev dataset: introduces, "a large-scale dataset for evaluating and training autonomous coding systems on feature-driven software development tasks", with Project Requirement Description (task description), Codebase (repository context), Test Suite (executable tests), Ground Truth Code (correct solution), Runnable Environment (execution context), Evaluation (test-based assessment), Training Support (training paradigms), where SWE-Dev provides real-world feature development tasks with executable tests and runnable environments.
- The dataset includes 14,000 training and 500 test samples derived from open-source projects, enabling reliable and functionally verifiable supervision.
- It supports diverse training paradigms like Supervised Fine-Tuning, Reinforcement Learning, and multi-agent training using execution-based feedback.


---

[Cracking Aegis: An Adversarial LLM-based Game for Raising Awareness of Vulnerabilities in Privacy Protection](http://arxiv.org/abs/2505.16954v1)

- LLM-Driven Game System: introduces, "Cracking Aegis", with Player Input, GPT-4o, System Prompt, LLM Response (json), JSON Parsing, Game State Update, and End components, where the system leverages GPT-4o to drive a text-based adventure game for privacy education.
- The system processes player input via GPT-4o guided by a system prompt, parses the JSON response, and updates the game state to provide dynamic guidance, dialogue, and scenario progression.
- This architecture simulates adversarial dialogue with an AI agent, enabling players to experience privacy vulnerabilities and reflect on real-world risks.


---

[A Comprehensive Evaluation of Contemporary ML-Based Solvers for Combinatorial Optimization](http://arxiv.org/abs/2505.16952v1)

- FrontierCO: introduces a comprehensive benchmark for evaluating ML-based combinatorial optimization solvers, featuring diverse CO problem types, realistic test sets, standardized training data, and a toolkit for LLM agents.
- The benchmark includes challenging instances from real-world applications and frontier research, designed to assess solver performance under realistic and large-scale conditions.
- The study evaluates various ML-based solvers, including neural networks and LLM agents, against state-of-the-art human-designed algorithms across the benchmark's problems and difficulty levels.


--

[AGENTIF: Benchmarking Instruction Following of Large Language Models in Agentic Scenarios](http://arxiv.org/abs/2505.16944v1)

- AGENTIF: introduces a benchmark for evaluating large language model instruction following in agentic scenarios, featuring a Dataset with realistic, long, complex instructions categorized by a Constraint Taxonomy and Meta Constraints, assessed via an Evaluation Protocol using Code Evaluation, LLM Evaluation, and Hybrid Evaluation methods generated by Evaluation Generation.
- The benchmark includes 707 instructions from real-world agentic tasks, averaging 1,723 words and 11.9 constraints per instruction.
- Evaluation results show that current models perform poorly on AGENTIF, particularly on condition and tool constraints, highlighting challenges with instruction length and complexity.


---

[Beyond Needle(s) in the Embodied Haystack: Environment, Architecture, and Training Considerations for Long Context Reasoning](http://arxiv.org/abs/2505.16928v1)

- Embodied VLA Model Architecture: introduces architectural adaptations for long-horizon embodied tasks, including a Multimodal LLM Backbone, Interleaved Goal-State-Action Modeling, Vision Encoder, Context Extension Techniques, and Context Parallelism, designed to enable long-context reasoning and interaction.
- The architecture uses an interleaved input structure of goal, state, and action tokens processed by a multimodal LLM to support coherent, real-time interaction modeling over extended sequences.
- Context Extension Techniques and Context Parallelism are explored to address the limitations of standard LLMs in processing the extremely long input sequences generated by the ∞-THOR framework.


---

[CODE GRAPH MODEL (CGM): A GRAPH-INTEGRATED LARGE LANGUAGE MODEL FOR REPOSITORY-LEVEL SOFTWARE ENGINEERING TASKS](http://arxiv.org/abs/2505.16901v1)

- Graph RAG: introduces Code Graph Models (CGMs) as the Reader component, along with Rewriter, Retriever, and Reranker, to integrate repository code graphs into LLMs for software engineering tasks.
- The CGM itself comprises an Encoder, Adapter, and LLM Decoder to process semantic and structural code information.
- This agentless framework achieves high resolution rates on repository-level issue fixing benchmarks using open-source LLMs.


---

[LLM-Based Emulation of the Radio Resource Control Layer: Towards AI-Native RAN Protocols](http://arxiv.org/abs/2505.16821v2)

- RRC-LLM: introduces, an LLM-based framework for RRC emulation, with Large RRC Model (Core LLM), Base model (Pre-trained LLaMA3-8B), Instruction Tuning (LoRA adaptation), Uplink messages (RRC input), Downlink messages (RRC output), Network Context (Additional input data), RRC traces (Historical training data), BERT Encoder (Embeds messages), Pooling (Creates sentence embeddings), and Cosine-sim (Measures similarity), where the framework fine-tunes a Base model using Instruction Tuning on RRC traces to create a Large RRC Model that generates Downlink messages from Uplink messages and Network Context, evaluated via BERT Encoder, Pooling, and Cosine-sim.
- The fine-tuned model achieves high cosine similarity with ground-truth RRC messages, demonstrating improved structural and semantic fidelity compared to a baseline LLM.
- This work demonstrates the feasibility of using LAMs for control-plane procedures, laying groundwork for AI-Native Air Interface paradigms.


---

[MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models](http://arxiv.org/abs/2505.16700v1)

- MCP-RADAR benchmark: introduces a comprehensive benchmark for evaluating LLM tool use capabilities in the Model Context Protocol framework, featuring a Radar Bench (Testing environment), Dataset Construction (Benchmark task creation), Radar Test (Execution and analysis), and Implementation (Practical test setup).
- The benchmark employs a novel five-dimensional approach measuring answer accuracy, tool selection efficiency, computational resource efficiency, parameter construction accuracy, and execution speed.
- It provides objective, quantifiable measurements across multiple task domains including software engineering, mathematical reasoning, and general problem-solving.


---

[O²-Searcher: A Searching-based Agent Model for Open-Domain Open-Ended Question Answering](http://arxiv.org/abs/2505.16582v2)

- O²-Searcher: introduces, "O²-Searcher: A Searching-based Agent Model for Open-Domain Open-Ended Question Answering", with RL-based search agent, Simulated search interface, Local data source, Access corpus, Process retrieved info, Core model, RL-optimized agent, RL training signals, Interaction protocol components, designed to tackle open-domain open-ended and closed-ended questions.
- The framework leverages a local simulated search environment for dynamic knowledge acquisition and employs a unified reinforcement learning mechanism with meticulously designed reward functions.
- It uses a chat template for multi-round interaction, enabling the agent to reason, search, learn from feedback, and generate answers.


---

[Large Language Model-Empowered Interactive Load Forecasting](http://arxiv.org/abs/2505.16577v1)

- LLM-based multi-agent collaboration framework: introduces an interactive load forecasting system with Human User, Task Manager, Preparation Assistant, Model Manager, Model Developer, Deployment Operator, Visualization Panel, and Experiment database components.
- This framework leverages specialized LLM agents collaborating via messaging to manage the forecasting pipeline and integrate human expertise.
- The system aims to lower technical barriers and improve forecasting accuracy through user interaction at key stages.


---

[Is Your LLM-Based Multi-Agent a Reliable Real-World Planner? Exploring Fraud Detection in Travel Planning](http://arxiv.org/abs/2505.16557v1)

- WandaPlan: introduces, with Travel Plan Agent (Central Coordinator), Crawler Agent (Information Retrieval), Extractor Agent (Data Extraction), Summary Agent (Option Ranking), and Confirmation Agent (Final Decision), a fraudulent evaluation environment for LLM-based multi-agent travel planning systems.
- The environment injects deceptive content into real-world data across misinformation, coordinated multi-person, and level-escalating multi-round fraud cases to assess agent vulnerability.
- The study highlights existing frameworks' susceptibility to fraud and proposes an Anti-fraud Agent (Risk Analysis) integration to improve reliability.


---

[Let's Get You Hired: A Job Seeker's Perspective on Multi-Agent Recruitment Systems for Explaining Hiring Decisions](http://arxiv.org/abs/2505.20312v1)

- Multi-Agentic Recruitment System: introduces a multi-agent AI system with MODERATOR, RECRUITER, and MENTOR agents, Memory, and an Agent Toolkit to guide job seekers and explain hiring decisions.
- The system was developed using an iterative, user-centric design approach informed by active job seekers.
- Evaluation demonstrated the system was perceived as significantly more actionable, trustworthy, and fair compared to traditional recruitment methods.


---

[Psychology-driven LLM Agents for Explainable Panic Prediction on Social Media during Sudden Disaster Events](http://arxiv.org/abs/2505.16455v1)

- PsychoAgent (Psychology-driven generative Agent framework): introduces a psychology-driven framework for explainable panic prediction, integrating multi-domain data via a CoT-driven LLM-based agent, individual feature extraction, MoE system, and fine-tuned BERT model.
- The framework simulates the psychological chain of panic formation through the agent's four stages: disaster event perception, risk cognition formation, panic emotion arousal, and posting response.
- This approach provides mechanistic interpretability by modeling psychological processes, moving beyond traditional data-fitting methods for panic detection.


---

[Beyond Static Testbeds: An Interaction-Centric Agent Simulation Platform for Dynamic Recommender Systems](http://arxiv.org/abs/2505.16429v1)

- RecInter: introduces an agent-based simulation platform for dynamic recommender systems, featuring User Agents with User Profile, Memory Module, and Action Module, interacting with a Recommendation Platform and Merchant Agent, enhanced by Behavior Simulation Training.
- The platform incorporates a novel interaction mechanism where user actions and merchant replies dynamically update item attributes, creating a realistic and evolving environment.
- High-fidelity simulation is achieved through Multidimensional User Profiling, Advanced Agent Architecture, and LLM fine-tuned on Chain-of-Thought data, enabling replication of emergent phenomena like Brand Loyalty.


---

[WEBAGENT-R1: Training Web Agents via End-to-End Multi-Turn Reinforcement Learning](http://arxiv.org/abs/2505.16421v1)

- WEBAGENT-R1: introduces an end-to-end multi-turn reinforcement learning framework for training web agents, including an Agent (LLM), Dynamic Context Compression, Asynchronous Trajectory Rollout, and Multi-turn GRPO.
- The framework learns directly from online interactions with web environments, guided by binary rewards, utilizing efficient mechanisms for context handling and trajectory generation.
- WEBAGENT-R1 achieves state-of-the-art performance on the WebArena-Lite benchmark, highlighting the importance of behavior cloning initialization and thinking-based prompting.


---

[LLM-Powered Agents for Navigating Venice's Historical Cadastre](http://arxiv.org/abs/2505.17148v1)

- LLM-Powered Agents framework: introduces a text-to-programs approach leveraging large language models to translate natural language queries into executable code for analyzing historical cadastral records, including SQL-Agent, Text-to-Python Agent, Entity Extractor, Planer, Coder, Code Execution Environment, Text2SQL (CodeS-7B), SQLite DB, Datasets, Prompt template, Column Extractor, Row Extractor, and Entity Search components.
- The framework employs a SQL-Agent for structured data retrieval and a Text-to-Python Agent with specialized sub-agents (Entity Extractor, Planer, Coder) for complex analytical tasks.
- The system processes historical cadastral datasets by extracting entities, planning analysis steps, generating code, and executing it to answer user queries about Venice's urban history.


---

[Embodied Agents Meet Personalization: Exploring Memory Utilization for Personalized Assistance](http://arxiv.org/abs/2505.16348v1)

- MEMENTO (Personalized Embodied Agent Evaluation Framework): introduces a two-stage evaluation process with Memory Acquisition Stage and Memory Utilization Stage, utilizing an LLM-powered embodied agent architecture with semantic and episodic memory for personalized assistance tasks.
- The framework assesses memory utilization by comparing performance between stages where instructions vary in their reliance on previously acquired personalized knowledge.
- The evaluation process includes Single-memory and Joint-memory tasks to test different levels of memory complexity and personalized knowledge types like object semantics and user patterns.


---

[Manalyzer: End-to-end Automated Meta-analysis with Multi-agent System](http://arxiv.org/abs/2505.20310v1)

- Manalyzer (Meta-analysis analyzer): automates end-to-end meta-analysis using a multi-agent system comprising Researcher, Document Collector, Literature Reviewer, Data Extractor, Checker, Data Analyst, and Reporter agents, leveraging various Tools.
- It mitigates hallucinations in paper screening and data extraction through hybrid review, hierarchical extraction, self-proving, and feedback checking workflows.
- The system significantly outperforms LLM baselines on a new benchmark dataset for paper screening and data extraction tasks.


---

[No Black Boxes: Interpretable and Interactable Predictive Healthcare with Knowledge-Enhanced Agentic Causal Discovery](http://arxiv.org/abs/2505.16288v1)

- II-KEA (knowledge-enhanced Agentic Causal Discovery framework): introduces a multi-agent system for interpretable and interactive diagnosis prediction, comprising Clinical Datasets, Domain Knowledge, Knowledge Synthesis Agent, Causal Discovery Agent, and Decision-Making Agent, which leverages causal discovery to predict future diagnoses from EHR data.
- The system utilizes three collaborative LLM agents, supported by clinical data matrices and a vector database of external medical knowledge, to generate a causal graph and predict diagnoses with explanations.
- II-KEA enhances interpretability via causal analysis and interactivity through optional clinician input and external knowledge integration.


---

[ARPO: End-to-End Policy Optimization for GUI Agents with Experience Replay](http://arxiv.org/abs/2505.16282v1)

- ARPO (Agentic Replay Policy Optimization): introduces an end-to-end reinforcement learning approach for GUI agents, with VLM Agent, Vision-Language Model, Observations, Actions, Chain-of-Thought, Reinforcement Learning, GRPO, Reward, Policy Gradient, Distributed Environments, Rollout Workers, Centralized Inference Server, Replay Buffer, and Valuable Tasks Selection, designed for policy optimization in complex GUI environments.
- The framework augments Group Relative Policy Optimization (GRPO) with a replay buffer to reuse successful experience and employs a task selection strategy for stable training.
- ARPO leverages distributed rollout and structured rewards to train vision-language GUI agents capable of multi-turn interactions and self-correction.


---

[HIMATE: A Hierarchical Multi-Agent Framework for Machine Translation Evaluation](http://arxiv.org/abs/2505.16281v1)

- HIMATE (Hierarchical Multi-Agent Framework for Machine Translation Evaluation): introduces a hierarchical multi-agent framework for machine translation evaluation, utilizing Tier-1 and Tier-2 agents structured by the MQM Hierarchy to perform Subtype Evaluation, Self-Reflection, and Collaborative Discussion, culminating in Weighted Scoring.
- The framework employs a three-stage process where Tier-2 agents initially evaluate subtype errors, refine judgments through self-reflection, and engage in collaborative discussion with Tier-1 agents for low-confidence cases.
- This hierarchical structure and multi-stage process, guided by the MQM error typology, enhance error span detection and severity assessment accuracy.


---

[RAP: Runtime-Adaptive Pruning for LLM Inference](http://arxiv.org/abs/2505.17138v2)

- RAP (Runtime-Adaptive Pruning): introduces a framework for dynamically adjusting LLM (Large Language Model) compression strategies based on real-time conditions, utilizing an Inference Environment, Execution State, RL Agent, Greedy Sequential Importance (GSI), Pruning Action, Pruning & Inference Module, LLM, and Reward Calculation.
- The framework employs a reinforcement learning agent that observes runtime state, including request characteristics and memory budget, to select an optimal pruning policy.
- This adaptive approach prunes LLM components like FFN and MHA blocks, guided by GSI analysis, to balance memory efficiency and generative performance during inference.


---

[LLM-Powered AI Agent Systems and Their Applications in Industry](http://arxiv.org/abs/2505.16120v1)

- LLM-Powered AI Agent System: introduces a comprehensive architecture, with Environment (Source of perception/interaction), Task Input (Defines objective/instructions), Context Augmentation (Leverages external knowledge sources), Agent (Central processing/decision unit), LLM (Cognitive engine/reasoning core), Multi-Modality Model (Processes diverse data inputs), Memory (Accesses external knowledge/history), Tool Utilization (Invokes APIs/databases/models), Output Guardrails (Filters/validates outputs), Actions (Executes decisions in environment), Other Agents (Interacts with other agents), Iterative Process (Continuous sensing/acting loop), enabling autonomous, goal-oriented behavior.
- The system integrates LLMs with components for perception, memory, tool use, and guardrails to enable autonomous, goal-oriented behavior in dynamic environments.
- The architecture facilitates context-aware decision-making and reliable execution through iterative sensing, planning, and action, addressing challenges like latency and uncertainty.


---

[Optimizing LLM-Based Multi-Agent System with Textual Feedback: A Case Study on Software Development](http://arxiv.org/abs/2505.16086v1)

- Two-Step Optimization Pipeline: introduces a method to optimize a Multi-Agent System (Role-based LLM agents) by utilizing a Critic Mechanism (Evaluates output, generates feedback) to produce Textual Feedback (Natural language evaluation output), which is then used by a Locator (Identifies underperforming agents) to pinpoint issues and an Optimizer (Optimizes agent prompts) to refine Agent Prompts (System prompts for agents).
- The pipeline focuses on improving the performance of role-based LLM agents collaborating on complex tasks like software development by iteratively refining their prompts based on feedback.
- The approach demonstrates effectiveness across various software development evaluation dimensions and investigates the impact of different optimization settings.


---

#### 21st May 2025

[How Memory Management Impacts LLM Agents: An Empirical Study of Experience-Following Behavior](http://arxiv.org/abs/2505.16067v1)

- LLM Agent with Memory: introduces, with Agent Execution (Performs tasks), Memory Management (Manages stored experiences), Stored Episodic Memory (Stores past experiences), Query (Input task), Retrieved Memory (Past experiences for guidance), Planning (Agent reasoning), Execution (Agent output/action), Addition (Adds new experiences), and Deletion (Removes past experiences), an empirical study on how memory management choices impact LLM agent behavior and long-term performance.
- The study focuses on the fundamental memory operations of addition and deletion, investigating their impact on the agent's experience-following property and associated challenges like error propagation and misaligned experience replay.
- The research proposes selective addition and combined deletion strategies to mitigate negative effects, demonstrating performance gains and robustness under challenging conditions.


---

[MAPS: A Multilingual Benchmark for Global Agent Performance and Security](http://arxiv.org/abs/2505.15935v1)

- MAPS (Multilingual Agentic AI Benchmark Suite): introduces a benchmark suite for evaluating agentic AI systems across diverse languages and tasks, comprising GAIA Dataset (Real-world tasks), SWE-Bench Dataset (Code generation), MATH Dataset (Mathematical reasoning), Agent Security Benchmark Dataset (Security assessment), and a Translation Pipeline (Multilingual data generation).
- The Translation Pipeline (Multilingual data generation) component utilizes Machine Translation (Initial structural translation), Meaning Preservation Verification (Check MT semantic fidelity), Translation Refinement (LLM-based enhancement), Integrity Check (Check refinement quality), and Direct LLM Translation (LLM fallback translation) to create multilingual versions of the datasets.
- MAPS facilitates systematic analysis of agent performance and security degradation in multilingual settings, highlighting vulnerabilities not captured by English-only benchmarks.


---

[ViQAgent: Zero-Shot Video Question Answering via Agent with Open-Vocabulary Grounding Validation](http://arxiv.org/abs/2505.15928v1)

- ViQAgent: introduces a zero-shot video question answering framework with VideoLLM Analyzer, Object Grounder, and CoT Judgment components.
- The framework uses the VideoLLM Analyzer for initial video understanding and target identification, and the Object Grounder for open-vocabulary object detection and tracking.
- The CoT Judgment module compares initial analysis with grounded data, generates clarification questions, and refines the final answer.


---

[Aligning Dialogue Agents with Global Feedback via Large Language Model Reward Decomposition](http://arxiv.org/abs/2505.15922v1)

- LLM-GELI / Multimodal-LLM-GELI: introduces a framework that leverages a Large Language Model (LLM) to decompose sparse Global Explicit Rewards into dense Turn-level Pseudo-rewards, which are then used to train a Lightweight Reward Model for aligning a Dialogue Agent.
- The Multimodal variant enhances decomposition by incorporating Multimodal Feedback Features, such as facial expressions and gaze, alongside the Dialogue Transcript as input to the LLM.
- This approach obviates the need for manual reward shaping and granular human feedback, demonstrating the LLM's effectiveness in decomposing global feedback for fine-grained behavioral alignment.


---

[HCRMP: A LLM-HINTED CONTEXTUAL REINFORCEMENT LEARNING FRAMEWORK FOR AUTONOMOUS DRIVING](http://arxiv.org/abs/2505.15793v2)

- HCRMP (LLM-Hinted Contextual Reinforcement Learning Motion Planner): introduces a novel motion planning architecture for autonomous driving, with Augmented Semantic Representation Module (extends state space), Contextual Stability Anchor Module (improves weight reliability), and Semantic Cache Module (integrates LLM guidance).
- The framework proposes an LLM-Hinted RL paradigm where the LLM provides semantic hints for state augmentation and policy optimization, while the RL agent maintains relative independence to counteract potential hallucinations.
- This approach significantly improves driving performance in diverse and safety-critical conditions by combining LLM's understanding with RL's self-learning capabilities.


---

[Alignment Under Pressure: The Case for Informed Adversaries When Evaluating LLM Defenses](http://arxiv.org/abs/2505.15738v1)

- Checkpoint-GCG: introduces an informed adversarial attack leveraging Intermediate Model Checkpoints from the Alignment Process of an LLM to initialize the GCG algorithm sequentially, aiming to find an Adversarial Suffix that produces a Target Output from a Prompt, evaluated on the Base Model and Final Aligned Model, guided by a Checkpoint Selection Strategy.
- The method exploits the incremental nature of alignment training by using successful suffixes found at earlier checkpoints as initialization for attacking later ones.
- This approach demonstrates that existing alignment-based defenses are vulnerable to attacks when adversaries have knowledge of the alignment process, achieving high attack success rates.


---

[DEBATE, TRAIN, EVOLVE: Self-Evolution of Language Model Reasoning](http://arxiv.org/abs/2505.15734v1)

- DTE (DEBATE, TRAIN, EVOLVE): introduces a novel ground truth-free training framework using multi-agent debate traces to evolve a single language model, including the DEBATE (Multi-agent debate process), Agents (Language models debating), RCR Prompting (Prompting strategy for debate), Debate Traces (Records of debate interactions), Consensus Answer (Final answer from debate), TRAIN (Fine-tuning process), Single Policy (Language model being trained), Reference Model (Frozen base policy), Reward Module (Calculates training reward), GRPO Optimizer (Optimization algorithm), EVOLVE (Iterative self-improvement), Evolved Single Model (Fine-tuned model), and Evolution Loop (Iterative training cycle) components.
- The framework combines multi-agent debate (MAD) with self-supervised reinforcement learning (GRPO) to enable autonomous reasoning capability enhancement.
- A key component is the REFLECT-CRITIQUE-REFINE (RCR) prompting strategy designed to improve debate quality and reduce issues like sycophancy.


---

[From Grounding to Manipulation: Case Studies of Foundation Model Integration in Embodied Robotic Systems](http://arxiv.org/abs/2505.15685v1)

- End-to-End VLA Models: introduces a paradigm that directly maps language and vision inputs to low-level actions using Language encoder, Vision encoder, Action decoder, and Controller components.
- Modular VLM Pipelines utilize a specialist VLM for perception and a separate Controller for action, exemplified by a prototype with Speech Transcription, Task Decomposition, Object Detection, Object Segmentation, and Manipulation modules.
- Multimodal LLM Agents position a Multimodal LLM as a cognitive hub that orchestrates Auxiliary tools for perception and a Controller for action primitives via function calls.


---

[Efficient and Direct Duplex Modeling for Speech-to-Speech Language Model](http://arxiv.org/abs/2505.15670v1)

- Duplex S2S Model: introduces a novel duplex speech-to-speech architecture with a Streaming Speech Encoder (Encodes user speech), Modality Adapter (Connects encoder to LLM), Channel Fusion (Combines user/agent streams), Decoder-only LLM (Processes combined streams), Pooling (Processes agent/user embeddings), Codec (Tokenizes agent speech), Text Projector (Outputs agent text), and Audio Projector (Outputs agent audio), designed for simultaneous user and agent interaction.
- The model uses a pretrained streaming encoder for user input and a personalized codec for agent outputs, enabling duplex S2S without speech pretraining.
- Separate modeling of agent and user facilitates codec fine-tuning for improved agent voices and reduces bitrate compared to prior work.


---

[Swarm Intelligence Enhanced Reasoning: A Density-Driven Framework for LLM-Based Multi-Agent Optimization](http://arxiv.org/abs/2505.17115v2)

- SIER: introduces a framework for LLM-based multi-agent optimization, conceptualizing reasoning as a solution search process guided by swarm intelligence, featuring Population Initialization, Population Evolution, and Population Clustering and Selection phases, utilizing LLM-based agents, a Generator, and an Evaluator.
- The framework employs a density-driven strategy within Population Evolution, using kernel density estimation and non-dominated sorting for multi-criteria selection to balance solution quality and diversity.
- Step-level quality evaluation and adaptive sampling are used to refine reasoning paths and dynamically control exploration for efficient problem-solving.


---

[InfoDeepSeek: Benchmarking Agentic Information Seeking for Retrieval-Augmented Generation](https://infodeepseek.github.io/)

- InfoDeepSeek (Agentic RAG Framework): introduces a benchmark for evaluating agentic information seeking in dynamic web environments, featuring an Agent (Orchestrates information seeking process) that operates through a Retrieval Stage (Iteratively searches and browses web), Augmentation Stage (Filters and distills retrieved content), and Generation Stage (Synthesizes final answer), utilizing an LLM (Central reasoning engine for agent), Memory (Stores agent's interaction trajectory), and Tool Library (Interface to external tools).
- The framework employs an autonomous LLM agent to perform multi-step planning, search, and reflection for robust evidence acquisition from the live web.
- The benchmark includes challenging questions with attributes like multi-hop, long-tail, and distracting information, evaluated using fine-grained metrics for accuracy, utility, and compactness.


---

[Collaborative Problem-Solving in an Optimization Game](http://arxiv.org/abs/2505.15490v1)

- Neurosymbolic Agent (Problem-Solving version): introduces a collaborative problem-solving agent for a Traveling Salesman-based game, incorporating a Language Model with symbolic components for state tracking, grounding, and an external optimization solver.
- The agent collaborates with a partner through dialogue to find an optimal path in a graph where each player has partial information about edge weights.
- The neurosymbolic agent outperforms a purely LLM-based baseline, demonstrating improved correctness and optimality in finding solutions.


---

[X-WebAgentBench: A Multilingual Interactive Web Benchmark for Evaluating Global Agentic System](http://arxiv.org/abs/2505.15372v1)

- X-WebAgentBench: introduces a multilingual interactive web benchmark for evaluating language agents, comprising Data Preparation (selects languages, prepares data), Multilingual Instruction Construction (translates instructions), Multilingual Environment Construction (translates environment), and Quality Check (validates data accuracy) stages.
- The benchmark includes 14 languages, 2,800 instructions, and 589,946 products to assess agent performance in multilingual web environments.
- Evaluation on X-WebAgentBench reveals challenges for current language agents in multilingual scenarios, particularly regarding language alignment and long interactions.


---

[CRAKEN: Cybersecurity LLM Agent with Knowledge-Based Execution](http://arxiv.org/abs/2505.17107v1)

- CRAKEN: introduces a knowledge-based LLM agent framework, with Planner (devises task plan), Executor (executes delegated tasks), Trigger Retriever (initiates knowledge retrieval), Decompose Context (extracts task information), Knowledge Database (stores domain knowledge), RETRIEVER (retrieves relevant documents), RELEVANCEGRADER (grades document relevance), GENERATOR (generates knowledge hint), HALLUCINATIONGRADER (grades hint grounding), REWRITER (rewrites query), SOLVEDGRADER (grades hint sufficiency), and Injection (integrates knowledge hint), designed to enhance cybersecurity capabilities.
- The framework combines a planner-executor multi-agent system with an iterative retrieval system using Self-RAG and Graph-RAG on a cybersecurity knowledge database.
- CRAKEN improves performance on complex cybersecurity tasks by decomposing context, iteratively retrieving knowledge, and injecting insights into the agent's workflow.


---

[Multiple Weaks Win Single Strong: Large Language Models Ensemble Weak Reinforcement Learning Agents into a Supreme One](http://arxiv.org/abs/2505.15306v1)

- LLM-Ens: introduces a framework that leverages LLMs to dynamically ensemble multiple weak reinforcement learning agents by categorizing task situations and selecting the best-performing agent for the current context.
- The framework consists of three stages: situation generation, agent reward distribution analysis, and dynamic model ensemble during inference.
- LLM-Ens demonstrates improved performance over baseline ensemble methods and single agents on Atari tasks by adapting to varying task conditions and agent strengths.


---

[LLM-Explorer: A Plug-in Reinforcement Learning Policy Exploration Enhancement Driven by Large Language Models](http://arxiv.org/abs/2505.15293)

- LLM-Explorer: introduces a plug-in method that utilizes two LLMs, one for analyzing the agent's learning status and another for generating a policy exploration strategy distribution, enabling the Agent to adaptively explore the Environment.
- The framework samples action-reward trajectories from the Agent's interaction with the Environment to inform the LLMs' analysis and strategy generation.
- This design allows LLM-Explorer to enhance policy exploration in reinforcement learning by dynamically adjusting the exploration strategy based on the agent's real-time learning status.


---

[P2P: Automated Paper-to-Poster Generation and Fine-Grained Benchmark](http://arxiv.org/abs/2505.17104v1)

- P2P (Automated Paper-to-Poster Generation): introduces a flexible, LLM-based multi-agent framework for generating academic posters, including Figure Agent (Processes visual elements), Figure Extractor (Extracts figures, tables), Figure Describer (Describes visual elements), Figure Checker (Validates figure processing), Section Agent (Generates textual content), Section Generator (Creates text content), Section Checker (Validates text content), Orchestrate Agent (Assembles final poster), HTML Generator (Renders HTML poster), Poster Checker (Evaluates poster layout), and Reflection loops (Enables iterative refinement).
- The framework processes research papers through specialized agents, each with a checker module, to extract visual elements, generate content, and assemble HTML-rendered posters.
- Iterative refinement via checker modules and reflection loops ensures output quality and seamless integration of visual and textual components into cohesive posters.


---

[ReflAct: World-Grounded Decision Making in LLM Agents via Goal-State Reflection](http://arxiv.org/abs/2505.15182v1)

- ReflAct (Reflect for Action): introduces a novel backbone that shifts reasoning from planning next actions to continuously reflecting on the agent's state relative to its goal, using Task Goal, Observation, Internal State, Reflection, and Action components.
- This framework grounds decisions in actual observations and maintains continuous goal alignment to improve strategic reliability and reduce hallucinations.
- ReflAct achieves this by explicitly prompting the LLM agent to generate a Reflection encoding the internal belief state and task goal before selecting an Action.


---

[LMGAME-BENCH: How Good are LLMs at Playing Games?](http://arxiv.org/abs/2505.15146v1)

- Imgame-Bench (LMGAME-BENCH): introduces a benchmark for evaluating LLMs on games, with Models (LLM/VLM agents), Perception Module (Converts UI to symbolic/text), Memory Modules (Integrates transient memory/reflection), and Reasoning Modules (Supports reasoning traces) to enhance evaluation reliability.
- The benchmark uses a modular harness to improve LLM game-playing capabilities and address challenges like poor perception, prompt sensitivity, and data contamination.
- Evaluation across 13 models and 6 games shows the benchmark is challenging, differentiates models, and reveals that game-based training can transfer to other planning and agentic tasks.


---

[Multicrossmodal Automated Agent for Integrating Diverse Materials Science Data](http://arxiv.org/abs/2505.15132v1)

- Multicrossmodal Agent: introduces a multi-agent LLM framework integrating diverse materials science data using specialized agents, a shared embedding space, and a fusion process.
- The framework employs a Unified Team Agent to orchestrate modality-specific agents (Web, PDF, Image, Video, CSV) that process data and project insights into a shared embedding space.
- A Fusion Agent orchestrates dialogue, applies dynamic gating to weighted insights from specialized agents, and generates a unified scientific report or retrieval results.


---

[LTDA-Drive: LLMs-guided Generative Models based Long-tail Data Augmentation for Autonomous Driving](http://arxiv.org/abs/2505.18198v1)

- LTDA-Drive (Long-Tail Data Augmentation framework): introduces a data augmentation framework with head-class object removal, tail-class object insertion, and LLM-guided candidate filtering, designed to address long-tail distribution in 3D object detection.
- The framework replaces frequent head-class objects with synthetically generated tail-class instances in driving scenes.
- It leverages text-guided diffusion models for generation and an LLM agent for filtering to ensure high-quality, diverse augmented data.


---

[An Empirical Study on Reinforcement Learning for Reasoning-Search Interleaved LLM Agents](http://arxiv.org/abs/2505.15117v1)

- LLM-based Search Agent: introduces an empirical study on training LLM agents capable of interleaved reasoning and search using reinforcement learning, investigating the impact of reward formulation, underlying LLM characteristics, and search engine choice.
- The framework involves an LLM Agent interacting with a Search Engine, guided by a Reward Function within a Reinforcement Learning process.
- Key findings highlight the importance of format rewards, the influence of LLM type and scale, and the critical role of the search engine in training dynamics and inference robustness.


---

[A Risk Taxonomy for Evaluating Al-Powered Psychotherapy Agents](http://arxiv.org/abs/2505.15108v1)

- Risk Taxonomy: introduces a structured framework for evaluating AI-powered psychotherapy agents with Immediate Risk (Imminent danger) and Potential Risk (Emerging vulnerability) components.
- The taxonomy aims to identify and categorize potential negative outcomes and user harms in AI psychotherapy interactions.
- Developed through literature review, expert interviews, and clinical criteria alignment, the taxonomy provides a basis for safer AI mental health support.


---

[Nek Minit: Harnessing Pragmatic Metacognitive Prompting for Explainable Sarcasm Detection of Australian and Indian English](http://arxiv.org/abs/2505.15095v1)

- PMP (Pragmatic Metacognitive Prompting): introduces, with Comprehension of Context/Understanding, General Pragmatic Analysis, Preliminary Judgment, Meta-Comprehension, Specific Pragmatic Reassessment, and LLM components, a method for explainable sarcasm detection across English varieties.
- The approach adapts pragmatic metacognitive prompting to guide large language models in generating textual explanations for sarcasm in Australian, Indian, and American English.
- PMP significantly improves performance compared to baseline prompting strategies, particularly for non-standard English varieties, by providing pragmatic scaffolding.


---

[StepSearch: Igniting LLMs Search Ability via Step-Wise Proximal Policy Optimization](http://arxiv.org/abs/2505.15107v2)

- StepSearch: introduces a reinforcement learning framework for search LLMs, utilizing a Policy LLM interacting with a Search Engine, trained via StePPO with a detailed Reward Mechanism and supported by a Data Augmentation Pipeline and Memory/History.
- The Reward Mechanism includes both global and step-wise token-level rewards based on information gain and redundancy penalties to guide search actions.
- The framework aims to improve multi-hop reasoning by providing fine-grained supervision for iterative retrieval and query formulation.


---

[AutoData: A Multi-Agent System for Open Web Data Collection](http://arxiv.org/abs/2505.15859v1)

- AutoData (Automated web Data collection): introduces a novel multi-agent system for open web data collection, with Manager Agent orchestrating workflow, Research Squad extracting knowledge and designing blueprint, Develop Squad building program and validating data, and Oriented HyperGraph Cache System optimizing information flow and managing artifacts.
- The system comprises eight specialized agents organized into research and development squads coordinated by the manager agent.
- The OHCache system includes an oriented message hypergraph, an oriented hyperedge formatter, and a local cache system to enhance multi-agent collaboration efficiency.


---

[ModelingAgent: Bridging LLMs and Mathematical Modeling for Real-World Challenges](http://arxiv.org/abs/2505.15068v1)

- ModelingAgent: introduces a multi-agent framework with Idea Proposer, Data Searcher, Model Implementor, Report Writer, Critic Module, Shared Memory, and External Tool Set components, designed to tackle complex mathematical modeling problems.
- The framework utilizes a shared memory for agent coordination and an external tool set for data acquisition and code execution.
- An integrated Critic Module enables iterative self-refinement of agent outputs based on specific evaluation rubrics.


---

[UrduFactCheck: An Agentic Fact-Checking Framework for Urdu with Evidence Boosting and Benchmarking](http://arxiv.org/abs/2505.15063v1)

- URDUFACTCHECK: introduces an end-to-end fact-checking framework for Urdu, with CLAIMPROCESSOR, QUERYGENERATOR, RETRIEVER, and VERIFIER components, utilizing multi-strategy evidence retrieval including Monolingual, Translated, and Thresholded Translated Retrieval.
- The framework addresses the scarcity of high-quality Urdu evidence through its dynamic evidence retrieval pipeline that combines monolingual and translation-based approaches.
- The paper also introduces two new hand-annotated benchmarks, URDUFACTBENCH and URDUFACTQA, for evaluating claim verification and LLM factuality in Urdu.


---

[PiFlow: Principle-aware Scientific Discovery with Multi-Agent Collaboration](http://arxiv.org/abs/2505.15047v1)

- PiFlow: introduces a principle-aware multi-agent system for scientific discovery, including PiFlow (Strategic director, information-theoretical), Planner Agent (Relays strategic guidance), Hypothesis Agent (Proposes testable hypotheses), Experiment Agent (Validates hypotheses, using tool), and Tt (Accumulated principle-outcome data).
- The framework views scientific discovery as a structured uncertainty reduction problem guided by scientific principles selected via Min-Max optimization.
- This approach enhances discovery efficiency and solution quality by systematically steering hypothesis generation and validation based on accumulated evidence.


---

[Large Language Model-Powered Agent for C to Rust Code Translation](http://arxiv.org/abs/2505.15858v1)

- LAC2R (LLM-powered Agent for C-to-Rust code translation): introduces a novel C-to-Rust translation approach with LLM(s) (Heterogeneous), Virtual Fuzzing-based equivalence Test, Monte Carlo Tree Search, Preprocessor, Code Analyzer, Verifier, and Postprocessor.
- The framework leverages LLMs' agentic capabilities, using VFT to identify functional non-equivalence and MCTS to plan iterative code refinement steps.
- The approach aims to improve the safety and correctness of Rust code translated from C by systematically guiding the LLM refinement process.


---

[Simulating Prosocial Behavior and Social Contagion in LLM Agents under Institutional Interventions](http://arxiv.org/abs/2505.15857v1)

- PROSIM: introduces a simulation framework for modeling prosocial behavior in LLM agents, with Individual Simulation (instantiates agents), Scenario Simulation (defines contexts), Interaction Simulation (models network dynamics), and Intervention Simulation (manipulates policies) components.
- The framework examines how prosocial behavior emerges, adapts, and erodes in LLM-based agents under diverse social and institutional conditions.
- PROSIM integrates four key modules to approximate the complexity of real human social environments for studying social alignment and institutional dynamics.


---

[MAS-ZERO: Designing Multi-Agent Systems with Zero Supervision](https://mas-design.github.io/)

- MAS-ZERO: introduces a self-evolved, inference-time framework for automatic multi-agent system design, utilizing a Meta-Agent that orchestrates design and verification, leverages Building Blocks of pre-defined MAS configurations, performs Meta-Iterations through iterative design and feedback, executes the generated MAS via a Compiler to obtain Intermediate Outputs and Candidate Answers, and employs Self-Verification to select the best final solution.
- The framework iteratively refines MAS configurations tailored to each problem instance by decomposing tasks (Meta-Design) and evaluating performance based on intermediate outputs (Meta-Feedback) without requiring a validation set.
- This approach enables dynamic agent composition and problem decomposition, leading to improved performance and cost-efficiency compared to manual and existing automatic MAS design methods.


---

#### 20th May 2025

[ContextAgent: Context-Aware Proactive LLM Agents with Open-World Sensory Perceptions](http://arxiv.org/abs/2505.14668v1)

- ContextAgent: introduces a context-aware proactive LLM agent framework with Sensory Context Extraction (Extracts context from perceptions), Persona Context Extraction (Extracts context from historical data), Context-aware Reasoner (Integrates contexts, reasons, predicts), LLM (Core reasoning engine), Thought Traces (Generated reasoning steps), Proactive Predictions (Predicts need for service), External Tool Calling (Calls external tools), and Services (Provides assistance).
- The framework leverages extensive sensory perceptions from wearables and persona contexts to understand user intentions and predict the need for proactive assistance.
- ContextAgent utilizes tool-augmented LLM reasoning and introduces ContextAgentBench, a benchmark for evaluating such agents.


---

[Log-Augmented Generation: Scaling Test-Time Reasoning with Reusable Computation](http://arxiv.org/abs/2505.14398v1)

- LAG (log-augmented generation): introduces a framework that directly reuses prior computation and reasoning from past logs at test time, utilizing a Log Store, Log Encoder, Log Retriever, and augmented Generator LM.
- The framework represents task logs using key-value (KV) caches, encoding the full reasoning context of prior tasks while storing KV caches for a subset of tokens.
- This approach directly reuses prior reasoning and computations without additional steps for knowledge extraction, enhancing performance and efficiency.


---

[JARVIS: A Multi-Agent Code Assistant for High-Quality EDA Script Generation](http://arxiv.org/abs/2505.14978v1)

- JARVIS (Just A Remarkable VLSI Intelligence System): introduces a multi-agent framework for high-quality EDA script generation, leveraging LLMs and domain expertise with components including a Top Agent, Code Fixing Agent, Guardrail Agent, Code Generator, RuleEnforce, Code Compiler, RAG, Simulate ProcessSim, User Query, Instructions, and Final code.
- The framework employs an iterative refinement process using a feedback loop between agents and custom tools like the Code Compiler and RuleEnforce to detect and fix errors.
- JARVIS integrates domain-specific knowledge through RAG and custom compiler checks, addressing challenges like data scarcity and hallucination in specialized EDA tasks.


---

[MedBrowseComp: Benchmarking Medical Deep Research and Computer Use](http://arxiv.org/abs/2505.14963v1)

- MedBrowseComp: introduces a benchmark for evaluating agent performance on complex medical information retrieval, including Primary Data Sources (External knowledge bases), Task Types (Question categories), and Verification & Scoring (Evaluation method).
- The benchmark utilizes diverse medical knowledge bases and defines distinct task categories to assess agent capabilities in navigating and synthesizing information.
- Evaluation involves verifying agent answers against ground truth using standardized metrics, highlighting performance gaps in multi-hop reasoning and computer use.


---

[Think, Reflect, Create: Metacognitive Learning for Zero-Shot Robotic Planning with LLMs](http://arxiv.org/abs/2505.14899v1)

- Metacognitive Learning Module: introduces a framework integrating metacognitive learning into LLM-powered multi-robot collaboration with Modular Skill Set Construction, Metacognitive Inference, and Self-Reflection components.
- The framework enables LLM-powered robotic agents to decompose skills, reason about tasks, synthesize plans, reflect on failures, and generate new solutions.
- This approach aims to enhance zero-shot robotic task performance by empowering LLMs with capabilities for reasoning, reflection, and creative problem-solving.


---

[MAATS: A Multi-Agent Automated Translation System Based on MQM Evaluation](http://arxiv.org/abs/2505.14848v1)

- MAATS (Multi-Agent Automated Translation System): introduces a modular framework using specialized LLM-based agents, including a Translator Agent (Generates initial translation), MQM Evaluator Agents (Evaluate translation errors) for specific dimensions, and an Editor Agent (Synthesizes annotations, refines translation), to enhance machine translation quality.
- The system leverages the Multi-dimensional Quality Metrics (MQM) framework to provide fine-grained error detection and refinement signals across multiple dimensions.
- This multi-agent architecture simulates human translation workflows, outperforming single-agent and zero-shot baselines in error detection and translation quality.


---


[Strategic Planning and Rationalizing on Trees Make LLMs Better Debaters](http://arxiv.org/abs/2505.14886)

- TreeDebater: introduces a novel debate framework for LLMs, utilizing a Rehearsal Tree (anticipates attacks/defenses), Debate Flow Tree (tracks debate status), Human Debate Trees (references for feedback), Simulated Audience (provides revision feedback), Speech Time Controller (controls speaking time), and Writer (drafts debate statement) to improve strategic planning in competitive debate.
- The framework models dynamic debate interaction on trees, enabling LLMs to make tactical decisions under time constraints.
- TreeDebater retrieves prepared arguments, selects impactful actions, and refines statements based on simulated audience feedback and time limits.


---

[Reinforcing Question Answering Agents with Minimalist Policy Gradient Optimization](http://arxiv.org/abs/2505.17086v1)

- Mujica (Multi-hop Joint Intelligence for Complex Question Answering): introduces an agentic QA framework with a planner (decomposes questions, plans subquestions) and a worker (answers subquestions, uses retriever).
- The planner module is responsible for breaking down complex questions into a directed acyclic graph and managing the overall process.
- The worker module acts as a mini-RAG system, retrieving information and answering subquestions assigned by the planner.


---




[Empowering LLMs in Task-Oriented Dialogues: A Domain-Independent Multi-Agent Framework and Fine-Tuning Strategy](http://arxiv.org/abs/2505.14299v1)

- DIMF (Domain-Independent Multi-Agent Framework): introduces a task-oriented dialogue system with Intent Classification Agent (extracts user intent), Slot Filling Agent (extracts dialogue slots), and Response Agent (generates system response), trained using SFT (initial model fine-tuning), DPO (preference-based training), and DDA (mitigates DPO degradation).
- The framework separates complex tasks into domain-independent components to improve performance on lightweight large language models.
- The proposed Data Distribution Adaptation method enhances DPO training stability and the framework demonstrates strong generalizability and zero-shot capabilities.


---

[Safety Devolution in AI Agents](http://arxiv.org/abs/2505.14215v1)

- Core Evaluation Framework: introduces, "a framework to measure the impact of retrieval and alignment mechanisms on model bias and harmfulness", with Censored LLM, Uncensored LLM, Agents with Censored LLM, Generate Query, Search, ReRank, Crawl, Answer, WikiAgent, WebAgent, System-Level Safety Prompts, and Evaluator components, where "the framework systematically compares LLMs with and without retrieval augmentation and safety mitigations across various benchmarks".
- The framework reveals that integrating external retrieval into safety-aligned LLMs leads to a phenomenon termed safety devolution, characterized by reduced refusal rates, increased bias, and degraded safety scores.
- Controlled experiments within the framework indicate that this safety degradation is primarily caused by the mere presence of retrieved context, rather than retrieval depth or accuracy, highlighting a structural vulnerability in RAG systems.


---

[DSMENTOR: ENHANCING DATA SCIENCE AGENTS WITH CURRICULUM LEARNING AND ONLINE KNOWLEDGE ACCUMULATION](http://arxiv.org/abs/2505.14163v1)

- DSMentor: introduces a framework with a Mentor agent (curriculum designer) that processes a Dataset (input tasks) to create a Curriculum-based dataset (ordered tasks), which is then used by a Student agent (code generator) interacting with a Long-term memory (accumulated knowledge) and an Environment (evaluates code) for problem-solving.
- The framework operates in two stages: curriculum generation and problem-solving, leveraging curriculum learning and online knowledge accumulation.
- The Mentor agent determines task difficulty to sequence problems from easy to hard, guiding the Student agent's learning progression.


---

[MM-Agent: LLM as Agents for Real-world Mathematical Modeling Problem](http://arxiv.org/abs/2505.14148v1)

- MM-Agent: introduces an expert-inspired framework that decomposes mathematical modeling into four sequential phases: Problem Analysis, Mathematical Modeling, Computational Solving, and Solution Reporting.
- The framework utilizes specialized agents like the Analyst Agent, Task Coordinator Agent, Modeling Actor, Modeling Critic, Modeling Programmer Agent, and Reporting Agent to handle distinct tasks within each phase.
- Key components such as the Hierarchical Mathematical Modeling Library (HMML) and MLE-Solver support knowledge retrieval, model formulation, and computational execution for real-world problems.


---

[s3: You Don't Need That Much Data to Train a Search Agent via RL](http://arxiv.org/abs/2505.14146v1)

- s3: introduces a modular, RL-based search framework with a Searcher LLM (RL-trained agent), Search Engine (retrieval source), frozen Generator LLM (frozen answer generator), and Gain Beyond RAG (reward signal), which trains a search-only agent using a novel reward signal to optimize retrieval for generation quality.
- The framework decouples the searcher from the generator, allowing the searcher to be trained with reinforcement learning based on the improvement in generator accuracy using retrieved documents compared to naive retrieval.
- By focusing training solely on the searcher using a generation-aware reward, s3 achieves strong performance with significantly less training data and is compatible with black-box generator LLMs.


---

[Building a Stable Planner: An Extended Finite State Machine Based Planning Module for Mobile GUI Agent](http://arxiv.org/abs/2505.14141v1)

- SPlanner: introduces a framework for mobile GUI agents that includes Application Modeling via EFSM (models applications), Structured Knowledge Base (collection of EFSMs), Plan Generation (creates execution plan), Instruction Parsing (parses user instruction), EFSM Solving (finds execution path), Path Polishing (refines execution path), Task Execution with VLM (executes the plan), Vision-Language Model (VLM) (executes GUI actions), LLM (parses/polishes text), BFS-based Solver (finds path in EFSM), User Instruction (input command), GUI Screenshot (current screen state), Action History (previous actions), Task Plan (step-by-step guide), and Operation Instruction (GUI action).
- The framework models mobile applications using Extended Finite State Machines (EFSMs) to create a structured knowledge base for planning.
- SPlanner generates interpretable and reliable execution plans by parsing user instructions, solving EFSMs, and polishing the resulting paths using LLMs, which are then executed by a VLM.


---

[BAR: A Backward Reasoning based Agent for Complex Minecraft Tasks](http://arxiv.org/abs/2505.14079v1)

- BAR (Backward Reasoning based Agent): introduces an agent for complex Minecraft tasks with recursive goal decomposition (Recursive goal decomposition), state consistency maintaining (State conflict resolution), and stage memory (Memory from environment interaction) modules.
- The agent utilizes backward reasoning to plan from the terminal state, aiming to overcome the perception gap faced by forward reasoning in complex tasks.
- State consistency is ensured by integrating forward and backward reasoning, and planning efficiency is enhanced by leveraging successful past interactions stored in stage memory.


---

[Process vs. Outcome Reward: Which is Better for Agentic RAG Reinforcement Learning](http://arxiv.org/abs/2505.14069v1)

- ReasonRAG: introduces, "Process vs. Outcome Reward: Which is Better for Agentic RAG Reinforcement Learning", with all LLM (Core reasoning model), Retriever (External knowledge access), Reasoning Stage (Decide query or answer), Grounding Stage (Extract evidence), Terminal Stage (Final answer state), Query Generation (Formulate search query), Evidence Extraction (Identify relevant text), Answer Generation (Produce final response), Memory (Stores previous steps)-components, where ReasonRAG is a process-supervised agentic RAG method using fine-grained rewards for policy optimization.
- The framework employs Monte Carlo Tree Search and Shortest Path Reward Estimation to generate a high-quality process-level dataset, RAG-ProGuide, for training.
- ReasonRAG enables LLMs to autonomously manage dynamic retrieval, iterative context refinement, and adaptive workflows for complex search queries.


---

[Divide by Question, Conquer by Agent: SPLIT-RAG with Question-Driven Graph Partitioning](http://arxiv.org/abs/2505.13994v1)

- SPLIT-RAG (Semantic Partitioning of Linked Information for Type-Specialized Multi-Agent RAG): introduces a multi-agent RAG framework with Knowledge Base Preprocessing (Prepare data), QA Input Processing (Analyze query), Retrieval Plan Decision (Determine subgraphs/agents), Multi-Agent RAG (Distributed retrieval), Answer Generation (Combine, resolve, finalize), Lightweight LLM Agents (Query subgraphs), and Head Agent (Final answer generation), which partitions knowledge graphs based on question types and uses multiple agents for efficient, conflict-resistant retrieval and answer generation.
- The framework employs question-driven graph partitioning to create semantically coherent subgraphs, enabling lightweight agents to query only relevant partitions in parallel.
- A hierarchical merging module resolves inconsistencies across subgraph-derived answers through logical verifications, with a head agent synthesizing the final response.


---

[MLZero: A Multi-Agent System for End-to-end Machine Learning Automation](http://arxiv.org/abs/2505.13941v1)

- MLZero: introduces a multi-agent system for end-to-end machine learning automation, featuring Perception, Semantic Memory, Episodic Memory, and Iterative Coding modules, coordinated by specialized agents including File Grouping and File Perception, Task Perception, ML Library Selection, Condensation, Summarization, Retrieval, Error Analyzer, Coder, and Executer agents.
- The system processes raw multimodal data through perception, leverages dual memory modules for knowledge and history, and employs iterative coding with agents for code generation, execution, and debugging.
- MLZero achieves end-to-end ML automation with minimal human intervention by transforming raw data into ready-to-use models and predictions through this integrated multi-agent architecture.


---

[DRUGPILOT: LLM-BASED PARAMETERIZED REASONING AGENT FOR DRUG DISCOVERY](http://arxiv.org/abs/2505.13940v1)

- DrugPilot (LLM-based parameterized reasoning agent): introduces an agent system for automating multi-stage drug discovery workflows, comprising LLM Backbones (Core language model), Parameterized Memory Pool (PMP) (Structured key-value data storage), AI Model Zoo (Drug discovery tools/models), and Fe-Fo Mechanism (Error feedback and focus).
- The Parameterized Memory Pool (PMP) is a core component designed to handle large-scale, multi-modal drug data by converting it into standardized parametric representations for efficient retrieval and interaction.
- The Fe-Fo Mechanism enhances the agent's robustness by providing specific error feedback and maintaining focus during complex multi-turn tasks and tool interactions.


---

[CLEVER: A Curated Benchmark for Formally Verified Code Generation](http://arxiv.org/abs/2505.13938v1)

- CLEVER (Curated Lean Verified Code Generation Benchmark): introduces a benchmark for formally verified code generation, requiring models to perform specification generation, isomorphism proving, Lean implementation generation, and correctness proving to achieve end-to-end verification.
- The benchmark evaluates models in two stages: specification certification (generating and proving equivalence of a Lean specification) and implementation certification (generating and proving correctness of a Lean implementation).
- Success in CLEVER requires both the generated specification and implementation to be formally certified via Lean proofs, ensuring semantic correctness beyond test cases.


---

[PANDAGUARD: Systematic Evaluation of LLM Safety in the Era of Jailbreaking Attacks](http://arxiv.org/abs/2505.13862v1)

- PANDAGUARD: introduces a unified and modular framework for systematic LLM safety evaluation, conceptualizing jailbreak safety as a multi-agent system with Attacker (generates adversarial prompts), Defender (implements protection mechanisms), Target LLM (model being evaluated), and Judger (evaluates response safety) components.
- The framework supports plug-and-play experimentation with diverse attack methods, defense mechanisms, and judgment strategies within a flexible pipeline architecture.
- Built upon this framework, PANDABENCH provides a large-scale benchmark for comprehensive and reproducible evaluation of LLM jailbreak vulnerabilities and defenses.


---

[Structured Agent Distillation for Large Language Model](http://arxiv.org/abs/2505.13820v1)

- SAD (Structured Agent Distillation): introduces a framework that compresses large LLM agents into smaller student models by segmenting teacher trajectories into Reasoning and Action Segments, applying span-specific supervision via Segment Masks and aggregating losses using CoT-Policy Alignment Loss and Action Consistency Loss, guided by Curriculum Sampling.
- The framework uses a Teacher to generate trajectories, which the Student learns to imitate by minimizing the Total Loss, preserving both reasoning fidelity and action consistency.
- This structure-aware distillation method outperforms token-level baselines, enabling compact agents to better replicate the teacher's decision process with minimal performance drop.


---

[RAG/LLM Augmented Switching Driven Polymorphic Metaheuristic Framework](http://arxiv.org/abs/2505.13808v1)

- PMF (Polymorphic Metaheuristic Framework): introduces a self-adaptive metaheuristic framework for optimization problems, with PMA (Orchestrates algorithms), PMSA (Selects algorithms), Metaheuristic Algorithms Pool (Available algorithms), Feedback Loop (Real-time adaptation), and Population Transfer (Transfers solutions).
- The framework utilizes a Polymorphic Metaheuristic Agent (PMA) and a Polymorphic Metaheuristic Selection Agent (PMSA) for dynamic algorithm selection and switching based on real-time performance feedback.
- PMF leverages real-time performance feedback and can integrate RAG/LLM for enhanced decision-making, demonstrating improved optimization efficiency and adaptability.


---

[LLINBO: Trustworthy LLM-in-the-Loop Bayesian Optimization](http://arxiv.org/abs/2505.14756v1)

- LLINBO (LLM-in-the-Loop Bayesian Optimization): introduces a hybrid framework for Bayesian Optimization combining LLM Agent (Suggests design points), Statistical Surrogate (GP) (Models function, quantifies uncertainty), and Dataset (Stores historical observations).
- The framework leverages LLMs for early exploration using contextual reasoning and GPs for efficient exploitation using principled statistical models.
- Three specific mechanisms (Transient, Justify, Constrained) are proposed to enable this collaboration and provide theoretical guarantees.


---


#### 19th May 2025

[SIMULATION AGENT: A FRAMEWORK FOR INTEGRATING SIMULATION AND LARGE LANGUAGE MODELS FOR ENHANCED DECISION-MAKING](http://arxiv.org/abs/2505.13761v1)

- Simulation Agent framework: introduces, with Simulation Model (Core engine), Inputs (Configuration files), Outputs (Time-series data), AI Agent (Bridge/interpreter), and User (End stakeholder), a system integrating simulations and LLMs for enhanced decision-making.
- The AI Agent utilizes LLMs and tool-calling capabilities to enable natural language interaction for running simulations, modifying inputs, and interpreting outputs.
- This framework aims to improve the usability and accessibility of complex simulation analysis for non-technical users by grounding LLM interactions in accurate simulation results.


---

[Guided Search Strategies in Non-Serializable Environments with Applications to Software Engineering Agents](http://arxiv.org/abs/2505.13652v1)

- Guided Search Strategies: introduces two guided search methods, 1-step lookahead and trajectory selection, guided by a learned action-value function estimator, applicable to non-serializable environments like SWE-agent scaffolding.
- The approach leverages a base policy (LLM) and a critic model to improve performance consistency in environments where intermediate states cannot be saved or restored.
- Empirical evaluation on SWE-bench Verified demonstrates that these strategies significantly improve the success rate of both open-weight and closed models.


---

[Incentivizing Truthful Language Models via Peer Elicitation Games](http://arxiv.org/abs/2505.13636v1)

- Peer Elicitation Games (PEG): introduces a training-free, game-theoretic framework for aligning LLMs, including a Generator (produces responses), Discriminators (evaluate responses), Peer Elicitation Game (structures agent interaction), Reward Mechanism (incentivizes truthful reporting), Policy Update (adjusts agent strategies), and Majority Vote (aggregates discriminator judgments).
- PEG employs multiple LLM discriminators that evaluate a generator's output and are rewarded based on mutual evaluation using a determinant-based score, promoting truthful reporting without ground-truth labels.
- The framework utilizes online learning with policy updates to converge agents towards a truthful Nash equilibrium, demonstrating improved factual accuracy and competitive performance with smaller models.


---


[Rethinking Stateful Tool Use in Multi-Turn Dialogues: Benchmarks and Challenges](http://arxiv.org/abs/2505.13328v1)

- DialogTool/VirtualMobile: introduces a benchmark and environment for evaluating stateful tool use in multi-turn dialogues, featuring a Dialogue Agent interacting with a VirtualMobile Environment containing Apps and APIs with a Database.
- The benchmark assesses large language models across the entire tool use lifecycle, including creation, utilization (awareness, selection, execution), and role-consistent response.
- Experiments reveal that current large language models struggle with tool creation and execution, particularly over long dialogue horizons and with complex APIs.


---

[TimeSeriesGym: A Scalable Benchmark for (Time Series) Machine Learning Engineering Agents](http://arxiv.org/abs/2505.13291v1)

- TimeSeriesGym: introduces, with (Origins), (Tasks), (Agent artifacts), (Supports agents), (Numeric metrics), (LLM assessment), (LLM qualitative), and (Combined evaluation) components, a scalable benchmark for evaluating AI agents on time series ML engineering tasks.
- The framework provides diverse challenges and evaluates multimodal agent outputs using a dual quantitative and qualitative assessment approach.
- Its agent-agnostic design and scalable task generation mechanism support comprehensive and practical evaluation of AI agents.


---

[Hybrid Voting-Based Task Assignment in Modular Construction Scenarios](http://arxiv.org/abs/2505.13278v1)

- HVBTA (Hybrid Voting-Based Task Assignment): introduces a framework for multi-agent task assignment in construction, integrating Task Descriptions (Define task requirements), Agent Capability Profiles (Define agent abilities), Suitability Matrix Generation (Calculate agent-task compatibility), LLM Integration for Semantic Reasoning (Use LLM for suitability), Voting and Allocation Mechanism (Assign tasks using voting), and CBS for Path Planning (Generate collision-free paths).
- The framework defines tasks and agents, calculates suitability, uses voting and LLM for assignments, and plans collision-free paths.
- HVBTA aims to improve efficiency and coordination for heterogeneous robotic teams in modular construction.


---

[From Automation to Autonomy: A Survey on Large Language Models in Scientific Discovery](http://arxiv.org/abs/2505.13259v1)

- Three-level taxonomy: introduces, "From Automation to Autonomy: A Survey on Large Language Models in Scientific Discovery", with all LLM as Tool (Task Automation Tool), LLM as Analyst (Data Modeling & Analytical Agent), and LLM as Scientist (Open Exploratory & Discovery Agent)-components, where the survey systematically charts the progression of Large Language Models in scientific discovery through distinct levels of autonomy.
- This framework delineates the escalating autonomy and evolving responsibilities of LLMs within the scientific research lifecycle, from foundational assistants to autonomous researchers.
- The paper categorizes existing research works based on this taxonomy and the stages of the scientific method, highlighting the shift towards sophisticated, multi-stage agentic workflows.


---

[Effective and Transparent RAG: Adaptive-Reward Reinforcement Learning for Decision Traceability](http://arxiv.org/abs/2505.13258v1)

- ARENA (Adaptive-Rewarded Evidence Navigation Agent): introduces a transparent RAG generator framework trained via reinforcement learning, with Structured Generation, KL Stabilization, and Adaptive Reward Calculation components, enabling interpretable decision traces and effective reasoning.
- The framework uses a structured output format including selected evidence, reasoning traces, and final answers for end-to-end interpretability.
- Adaptive, task-specific rewards and a stabilized optimization strategy are tailored for multi-hop question answering tasks.


---

[Agentic Publications: An LLM-Driven Framework for Interactive Scientific Publishing, Supplementing Traditional Papers with AI-Powered Knowledge Systems](http://arxiv.org/abs/2505.13246v1)

- Agentic Publications (AP): introduces an LLM-driven framework, with Knowledge Representation Layer (Store scientific knowledge), Interactive Query Interface (User/AI interaction), Dynamic Updating Mechanism (Continuous knowledge ingestion), and Verification and Governance Process (Ensure quality/integrity), transforming traditional papers into interactive knowledge systems.
- The framework integrates structured and unstructured data using Retrieval-Augmented Generation (Connect LLM to knowledge) and Multi-Agent Verification (Collaborative accuracy checks) processes.
- Supported by a Knowledge Base (Integrated data store), Agents (Perform tasks/checks), Databases (Vector/graph/relational storage), and Integration APIs (External/internal connectivity), the system enables dynamic knowledge synthesis and interactive access for humans and AI.


---

[Adversarial Testing in LLMs: Insights into Decision-Making Vulnerabilities](http://arxiv.org/abs/2505.13195v1)

- Adversarial Evaluation Framework: introduces a method to stress-test LLM decision-making using LLM (Subject under test), Task (Interactive environment), Learner Model (RNN) (Predicts LLM behavior), and Adversary (RL agent) (Manipulates environment).
- The framework trains a Learner Model to predict LLM actions and an Adversary to exploit these patterns by manipulating task rewards and observations.
- This approach reveals LLM vulnerabilities to manipulation and rigidity in strategy adaptation in dynamic, adversarial settings.


---

[Fixing 7,400 Bugs for 1$: Cheap Crash-Site Program Repair](http://arxiv.org/abs/2505.13103v1)

- WILLIAMT: introduces a cheap crash-site program repair approach, comprising Regex-Based Context Retrieval (identifies crash site) and Template-Guided Patch Generation (generates fix using templates and LLM).
- The system leverages regex on sanitizer reports for context retrieval and template-guided LLM analysis to identify key variables for patch generation, producing a One-Shot Patch.
- This strategy minimizes LLM reliance, substantially reducing query costs and enabling effective repair with smaller, cheaper models.


---

[Q²Forge: Minting Competency Questions and SPARQL Queries for Question-Answering Over Knowledge Graphs](http://arxiv.org/abs/2505.13572v1)

- Q²Forge: introduces an end-to-end pipeline for generating question-query datasets for knowledge graphs, including KG Configuration Creation (Configure KG), Competency Question Generation (Generate NL questions), SPARQL Query Generator & Executor (Translate & run queries), and SPARQL Query Refinement (Iteratively improve queries).
- The framework guides users through configuring a knowledge graph, generating natural language competency questions, translating them into SPARQL queries, executing the queries, and refining the results.
- Q²Forge leverages language models and other services to automate and assist in creating high-quality question-query pairs for knowledge graph documentation, training, and benchmarking.


---

[The Hidden Dangers of Browsing AI Agents](http://arxiv.org/abs/2505.13076v1)

- Browser Use: introduces a security evaluation of autonomous browsing AI agents, focusing on systemic vulnerabilities across architectural layers, using Browser Use as a case study.
- The paper analyzes the attack surface of browsing agents, detailing threats related to Perception, Reasoning/Planning, External Tools (Actions), Browsing Engine, Sensitive Data Handling, and Domain Restriction components.
- Identified vulnerabilities in Browser Use, including domain restriction bypass and credentials exfiltration via prompt injection, highlight the need for multi-layered security approaches.


---

[CAIM: Development and Evaluation of a Cognitive AI Memory Framework for Long-Term Interaction with Intelligent Agents](http://arxiv.org/abs/2505.13044v1)

- CAIM (Cognitive AI Memory Framework): introduces a framework with a Memory Controller (Central decision unit), Memory Retrieval (Filters relevant LTM data), Post-Thinking (Maintains LTM storage), Memory (STM/LTM) (Stores conversation/historical data), LLM Agent (Performs tasks within modules), and Python task (Processes/stores data) for long-term interaction.
- The framework enhances LLMs' memory capabilities by integrating cognitive AI principles and memory-augmented methods.
- CAIM addresses challenges in long-term interactions by managing memory usage, filtering relevant information, and maintaining memory storage.


---

[Adversarial Reasoning for Repair Based on Inferred Program Intent](http://arxiv.org/abs/2505.13008v1)

- ADVERINTENT-AGENT: introduces a multi-agent framework for automated program repair, with Reason Agent (reasons program intent), Test Agent (generates tests), Repair Agent (generates patches), and Environment (compiles, executes, searches) components, that infers adversarial program intents to guide patch generation and testing.
- The approach uses adversarial reasoning to explore multiple potential program intents and generate corresponding tests to validate patches and reduce overfitting.
- The system provides developers with a package including inferred intent, generated tests, and patches to facilitate patch review and acceptance.


---

[From Assistants to Adversaries: Exploring the Security Risks of Mobile LLM Agents](http://arxiv.org/abs/2505.12981v2)

- Mobile LLM Agent Workflow: introduces, a security analysis of mobile LLM agents, with Instruction Interpretation & Decomposition (Understand user intent, decompose tasks), Screen Context Understanding (Analyze UI, identify elements), Decision Generation (Plan actions based on state), Action Execution (Perform device operations), Reflection & Task Completion (Assess progress, verify goal), where the paper analyzes security risks across the agent's operational pipeline.
- The analysis identifies 11 distinct attack surfaces spanning LLM, GUI, and System interaction layers.
- The AgentScan framework is presented to systematically evaluate agent vulnerabilities across these attack scenarios.


---

[Leveraging LLM Inconsistency to Boost Pass@k Performance](http://arxiv.org/abs/2505.12938v2)

- Variator agent: introduces a novel method leveraging LLM inconsistency by generating task variants and submitting a solution for each, including Task (original problem), LLM (Variant Generation) (generates task variants), Variant (modified task), LLM (Solution Generation) (generates candidate solution), and Solution (candidate output).
- This approach aims to boost Pass@k performance by utilizing the variability in LLM success rates across equivalent inputs.
- The method is compared against a baseline Repeater agent that generates multiple solutions for the original task.


---

[The Traitors: Deception and Trust in Multi-Agent Language Model Simulations](http://arxiv.org/abs/2505.12923v1)

- The Traitors: introduces a multi-agent simulation framework with Environment (game structure), Agents (LLM instances), Observation Function (state mapping), Policy Function (action mapping), Agent Memory (persistent structured), and Interaction Prompts (phase guidance), designed to study deception and trust dynamics among LLM agents under asymmetric information.
- The framework implements a scenario where a minority of traitors deceive a majority of faithful agents, who maintain persistent memory and update beliefs based on dialogue and voting patterns.
- This stateful architecture enables testing hypotheses about emergent deceptive behaviors and provides a testbed for investigating LLM behavior in socially nuanced interactions relevant to AI safety.


---

[Reasoning BO: Enhancing Bayesian Optimization with the Long-Context Reasoning Power of LLMs](http://arxiv.org/abs/2505.12833v1)

- Reasoning BO: introduces, with Experiment Compass (User input), Reasoning Data (LLM output), LLM (Reasoning model), Notes Agent (Integrates knowledge), Formatter (Structures knowledge), Verifier (Validates knowledge), Insights History (Accumulated insights), Insight (LLM-generated guidance), Acquisition Function (Guides sampling), Results History (Experimental data), Surrogate Model (Objective function model), Knowledge Graph (Structured domain rules), Milvus Database (Vector database), Expert Knowledge (Prior domain knowledge), Prior Knowledge (Initialization knowledge), RLHF (Post-training strategy), Base Model (Underlying LLM), Stage 1: SFT (Supervised fine-tuning), and Stage 2: GRPO (RL fine-tuning), a framework enhancing Bayesian Optimization using LLM reasoning, knowledge graphs, and multi-agent systems.
- The framework integrates LLM reasoning to guide the BO sampling process and incorporates dynamic knowledge management via a dual-channel system.
- It utilizes a multi-agent system for knowledge precipitation and employs RLHF for fine-tuning smaller LLMs, creating a closed loop for scientific discovery.


---

[Forewarned is Forearmed: A Survey on Large Language Model-based Agents in Autonomous Cyberattacks](http://arxiv.org/abs/2505.12786v1)

- LLM-based cyberattack agent: introduces a modular architecture for autonomous cyberattack agents, comprising Models, Perception, Memory, Reasoning & Planning, and Action and Tools components.
- This architecture enables agents to ingest diverse inputs, manage contextual knowledge, plan multi-stage attacks, and interact with external tools.
- The survey analyzes the capabilities of these agents across various network types and discusses implications for defense.


---

[Prompt Stability Matters: Evaluating and Optimizing Auto-Generated Prompt in General-Purpose Systems](http://arxiv.org/abs/2505.13546v1)

- Promptor: introduces a stability-aware general-purpose prompt generation framework with Planner, Subtask Optimizer, Domain Knowledge Generator, Prompt Generator, Prompt Reviewer, Stability Reviewer, Executor, Summarizer Agent, and Plan Updater components.
- The framework leverages semantic stability, a metric quantifying output consistency across repeated executions, to guide prompt optimization.
- Promptor iteratively refines prompts and updates the plan based on stability feedback and execution results to improve reliability and task success.


---

[AutoMat: Enabling Automated Crystal Structure Reconstruction from Microscopy via Agentic Tool Use](http://arxiv.org/abs/2505.12650v1)

- AutoMat: introduces an end-to-end agent-assisted pipeline for crystal structure reconstruction and property prediction from STEM images, including an LLM Agent (Orchestrates pipeline), Image Denoising (Denoises STEM images), Candidate Structure Selection (Matches image to templates), Atomic Structure Reconstruction (Reconstructs crystal structure), and Property Prediction (Predicts material properties).
- The system leverages specialized tools like MOE-DIVAESR, Image Template Matching, STEM2CIF, and MatterSim coordinated by the LLM agent.
- AutoMat achieves state-of-the-art performance on a new benchmark, STEM2Mat-Bench, bridging microscopy and atomistic simulation.


---


[Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents](http://arxiv.org/abs/2505.12632v1)

- MONDAY dataset collection framework: introduces an automated framework to extract mobile OS navigation procedures from instructional videos, with Video Collection (Instructional videos input), Scene Transition Detection (Identify screen changes), and Action Identification (Identify user actions) components.
- The Scene Transition Detection component includes steps to Isolate phone screens (Detect phone screen area) and Detect transitions (Track text changes).
- The Action Identification component utilizes UI Element Detection (Detect interactive elements) and a three-step process: Scene summary (Summarize frame content), Initial action identification (Identify potential actions), and Refined action identification (Precise action localization).


---

[Chain-Talker: Chain Understanding and Rendering for Empathetic Conversational Speech Synthesis](http://arxiv.org/abs/2505.12597v1)

- Chain-Talker: introduces a three-stage framework for empathetic conversational speech synthesis, with EmGPT (Autoregressive Language Modeling, Emotion Understanding, Semantic Understanding) handling understanding and Synthesizer (Empathetic Rendering, speech generation) handling rendering.
- The framework processes dialogue history and target utterance through sequential understanding stages before rendering expressive speech.
- A supporting LLM-driven pipeline, CSS-EmCap, is developed to generate empathetic captions used for training the model.


--


#### 18th May 2025

[A Survey of Attacks on Large Language Models](http://arxiv.org/abs/2505.12567v1)

- LLM-based Agents: introduces, with Profiling Module, Memory Module, Planning Module, and Action Module components, autonomous systems leveraging LLMs to plan and act in complex environments.
- The Profiling Module defines the agent's role, the Memory Module stores information, the Planning Module breaks down tasks, and the Action Module executes decisions.
- This architecture exposes vulnerabilities targeted by agent-based attacks discussed in the paper.


---

[Right Question is Already Half the Answer: Fully Unsupervised LLM Reasoning Incentivization](https://arxiv.org/abs/2504.05812)

- EMPO (Entropy Minimized Policy Optimization): introduces a fully unsupervised LLM reasoning incentivization framework with a Policy Model, LLM Outputs, Semantic Clusters, Rewards, Normalize, and Advantages.
- The framework samples LLM outputs, clusters them semantically, and calculates rewards based on cluster likelihood to minimize semantic entropy.
- EMPO leverages semantic entropy as an intrinsic reward signal and uses entropy thresholding to stabilize training without external supervision.


---


[ESC-Judge: A Framework for Comparing Emotional Support Conversational Agents](http://arxiv.org/abs/2505.12531v1)

- ESC-Judge: introduces a framework for comparing emotional support conversational agents, with Role Construction (Synthesizes help-seeker roles), Help Seeker Agent (Simulates patient role), ES Agents (Candidate support models), Dialogue Engine (Manages conversation flow), End-of-Conversation Detector (Identifies dialogue conclusion), Judge LLM (Compares agent performance), and Evaluation Rubric (Hill's E-I-A based), which automates evaluation using a three-stage LLM-driven pipeline grounded in the E-I-A counselling model.
- The framework synthesizes realistic help-seeker roles, simulates conversations between candidate agents and the help-seeker, and uses a specialized LLM judge to issue pairwise preferences based on a theory-grounded rubric.
- ESC-Judge achieves human-level reliability in judging agent performance across Exploration, Insight, and Action stages, providing a scalable and reproducible benchmark for emotional support AI.


---

[ALAS: A Stateful Multi-LLM Agent Framework for Disruption-Aware Planning](http://arxiv.org/abs/2505.12501v1)

- ALAS (Adaptive LLM Agent System): introduces a multi-agent architecture for planning and execution, comprising a Template Layer (Defines workflow blueprint), Factory Layer (Instantiates executable agents), Runtime Layer (Executes agents, adapts), and Persistent Memory (Stores state, logs, supports recovery).
- The framework decomposes planning into specialized agents defined by the Template Layer, instantiated by the Factory Layer, and executed by the Runtime Layer, with Persistent Memory maintaining state and enabling recovery.
- ALAS addresses LLM limitations in planning by providing modularity, state tracking, and reactive adaptation for dynamic environments through its layered architecture and persistent memory.


---

[Beyond Frameworks: Unpacking Collaboration Strategies in Multi-Agent Systems](http://arxiv.org/abs/2505.12467v1)

- Multi-Agent Collaboration Strategies: investigates four dimensions of collaboration—Decentralized/Centralized Governance, Full/Selective/Instructor-decided Participation, Simultaneous/Ordered/Random/Point-to-Point Interaction Patterns, and Full Log/Self-Summarized/Instructor Summary Context Management—among Agents and an Instructor Agent utilizing Dialogue History Memory.
- The study evaluates the impact of various combinations of these strategies on task accuracy and computational efficiency in two context-dependent scenarios.
- Findings indicate that centralized governance, instructor-led participation, ordered interaction, and instructor-curated context summarization balance decision quality and resource utilization.


---

[IP Leakage Attacks Targeting LLM-Based Multi-Agent Systems](http://arxiv.org/abs/2505.12442v2)

- MASLEAK: introduces a novel attack framework, with Offline Adversarial Query Generation, Adversarial Query, Leak Query, Hooking, Propagate Query, and Target MAS IP Reconstruction components, designed to extract intellectual property from black-box Multi-Agent Systems by crafting queries that hijack, elicit, propagate, and retain responses from individual agents.
- The framework operates in two phases, first generating adversarial queries offline and then reconstructing the target MAS IP from the final system output.
- MASLEAK demonstrates high accuracy in extracting system prompts, task instructions, tool usages, agent number, and topology from both synthetic and real-world MAS applications.


---



#### 14th May 2025

[AlphaEvolve: A coding agent for scientific and algorithmic discovery](https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/AlphaEvolve.pdf)

- AlphaEvolve: introduces an evolutionary coding agent that orchestrates an autonomous pipeline including a User defining the task, Task Specification, an Initial Program, an Evaluation Function, a Prompt Sampler, an LLMs Ensemble generating Code Modifications, an Evaluators Pool executing and scoring programs, a Program Database storing results and guiding evolution, and a Distributed Controller Loop orchestrating the process to find the Best Program.
- The system iteratively improves algorithms by making direct code changes using an evolutionary approach, continuously receiving feedback from evaluators.
- AlphaEvolve leverages state-of-the-art LLMs and automated evaluation to discover novel algorithms and optimize computational infrastructure.


---

[Mind the Metrics: Patterns for Telemetry-Aware In-IDE AI Application Development using Model Context Protocol (MCP)](https://arxiv.org/abs/2506.11019)

- MCP (Model Context Protocol): introduces telemetry-aware IDEs, with AI Application (streams traces), AI-Assisted IDE (contains client, LLM), MCP Client (requests metrics/traces), MCP Server (stores, queries telemetry), Metrics & Telemetry Store (backend data storage), Tool-calling LLM (refines prompts/code), Autonomous Monitoring Agents (monitor, suggest improvements), and CI Job (tests, telemetry checks), enabling iterative optimization and robust monitoring of AI applications by integrating real-time telemetry into the development loop.
- The framework unifies prompt engineering with live metrics, traces, and evaluations via an MCP client/server architecture.
- This approach provides a general architecture for consolidating prompt and agent telemetry to support various optimization techniques and workflows across development, CI, and production.


---


#### 13th May 2025

[HealthBench: Evaluating Large Language Models Towards Improved Human Health](https://arxiv.org/abs/2505.08775)

- HealthBench: introduces, "evaluating large language models towards improved human health", with all Conversation (Multi-turn interaction), Model (Large language model), Rubric Criteria (Physician-written evaluation rules), Model-based Grader (LLM evaluating responses), and Score (Evaluation outcome)-components, where "HealthBench is an open-source benchmark measuring the performance and safety of large language models in healthcare using physician-written rubric criteria".
- The benchmark consists of 5,000 realistic multi-turn health conversations evaluated by a model-based grader against conversation-specific rubrics created by 262 physicians.
- HealthBench provides a meaningful, trustworthy, and unsaturated evaluation standard for AI systems in health, enabling detailed analysis of model performance across different themes and behavioral axes.
- Reviews Context-seeking of the conversations by analysing, if enough context to make correct decision is available or not or in case the model should seek more context to make proper decision.


---


[Enhancing Software Development with Context-Aware Conversational Agents: A User Study on Developer Interactions with Chatbots](http://arxiv.org/abs/2505.08648v1)

- Rasa-based Chatbot Prototype: introduces a study using a prototype built on the Rasa chatbot platform, including NLU, Dialogue Management, Facebook Messenger, and RASA webhook components, to investigate software developers' preferences and requirements for conversational agents.
- The study employed a mixed-methods approach with 29 developers interacting with the prototype via Facebook Messenger based on a predefined scenario.
- Findings from the interactions, questionnaires, and interviews aim to inform the design of context-aware chatbots for software development tasks like task and repository management.


---

[TRAIL: Trace Reasoning and Agentic Issue Localization](http://arxiv.org/abs/2505.08638v1)

- TRAIL: introduces a formal taxonomy (Classifies agent errors) and a dataset of human-annotated traces from agentic workflows, including Manager Agent (Orchestrates tasks), Search Agent (Performs web search), and various Tools (External functions/APIs).
- The paper evaluates the ability of large language models to act as judges for debugging complex agentic workflow traces using the proposed taxonomy and dataset.
- Evaluation results show that current state-of-the-art models perform poorly at identifying and localizing errors within these traces, highlighting the challenge of evaluating complex agentic systems.


---

[The Truth Becomes Clearer Through Debate! Multi-Agent Systems with Large Language Models Unmask Fake News](http://arxiv.org/abs/2505.08532v1)

- TED (TruEDebate): introduces a multi-agent system for fake news detection, simulating a structured debate process with DebateFlow Agents and analyzing the outcome with InsightFlow Agents.
- The DebateFlow Agents organize LLM-powered agents into Proponents and Opponents teams that engage in Opening Statement, Cross-examination and Rebuttal, and Closing Statement stages.
- The InsightFlow Agents, consisting of a Synthesis Agent for summarization and an Analysis Agent utilizing a Role-aware Encoder, Debate Graph, and News-Debate Interactive Attention, predict the news truth value.


---

[Strategy-Augmented Planning for Large Language Models via Opponent Exploitation](http://arxiv.org/abs/2505.08459v1)

- SAP (Strategy-Augmented Planning framework): introduces a two-stage framework with LLM (Identifies opponent strategy), LLM (Generates action plan), Strategy Space Ξ (Explicit strategy dimensions), Strategy Set Dξ (Generated strategy library), SEN U (Strategy Evaluation Network), Trajectory Extractor E (Summarizes environment trajectory), abstract trajectory Tabs (Summarized observation data), Strategy Search (Finds optimal counter strategy), best response strategy ξ¹,* (Optimal counter strategy), Expert Tips H (Guides LLM planning), and Environment (Simulation environment), designed to enhance LLM-based agents' opponent exploitation in competitive environments.
- The offline stage of SAP involves LLM generating strategies within the Strategy Space, evaluating them in the Environment to create a Strategy Set and Battle Result Dataset, which trains the SEN.
- In the online stage, SAP uses the Trajectory Extractor to summarize observations, the LLM as Recognizer to identify the opponent's strategy, the SEN and Strategy Search to find the best response, and the LLM as Planner, guided by Expert Tips, to generate the final action Plan.


---

[Scalable UAV Multi-Hop Networking via Multi-Agent Reinforcement Learning with Large Language Models](http://arxiv.org/abs/2505.08448v1)

- MRLMN (Multi-agent Reinforcement learning with Large language model in Multi-hop Networking): introduces a framework integrating MARL and LLMs for scalable UAV multi-hop networking.
- The framework includes MARL agents with policy/critic networks, enhanced by information aggregation, agent grouping, reward decomposition, and behavioral constraints.
- It leverages an LLM agent, knowledge distillation, bipartite matching, an LLM verifier, and prompt engineering to guide MARL training and improve exploration.


---

[Benchmarking AI scientists in omics data-driven biological research](http://arxiv.org/abs/2505.08341v1)

- BaisBench (Biological AI Scientist Benchmark): introduces a benchmark for evaluating AI scientists in biological research with two tasks, BAIS-CTA (Cell type annotation task) and BAIS-SD (Scientific discovery task).
- BAIS-CTA assesses cell type identification on single-cell datasets, while BAIS-SD evaluates reasoning and insight generation through multiple-choice questions based on data analysis.
- The benchmark uses real biological omics data and compares AI performance to human experts, highlighting current limitations in data-driven scientific discovery.


---

[Aitomia: Your Intelligent Assistant for AI-Driven Atomistic and Quantum Chemical Simulations](http://arxiv.org/abs/2505.08195v1)

- Aitomia: introduces an intelligent assistant platform for AI-driven atomistic and quantum chemical simulations, with Chatbot (user interface), AI Agents (task execution), LLMs (fine-tuned models), Rule-based Agents (fail-safe logic), Retrieval-Augmented Generation (RAG) system (knowledge retrieval), MLatom ecosystem (computational backend), Cloud Computing Services (simulation execution), and Database (information storage).
- The platform leverages fine-tuned large language models, rule-based agents, and a retrieval-augmented generation system to assist users in setting up, running, and analyzing simulations.
- Aitomia integrates with the MLatom ecosystem and cloud computing services like Aitomistic Hub and XACS to provide a wide range of computational chemistry capabilities.


---

[DSADF: Thinking Fast and Slow for Decision Making](http://arxiv.org/abs/2505.08189v1)

- DSADF (Dual-System Adaptive Decision Framework): introduces a framework integrating System 1 (Fast thinking component) with RL Agent (Goal-conditional action selection) and Memory Space (Stores task proficiency), and System 2 (Slow thinking component) with VLM (Vision Language Model) acting as Planner (Decomposes tasks, reflects) and Auxiliary Performer (Handles unfamiliar tasks), utilizing CLIP (Image to text), Image Encoder (Encodes image observation), Text Encoder (Encodes text observation/goal), and Self-reflection (Evaluates and refines plans) for generalized decision making.
- The framework draws inspiration from Kahneman's dual-process theory, leveraging the RL agent for fast, intuitive responses and the VLM for slow, analytical reasoning and planning.
- DSADF demonstrates improved efficiency and generalization in complex environments by dynamically allocating tasks between the fast and slow systems based on task familiarity and agent proficiency.


---


#### 12th May 2025

[Putting It All into Context: Simplifying Agents with LCLMs](https://arxiv.org/abs/2505.08120)

- State-in-Context Agent: introduces a simplified agent architecture using LCLMs (Processes large context) to process the entire Environment (Code repository state) as Context (Input to LM), eliminating complex scaffolding to produce a Solution (Output patch).
- The approach leverages LCLMs' long-context capabilities for full observability, transforming open-ended tasks into direct, close-ended problems.
- Variations include a Compressor (Ranks/selects files) for large environments and a SELECTSOLVE method combining LCLMs via a Selector (LCLM identifies files) with SCLMs (Superior problem-solving) for repair.


---


[Agent RL Scaling Law: Spontaneous Code Execution for Mathematical Problem Solving](http://arxiv.org/abs/2505.07773v1)

- ZeroTIR: introduces a framework for training a base LLM agent to spontaneously use a code execution environment for mathematical problem solving via reinforcement learning, including an RL trainer, value network, replay buffer, interaction logic, and reward signal.
- The framework utilizes outcome-based rewards and techniques like dynamic stop tokens and replay buffer filtering to enable the LLM agent to learn effective tool use strategies.
- ZeroTIR demonstrates an Agent RL Scaling Law where training progression correlates with increased code usage frequency, response length, and task accuracy, outperforming non-tool baselines.


---


[Codifying Character Logic in Role-Playing](http://arxiv.org/abs/2505.07705v1)

- Codified Profiles: introduces a framework that represents character logic as structured, executable functions, including Codified Profile (Executable logic), parse_by_scene function (Outputs triggered statements), check_condition function (Evaluates scene conditions), Role-playing LLM (Generates character response), Scene (Input context), Triggered Statements (Guide LLM response), Groundtruth Reference (Evaluation target), NLI Scoring (Compares response to reference), Profile Update (Revises codified logic), Randomness Components (Control behavioral variability), Textual Profile (Original character description), and Distilled Condition Checker (Efficient condition evaluation), enabling persistent, updatable, and controllable role-playing.
- The approach compiles natural language character descriptions into executable code, offloading complex reasoning from the LLM to deterministic control logic.
- Experiments demonstrate improved behavioral consistency, adaptability, and diversity compared to prompt-based methods, particularly benefiting smaller language models.


---

[ARE LLMS COMPLICATED ETHICAL DILEMMA ANALYZERS?](http://arxiv.org/abs/2505.08106v1)

- Evaluation Framework: introduces, a novel evaluation framework, with Data Retrieval (Collects ethical dilemmas), Preprocessing (Structures data), Text Processing (Generates/formats responses), LLMs (Generate dilemma responses), Human (Provide baseline responses), Structured Output (Formatted responses), Human Evaluation (Collects human feedback), Benchmark Metrics (Quantitative evaluation methods), Metrics Weighting (Assigns metric importance), and Aggregated Score (Final performance score), where the framework assesses LLM performance on ethical dilemmas using structured responses and quantitative metrics.
- The framework utilizes a dataset of ethical dilemmas with expert and non-expert responses, processed into a five-section structured format for component-wise evaluation.
- Performance is measured using a composite metric combining lexical, n-gram, embedding, and semantic similarity scores, weighted based on inversion analysis and AHP.


---

[HYPERNYM MERCURY: Token Optimization through Semantic Field Constriction and Reconstruction from Hypernyms. A New Text Compression Method](http://arxiv.org/abs/2505.08058v1)

- Hypernym Mercury: introduces a novel text compression method using Field Constriction, which involves Parsing and Structuring input text into a Dart intermediate representation, performing Detail Importance Evaluation, and applying Compression Optimization to the dart.
- The Dart structure splits information into a core statement and attached details, allowing for controllable granularity during Recomposition back into text.
- Multi-Model Verification ensures semantic fidelity of the compressed output by checking against independent models.


---

[FalseReject: A Resource for Improving Contextual Safety and Mitigating Over-Refusals in LLMs via Structured Reasoning](http://arxiv.org/abs/2505.08054v1)

- Graph-informed adversarial multi-agent interaction framework: introduces a system to generate diverse, challenging over-refusal queries using interacting agents and LLM validation, including Generator, Discriminator, LLM Refusal Validation, and Orchestrator components.
- The framework is guided by an Entity Graph extracted from safety-related datasets and uses Feedback between agents to refine generated prompts.
- This iterative process produces Collected Over-refusal Queries that appear unsafe but are objectively benign, simulating scenarios where LLMs might over-refuse.


---

[Web-Bench: A LLM Code Benchmark Based on Web Standards and Frameworks](http://arxiv.org/abs/2505.07473v1)

- Web-Bench (Evaluation System): introduces a benchmark and evaluation system for LLM code generation on web development tasks, including an Evaluator, Web-Agent, LLM, Web-Bench Dataset, Tasks, Projects, E2E Tests, and Generated Files.
- The system evaluates LLMs on sequential coding tasks within projects, simulating real-world web development workflows based on Web Standards and Frameworks.
- The Evaluator orchestrates the process, using the Web-Agent to interact with the LLM, and verifies the generated code against E2E tests.


---


[MLE-Dojo: Interactive Environments for Empowering LLM Agents in Machine Learning Engineering](http://arxiv.org/abs/2505.07782v1)

- MLE-Dojo: introduces, an interactive Gym-style framework for training, evaluating, and benchmarking autonomous LLM agents in machine learning engineering workflows, with MLE-Agent (LLM-based assistant), Environment (Task-specific interactive space), Error (Encodes error types), Interface (Governs action execution), Feedback (Translates outcomes to guide), Metric (Defines evaluation metrics), Task Space (Collection of tasks), Docker container (Isolates task execution), Sandbox (Executes agent code safely), Observation Space (Environment state information), Dataset Information (Task data details), Evaluation Metric Scores (Performance metrics), Code Execution Results (Outcome of code runs), Error Messages (Debugging information), Interaction History (Record of interactions), Action Space (Agent's possible operations), request_info (Action to query task info), validate_code (Action for syntax/runtime check), execute_code (Action for full execution/submission), get_history (Action to retrieve past interactions), reset (Action to restart environment), Reward Space (Signal for performance), HumanRank Score (Relative performance metric), Agent Scaffolds (Agent implementations), MLE Agent (Minimalistic agent design), and AIDE (Iterative problem-solving agent), enabling systematic experimentation and rigorous evaluation on 200+ real-world Kaggle challenges.
- The framework provides a fully executable environment supporting comprehensive agent training via supervised fine-tuning and reinforcement learning, facilitating iterative experimentation and real-time outcome verification through structured feedback loops.
- MLE-Dojo features a modular and extensible architecture that decouples agent capabilities from the environment, promoting interoperability, scalability, and reproducibility, and is open-sourced to foster community-driven innovation.


---


[KAQG: A Knowledge-Graph-Enhanced RAG for Difficulty-Controlled Question Generation](http://arxiv.org/abs/2505.07618v1)

- KAQG (Knowledge Augmented Question Generation): introduces a framework that fuses knowledge graphs, RAG retrieval, and educational assessment theory into a pipeline for difficulty-controlled question generation.
- The framework includes a KAQG-Retriever for building a Knowledge Graph from educational materials and a KAQG-Generator for creating and evaluating questions based on the graph and assessment theory.
- Implemented using an AI Agents Framework, the system operationalizes difficulty metrics and demonstrates strong performance in generating psychometrically sound exam items.


---

[Reinforced Internal-External Knowledge Synergistic Reasoning for Efficient Adaptive Search Agent](http://arxiv.org/abs/2505.07596v1)

- IKEA: introduces Reinforced Internal-External Knowledge Synergistic REasoning Agent, with LLM Agent, Environment (Search Engine/Retriever/Text Corpus), Reward Model, Knowledge-boundary aware reward function, Knowledge-boundary aware training dataset, Reinforcement Learning (GRPO), and Special Tags components, which trains an efficient adaptive search agent to synergistically integrate internal and external knowledge.
- The agent learns to identify its knowledge boundary, prioritizing internal knowledge and resorting to external search only when necessary, guided by a novel reward function and training data.
- This approach aims to reduce redundant retrievals, mitigate knowledge conflicts, and improve inference efficiency compared to methods relying solely on internal or external knowledge.


---

[YuLan-OneSim: Towards the Next Generation of Social Simulator with Large Language Models](http://arxiv.org/abs/2505.07581v1)

- YuLan-OneSim: introduces a novel social simulator, with Scenario Auto-Construction Subsystem (User input to code), Simulation Subsystem (Execute and manage simulation), Feedback-driven Evolving Subsystem (Improve LLMs via feedback), and AI Social Researcher Subsystem (Automate social science research), designed for code-free scenario construction, large-scale simulation, evolvability, and automating the social science research loop.
- The simulator is built upon four core subsystems that handle scenario creation, simulation execution, model refinement, and autonomous research tasks.
- YuLan-OneSim aims to advance LLM-based social simulation by enabling automatic scenario construction, autonomous evolution, and completing the full research cycle.


---

[Learning to Reason and Navigate: Parameter Efficient Action Planning with Large Language Models](http://arxiv.org/abs/2505.07500v1)

- PEAP-LLM (Parameter Efficient Action Planner using Large Language Models): introduces a novel parameter-efficient action planner for embodied agents, consisting of an LLM goal planner (LGP) that extracts task goals and a LoRA action planner (LAP) that generates single-step instructions using a fine-tuned LLM.
- The framework utilizes a Base LLM for goal planning and a Fine-tuned LLM for action planning, with fine-tuning performed via supervised fine-tuning (SFT) and direct preference optimization (DPO) using specific datasets.
- PEAP-LLM integrates with a Policy Model that predicts the next action based on high-level instructions, generated single-step instructions, and visual observations processed by Object Retrieval and State Text Generator components.


---

[Can Generative AI agents behave like humans? Evidence from laboratory market experiments](http://arxiv.org/abs/2505.07457v1)

- LLM Agent Simulation: introduces, "explore the potential of Large Language Models (LLMs) to replicate human behavior in economic market experiments", with LLM Agents (Simulate human participants), OpenAI API (Interface for LLMs), Model (GPT-3.5 or GPT-4), Temperature (Controls response randomness), Context Window (Total text model considers), Memory (Number of previous messages), Seed (Initializes random generator), Market Environment (Simulated economic market), Feedback Mechanism (Positive or negative price feedback), where "the framework simulates market dynamics by having LLM agents predict prices iteratively based on market information and their own history".
- The simulation compares LLM agent behavior to human participants in positive and negative feedback markets, analyzing market dynamics and forecasting strategies.
- Key parameters like memory and temperature significantly influence LLM agent behavior and their ability to replicate human-like market dynamics and bounded rationality.


---

[Private LoRA Fine-tuning of Open-Source LLMs with Homomorphic Encryption](http://arxiv.org/abs/2505.07329v1)

- Private LoRA Fine-tuning: introduces an interactive client-server protocol for private fine-tuning of open-source LLMs, with Client (orchestrates training, non-linear operations), Server (linear operations under HE), Homomorphic Encryption (HE) (enables encrypted computation), LoRA Weights (U, D) (client-side adaptation parameters), and Base Model Weights (W) (server-side public parameters) components.
- The client manages private data and LoRA weights while performing non-linear computations locally.
- The server handles computationally intensive linear operations on public base model weights using homomorphic encryption on client-provided encrypted activations.


---

[Towards Multi-Agent Reasoning Systems for Collaborative Expertise Delegation: An Exploratory Design Study](http://arxiv.org/abs/2505.07313v1)

- Multi-Agent Reasoning System: introduces a system with Agents (Individual LLMs), Expertise Specialization (Domain-specific roles), Collaboration Paradigm (Interaction mechanism), Communication Protocol (Information exchange), and System Scale (Number of agents) to investigate collaborative reasoning performance.
- The study empirically evaluates how expertise-domain alignment, collaboration paradigm (structured workflow vs. diversity-driven), and system scale affect collective reasoning.
- Findings indicate that expertise alignment is domain-contingent, diversity-driven collaboration outperforms structured workflows, and increasing agents generally boosts performance with diminishing returns.


---

[UAV-CodeAgents: Scalable UAV Mission Planning via Multi-Agent ReAct and Vision-Language Reasoning](http://arxiv.org/abs/2505.07236v1)

- UAV-CodeAgents: introduces a scalable multi-agent framework for autonomous UAV mission generation, utilizing Airspace Management Agent (AMA), UAV Agent, LLM, VLM, ReAct, Pixel-Pointing Grounding Mechanism, smolagents framework, Message-passing interface, and Tools to interpret instructions and generate UAV trajectories.
- The system leverages the ReAct paradigm for iterative reasoning and dynamic adaptation, enabling agents to reflect on observations and revise mission goals in evolving environments.
- A key component is the vision-grounded pixel-pointing mechanism, which facilitates precise localization of semantic targets on aerial maps for spatial grounding and context-aware flight routes.


---

[DynamicRAG: Leveraging Outputs of Large Language Model as Feedback for Dynamic Reranking in Retrieval-Augmented Generation](http://arxiv.org/abs/2505.07233v1)

- DynamicRAG: introduces a novel RAG framework, with Retriever (Retrieves documents), Dynamic Reranker (Dynamically adjusts documents), Generator (Generates final answer), Reward Function (Evaluates response quality), Reinforcement Learning (Optimizes reranker agent), Direct Preference Optimization (RL optimization method), and Behavioral Cloning (Initial reranker training), where the reranker dynamically adjusts document order and number using LLM feedback and RL.
- The reranker is modeled as an RL agent trained via behavioral cloning and DPO, leveraging LLM output quality as reward signals.
- This dynamic reranking approach enhances RAG system efficiency and effectiveness by optimizing the generator's input based on query context.


---

[Structural Entropy Guided Agent for Detecting and Repairing Knowledge Deficiencies in LLMS](http://arxiv.org/abs/2505.07184v1)

- SENATOR (Structural Entropy-guided Knowledge Navigator): introduces a framework for detecting and repairing LLM knowledge deficiencies, with MCTS (Knowledge graph exploration), LLM (Model under evaluation), KG (External knowledge source), Structural Entropy (Exploration reward signal), Synthetic Data (Generated training samples), and SFT (Model fine-tuning) components.
- The framework employs MCTS guided by structural entropy on a knowledge graph to efficiently explore and identify areas where the LLM exhibits high uncertainty or knowledge deficiencies.
- Based on the identified high-uncertainty paths, SENATOR generates targeted synthetic data used for supervised fine-tuning to repair the LLM's knowledge deficiencies.


---


#### 11th May 2025

[Exploring Anthropomorphism in Conversational Agents for Environmental Sustainability](http://arxiv.org/abs/2505.07142v1)

- Washy: introduces a system integrating a Conversational Agent (User interface) powered by an LLM (Language model) using a Function Calling API (LLM tool interface) to interact with External API (Solar data source), a Smart Plug (Appliance controller), a Scheduler (Slot/notification management), and a Database (Data storage), supported by a Backend (Server logic), Client (User applications), and Notification System (Alert delivery), to help users schedule Washing Machine (Physical appliance) cycles based on solar energy availability.
- The system compares a Personified Agent and a Traditional Assistant interface to evaluate the impact of anthropomorphism on user interaction and eco-friendly behavior adoption.
- A lab study assessed the system's effectiveness in promoting sustainable home energy management and the influence of agent personality on user engagement and rapport.


---

[Architectural Precedents for General Agents using Large Language Models](http://arxiv.org/abs/2505.07087v1)

- Cognitive Design Patterns: introduces recurring patterns of processes, representations, and memories found in cognitive architectures and Agentic LLM Systems, including Observe-decide-act, 3-stage memory commitment, Hierarchical decomposition, Short-term (context) memory, Ahistorical KR/memory, Historical KR/memory, Procedural KR/memory, Reconsideration, Knowledge compilation, and Step-wise reflection.
- The paper analyzes how these cognitive design patterns are evident in existing Agentic LLM systems and identifies patterns apt for future exploration.
- Examining these patterns helps predict gaps and deficiencies in current LLM systems and suggests future research directions towards general intelligence.


---

[Can LLM-based Financial Investing Strategies Outperform the Market in Long Run?](http://arxiv.org/abs/2505.07078v1)

- FINSABER (Financial Investing Strategy Assessment with Bias mitigation, Expanded time, and Range of symbols): introduces a comprehensive framework for benchmarking LLM timing-based investing strategies, with Multi-source Data Module (Integrates diverse financial data), Strategies Base Module (Covers selection and timing strategies), Bias-Mitigated Backtest Pipeline (Supports robust backtesting), Selection-based Strategy (Identifies asset subset), Timing-based Strategy (Dictates buy/sell/hold decisions), Traditional Rule-based (Uses technical indicators/rules), Predictor-based (Relies on data-driven models), RL-based (Learns optimal investing policies), LLM-based (Leverages large language models), Rolling Window Test (Evaluates across multiple periods), and Evaluation Metrics (Measures strategy performance).
- The framework integrates 20 years of multi-source data, expands symbol coverage, and explicitly mitigates survivorship, look-ahead, and data-snooping biases.
- FINSABER supports robust and reproducible benchmarking across diverse experimental setups to provide empirical guidance for LLM-based investment research.


---

[DialogueReason: Rule-Based RL Sparks Dialogue Reasoning in LLMS](http://arxiv.org/abs/2505.07049v1)

- DialogueReason: introduces a dialogue-based reasoning pattern, with System Prompt (input instruction), Adaptive Thinking Pattern Config (configuration), Thinking Process (iterative simulation), and Final Answer (output).
- The Adaptive Thinking Pattern Config includes Agent Config (agent roles), Environment Config (setting), and Interaction Config (communication rules).
- The Thinking Process involves iterative Agent-Agent Interaction (dialogue) and Agent-Environment Interaction (task progression).


---

[Seed1.5-VL Technical Report](http://arxiv.org/abs/2505.07062v1)

- Seed1.5-VL: introduces a vision-language foundation model composed of Seed-ViT (Vision encoder (encode images/videos)), MLP Adapter (Project visual features), and Large Language Model (LLM) (Process multimodal inputs (MoE)).
- The Seed-ViT vision encoder handles dynamic image resolutions, while the LLM is a 20B active parameter Mixture-of-Experts model.
- The model is designed for general-purpose multimodal understanding and reasoning across diverse tasks.


---

[The Wisdom of Agent Crowds: A Human-AI Interaction Innovation Ignition Framework](http://arxiv.org/abs/2505.06947v1)

- Brainwrite: introduces a human-AI interaction framework for multi-agent brainstorming, incorporating Human (User), LLM (Large Language Model), Cothinker (Interactive module), Internet (External information source), Knowledge Base (Internal information source), and Mindmap (Structured text summary) components.
- The framework utilizes LLMs and a Cothinker module to assist human users in topic definition, deep exploration, and output generation, drawing information from the Internet and a Knowledge Base.
- The system aims to reduce user cognitive load through structured text summaries like Mindmaps and enhance viewpoint diversity in complex financial analysis tasks.


--- 

[EcoLANG: Efficient and Effective Agent Communication Language Induction for Social Simulation](http://arxiv.org/abs/2505.06904v1)

- EcoLANG: introduces a two-stage paradigm, with Language Evolution (create efficient language) and Language Utilization (agents use evolved language), to induce efficient and effective agent communication language for large-scale social simulations.
- The Language Evolution stage comprises Vocab Compression (reduce vocabulary size) via Semantic Clustering (group words by meaning), Intra-Cluster Selection (filter words within groups), and Tokenization (map words to tokens), alongside Rule Evolution (evolve communication rules) through Initialization (start with initial rules), Communication (simulate agent dialogues), Selection (evaluate and select rules), Crossover & Mutation (generate new rules), and Update and Iteration (refine rule population).
- The Language Utilization stage applies the evolved language by modifying LLM decoding and incorporating rules into prompts, enabling agents to communicate more efficiently in social simulations.


---

[Towards Human-Centric Autonomous Driving: A Fast-Slow Architecture Integrating Large Language Model Guidance with Reinforcement Learning](http://arxiv.org/abs/2505.06875v1)

- Fast-Slow Architecture: introduces a human-centric decision-making framework integrating an LLM-Based Slow System and an RL-Based Fast System, designed to interpret high-level user instructions and execute real-time control.
- The LLM-Based Slow System processes user commands and scene context using components like Human-Language Parsing and CoT Analytic Reasoning, referencing a Memory Bank to generate structured Human-Centric Instruction.
- The RL-Based Fast System, utilizing Instruction and Scenario Encoders and a Multi-Head Attention-based Actor-Critic network, executes actions validated by a Safety Mask via a PID Controller, balancing user preference and safety.


---

[ThreatLens: LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification](http://arxiv.org/abs/2505.06821v1)

- ThreatLens: introduces, with Threat Identification Agent (identifies physical/supply threats), Security Policy Generator Agent (extracts security policies), Test Plan Generator Agent (generates test plans), LLM (performs reasoning/generation), RAG (retrieves relevant knowledge), System-User Conversation (interacts with engineer), Security Knowledge Dataset (stores threat models), and Design Spec. & ISA document (input design information), a multi-agent framework automating hardware security threat modeling and test plan generation.
- The framework leverages LLMs for reasoning and generation, RAG for efficient knowledge retrieval from datasets and documents, and interactive conversation with verification engineers.
- ThreatLens aims to reduce manual effort, enhance coverage, and provide a structured approach for hardware security verification by automating threat identification and test plan formulation.


---

[Control Plane as a Tool: A Scalable Design Pattern for Agentic AI Systems](http://arxiv.org/abs/2505.06817v1)

- Control Plane as a Tool: introduces a design pattern for Agentic AI systems that modularizes tool orchestration using a Request Router, Registration Module, Invocation Module, Input Validator, Intent Resolver, Intent Validator, Routing Handler, Feedback Integrator, Output Validator, Failure Handler, Usage tracker, Agent Registry, Tool Registry, validation rules, Metrics Registry, and Log/DB.
- This pattern decouples tool management from agent logic, enabling dynamic tool selection, governance, and extensibility across multiple agents.
- The architecture provides a single tool interface to agents while encapsulating complex routing and validation logic internally.


---

#### 10th May 2025

[VTutor: An Animated Pedagogical Agent SDK that Provide Real Time Multi-Model Feedback](http://arxiv.org/abs/2505.06676v1)

- VTutor: introduces an animated pedagogical agent SDK, with Large Language Model Integration (AI-generated text responses), Text-to-Speech (text to audio conversion), LipSync Module (audio to avatar mouth movements), and WebGL-Based Rendering (Unity environment web embedding), designed for real-time multi-model feedback in education.
- The SDK leverages lightweight WebGL, Unity, and JavaScript frameworks to convert LLM text outputs into audio and then render a real-time, lip-synced pedagogical agent.
- VTutor provides on-demand, personalized feedback using anime-like aesthetics to avoid the uncanny valley effect and enhance engagement.


---


#### 9th May 2025



[Reliable Collaborative Conversational Agent System based on LLMs and Answer Set Programming](http://arxiv.org/abs/2505.06438v1)

- AutoManager: introduces a dual-agent system with Administrator Bot (Manages knowledge base) and Assistant Bot (Interacts with customers) that share a Knowledge Base (Shared facts and menu), Temporary Information (Shared session data), and Collaborative Rule Set (Shared collaboration rules), utilizing Knowledge Extraction (Natural language to predicates), Commonsense Reasoning (Predicate reasoning with ASP), and Response Generation (Predicates to natural language) for reliable collaborative task-oriented dialogue.
- The system leverages Large Language Models for natural language processing and Answer Set Programming for robust logical reasoning and consistency checking within each agent.
- This architecture enables reliable collaboration between agents by sharing knowledge and rules, demonstrated in a fast-food restaurant management scenario.


---
[SCALEMCP: DYNAMIC AND AUTO-SYNCHRONIZING MODEL CONTEXT PROTOCOL TOOLS FOR LLM AGENTS](http://arxiv.org/abs/2505.06416v1)

- ScaleMCP: introduces a novel tool selection approach, with Agent, MCP Retrieval Tool, Automatic Indexing Pipeline, MCP Storage Index, and MCP Servers, enabling LLM agents to dynamically discover and equip Model Context Protocol (MCP) servers as tools.
- The framework features an auto-synchronizing tool storage system pipeline that uses CRUD operations with MCP servers as the single source of truth to maintain the MCP storage index.
- LLM agents are equipped with an MCP retrieval tool, allowing them to autonomously query the storage index and invoke relevant MCP servers during multi-turn interactions.


---

[A New DAPO Algorithm for Stock Trading](http://arxiv.org/abs/2505.06408v1)

- Improved DAPO Algorithm: introduces a novel trading agent integrating GRPO, Decoupled Clipping, Dynamic Sampling, and Sentiment-Risk Adjusted Rewards for financial trading.
- The approach adapts DAPO principles to a GRPO framework, incorporating LLM-based risk and sentiment signals into an adjustable reward function.
- This method demonstrates improved performance and significantly reduced computational requirements compared to a CPPO-DeepSeek baseline on the NASDAQ-100 index.


---

[LATENT: LLM-Augmented Trojan Insertion and Evaluation Framework for Analog Netlist Topologies](http://arxiv.org/abs/2505.06364v1)

- LATENT (LLM-Augmented Trojan Insertion and Evaluation Framework for Analog Netlist Topologies): introduces a framework for generating stealthy analog Trojans, utilizing an LLM Agent (autonomous agent) to modify a Circuit Netlist (analog circuit design), validated by a Syntax Checker (validates Trojan syntax), simulated by HSPICE (circuit simulator), evaluated by SPICED (LLM-based detection tool), and refined via Feedback-driven learning (iterative strategy refinement).
- The framework employs a Thought-Action-Observation loop where the LLM agent iteratively selects and inserts Trojan components based on detection feedback to evade detection.
- By integrating simulation and detection tools into the iterative process, the framework generates diverse, circuit-specific analog Trojans with low activation ranges and significant performance degradation upon activation.


---

[Remote Rowhammer Attack using Adversarial Observations on Federated Learning Clients](http://arxiv.org/abs/2505.06335v1)

- PPO-TS (PPO-based adversarial attack framework): introduces a novel threat vector that leverages a PPO Attack Agent to generate Adversarial Waveforms interfering with Client Sensors, resulting in Clustered Updates that induce Rowhammer bit-flips on Server DRAM.
- The framework utilizes reinforcement learning to manipulate client sensor observations, maximizing server repetitive memory updates necessary for Rowhammer exploitation.
- This approach enables remote Rowhammer attacks on federated learning servers without requiring direct access or system-level privileges.


---


[Multi-Agent Systems for Robotic Autonomy with LLMS](http://arxiv.org/abs/2505.05762v1)

- Multi-Agent System: introduces a framework for robotic autonomy, with Task Analyst (analyzes task input), Robot Designer (designs robot configuration), RL Designer (generates RL components), Code & Report Extractor (extracts code/reports), RL Execution (runs RL training/evaluation), Figures (visualizes results), and Report (summarizes analysis/results).
- The system takes task scenario descriptions as input and outputs multimodal results including code files, technical reports, and visualizations.
- This framework enables autonomous robotic task analysis, mechanical design, and path generation using LLMs and reinforcement learning.


---


[APOLLO: Automated LLM and Lean Collaboration for Advanced Formal Reasoning](http://arxiv.org/abs/2505.05758v1)

- APOLLO: introduces a modular pipeline combining LLM, Lean Server, Syntax Refiner, Sorrifier, Auto Solver, Subproof Extractor, and Proof Assembler.
- The pipeline directs LLM proof generation, analyzes and fixes errors using Lean feedback, isolates failing sub-lemmas, and applies automated solvers.
- This iterative process repairs and recombines sub-proofs, improving proof generation efficiency and correctness with lower sampling budgets.


---



[EVOLUTIONARY ECOLOGY OF WORDS](http://arxiv.org/abs/2505.05863v1)

- Word Evolutionary Ecology Model: introduces a model utilizing a Large Language Model for word creation, interaction judgment, and mutation within a spatial agent-based simulation, where individuals possessing words compete and evolve.
- The model simulates the evolutionary ecology of words by having agents with words move in a grid, compete based on LLM-determined outcomes, and mutate their words using the LLM.
- Competition outcomes between words are stored in a dictionary to improve computational efficiency for repeated interactions.


---

[ELA-ZSON: Efficient Layout-Aware Zero-Shot Object Navigation Agent with Hierarchical Planning](http://arxiv.org/abs/2505.06131v1)

- ELA-ZSON (Efficient Layout-Aware Zero-Shot Object Navigation): introduces an efficient zero-shot object navigation approach with an LLM Agent (manages process) that leverages a hierarchical Scene Representation (hierarchical environment map) for Hierarchical Planning (two-level path generation) and Robotic Navigation (executes planned path).
- The Scene Representation includes a global Topometric Map (global topological graph) and a local Learned Scene Representation (local dense memory), supporting both Global Topology Plan (coarse route planning) and Local Ego-centric Plan (dense waypoint generation).
- The LLM Agent manages the overall workflow, integrating Perception (RGB-D input, pose) and Control Flow (manages actions, status, errors) for autonomous navigation in complex indoor environments without costly training.


---

[AGENTXPLOIT: End-to-End Redteaming of Black-Box AI Agents](http://arxiv.org/abs/2505.05849v1)

- AGENTXPLOIT: introduces a generic black-box fuzzing framework for indirect prompt injection attacks, utilizing an Initial Corpus (High-quality templates), Seed Storage (Pool of seeds), Seed Selector (MCTS-based algorithm), a Mutator (Generates new variants), and a Scorer (Evaluates seeds) to iteratively refine adversarial prompts.
- The framework systematically explores adversarial prompts by selecting promising seeds, mutating them, and scoring their effectiveness based on attack success rate and task coverage.
- This adaptive and iterative process enables the framework to effectively discover and exploit indirect prompt injection vulnerabilities in black-box LLM agents across diverse architectures and tasks.


---



#### 8th May 2025

[Scalable Chain of Thoughts via Elastic Reasoning](https://arxiv.org/abs/2505.05315)

- Elastic Reasoning: introduces a framework for scalable chain of thoughts, explicitly separating reasoning into thinking and solution phases with independently allocated budgets.
- The framework employs a budget-constrained rollout strategy during training to teach the model adaptive reasoning under truncated conditions.
- At inference, separate budgeting prioritizes the completeness of the solution segment, improving reliability under strict resource constraints.


---


[MULTI-AGENT EMBODIED AI: ADVANCES AND FUTURE DIRECTIONS](http://arxiv.org/abs/2505.05108v1)

- Multi-Agent Embodied AI Survey: introduces a comprehensive review of recent advances and future directions in embodied AI systems with multiple agents, covering control, learning, and generative model-based methods.
- The survey analyzes key contributions and identifies challenges in multi-agent embodied AI, including asynchronous decision-making, agent heterogeneity, and open environments.
- It reviews benchmarks and discusses future research directions to guide innovation in this rapidly evolving field.


---

[Perception, Reason, Think, and Plan: A Survey on Large Multimodal Reasoning Models](http://arxiv.org/abs/2505.04921v1)

- LMRM (Large Multimodal Reasoning Model): introduces a structured roadmap for multimodal reasoning research, encompassing four stages: Stage 1 Perception-Driven Modular Reasoning, Stage 2 Language-Centric Short Reasoning, Stage 3 Language-Centric Long Reasoning, and Stage 4 Native LMRMs.
- The survey analyzes the progression from early modular, perception-driven systems to unified, language-centric frameworks and projects towards native models with omnimodal perception and agentic behavior.
- It provides a comprehensive review of over 540 publications, categorizes models and benchmarks, and discusses challenges and future prospects for next-generation multimodal reasoning systems.


---



[Not Like Us, Hunty: Measuring Perceptions and Behavioral Effects of Minoritized Anthropomorphic Cues in LLMs](http://arxiv.org/abs/2505.05660v1)

- Simulated LLM Agents: introduces a study evaluating user reliance and perception of LLM agents using minoritized sociolects (AAE, Queer slang) compared to Standard American English, utilizing templated suggestions constructed with warmth phrases and confidence expressions, generated via in-context learning and persona-based prompting with GPT-4.
- The study found that AAE speakers preferred and relied more on the SAE agent, while Queer slang speakers showed no significant preference but felt greater social presence with the Queer slang agent.
- Findings highlight the nuanced dynamics of sociolect use in machine interactions, emphasizing the need for careful design to respect cultural boundaries and avoid appropriation.


---

[CityNavAgent: Aerial Vision-and-Language Navigation with Hierarchical Semantic Planning and Global Memory](http://arxiv.org/abs/2505.05622v1)

- CityNavAgent: introduces a large language model-empowered agent for aerial vision-and-language navigation, featuring an open-vocabulary perception module, a hierarchical semantic planning module, and a global memory module.
- The agent extracts urban scene semantics, decomposes long-horizon tasks into hierarchical sub-goals, and stores historical trajectories in a topological graph to reduce navigation complexity.
- This approach enables zero-shot navigation in continuous urban environments, addressing challenges of complex scene understanding and exponential planning complexity.


---

[HiBayES: A Hierarchical Bayesian Modeling Framework For AI Evaluation Statistics](http://arxiv.org/abs/2505.05602v1)

- HiBayES (A Hierarchical Bayesian Modeling Framework for AI Evaluation Statistics): introduces a generalizable framework with Hierarchical Bayesian GLMs, Bayesian Data Analysis, MCMC Sampling, Uncertainty Quantification, Formal Model Comparison, and Quality Control components, designed for principled uncertainty quantification and robust parameter estimation in AI evaluations.
- The framework addresses challenges in AI evaluation statistics, including stochastic outputs, complex hierarchical data structures, and high testing costs, particularly in low-data scenarios.
- HiBayES enables robust inferences, explicit modeling of hierarchical data, and formal model comparison, offering advantages over conventional statistical methods like t-tests and flat models.


---

[clem: todd: A Framework for the Systematic Benchmarking of LLM-Based Task-Oriented Dialogue System Realisations](http://arxiv.org/abs/2505.05445v1)

- clem: todd (chat-optimized LLMs for task-oriented dialogue systems development): introduces a framework for systematically evaluating LLM-based task-oriented dialogue systems, featuring a Game Master (coordinates interaction), User Simulator (simulates user), and Dialogue System (acts as agent), which can be implemented as Monolithic Dialogue System (single LLM agent), Modular-Prog Dialogue System (programmed flow agent), or Modular-LLM Dialogue System (LLM-controlled agent), utilizing components such as Dialogue Manager (manages dialogue flow), Intent Detection (identifies user intent), Slot Extraction (extracts entities), Response Generation (generates response), Database Retriever (queries database), and Booking Confirmer (confirms bookings).
- The framework facilitates turn-based interactions between the user simulator and dialogue system, coordinated by the game master, and supports plug-and-play integration of different models and architectures.
- Evaluation within the framework involves consistent datasets, metrics, and computational constraints, enabling detailed benchmarking and analysis of performance and efficiency trade-offs.


---

[EcoAgent: An Efficient Edge-Cloud Collaborative Multi-Agent Framework for Mobile Automation](http://arxiv.org/abs/2505.05440v2)

- EcoAgent: introduces an edge-cloud collaborative multi-agent framework for mobile automation, featuring a Cloud-Based Planning Agent (Task decomposition, planning), Edge-Based Execution Agent (Action execution), Edge-Based Observation Agent (Monitor screen, verify outcomes), Memory Module (Stores screen history), Reflection Module (Supports replanning), and Pre-Understanding Module (Compresses screen images).
- The framework coordinates cloud and edge agents in a closed loop, leveraging cloud-based MLLMs for planning and edge-based MSLMs for execution and observation.
- The Pre-Understanding Module reduces communication overhead by compressing screen images, while Memory and Reflection modules enable replanning upon execution failure.


---

[HEXGEN-TEXT2SQL: Optimizing LLM Inference Request Scheduling for Agentic Text-to-SQL Workflows](http://arxiv.org/abs/2505.05286v1)

- HEXGEN-TEXT2SQL: introduces a novel framework for scheduling agentic Text-to-SQL workflows on heterogeneous GPU clusters, featuring a Global Coordinator (Dispatcher) that assigns requests, LLM Model Instances (with Local Priority Queue) that process and prioritize tasks, and a Simulator (Alpha-Tuning) that tunes the dispatcher parameter.
- The framework employs a two-level hierarchical scheduling approach combining global workload-balanced dispatching and local adaptive urgency-guided prioritization to manage multi-stage dependencies and resource heterogeneity.
- This design significantly improves SLO attainment and system throughput for LLM-based Text-to-SQL serving compared to baseline methods.


---

[MARK: Memory Augmented Refinement of Knowledge](http://arxiv.org/abs/2505.05177v1)

- MARK (Memory-Augmented Refinement of Knowledge): introduces a scalable agentic memory design framework, with Conversational LLM Agent, LLM, System Prompt, Domain Knowledge Source, Chat History, Memory Builder Service (MBS), Memory Search Service (MSS), Memory Store, Residual Refined Memory Agent, User Question Refined Memory Agent, LLM Response Refined Memory Agent, Memory Relevance Scoring (MRS), and Memory, enabling LLMs to continuously learn and refine domain knowledge.
- The framework utilizes specialized memory agents (Residual, User Question, LLM Response) to extract refined memories from conversations, stored in a Memory Store.
- Memory Search Service retrieves and ranks relevant memories using Memory Relevance Scoring for injection into the LLM context, improving accuracy and adaptability.


---

[From First Draft to Final Insight: A Multi-Agent Approach for Feedback Generation](http://arxiv.org/abs/2505.04869v1)

- G-E-RG (Generation, Evaluation, and Regeneration): introduces a multi-agent framework for feedback generation, including External Database (slides), Question, Student response, Agent 1 (Generation), Feedback in the first round, Agent 2 (Evaluation), Evaluation results, Agent 3 (Re-Generation), and Feedback in the second round, which generates initial feedback, evaluates it, and then regenerates improved feedback.
- The framework utilizes three distinct GPT-4o agents for the sequential tasks of initial generation, evaluation based on a rubric, and final regeneration informed by evaluation results.
- The iterative G-E-RG process significantly improves feedback quality across multiple dimensions compared to single-round generation methods.


---

[Reasoning Models Don't Always Say What They Think](https://arxiv.org/abs/2505.05410)

- CoT Faithfulness Evaluation and RL Training Framework: introduces an evaluation of large language models, including Claude 3.5 Sonnet (New), Claude 3.7 Sonnet, DeepSeek V3, and DeepSeek R1, assessing the faithfulness of their Chain-of-Thought reasoning when responding to Input Prompts and Prompt Pairs, and studies the impact of Outcome-Based Reinforcement Learning in synthetic RL Environments with Reward Hacks defined by a Reward Function.
- The evaluation measures how often models verbalize hints used in their reasoning process, finding that CoTs often lack faithfulness, particularly on misaligned hints and harder tasks.
- Outcome-based RL initially improves CoT faithfulness but plateaus, and models exploiting Reward Hacks in RL Environments rarely verbalize the hack in their CoTs.


---


#### 7th May 2025


[Large Language Models are Autonomous Cyber Defenders](http://arxiv.org/abs/2505.04843v1)

- LLM Adapter Framework: introduces a system to integrate LLMs into the CybORG CAGE 4 environment, including an LLM Adapter, Formatter, Backend, LLM Models, Custom Policies, Communication Protocol, Blue Agent (LLM), Blue Agent (RL), Red Agent, and Green Agent.
- The framework enables LLM-driven agents to act as autonomous cyber defenders in a multi-agent simulation alongside RL and finite-state agents.
- A novel communication protocol allows diverse blue agents to share threat information and coordinate defensive actions within the simulated network.


---

[Safeguard-by-Development: A Privacy-Enhanced Development Paradigm for Multi-Agent Collaboration Systems](http://arxiv.org/abs/2505.04799v1)

- Maris: introduces a privacy-enhanced development paradigm for multi-agent collaboration systems, with MACS Data Protection Manifest (Specifies data protection policy), Data Safeguard Engine (Integrates policy into workflows), Conversation Handler (Hooks into message flows), Manifest Enforcer (Validates messages, applies actions), AutoGen (Multi-agent development framework), ConversableAgent (Generic agent class), GroupChatManager (Group conversation manager), Agents (Autonomous actors), LLMs (Large Language Models), Tools (External services/functions), and Users (Human participants), designed to address data leakage threats by enforcing rigorous message flow control.
- The system embeds reference monitors into key conversation components to validate message flows against user-defined policies at runtime.
- Evaluation across healthcare, supply chain, and recommendation use cases demonstrates satisfactory effectiveness and low performance overhead.


---



[Benchmarking LLMs' Swarm intelligence](http://arxiv.org/abs/2505.04364v1)

- SwarmBench: introduces a novel benchmark for evaluating LLM swarm intelligence, featuring a launcher (Launches benchmark), a framework orchestrator (Orchestrates interactions), a simulation environment (Simulation environment), task definitions (Defines coordination tasks), a physics engine (Manages environment physics), LLM-powered agents (LLM-powered agents logic), and a data logger (Captures simulation data).
- The benchmark assesses emergent decentralized coordination in LLM swarms under strict perception and communication constraints within a configurable 2D grid world.
- SwarmBench includes five core multi-agent coordination tasks: Pursuit, Synchronization, Foraging, Flocking, and Transport, evaluated using a zero-shot protocol.


---


[CompileAgent: Automated Real-World Repo-Level Compilation with Tool-Integrated LLM-based Agent System](http://arxiv.org/abs/2505.04254v1)

- CompileAgent: introduces an LLM-based agent framework for automated repo-level compilation, integrating a MasterAgent, Flow-based Agent Strategy, Shell Tool, File Navigator Tool, Instruction Extractor Tool, Website Search Tool, and Multi-Agent Discussion Tool to handle instruction search and error resolution.
- The framework leverages five specialized tools and a flow-based strategy orchestrated by a MasterAgent to interact with software artifacts and the interactive environment.
- CompileAgent significantly improves compilation success rates and reduces time/cost compared to baselines on a new benchmark, demonstrating the potential of agent-based approaches for complex software engineering tasks.


---


[A Proposal for Evaluating the Operational Risk for ChatBots based on Large Language Models](http://arxiv.org/abs/2505.04784v1)

- LLM Risk Evaluation Framework: introduces a novel metric and framework for evaluating the operational risk of LLM-based chatbots, integrating an Improved Probes Set, Garak scanner, the Prospected Chatbot System, a Metric Calculator, Industry Factor, Age Profile of Users, Technical Complexity, and Hits to assess risks to the system, users, and third parties.
- The framework leverages the open-source GARAK tool, enhancing its probes and incorporating contextual factors like industry and user demographics into the risk calculation.
- Evaluation results using the framework demonstrate varying risk levels across different LLM models and the impact of prompt protection and contextual multipliers on risk assessment.


---


[AutoPatch: Multi-Agent Framework for Patching Real-World CVE Vulnerabilities](http://arxiv.org/abs/2505.04195v1)

- AutoPatch: introduces a multi-agent framework with a security plugin, similarity analyzer, taint analysis, semantic analysis, unified similarity model, RAG database, vulnerability verifier, code patcher, and LLM-based code generation model, designed to patch vulnerable LLM-generated code by identifying and fixing real-world CVEs.
- The framework leverages retrieval-augmented generation and specialized LLM agents to analyze code, find similar vulnerabilities in a database, verify their presence, and generate secure patches.
- This approach aims to overcome the knowledge cutoff limitation of LLMs and provide a cost-efficient alternative to frequent fine-tuning for handling newly disclosed vulnerabilities.


---


[Benchmarking LLMs' Swarm intelligence](http://arxiv.org/abs/2505.04364v1)

- SwarmBench: introduces a novel benchmark for evaluating LLM swarm intelligence, featuring a launcher (Launches benchmark), a framework orchestrator (Orchestrates interactions), a simulation environment (Simulation environment), task definitions (Defines coordination tasks), a physics engine (Manages environment physics), LLM-powered agents (LLM-powered agents logic), and a data logger (Captures simulation data).
- The benchmark assesses emergent decentralized coordination in LLM swarms under strict perception and communication constraints within a configurable 2D grid world.
- SwarmBench includes five core multi-agent coordination tasks: Pursuit, Synchronization, Foraging, Flocking, and Transport, evaluated using a zero-shot protocol.


---


[Absolute Zero: Reinforced Self-play Reasoning with Zero Data](https://arxiv.org/abs/2505.03335)

- Absolute Zero Reasoner (AZR): introduces a system where a single Language Model (acts as proposer and solver) learns to propose tasks (Proposer) and solve them (Solver) through self-play, utilizing a Code Executor (validates tasks, verifies answers) as the Environment (provides feedback) and guided by a Reward Function (guides learning) and RL Algorithm (updates model).
- The system operates under the Absolute Zero paradigm, learning entirely from self-generated tasks and environmental feedback without relying on external human-curated data.
- AZR leverages three distinct task types (deduction, abduction, induction) and a task-relative reinforcement learning approach (TRR++) to achieve strong reasoning capabilities across coding and mathematical domains.


---



[Facilitating Trustworthy Human-Agent Collaboration in LLM-based Multi-Agent System oriented Software Engineering](http://arxiv.org/abs/2505.04251v1)

- RACI-based framework: introduces a method for assigning responsibilities between Human Actors and LLM-based Agents using RACI roles to facilitate trustworthy human-agent collaboration in LLM-based multi-agent systems for software engineering.
- The framework aims to enhance collaboration, ensure accountability, and mitigate risks associated with LLM-driven automation by systematically distributing decision-making authority and oversight.
- The approach defines specific roles (Responsible, Accountable, Consulted, Informed) for humans and agents across tasks within the software development lifecycle.


---

[Identification and Optimization of Redundant Code Using Large Language Models](http://arxiv.org/abs/2505.04040v1)

- LLM-agent: introduces a framework leveraging Large Language Models (Core engine) to analyze and optimize a Codebase (Input code), verified by Test Cases (Verification).
- The framework incorporates Static Analysis Tools (Evaluation) for metric evaluation and Developer Feedback (Validation/Insights) for understanding redundancy causes.
- The LLM Agent (Orchestrator) manages the process, aiming to build a Catalog (Knowledge base) of redundant code patterns and reasons.


---



#### 6th May 2025

[The Power of Stories: Narrative Priming Shapes How LLM Agents Collaborate and Compete](http://arxiv.org/abs/2505.03961v1)

- Narrative Primed LLM Agents: introduces a system where LLM agents play a public goods game, influenced by narrative priming from a story pool.
- The study investigates how shared versus different narratives affect agent collaboration and competition outcomes in the game.
- Experiments explore the influence of narrative type, group size, and the presence of selfish agents on collaboration scores and payoffs.


---

[Frog Soup: Zero-Shot, In-Context, and Sample-Efficient Frogger Agents](http://arxiv.org/abs/2505.03947v1)

- LLM Demonstrations Guided DQN: introduces enhancing a traditional DQN agent with LLM-generated gameplay demonstrations, utilizing Objects Coordinates Extraction, LLM Agents, LLM Demo, and LLM Loop to collect expert trajectories, which are then integrated into the DQN Components including Self-Play Experience, Evaluation NNet, Target NNet, Priority Experience Replay, Priority Sampling, DQN loss calculation, and DQN Loop interacting with the Atari-Frogger Env.
- The approach leverages Prioritized Experience Replay to prioritize sampling of the LLM-generated expert demonstrations, aiming to improve the sample efficiency and initial performance of the DQN agent on the challenging Frogger game.
- Experiments show that incorporating LLM demonstrations leads to significantly higher episodic rewards and faster convergence compared to a standard DQN baseline within a limited training budget.


---

[Performance Evaluation of Large Language Models for High-Performance Code Generation: A Multi-Agent Approach (MARCO)](http://arxiv.org/abs/2505.03906v1)

- MARCO (Multi-Agent Reactive Code Optimizer): introduces a multi-agent system with Code Optimizer Agent, Web-Search Engine, Performance Evaluator Agent, and Adaptive Feedback Loop for optimizing high-performance computing code.
- The Code Optimizer Agent generates and refines code using strategies informed by the Web-Search Engine and feedback from the Performance Evaluator Agent.
- The Adaptive Feedback Loop iteratively improves code quality by feeding performance metrics from the evaluator back to the optimizer.


---


[Divide, Optimize, Merge: Fine-Grained LLM Agent Optimization at Scale](http://arxiv.org/abs/2505.03973v1)

- FGO (Fine-Grained Optimization): introduces, "Divide (Splits dataset) / Optimize (Optimizes subsets) / LLM Optimizer (Updates modules) / Agent (Executes tasks) / Module (Part optimized) / Evaluate (Assesses performance) / Merge (Combines modules) / Recursive Clustering (Groups modules) / Direct Merge (Combines groups) / Optimal Agent System (Final agent)", a scalable framework for LLM agent optimization.
- FGO divides large optimization tasks into manageable subsets, performs fine-grained optimization on each subset, and progressively merges the optimized components.
- The framework demonstrates improved performance and efficiency for LLM-based agent optimization on large datasets compared to traditional methods.


---

[SLOT: Structuring the Output of Large Language Models](http://arxiv.org/abs/2505.04016v1)

- SLOT (Structured LLM Output Transformer): introduces a model-agnostic post-processing approach using a fine-tuned lightweight language model to transform unstructured LLM output into structured formats, incorporating a Data Synthesizer LLM and Validation for data creation, and utilizing Loss Calculation and Weight Update for training.
- The framework takes unstructured text from an upstream LLM and a JSON Schema as input to the SLOT model, producing structured output, and is evaluated using metrics like Schema Accuracy and Content Similarity.
- SLOT can be combined with Constrained Decoding methods to further enhance structural validity and performance, demonstrating that targeted training can enable smaller models to achieve high-quality structured generation.


---

[Divide, Optimize, Merge: Fine-Grained LLM Agent Optimization at Scale](http://arxiv.org/abs/2505.03973v1)

- FGO (Fine-Grained Optimization): introduces, "Divide (Splits dataset) / Optimize (Optimizes subsets) / LLM Optimizer (Updates modules) / Agent (Executes tasks) / Module (Part optimized) / Evaluate (Assesses performance) / Merge (Combines modules) / Recursive Clustering (Groups modules) / Direct Merge (Combines groups) / Optimal Agent System (Final agent)", a scalable framework for LLM agent optimization.
- FGO divides large optimization tasks into manageable subsets, performs fine-grained optimization on each subset, and progressively merges the optimized components.
- The framework demonstrates improved performance and efficiency for LLM-based agent optimization on large datasets compared to traditional methods.


---

[WebGen-Bench: Evaluating LLMs on Generating Interactive and Functional Websites from Scratch](http://arxiv.org/abs/2505.03733v1)

- WebGen-Bench (Evaluation Pipeline): introduces a benchmark and pipeline to evaluate LLM-based agents on generating websites from scratch, including Data Curation, Website Generation, Test Case Construction, UI Agent, UI Agent Engine, Appearance Grading, and Manual Validation components.
- The pipeline uses LLMs and human annotators for data creation, LLM-based agents for website generation, and a UI agent powered by an LLM for automated functional testing.
- Website appearance is graded by a separate LLM, and human testers perform manual validation of test cases.


---

[LlamaFirewall: An open source guardrail system for building secure AI agents](http://arxiv.org/abs/2505.03574v1)

- LlamaFirewall: introduces an open-source, system-level security framework for LLM-powered applications, including a Unified Policy Engine (Orchestration), PromptGuard 2 (Jailbreak detection), AlignmentCheck (Agent alignment), and CodeShield (Code analysis).
- The framework provides layered defense against prompt injection, agent misalignment, and insecure code generation risks.
- LlamaFirewall offers a modular design supporting custom pipelines, conditional remediation strategies, and pluggable detectors for real-time security monitoring.


---

[A Comprehensive Survey of Large AI Models for Future Communications: Foundations, Applications and Challenges](http://arxiv.org/abs/2505.03556v1)

- LAMs (Large AI Models): introduces a comprehensive survey of Large AI Models for future communications, covering their foundations including Transformer, Diffusion, and Mamba architectures, classification into LLM, LVM, LMM, and World models, training methods like Pre-training, Fine-tuning, and Alignment, and optimization techniques such as CoT, RAG, and Agentic systems.
- The paper details the application of LAMs across various communication scenarios, including physical layer design, resource allocation, network management, edge intelligence, semantic communication, agentic systems, and emerging applications.
- It analyzes the research challenges faced by LAMs in communication, such as data quality, structured knowledge integration, generative hallucination, reasoning limitations, explainability, adaptability, task diversity, resource constraints, inference latency, and security/privacy.


---

[A HASHGRAPH-INSPIRED CONSENSUS MECHANISM FOR RELIABLE MULTI-MODEL REASONING](http://arxiv.org/abs/2505.03553v1)

- Hashgraph-inspired Consensus Mechanism: introduces a system for reliable multi-model reasoning using a Query Handler (accepts user request), Model Interface Layer (manages model connections), Consensus Controller (implements gossip and checks convergence), Prompt Generator (formulates model prompts), Comparer/Evaluator (compares model outputs), Result Aggregator (formats final output), and a Reasoning Model Pool (set of black-box models).
- The system treats each reasoning model as a node in a distributed network, using gossip-about-gossip and virtual voting principles to achieve consensus on a final answer.
- This iterative process allows models to exchange and refine answers, aiming to reduce hallucinations and improve accuracy by leveraging collective intelligence.


---

[LogisticsVLN: Vision-Language Navigation For Low-Altitude Terminal Delivery Based on Agentic UAVs](http://arxiv.org/abs/2505.03460v1)

- LogisticsVLN: introduces a UAV-based vision-language navigation system for terminal delivery, integrating an LLM (interprets request, extracts attributes), Floor Count VLM (estimates floors, guides vertical movement), Object Recognition VLM (identifies target window/object), Choice VLM (determines next action), Depth Assistant (ensures safety, calculates distances), and RGB-Depth Observation (input data).
- The system processes user requests and environmental observations to guide a drone to a specific window for package delivery.
- It operates without prior maps or fine-tuning, relying on foundation models for perception, understanding, and decision-making in unseen residential environments.


---

[Procedural Memory Is Not All You Need: Bridging Cognitive Gaps in LLM-Based Agents](http://arxiv.org/abs/2505.03434v1)

- Modular Semantic-Associative System: introduces a modular architecture augmenting LLMs with semantic and associative memory components to bridge cognitive gaps.
- This system decouples procedural execution (LLM actor) from adaptive reasoning (semantic/associative modules) for robust decision-making.
- The architecture is designed for agents operating in complex, unpredictable "wicked" environments by specializing cognitive functions.


---

[DYSTIL: Dynamic Strategy Induction with Large Language Models for Reinforcement Learning](http://arxiv.org/abs/2505.03209v1)

- DYSTIL: introduces a strategy-based reinforcement learning framework with DYSTIL RL Agent L, Memory Mc, Input Constructor, Core Reasoning LLM, Actor Module, Critic Module, Strategy-Generating LLM Q, Observation-to-Text Converter Co→t, Experience Buffer B, and PPO Parameter Optimization, which dynamically induces textual strategies using large language models to improve reinforcement learning from expert demonstrations.
- The framework integrates a strategy-generating LLM for strategy induction with a lightweight core reasoning LLM for policy optimization.
- DYSTIL iteratively updates strategies based on experience and advantage estimations, enhancing sample efficiency and model interpretability.


---

[VLM Q-LEARNING: ALIGNING VISION-LANGUAGE MODELS FOR INTERACTIVE DECISION-MAKING](http://arxiv.org/abs/2505.03181v1)

- LVLMQ (VLM Q-Learning): introduces, "aligning vision-language models for interactive decision-making", with VLM (core RL policy), Image Encoder (processes image input), Text Encoder (processes text input), LoRA Transformer (adapted VLM body), Language Head (Actor) (predicts output tokens), Critic Head (estimates action values), Environment (interactive system), Observation Prompt (formats VLM input), parseagent (parses VLM response), and parseenv (interprets action for environment), where the method applies off-policy reinforcement learning to fine-tune VLMs for agent tasks by adding a critic head and using an advantage-filtered supervised fine-tuning loss.
- The approach converts turn-based agent interactions into token-based RL transitions, allowing the VLM's language head to act as the policy and the critic head to filter suboptimal actions based on learned value estimates.
- This technique enables VLMs to self-improve and learn from low-quality datasets, effectively replacing standard supervised fine-tuning for VLM agent training while handling action syntax challenges.


---

[An LLM-based Self-Evolving Security Framework for 6G Space-Air-Ground Integrated Networks](http://arxiv.org/abs/2505.03161v1)

- LLM-based Self-Evolving Security Framework: introduces a security framework for 6G SAGINs with LLM-6GNG (Processes threat data, generates strategies), 6G-INST (Enables framework self-evolution), and 6G Simulator (Simulates 6G SAGINs environment).
- The LLM-6GNG component processes threat information and generates security strategies using multi-agent LLMs and chain-of-thought reasoning.
- The 6G-INST component enables the framework to self-evolve by automatically updating the LLM-6GNG with new training data generated from encountered threats.


---

[Assessing and Enhancing the Robustness of LLM-based Multi-Agent Systems Through Chaos Engineering](http://arxiv.org/abs/2505.03096v1)

- Chaos Engineering Framework: introduces a framework for assessing and enhancing the robustness of LLM-based Multi-Agent Systems (LLM-MAS) by systematically applying chaos engineering principles.
- The framework includes components like a Chaos Module for fault injection and Monitoring Components/Modules for data collection and analysis.
- The research proposes validating the framework through controlled experiments simulating various failure scenarios in LLM-MAS deployments.


---



#### 5th May 2025


[Improving Model Alignment Through Collective Intelligence of Open-Source LLMS](http://arxiv.org/abs/2505.03059v1)

- MoAA: introduces a two-stage alignment recipe leveraging the collective intelligence of multiple open-source LLMs, including Mixture of Agents (MoA), Proposers, Aggregators, Synthetic Data Generator, Reward Model, Criteria Filtering, Target Model, SFT Model, and DPO Model, to generate high-quality synthetic data for supervised fine-tuning and preference optimization.
- The approach utilizes MoA as a synthetic data generator in the first stage (MoAA-SFT) to fine-tune a target model and as a reward model in the second stage (MoAA-DPO) to annotate preference data for direct preference optimization.
- MoAA demonstrates significant improvements in model performance on alignment benchmarks by effectively integrating the strengths and diversity of open-source LLMs without relying on stronger external supervision.


---

[34 Examples of LLM Applications in Materials Science and Chemistry: Towards Automation, Assistants, Agents, and Accelerated Scientific Discovery](http://arxiv.org/abs/2505.03049v1)

- The LLM-Powered Research Constellation: introduces 34 LLM applications across materials science and chemistry, categorized into Property Prediction (Forecasting properties), Molecular & Material Design (Generating novel molecules/materials), Automation & Novel Interfaces (Developing interfaces/automations), Scientific Communication and Education (Enhancing communication/education), Research Data Management and Automation (Streamlining data handling/processing), Hypothesis Generation & Evaluation (Generating/evaluating hypotheses), and Knowledge Extraction & Reasoning (Extracting knowledge/reasoning).
- These applications, developed during a hackathon, demonstrate LLMs' versatility as predictive models and platforms for rapid prototyping of domain-specific tools.
- The work highlights how integrating LLMs into scientific workflows can accelerate discovery and improve researcher efficiency across the entire research lifecycle.


---

[The Art of Repair: Optimizing Iterative Program Repair with Instruction-Tuned Models](http://arxiv.org/abs/2505.02931v1)

- Iterative Program Repair Pipeline: introduces an approach for automatic program repair using instruction-tuned large language models, balancing multi-output generation and iterative refinement within a limited patch budget, incorporating Input, LLM, Prompt, Output, Parsing, Validation, Execution, Feedback, and Iterative Process components.
- The pipeline processes buggy code input, uses an LLM guided by a prompt to generate output patches, which are then parsed and subjected to validation via execution with tests.
- Feedback from validation drives the iterative process to refine patches, aiming to maximize repair success while limiting the total number of generated patches.


---


[Scenethesis: A Language and Vision Agentic Framework for 3D Scene Generation](http://arxiv.org/abs/2505.02836v1)

- Scenethesis: introduces a training-free agentic framework for text to interactive 3D scene generation, with LLM Module (Coarse scene planning), Vision Module (Layout visual refinement), Optimization Module (Physics-aware optimization), and Judge Module (Spatial coherence judgment).
- The framework leverages language and visual priors to generate realistic and physically plausible indoor and outdoor environments.
- It integrates LLM-based scene planning with vision-guided layout refinement and physics-aware optimization to ensure spatial realism and physical plausibility.


---

[AutoLibra: Agent Metric Induction from Open-Ended Feedback](http://arxiv.org/abs/2505.02820v1)

- AutoLibra: introduces a framework for agent evaluation that transforms Human Feedback (Open-ended text) on Agent Trajectory (Agent actions/observations) using an LLM (Text processing model) to generate Aspects (Grounded behavior-feedback), induce AutoLibra Metrics (Induced evaluation criteria), evaluate agents producing Traits (LLM metric ratings), and meta-evaluate metrics using Meta-Metrics (Metric quality evaluation).
- The framework operates in a closed loop, using meta-evaluation results (coverage and redundancy) to optimize the induced metrics.
- AutoLibra-induced metrics serve as targets for agent improvement through prompt engineering or fine-tuning.


---

[Generating HomeAssistant Automations Using an LLM-based Chatbot](http://arxiv.org/abs/2505.02802v1)

- EcoMate: introduces an LLM-based chatbot system for generating HomeAssistant routines, utilizing an LLM to process User Commands, Home Template, and Energy Consumption data for execution by the HomeAssistant framework.
- The system evaluates different LLMs' ability to generate valid JSON routines for HomeAssistant and assesses user perception compared to rule-based chatbots.
- Findings indicate GPT models excel in routine generation, while user studies show positive engagement and usability for the LLM-based approach in promoting sustainable practices.


---

[Voila: Voice-Language Foundation Models for Real-Time Autonomous Interaction and Voice Role-Play](http://arxiv.org/abs/2505.02707v1)

- Voila: introduces a family of large voice-language foundation models, with Audio Tokenizer (Audio tokenization/decoding), Text Tokenizer (Text tokenization), Voice-language LLM backbone (Processes interleaved tokens), and Audio Transformer (Generates audio tokens), designed for real-time autonomous interaction and voice role-play.
- The model employs a hierarchical multi-scale Transformer architecture integrating LLM reasoning with acoustic modeling for natural, persona-aware voice generation.
- Voila supports end-to-end voice conversation and autonomous full-duplex interaction by processing interleaved audio and text tokens.


---

[Exploring LLM-Powered Role and Action-Switching Pedagogical Agents for History Education in Virtual Reality](http://arxiv.org/abs/2505.02699v1)

- VR Prototype with LLM-Powered Pedagogical Agents: introduces a system for VR history education featuring a Virtual Environment, Pedagogical Agents (PAs) powered by an LLM (Large Language Model), and modules for Conversation, Adaptive Role-Switching, and Adaptive Action-Switching.
- The LLM processes user input and context to drive the Conversation Module, while the Adaptive Role-Switching and Adaptive Action-Switching Modules dynamically adjust the PA's role, appearance, voice, tone, and actions based on the LLM's output and environmental factors.
- A user study found that adaptive role-switching enhanced perceived trustworthiness and expertise, while adaptive action-switching increased perceived social presence and humanness, offering insights for designing multi-role agents in immersive learning.


---

[A Survey of Slow Thinking-based Reasoning LLMs using Reinforced Learning and Inference-time Scaling Law](http://arxiv.org/abs/2505.02665v1)

- Test-Time Scaling, Reinforced Learning, and Slow Thinking: introduces a survey of reasoning LLMs, detailing methods like Test-Time Scaling (Adjusts computation complexity), Reinforced Learning (Optimizes policy via feedback), and Slow Thinking (Emulates deliberate reasoning).
- These approaches incorporate components such as Search and Sampling (Explores reasoning paths), Dynamic Verification Mechanism (Verifies, refines outputs), Policy Network (Learns reasoning strategies), Reward Design (Evaluates reasoning quality), and Self-Evolution (Iteratively improves performance).
- Slow Thinking frameworks further utilize Long CoT (Generates extended reasoning), Hierarchical Reasoning (Structures problem-solving modularly), and Hybrid Thinking (Combines fast, slow processes) to enhance reasoning capabilities.


---

[Evaluating Contrastive Feedback for Effective User Simulations](http://arxiv.org/abs/2505.02560v1)

- LLM-based User Simulation: introduces, "evaluating different prompting strategies for LLM-based user agents in interactive information retrieval simulations", with LLM (Core agent), Information Need (Initial context), Knowledge State (Evolving understanding), Relevance Feedback (Document summaries), Prompting Strategy (Contextual input method), Query Generation (LLM creates queries), Relevance Judgment (LLM judges documents), Knowledge State Update (Incorporates feedback), and Simulation Environment (Provides search results), where "the paper analyzes how different modalities of contextual information influence the effectiveness of user simulations".
- The study evaluates user configurations where the LLM agent's knowledge state is updated iteratively with summaries of previously judged relevant, irrelevant, or both types of documents.
- The research demonstrates that providing contrastive feedback (summaries of both relevant and irrelevant documents) to the LLM agent improves simulated user search effectiveness.


---

[Beyond the model: Key differentiators in large language models and multi-agent services](http://arxiv.org/abs/2505.02489v1)

- LLM Ecosystem Differentiators: introduces key differentiators beyond the core model, including Data Quality, Proprietary Datasets, Model Quantization, Model Pruning, Neural Attention Memory Models (NAMMs), Semantic Caching, Attention Offloading, Speculative Decoding, Low-Rank Adaptation (LoRA), Flash-LLM, Evaluation Frameworks, Monitoring Systems, Model-to-Data Movement, Synthetic Data Generation, Data Versioning, and Data Lineage.
- The paper reviews critical factors like data management, computational efficiency, latency reduction, and robust evaluation frameworks that ensure modern AI services are efficient and profitable.
- These ecosystem components and strategies are presented as the real competitive advantage in generative AI as large language models become increasingly commoditized.


---

[El Agente: An Autonomous Agent for Quantum Chemistry](http://arxiv.org/abs/2505.02484v1)

- El Agente Q: introduces an LLM-based multi-agent system with a hierarchical architecture, integrating working and long-term memory, an LLM reasoning core, and specialized agents for automated quantum chemistry workflows.
- The system features a hierarchical memory framework enabling flexible task decomposition, adaptive tool selection, post-analysis, and autonomous file handling.
- El Agente Q demonstrates robust problem-solving, adaptive error handling, and supports multi-step task execution for complex workflows.


---

#### 4th May 2025

[A survey of agent interoperability protocols: Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), and Agent Network Protocol (ANP)](http://arxiv.org/abs/2505.02279v1)

- MCP (Model Context Protocol), ACP (Agent Communication Protocol), A2A (Agent-to-Agent Protocol), and ANP (Agent Network Protocol): introduces a survey examining four emerging agent communication protocols, including MCP (Initiator, Provider, Message semantics, Physical transmission, Calls expecting replies, Successful responses, Failures, Asynchronous updates, Model-controlled capabilities, Application-controlled data, User-controlled templates, Server-controlled generation delegation), ACP (Initiates communication, Protocol broker, Execution endpoint, Identity and capability profile, Agent location, Unit of delegated work, Communication envelope, Execution outputs), A2A (Originator of intent, Intermediary orchestrator, Service endpoint, Self-description and discovery, Actionable capabilities, Atomic unit of work, Communication channel, Tangible outputs, Real-time streaming, Out-of-band updates), and ANP (Decentralized identifier, Structured metadata profile, Agent indexing and search, JSON-RPC, OpenAPI, YAML schemas, Dynamic protocol alignment, Secure communication, Protocol negotiation layer, Core application logic layer, Transport protocol), each addressing distinct interoperability tiers for LLM-powered agents.
- The protocols are compared across dimensions like interaction modes, discovery mechanisms, communication patterns, and security models to provide a foundation for designing secure, interoperable, and scalable agent ecosystems.
- A phased adoption roadmap is proposed, starting with MCP for tool access, progressing through ACP for multimodal messaging and A2A for enterprise collaboration, and extending to ANP for decentralized agent marketplaces.


---

[VECSR: Virtually Embodied Common Sense Reasoning System](http://arxiv.org/abs/2505.02144v1)

- VECSR: introduces a framework for common sense reasoning, with VECSR (Orchestrates process), s(CASP) Knowledge Base (Stores rules and state), s(CASP) Goal-Directed Solver (Generates action plans), and VirtualHome Simulation Environment (Provides embodied world), designed to break down high-level tasks into executable mid-level instructions.
- The system converts VirtualHome state into s(CASP) facts, combines them with common sense rules, and optimizes the resulting program using techniques like modularity, dependency graphs, and partial grounding.
- The s(CASP) solver then uses the optimized program to generate a sequence of actions that achieve the goal task in the simulated environment, providing explainable and executable plans.


---

[Enhancing LLM Code Generation: A Systematic Evaluation of Multi-Agent Collaboration and Runtime Debugging for Improved Accuracy, Reliability, and Latency](http://arxiv.org/abs/2505.02133v1)

- ACT + Debugger (Multi-Agent Collaboration and Runtime Debugging): introduces a chained system combining multi-agent collaboration and runtime debugging for LLM code generation, including Analyst, Coder, Tester, and Debugger agents, processing Code Requirements, Visible Test Cases, Code Blocks, and using Blocking and Tracing Process, Execute Program to produce a Final Answer.
- The system first uses Analyst, Coder, and Tester agents in a process-oriented phase, then transitions to a product-oriented debugging phase involving the Debugger and Coder agents if initial tests fail.
- This integrated approach aims to leverage the strengths of collaborative planning and iterative debugging to improve functional accuracy, code rigor, and latency trade-offs.


---

[DriveAgent: Multi-Agent Structured Reasoning with LLM and Multimodal Sensor Fusion for Autonomous Driving](http://arxiv.org/abs/2505.02123v1)

- DriveAgent: introduces a novel multi-agent framework for autonomous driving that leverages LLM and VLM reasoning combined with multimodal sensor fusion, structured into Descriptive Analysis, Vehicle Reasoning, Environmental Reasoning, and Response Generation modules.
- The framework integrates camera, LiDAR, GPS, and IMU data through a hierarchy of specialized agents within these modules to enhance situational understanding and decision-making.
- DriveAgent aims to provide clear, reliable, and interpretable insights into complex driving scenarios, improving robustness and reliability compared to baseline methods.


---

[MemEngine: A Unified and Modular Library for Developing Advanced Memory of LLM-based Agents](http://arxiv.org/abs/2505.02099v1)

- MemEngine: introduces a unified and modular library for developing advanced memory models for LLM-based agents, with Memory Models, Memory Operations, Memory Functions, Memory Configurations, Memory Utilities, and LLM components.
- The library provides a hierarchical framework comprising memory functions, operations, and models, supported by configuration and utility modules.
- MemEngine facilitates convenient development and pluggable usage of various pre-implemented and customizable memory models for LLM agents.


---

[Leveraging LLM Agents and Digital Twins for Fault Handling in Process Plants](http://arxiv.org/abs/2505.02076v1)

- Methodological Framework: integrates LLM agents with a Digital Process Plant Twin for autonomous fault handling, utilizing Monitoring Agent, Action Agent, Simulation, Validation Agent, and Reprompting Agent components.
- The framework operates in a closed loop, observing the Process Plant state, generating and validating corrective actions via the Digital Process Plant Twin simulation.
- Plant-specific knowledge from the Digital Twin informs the LLM agents' reasoning for deriving effective and safe corrective control actions.


---

#### 3rd May 2025

[CAMOUFLAGE: Exploiting Misinformation Detection Systems Through LLM-driven Adversarial Claim Transformation](http://arxiv.org/abs/2505.01900v1)

- CAMOUFLAGE (Claim Alteration for Misleading Output Using Feedback from Language Agent GuideancE): introduces an iterative LLM-driven adversarial attack framework with an Attacker Agent, Prompt Optimization Agent, Claim Evaluation, Misinformation Detection System, and History components.
- The Attacker Agent generates perturbed claims guided by the Prompt Optimization Agent, which refines instructions based on feedback from the Claim Evaluation and the target Misinformation Detection System.
- The framework optimizes attacks using only binary feedback from the target system and evaluation metrics, storing past attempts in History to guide future rewrites.


---

[Model Context Protocol-based Internet of Experts For Wireless Environment-aware LLM Agents](http://arxiv.org/abs/2505.01834v1)

- MCP-based Internet of Experts (IoX): introduces a framework equipping LLM Agents with wireless environment awareness by coordinating interactions with Expert Models hosted on Expert Servers via the Model Context Protocol, using input from the Wireless Environment.
- The framework enables the LLM Agent to selectively query and interpret outputs from lightweight, task-specific Expert Models at inference time without modifying its parameters.
- This architecture supports modular, extensible, and interpretable reasoning over wireless contexts, significantly improving classification accuracy compared to standalone LLMs.


---

[A Survey on Inference Engines for Large Language Models: Perspectives on Optimization and Efficiency](http://arxiv.org/abs/2505.01658v1)

- LLM Inference Engine: introduces a comprehensive survey of 25 open-source and commercial engines, detailing their support for Batch Optimization (groups requests), Parallelism (distributes computation), Compression (reduces model size), Fine-Tuning (adapts model), Caching (reuses computations), Attention Optimization (improves attention), Sampling Optimization (speeds token generation), and Structured Outputs (constrains output format).
- The paper examines each inference engine's ease-of-use, ease-of-deployment, general-purpose support, scalability, and suitability for throughput- and latency-aware computation across diverse hardware.
- It provides practical guidance for selecting and designing optimized LLM inference engines by analyzing their design goals, supported optimization techniques, and ecosystem maturity.


---

[The STROT Framework: Structured Prompting and Feedback-Guided Reasoning with LLMs for Data Interpretation](http://arxiv.org/abs/2505.01636v1)

- STROT (Structured Task Reasoning and Output Transformation): introduces a framework for structured data interpretation with LLMs, featuring Schema-Aware Context Construction (Analyze data schema), Prompt Scaffolding and Task Planning (Generate analysis plan), Transformation Logic Synthesis (Generate executable code), Program Execution (Run generated code), Feedback-Driven Refinement (Revise code based on errors), and Final Output (Deliver structured result).
- The framework embeds the LLM within a multi-phase, feedback-driven pipeline that treats data understanding as a dynamic and structured process, enabling iterative reasoning and self-correction.
- This agentic approach improves reliability, interpretability, and semantic alignment for structured data analysis tasks compared to single-shot methods.


---

#### 2nd May 2025

[PIPA: A Unified Evaluation Protocol for Diagnosing Interactive Planning Agents](http://arxiv.org/abs/2505.01592v1)

- PIPA (Unified evaluation Protocol for Interactive Planning Agents): introduces a unified evaluation protocol for interactive planning agents, conceptualizing their behavior within a POMDP paradigm, including Agent (Interactive planning agent), User (Interacts with agent), Interactive Session (Multi-turn dialogue), Intermediate Steps (Agent's internal reasoning), State Consistency Metric (S) (Aligns user requests with steps), Tool Efficiency Metric (A) (Measures tool utilization), Observation Alignment Metric (O) (Aligns observations with user needs), Policy Alignment Metric (P) (Follows predefined policies), and Task Completion Metric (R) (Measures goal achievement).
- The protocol provides a comprehensive assessment through atomic evaluation criteria to diagnose strengths and weaknesses in the agent's decision-making pipeline.
- PIPA enables multi-axis diagnosis and cross-benchmark comparisons, showing that user satisfaction is shaped by both outcomes and intermediate behaviors.


---

[AI agents may be worth the hype but not the resources (yet): An initial exploration of machine translation quality and costs in three language pairs in the legal and news domains](http://arxiv.org/abs/2505.01560v1)

- This paper evaluates five machine translation paradigms: Google Translate (GT), GPT-4o, o1-preview, sequential multi-agent system (s-agent), and iterative multi-agent system (i-agent), comparing their quality and cost-efficiency.
- The study benchmarks these systems using automatic metrics, human evaluation of adequacy and fluency, and token-based cost analysis across three language pairs and two domains.
- Findings indicate that reasoning-enhanced LLMs and multi-agent workflows show potential for higher quality in human evaluation but incur significantly greater computational costs compared to traditional NMT and general LLMs.


---


[WirelessAgent: Large Language Model Agents for Intelligent Wireless Networks](http://arxiv.org/abs/2505.01074v1)

- WirelessAgent: introduces a framework leveraging LLMs to create autonomous AI agents for wireless networks, integrating LLMs (Cognitive engine), Perception (Processes inputs), Memory (Stores data, context), Planning (Organizes tasks, reasons), Action (Executes commands), LangGraph (Graph-based workflow architecture), Global State (Shared workflow memory), External Tools (Specialized capabilities), Knowledge Base (Domain information repository), and System Prompts (Guide agent behavior).
- The framework is built on agentic workflows implemented using the LangGraph architecture to manage complex wireless tasks.
- WirelessAgent demonstrates near-optimal network throughput and higher bandwidth utilization compared to prompt-based methods in network slicing tasks.


---

[VTS-LLM: Domain-Adaptive LLM Agent for Enhancing Awareness in Vessel Traffic Services through Natural Language](http://arxiv.org/abs/2505.00989v1)

- VTS-LLM: introduces a domain-adaptive LLM agent for Vessel Traffic Services, with NER-based relational reasoning (clarifies query-database relations), agent-based domain knowledge injection (integrates maritime knowledge), semantic algebra intermediate representation (bridges natural language to SQL), query rethink (validates and corrects SQL), and LLM (core language model) components.
- The framework formalizes risk-prone vessel identification as a knowledge-augmented Text-to-SQL task, leveraging structured vessel databases and external maritime knowledge, supported by a curated benchmark dataset.
- VTS-LLM demonstrates superior performance and robustness across command-style, operational-style, and formal natural language queries compared to general-purpose and SQL-focused baselines.


---

[Multi-agents based User Values Mining for Recommendation](http://arxiv.org/abs/2505.00981v1)

- ZOOM (Zero-shot Multi-LLMs Collaborative Framework for User Values Mining): introduces a framework for extracting user values from historical interactions using User History, Text Summarization, Evaluators, Decoding Strategies, Supervisors, and Debate to produce User Values.
- The framework employs multi-agent collaboration between evaluators generating diverse value candidates and supervisors refining them through debate to mitigate LLM limitations.
- Text summarization addresses input length constraints, while the multi-agent debate enhances accuracy and reduces hallucinations in value extraction.


---

[Seeking to Collide: Online Safety-Critical Scenario Generation for Autonomous Driving with Retrieval Augmented Large Language Models](http://arxiv.org/abs/2505.00972v1)

- The LLM-driven framework: introduces an online safety-critical scenario generation method featuring an LLM Behavior Analyzer (Infers dangerous intent), Feasible Trajectory Generation (Synthesizes adversarial trajectories), and Dynamic Memorization and Retrieval (Adapts online).
- This framework utilizes a Memory bank (Stores intent-planner pairs) and offline processes including a Code Generator (Generates planner code), Simulation (Evaluates trajectories), and Code Modifier (Refines planner code) to support online adaptation and generation.
- By analyzing historical states, inferring intent, generating trajectories, and dynamically updating a behavior library, the method effectively generates high-risk scenarios for autonomous vehicle testing.


---

[SSRLBot: Designing and Developing an LLM-based Agent using Socially Shared Regulated Learning](http://arxiv.org/abs/2505.00945v1)

- SSRLBot: introduces an LLM-based agent for teamwork evaluation, integrating an LLM Backbone, Instructions/Preamble, SSRL Knowledge, Capabilities, Prompting Strategies, Iterative Refinement, Input, Output, and Output Evaluation to analyze diagnostic conversations.
- Grounded in Socially Shared Regulation of Learning (SSRL) theory, the agent evaluates team members' interpersonal influence and SSRL skills.
- The system provides contextualized feedback, comparative skill analysis, and improvement suggestions for collaborative learning and decision-making.


---


[Structured dataset of reported cloud seeding activities in the United States (2000-2025) using a large language model](http://arxiv.org/abs/2505.01555v1)

- Data Extraction Pipeline: introduces, "a pipeline for creating a structured dataset from historical cloud seeding reports", with PDF Reports (Source documents), Preprocessing (Organizes, merges files), Text Extraction (Converts PDF to text), Prompt Engineering (Designs LLM input), LLM (OpenAI o4-mini) (Extracts structured data), Response Parsing (Processes LLM output), and Structured Dataset (CSV) (Final tabular data), where "the pipeline processes inconsistent PDF reports using LLM-based extraction to generate a structured CSV dataset".
- The pipeline utilizes multi-stage PDF-to-text conversion and chain-of-thought prompting with OpenAI's o4-mini model to achieve high extraction accuracy.
- This framework provides a scalable method for unlocking structured environmental data from historical scanned documents across various scientific domains.


---


#### 1st May 2025

[Thoughts without Thinking: Reconsidering the Explanatory Value of Chain-of-Thought Reasoning in LLMs through Agentic Pipelines](http://arxiv.org/abs/2505.00875v1)

- Agentic Pipeline Framework: introduces an agentic pipeline framework for a perceptive task guidance system, comprising Perceptors (Perceive data (visual/language)), Planners (Decompose tasks/sequence agents), Action agents (Process data/generate response/verify), Tools (External utilities), and Memory/Context (Stores documents/past logs).
- The framework processes user input through a sequence of specialized agents, including Lead planner (Creates agent pipeline plan), Query planner (Assesses query/routes flow), Answer planner (Decides answerability/invokes generator), and various Action agents like RAG (Retrieves/summarizes documents) and Safety Agent (Filters inappropriate responses).
- The paper evaluates Chain-of-Thought reasoning within this pipeline, finding that it does not improve output quality or provide effective explainability for end users in the context of task guidance.


---

[From Texts to Shields: Convergence of Large Language Models and Cybersecurity](http://arxiv.org/abs/2505.00841v1)

- LLM and Agent Applications in Cybersecurity: reports on the convergence of large language models and cybersecurity, exploring emerging applications and challenges of integrating LLM Agent (dynamic reasoning engine), Meta Agent (agent of agents), RAG (retrieval-augmented generation), and Human-in-the-loop (human oversight) approaches.
- The report examines LLM applications in network security, generative security engineering, and socio-technical aspects, including interpretability, safety, and security challenges.
- It outlines a forward-looking research agenda for the secure and effective adoption of LLMs in cybersecurity, integrating technical advances with organizational and societal considerations.


---

[HMCF: A Human-in-the-loop Multi-Robot Collaboration Framework Based on Large Language Models](http://arxiv.org/abs/2505.00820v1)

- HMCF (Human-in-the-loop Multi-Robot Collaboration Framework): introduces a framework for multi-robot collaboration with Assistant LLM agent, Robot LLM agents, Human-in-the-loop mechanism, Heterogeneous Robots, Human-Robot Interaction Interface, and RAG (Retrieval Augmented Generation), enabling efficient and scalable task allocation and execution.
- The framework integrates LLM-based reasoning for task allocation and verification with human oversight to enhance adaptability, safety, and robustness in diverse environments.
- HMCF utilizes a web-based interface for natural language interaction, allowing users to configure robots, monitor operations, and intervene when necessary.


---

[Reasoning Capabilities and Invariability of Large Language Models](http://arxiv.org/abs/2505.00776v1)

- Large Language Models: introduces an evaluation of LLMs' reasoning capabilities using various prompting techniques and a new benchmark dataset focused on shallow logical reasoning with geometric figures.
- The evaluation assesses 24 different LLMs using zero-shot, few-shot, and chain-of-thought prompting on a dataset designed to test logical constructors and invariability to language variations.
- Results indicate that while larger LLMs perform better in zero-shot settings, overall performance on shallow reasoning remains limited, and model behavior is largely invariant to small language variations.


---

[Rethinking Memory in AI: Taxonomy, Operations, Topics, and Future Directions](http://arxiv.org/abs/2505.00675v1)

- Memory Framework: introduces, "a structured and dynamic perspective on memory in AI systems", with Parametric Memory (Implicit model knowledge), Contextual Structured Memory (Explicit organized memory), Contextual Unstructured Memory (Explicit general memory), Consolidation (Integrate short-term into persistent), Updating (Modify memory), Indexing (Organize for retrieval), Forgetting (Remove irrelevant content), Retrieval (Access relevant information), and Compression (Reduce memory size), clarifying functional interplay in LLM-based agents.
- The framework categorizes memory by representation type and defines fundamental operations for memory management and utilization.
- This survey maps these components and operations to relevant research topics and outlines future directions for memory in AI.


---

[USERCENTRIX: AN AGENTIC MEMORY-AUGMENTED AI FRAMEWORK FOR SMART SPACES](http://arxiv.org/abs/2505.00472v1)

- UserCentrix: introduces an agentic memory-augmented AI framework for smart spaces, with User Task Processing (User-side layer), Personal Agent (LLM-powered assistant), Personal Memory (Stores user history/preferences), Knowledge Retrieval Cycle (Memory recall/similarity assessment), Smart Building Side (Building-side layer), Decision-making Module (High-level agents), Classifier Agent (Determines task urgency), High-urgency Agent (Prioritizes speed), Low-urgency Agent (Prioritizes precision/generates solutions), Evaluator Agent (Assesses/selects solutions), Pareto Analyzer (Optimizes decision-making), Memory (Decision-making Module) (Stores solutions/tasks), Sub-tasks Execution Module (Low-level agents), Low-level Agents (Execute sub-tasks/generate commands), Management and Analysis Module (Manages/dispatches commands), Message Queue (Stores commands), Environment Agent (Tracks tasks/adjusts environment), and Smart Building Dataset (Data source), designed to enhance smart spaces through dynamic, context-aware decision-making.
- The framework integrates personalized LLM agents leveraging user preferences and memory management with a hybrid hierarchical control system balancing centralized and distributed processing.
- UserCentrix achieves resource-efficient AI interactions by embedding memory-augmented reasoning, cooperative agent negotiation, and adaptive orchestration strategies.


---

[A Survey on Large Language Model based Human-Agent Systems](http://arxiv.org/abs/2505.00753v1)

- LLM-HAS (LLM-based Human-Agent Systems): introduces a structured survey of these systems, detailing core components including Environment & Profiling (Context, roles, goals, capabilities), Human Feedback (Types, granularity, timing), Interaction Types (Collaboration, competition, coopetition), Orchestration Paradigm (Task strategy, temporal synchronization), and Communication (Structure, mode).
- The survey clarifies fundamental concepts and systematically presents these core components shaping human-agent systems.
- It explores emerging applications, discusses unique challenges, and offers a structured overview to foster research in this interdisciplinary field.


---

[Large Language Models as AI Agents for Digital Atoms and Molecules: Catalyzing a New Era in Computational Biophysics](http://arxiv.org/abs/2505.00270v1)

- ADAM (Agent for Digital Atoms and Molecules): introduces a multi-agent framework for computational biophysics, featuring a Plan Agent, Route Agent, Hybrid Neural-Symbolic Architecture, Neural Tools, Symbolic Tools, ADAM Tool Protocol (ATP), ATP Server, Distributed Tool Executors, Central Database, and Memory.
- The framework employs a hybrid neural-symbolic architecture combining LLM-driven semantic tools with deterministic symbolic computations for scientific workflows.
- Its ADAM Tool Protocol enables asynchronous, database-centric tool orchestration and community-driven extensibility for third-party tool integration.


---

[Self-Generated In-Context Examples Improve LLM Agents for Sequential Decision-Making Tasks](http://arxiv.org/abs/2505.00234v2)

- Traj-Bootstrap: introduces a method for LLM agents to improve performance on sequential decision-making tasks by constructing and refining a Trajectory Database of self-generated successful experiences, used by a ReAct-style Agent via a Retrieval Mechanism interacting with an Environment.
- The approach includes Traj-Bootstrap for naive accumulation, +DB-Selection for population-based database selection, and +Exemplar-Selection for selecting high-utility individual trajectories.
- These methods enable autonomous agent self-improvement without task-specific knowledge engineering, achieving performance comparable to methods using multiple test attempts or stronger LLMs.


---

#### 30th April 2025


[Which Agent Causes Task Failures and When? On Automated Failure Attribution of LLM Multi-Agent Systems](http://arxiv.org/abs/2505.00212v1)

- Automated Failure Attribution: introduces methods (All-at-once Method, Step-by-step Method, Binary Search Method, LLM Judge, Failure Logs, Query, Failure-Responsible Agent, Decisive Error Step) for identifying the agent and step responsible for task failures in LLM multi-agent systems using failure logs.
- The paper evaluates three LLM-based methods: All-at-once processes the full log, Step-by-step processes incrementally, and Binary Search processes log segments.
- The LLM Judge analyzes the query and failure logs to predict the failure-responsible agent and decisive error step.


---

[CoordField: Coordination Field for Agentic UAV Task Allocation In Low-altitude Urban Scenarios](http://arxiv.org/abs/2505.00091v1)

- CoordField: introduces a coordination field agentic system for UAV swarm task allocation, with a Semantic Understanding Module (Interprets natural language), LLM (Parses instructions), Planning Module (Transforms tasks), Planning Agent (Aggregates results), Coordination field (Guides motion, task selection), Perception Mapping (Constructs potential field), Task Decomposition (Converts potential field), Task Assignment (Enhances coordination efficiency), Execution Module (Translates outputs), Execution Agent (Manages control commands), UAV Deployment (Physical or virtual), and Prompt Tools API (Communicates with control), designed for heterogeneous UAV swarms in urban environments.
- The system leverages LLMs for high-precision task understanding and employs a coordination field control strategy for task-oriented autonomous navigation and collective coordination.
- CoordField utilizes dynamically updated potential fields and fluid-based velocity fields to enable decentralized and adaptive allocation of emergent tasks, demonstrating superior performance in task coverage, response time, and adaptability.


---

[TRUST: An LLM-Based Dialogue System for Trauma Understanding and Structured Assessments](http://arxiv.org/abs/2504.21851v1)

- TRUST (TRauma Understanding and Structured Assessments): introduces, "an LLM-based dialogue system for trauma understanding and structured assessments," with Database (stores system memory), Framework (manages dialogue and assessment), Conversation (manages dialogue flow), Assessment (manages assessment logic), LLM (powers conversation and assessment), Dialogue Act Schema (guides conversation), and Patient Simulation (evaluates system), designed to conduct formal diagnostic interviews for PTSD.
- The Database module contains Variable, History, and Score components to store variable metadata, conversation history, and assessment outcomes, respectively.
- The Framework's Conversation and Assessment submodules utilize an LLM for tasks like predicting dialogue acts, generating responses, and performing assessments, while the Dialogue Act Schema provides structured guidance, and Patient Simulation uses an LLM and real-life transcripts for robust evaluation.


---

[LLM-based Interactive Imitation Learning for Robotic Manipulation](http://arxiv.org/abs/2504.21769v1)

- LLM-iTeach: introduces a novel interactive imitation learning framework utilizing an LLM as a teacher for robotic manipulation, featuring an LLM Teacher, Agent, CodePolicy, Hierarchical Prompting, Similarity-checking mechanism, Evaluative feedback, Corrective feedback, Image, Robot State, Convolutional Layers, LSTM, Gauss Distribution, and Action.
- The framework employs hierarchical prompting to generate a CodePolicy from the LLM, which then provides feedback based on a similarity check between the agent's action and the LLM's action.
- The agent learns a stochastic policy parameterized by a Gaussian distribution, processing image and robot state inputs through convolutional layers and an LSTM to determine actions.


---

[LLM-Empowered Embodied Agent for Memory-Augmented Task Planning in Household Robotics](http://arxiv.org/abs/2504.21716v1)

- Agent Orchestrator: introduces an LLM-driven agent-orchestration architecture for embodied robots, with Agent Orchestrator (coordinates specialized agents), Routing Agent (analyzes and directs user requests), Task Planning Agent (handles action commands), Knowledge Base Agent (processes history queries), Memory (stores past actions and environment records), and Perception (provides object detection and scene understanding) components, enabling autonomous household object management.
- The system integrates memory-augmented task planning using RAG for long-term object tracking and utilizes specialized agents powered by task-specific LLMs.
- Perception components like Grounded SAM and LLaMa3.2-Vision facilitate robust object detection and semantic scene understanding for task planning.


---

[UAV-VLN: End-to-End Vision Language guided Navigation for UAVs](http://arxiv.org/abs/2504.21432v1)

- UAV-VLN: introduces, "LLM (Interprets instructions, generates sub-goals) / Automated Task Planner (Maps sub-goals to actions) / Visual Input (UAV camera feed) / Vision Model (Detects objects, Grounding DINO) / Cross-modal Grounding Module (Aligns language and visuals) / Control Pipeline (Executes plans, ROS 2) / UAV (Executes plan, provides visual input)", a novel end-to-end vision-language navigation framework for UAVs that interprets natural language instructions and plans aerial trajectories.
- The framework leverages a fine-tuned LLM for semantic parsing, a vision model (Grounding DINO) for scene understanding, and a cross-modal grounding module to align linguistic intent with visual context.
- An Automated Task Planner maps high-level sub-goals from the LLM to low-level control commands executed via a ROS 2 pipeline on the UAV.


---

[Meeseeks: An Iterative Benchmark Evaluating LLMs Multi-Turn Instruction-Following Ability](http://arxiv.org/abs/2504.21625v1)

- Meeseeks: introduces a multi-round automatic instruction-following benchmark with a hierarchical taxonomy, simulating human-LLM interaction through an iterative feedback process for evaluating LLMs' instruction-following ability.
- The benchmark employs an evaluation system with capability tags across three dimensions, using LLM-based extractors and evaluators alongside rule-based checks.
- Meeseeks utilizes data parameterization for flexible dataset generation and provides metrics like Utility Rate and Meeseeks Score to quantify performance and self-correction capabilities.


---

[Unsupervised Feature Transformation via In-context Generation, Generator-critic LLM Agents, and Duet-play Teaming](http://arxiv.org/abs/2504.21304v1)

- LPFG (Unsupervised Feature Transformation via In-context Generation, Generator-critic LLM Agents, and Duet-play Teaming): introduces a framework for unsupervised feature transformation using a Critic Agent (diagnoses data, provides advice), a Generator Agent (generates features), and Iterative Refinement (feedback loop for improvement).
- The Critic Agent provides semantic and distributional advice to guide the Generator Agent in producing tokenized feature transformations.
- The iterative feedback loop between the agents refines the generated features for improved structural integrity, predictive utility, and format compatibility.


---

[Talk Before You Retrieve: Agent-Led Discussions for Better RAG in Medical QA](http://arxiv.org/abs/2504.21252v1)

- Discuss-RAG: introduces an agent-led framework for medical QA RAG systems, featuring a multi-turn discussion and summarization module with a Recruiter R, Medical Team (Agents Hi), and Summarizer C generating a Distilled summary D, followed by a post-retrieval verification module where a Decision maker U evaluates Snippets S from Trivial RAG before LLMs generate the final Answer A.
- The multi-turn discussion simulates expert brainstorming via iterative Insights I and Output summary T, enriching context for retrieval.
- The post-retrieval verification step filters retrieved content using a Decision maker U and Verifier V, triggering an Alternative retrieval strategy if necessary, to improve answer accuracy and reliability.


---

#### 29th April 2025

[SecRepoBench: Benchmarking LLMs for Secure Code Generation in Real-World Repositories](http://arxiv.org/abs/2504.21205v1)

- SECREPOBENCH: introduces a benchmark construction framework that takes GitHub Projects, OSS-Fuzz Reports, and ARVO Dataset as inputs, uses a Task Constructor (Patch Locator, Mask Generator, Write Description, Code Mutator) to create repository-level code generation tasks, employs a Test Constructor (Unit Test Finder, Security Test Case Finder) to generate correctness and security tests, and outputs the task and tests.
- The framework focuses on generating secure code completion tasks within real-world C/C++ repositories by leveraging known security vulnerabilities and developer-written tests.
- The benchmark evaluates LLMs on their ability to generate correct and secure code in a repository context, which is shown to be more challenging than generating self-contained programs.


---

[AI-in-the-Loop Planning for Transportation Electrification: Case Studies from Austin, Texas](http://arxiv.org/abs/2504.21185v2)

- Urban Planning AI: introduces an AI-in-the-Loop framework for transportation electrification planning, integrating Planner, Urban AI, GeoAI, GenAI, LLMs, AI Agent, Automated System, UI, Community, and Feedback Loop components.
- The framework utilizes GeoAI for site suitability analysis, GenAI for estimations and visualizations, and LLMs for scenario simulations and chatbot interactions.
- Human planners and community feedback are crucial for providing oversight, auditing AI outputs, and ensuring accountable and equitable planning decisions.


---

[LLM Enhancer: Merged Approach using Vector Embedding for Reducing Large Language Model Hallucinations with External Knowledge](http://arxiv.org/abs/2504.21132v1)

- LLM-ENHANCER: introduces a system that enhances open-source LLMs using a User (Provides input), LangChain (Framework), ZeroShot React Agent (Selects tools), Agent Executor (Executes actions), Merged Tool (Combines online sources), Calculator (Performs calculations), Merging Data (Combines source data), Splitter (Divides data into chunks), Embeddings (Creates vector representations), ChromaDB database (Stores vector embeddings), Relevant chunks (Retrieved information), and Mistral 7B (Opensource LLM) (Generates response) to reduce hallucinations by integrating external knowledge.
- The system uses agents to gather data from multiple online sources in parallel, merges it, and processes it via vector embeddings to find relevant information for the LLM.
- This approach aims to provide accurate, up-to-date information to the LLM without extensive fine-tuning, mitigating issues with outdated training data and hallucinations.


---

[Toward Efficient Exploration by Large Language Model Agents](http://arxiv.org/abs/2504.20997v1)

- LLM-based PSRL: introduces an implementation of the Posterior Sampling for Reinforcement Learning algorithm using three distinct LLMs: an approximate posterior updater LLM, a posterior sampler LLM, and an optimal policy LLM.
- This approach explicitly implements an existing RL algorithm by outsourcing individual steps to distinct LLMs, contrasting with methods that implicitly induce RL behavior.
- The framework aims to leverage the exploration properties of PSRL in natural language environments by using LLMs for key functions like updating beliefs, sampling models, and determining optimal actions.


---

[AegisLLM: Scaling Agentic Systems for Self-Reflective Defense in LLM Security](http://arxiv.org/abs/2504.20965v1)

- AegisLLM (Adaptive Agentic Guardrails for LLM Security): introduces a cooperative multi-agent defense system, with Orchestrator (Routes queries based security), Deflector (Handles unsafe inputs, issues refusal), Responder (Generates outputs for safe queries), and Evaluator (Verifies safety of query/response), that ensures safe LLM outputs through a structured agent workflow.
- The framework promotes LLM security via a cooperative, inference-time multi-agent system that continuously monitors, analyzes, and mitigates adversarial threats in real time.
- AegisLLM leverages automated prompt optimization and Bayesian learning for continuous self-improvement without requiring model retraining, enabling real-time adaptability to evolving attacks.


---

[Using LLMs in Generating Design Rationale for Software Architecture Decisions](http://arxiv.org/abs/2504.20781v1)

- LLM-based Agents: introduces a multi-agent system including Aspect_Identifier (Identifies relevant aspects), Information_Collector (Gathers background information), Aspect_Analyst (Analyzes aspects), Aspect_Reviewer (Reviews analysis results), and Trade-off_Analyst (Generates final DR), to generate design rationale for software architecture decisions.
- The study evaluates this multi-agent approach against zero-shot and Chain-of-Thought prompting strategies using five different LLMs on a dataset of architecture problems and decisions from Stack Overflow and GitHub.
- Evaluation metrics include Precision, Recall, F1-score, and a qualitative IHUM-category classification, comparing LLM-generated rationale to human expert rationale.


---

[A Summary on GUI Agents with Foundation Models Enhanced by Reinforcement Learning](http://arxiv.org/abs/2504.20464v1)

- Multimodal LLM-based GUI Agent Architecture: introduces a modular architecture for GUI agents, with Perception (understand GUI), Planning (generate action plans), and Acting (execute actions) components, designed to autonomously interact with digital devices based on task instructions and screen state.
- The Perception module extracts semantic information from the GUI, the Planning module translates this into action plans, and the Acting module converts plans into executable interface interactions.
- The paper reviews the evolution of these modules, highlighting advancements in multimodal perception, dynamic planning, and adaptive action generation enhanced by reinforcement learning.


---

[TAMO:Fine-Grained Root Cause Analysis via Tool-Assisted LLM Agent with Multi-Modality Observation Data](http://arxiv.org/abs/2504.20462v2)

- TAMO: introduces a tool-assisted LLM agent framework for fine-grained root cause analysis, integrating domain-specific tools for data observation, root cause localization, and fault classification with an expert LLM agent.
- The framework decouples the LLM from raw observational data by using specialized tools to process multimodal data and model dynamic dependencies, structuring results for LLM input.
- The expert agent synthesizes tool outputs and system context to provide comprehensive fault analysis and remediation recommendations for site reliability engineers.


---

[CRASHFIXER: A crash resolution agent for the Linux kernel](http://arxiv.org/abs/2504.20412v1)

- CRASHFIXER: introduces an LLM-based agent that resolves Linux kernel crashes by iteratively performing Hypothesis Generation (creates root cause hypotheses) with Self-Reflection (selects best hypothesis), Patch Generation (synthesizes candidate patches) with Compilation Check (filters uncompilable patches) and Self-Consistency (selects patch aligned hypothesis), and Iterative Debug (manages debug cycles/trees/forests), supported by the KGYMSUITE Platform (provides system/tooling support) including an Execution Trace System (collects/minimizes relevant traces), SUITECACHE (provides cached kernel builds), Fast Compilation Check Tool (quickly checks compilation), and Reproducer Run (executes crash-triggering input).
- The agent emulates a kernel developer's workflow, leveraging execution logs and source code to diagnose issues and propose fixes.
- KGYMSUITE enhances the KGYM platform to provide scalable and reproducible evaluation infrastructure for LLM-driven kernel debugging.


---

#### 28th April 2025

[Towards Automated Scoping of AI for Social Good Projects](http://arxiv.org/abs/2504.20010v1)

- PSA (Problem Scoping Agent): introduces an LLM-based pipeline for automated AI for Social Good project scoping, with Background Retrieval, Challenge Retrieval, Method Retrieval, Annotator, Verbalized Confidence, and Solution Generator components.
- The framework leverages retrieval-augmented generation using external search APIs and an LLM to process information and generate project proposals.
- The PSA aims to automate the labor-intensive problem scoping process by identifying relevant background, challenges, and methods to generate comprehensive proposals.


---

[TD-EVAL: Revisiting Task-Oriented Dialogue Evaluation by Combining Turn-Level Precision with Dialogue-Level Comparisons](http://arxiv.org/abs/2504.19982v1)

- TD-EVAL (Turn and Dialogue-level Evaluation): introduces a two-step evaluation framework, with Turn-Level Evaluation (Evaluates individual turns), TOD Agent Arena (Ranks full dialogues), and LLM Judge (Scores, compares responses/dialogues), designed for task-oriented dialogue systems.
- The framework combines fine-grained turn-level analysis using an LLM judge with holistic dialogue-level comparisons via a pairwise ranking method.
- TD-EVAL aims to identify subtle errors missed by traditional metrics and provide a more reliable, human-aligned assessment of conversational quality.


---

[Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents](http://arxiv.org/abs/2504.19956v1)

- Agentic System Architecture: introduces a comprehensive threat model and mitigation framework for generative AI agents, detailing components like the Agent Brain, Memory Systems, and Tool Invocation Layer.
- The architecture highlights how agent autonomy, persistent memory, complex reasoning, and tool integration create novel security risks.
- The paper proposes the ATFAA threat model and SHIELD mitigation framework tailored to these unique agentic properties.


---

[Can AI Agents Design and Implement Drug Discovery Pipelines?](http://arxiv.org/abs/2504.19912v1)

- Deep Thought agentic system: introduces DO Challenge, a benchmark for evaluating AI agents in drug discovery, and presents the Deep Thought multi-agent system designed to solve complex scientific tasks.
- The DO Challenge benchmark requires agents to autonomously develop and execute strategies for identifying promising molecular structures from a large dataset under resource constraints.
- The system, composed of heterogeneous LLM-based agents and computational tools, was evaluated on the benchmark, demonstrating competitive performance compared to human teams and domain experts.


---

[LLM-Powered GUI Agents in Phone Automation: Surveying Progress and Prospects](http://arxiv.org/abs/2504.19838v1)

- LLM-Powered GUI Agent: introduces an architecture for phone automation, with Intent Comprehension, Perception, Brain (Storage, Decision Making), and Action components, where Intent Comprehension maps user goals to UI operations.
- The Perception component gathers UI Info and Phone State, providing input to the Brain for reasoning and decision-making.
- The Action component executes decisions through Touch Interactions and Atomic Skills, enabling interaction with the mobile environment.


---

[Prompt Injection Attack to Tool Selection in LLM Agents](http://arxiv.org/abs/2504.19793v1)

- ToolHijacker: introduces an automated framework for prompt injection attacks targeting LLM agent tool selection, utilizing a Shadow Framework (Simulates target system) with Shadow Task Descriptions (Attacker-generated tasks), Shadow Retriever (Attacker's retriever model), Shadow LLM (Attacker's LLM model), and Shadow Tool Library (Attacker's tool set) to craft a Malicious Tool Document (Injected attack document) comprising a Tool Name (Malicious tool identifier) and Tool Description (Malicious tool details).
- The attack employs a Two-phase optimization (Optimizes retrieval, selection) strategy with Retrieval Objective (Maximize malicious tool retrieval) and Selection Objective (Maximize malicious tool selection), optimized using Gradient-Free Method (Optimizes without gradients) and Gradient-Based Method (Optimizes using gradients) which incorporates Alignment Loss (L1), Consistency Loss (L2), and Perplexity Loss (L3).
- The paper evaluates the attack against standard Tool Selection components (Tool Library, Retriever, LLM Agent) and various defenses including prevention-based (StruQ, SecAlign) and detection-based (Known-answer detection, Perplexity detection, Perplexity windowed detection) methods, demonstrating the attack's effectiveness and the defenses' limitations.


---

[From LLM Reasoning to Autonomous AI Agents: A Comprehensive Review](http://arxiv.org/abs/2504.19678v1)

- General AI Agent Framework: introduces a conceptual architecture with Thinking/Prompt, Strategy Development, Task, Self-Evaluation, Designated Function, Utility Functions/Knowledge Store, AI Query Engines, Knowledge Store, and Agent Execution Environment.
- LangChain: presents an agent architecture including User, Agent (Chat Model, Scratchpad Prompting), Tools, and API for Bookings.
- Agentic RAG (Retrieval-Augmented Generation): integrates LLM (Reasoning, Action) with Modular Toolkits, Reflection, Planning, Tool Utilization, Multi-agent Collaboration, User Interface, System Reply, Internal Knowledge Store, and Retrieval Utilities.


---

[m-KAILIN: Knowledge-Driven Agentic Scientific Corpus Distillation Framework for Biomedical Large Language Models Training](http://arxiv.org/abs/2504.19565v1)

- m-KAILIN: introduces a knowledge-driven, multi-agent framework for distilling high-quality biomedical question-answering corpora, utilizing a Multi-Agent Collaborative Framework, Question Generation Agent, Context Retrieval Agent, Question Evaluation Agent, Answer Generation Agent, MeSH, Dense Passage Retrieval (DPR), BiomedBERT base encoder, Direct Preference Optimization (DPO), Preference Dataset, Training Corpus Dataset, and Target LLM.
- The framework employs specialized agents guided by the MeSH hierarchy to extract, synthesize, and self-evaluate textual data from scientific literature, generating domain-specific question-answer pairs.
- This automated pipeline produces high-quality, preference-based datasets for training biomedical LLMs, ensuring comprehensive coverage and consistency with biomedical ontologies.


---

[Research CodeAgent: An LLM Multi-Agent System for Automated Codification of Research Methodologies](http://arxiv.org/abs/2504.20117v1)

- ResearchCodeAgent: introduces a novel multi-agent system leveraging LLMs to automate research methodology codification, including Planning (determines next action), Research Logs (records history/memory), Workers (execute actions), Environment (input files/context), Action Space (available actions), LLM Cascade (hierarchical LLMs for planning), and Programmatic Constructs (system aids/constraints).
- The system bridges the gap between high-level research concepts and practical implementation by iteratively interacting with a research environment using a flexible agent architecture and dynamic planning.
- ResearchCodeAgent demonstrates improved code quality, error reduction, and significant time savings compared to baseline methods, particularly for complex tasks.


---

[AutoP2C: An LLM-Based Agent Framework for Code Repository Generation from Multimodal Content in Academic Papers](http://arxiv.org/abs/2504.20115v1)

- AutoP2C (An LLM-Based Agent Framework): introduces "Paper-to-Code", a task transforming multimodal paper content into executable code repositories, with repository blueprint extraction, multimodal content parsing, hierarchical task decomposition, and iterative feedback-driven implementation components.
- The framework analyzes existing codebases for structure, extracts and integrates text, images, and tables from papers using tools like MinerU, plans code generation hierarchically, and iteratively refines code through feedback.
- AutoP2C, a multi-agent framework based on large language models, generates multi-file code repositories and explanatory diagrams, addressing challenges of multimodal input and structured code output.


---

[Evolution of Cooperation in LLM-Agent Societies: A Preliminary Study Using Different Punishment Strategies](http://arxiv.org/abs/2504.19487v1)

- LLM-based Multi-Agent System Simulation: introduces a framework using LLM Agents (Agents powered by LLMs), Simulation Environment (Adapted Smallville world), Diner's Dilemma Process (Multi-stage agent interaction), Strategy Evolution (Pairwise imitation mechanism), and LLM Integration (API calls for decisions) to study the evolution of cooperation in agent societies.
- The framework models a realistic n-player diner's dilemma where LLM agents make decisions, calculate payoffs, and update strategies based on punishment mechanisms and pairwise imitation.
- Preliminary results suggest that LLM agents can replicate cooperation dynamics observed in abstract mathematical models, with punishment driving norm emergence.


---

[An Automated Reinforcement Learning Reward Design Framework with Large Language Model for Cooperative Platoon Coordination](http://arxiv.org/abs/2504.19480v1)

- PCRD (Platoon coordination Reward Design): introduces an automated framework for designing RL reward functions for platoon coordination, utilizing an LLM, AIR module, Reward Function Pool, Platoon Coordination Environment, Parallel Training, Training Feedback, and EvoLeap module.
- The framework automates reward function discovery through LLM-driven initialization and iterative optimization based on training feedback.
- The AIR module analyzes environment code and task requirements, while the EvoLeap module evolves reward functions based on training results.


---

[MemO: Building Production-Ready AI Agents with Scalable Long-Term Memory](http://arxiv.org/abs/2504.19413v1)

- MemO: introduces a scalable memory-centric architecture that dynamically extracts, consolidates, and retrieves salient information from ongoing conversations.
- The system operates in extraction and update phases, using an LLM with a tool call interface to manage memories stored in a database.
- An asynchronous summary generator maintains conversation context, while an enhanced variant, MemOº, uses graph-based memory for complex relationships.


---

#### 27th April 2025

[SAGA: A Security Architecture for Governing AI Agentic Systems](http://arxiv.org/abs/2504.21034v1)

- SAGA: introduces a security architecture for governing AI agentic systems, with User (Owner, manages agents), Agent (Autonomous entity, uses LLM), Provider (Central service, manages registries), LLM Backend (Agent core decision component), User Registry (Stores user identities), Agent Registry (Stores agent metadata), Access Contact Policy (User-defined agent rules), One-Time Key (OTK) (Ephemeral key for token), Access Control Token (ACT) (Limited communication token), Access Control Key (Long-term key for token), TLS Credentials (Secure communication), and Agent Metadata (Agent information), enabling user oversight and secure inter-agent communication.
- The architecture utilizes a centralized Provider for registration and policy enforcement, while inter-agent communication occurs directly using cryptographic tokens derived from one-time keys.
- SAGA balances security and performance by allowing users fine-grained control over agent interactions through access control policies and token granularity.


---

[BrowseComp-ZH: Benchmarking Web Browsing Ability of Large Language Models in Chinese](http://arxiv.org/abs/2504.19314v2)

- BrowseComp-ZH: introduces a high-difficulty benchmark for evaluating LLM web browsing in Chinese, built using Reverse Design (answer-first creation) by Expert Annotators (skilled data creators) through a Dataset Construction (topic/question design) process.
- The benchmark features Multi-constraint Design (ensuring answer uniqueness), Non-trivial Retrieval Validation (checking search difficulty), and Evidence Traceability (providing source URLs), validated via a Two-stage Quality Control (rigorous data filtering) process involving Human-in-the-loop Validation (human oversight), AI Agent Verification (initial answer generation), and Manual Verification (human answer checking).
- It evaluates various Benchmarked Models (evaluated LLMs/agents) using specific Grading (scoring model performance) procedures, revealing challenges in multi-hop retrieval and reasoning on the Chinese web.


---

[ANDROIDGEN: Building an Android Language Agent under Data Scarcity](http://arxiv.org/abs/2504.19298v1)

- ANDROIDGEN: introduces a framework to enhance LLM-based Android agents under data scarcity, including ExpSearch (in-context learning from trajectories), ReflectPlan (self-reflection and plan update), AutoCheck (verifies agent operations validity), and StepCritic (evaluates trajectory step-by-step).
- The framework leverages LLMs and its modules to generate high-quality browsing trajectories without manual annotation and train open-source mobile agents.
- Evaluations demonstrate ANDROIDGEN's improvements in reasoning, operational accuracy, and generalization on various Android benchmarks.


---

[APE-Bench I: Towards File-level Automated Proof Engineering of Formal Math Libraries](http://arxiv.org/abs/2504.19110v1)

- APE-Bench I evaluation pipeline: introduces a system for evaluating LLMs on proof engineering tasks, with LLM, DiffRepair, Eleanstic, Lean compiler, and LLM-as-a-Judge components.
- The pipeline uses LLMs to generate patches, normalizes them with DiffRepair, and verifies them syntactically via Eleanstic/Lean compiler and semantically via LLM-as-a-Judge.
- This two-stage verification process assesses both code correctness and adherence to natural language instructions for realistic proof engineering tasks.


---

#### 26th April 2025

[Generative AI in Embodied Systems: System-Level Analysis of Performance, Efficiency and Scalability](http://arxiv.org/abs/2504.18945v1)

- Embodied AI Agent System: introduces a system-level analysis of generative AI-based embodied agents, categorizing them into paradigms and evaluating performance and efficiency across modules, agent scales, and tasks.
- The paper identifies key building blocks including Sensing, Planning, Communication, Memory, Reflection, and Execution, analyzing their contribution to system latency and task success.
- Analysis reveals LLM-based planning and communication are major latency bottlenecks, while memory, reflection, and execution modules are critical for task efficiency and success.


---

[RESHAPING MOFS TEXT MINING WITH A DYNAMIC MULTI-AGENT FRAMEWORK OF LARGE LANGUAGE AGENTS](http://arxiv.org/abs/2504.18880v1)

- MOFh6: introduces a dynamic multi-agent framework of Large Language Agents, including crawler, parsing, comparison, resolution, and generation agents, for reshaping MOFs text mining.
- The system leverages fine-tuned LLMs and specialized agents to extract precise MOF synthesis conditions and structural information from scientific literature.
- MOFh6 provides an end-to-end intelligent interaction system supporting natural language queries, data analysis, and crystal structure visualization for streamlined MOF research.


---

[Stealing Creator's Workflow: A Creator-Inspired Agentic Framework with Iterative Feedback Loop for Improved Scientific Short-form Generation](http://arxiv.org/abs/2504.18805v1)

- SciTalk: introduces a multi-agent framework for generating scientific short-form videos, utilizing Preprocessing Stage (Prepare input materials), Planning Stage (Generate script structure), Editing Stage (Integrate visual elements), Feedback & Evaluation Stage (Assess refine video), Flashtalk Generator (Creates video script), Sceneplan Generator (Subdivides script scenes), Background Assistant (Selects background images), Text Assistant (Generates on-screen text), Effect Assistant (Applies visual effects), Layout Allocator (Determines visual positions), Feedback Agents (Review intermediate outputs), Reflection Agents (Integrate feedback prompts), Evaluation Agent (Assesses final video), Video editing library (Composes final video), Multi-modal LLM (Powers feedback evaluation), OpenAI/Synthesia APIs (Generate audio avatar), and MoviePy (Composites visual elements).
- The framework incorporates an iterative feedback loop where agents evaluate generated content and refine prompts for subsequent iterations.
- SciTalk grounds videos in source materials like text, figures, and screenshots to ensure factual accuracy in scientific video dissemination.


---

[MATCHA: Can Multi-Agent Collaboration Build a Trustworthy Conversational Recommender?](http://arxiv.org/abs/2504.20094v1)

- MATCHA: introduces a multi-agent conversational recommendation framework, with Risk Control Module (filters harmful content), Candidate Generation Module (generates game candidates), Ranking Agent (ranks candidates), Reflection Agent (refines candidates), Explainability Module (generates explanations), Data Sources (game information), User Context (user preferences), and Tools (specialized functions), designed to provide trustworthy game recommendations.
- The framework leverages specialized agents and large language models to handle complex user requests, enhance personalization, and ensure safety and transparency.
- MATCHA demonstrates superior performance across multiple metrics compared to baselines, highlighting the benefits of multi-agent collaboration for conversational recommendation systems.


---


[A Review of 3D Object Detection with Vision-Language Models](http://arxiv.org/abs/2504.18738v1)

- VLMs (Vision-Language Models): introduces a review of 3D object detection with VLMs, detailing the architecture including Image Encoder (processes visual inputs), Multimodal Projector (aligns visual and text), and Text Decoder (generates language output), and the 3D pipeline stages: 2D Object Proposals (initial 2D detection), Projection from 2D to 3D Space (maps 2D to 3D), Hierarchical Feature Alignment (aligns 2D and 3D features), and Refinement and Filtering (refines 3D detections).
- This approach integrates visual perception with natural language understanding to enable semantic reasoning and open-vocabulary detection in 3D space.
- The framework allows for flexible querying, zero-shot generalization, and instruction-based interaction, addressing limitations of traditional geometry-only methods.


---

[MODP: Multi Objective Directional Prompting](http://arxiv.org/abs/2504.18722v1)

- MODP (Multi Objective Directional Prompting): introduces a framework for prompt engineering that treats it as a multi-objective optimization problem, incorporating Data (Input data for evaluation), Objectives (Task-specific and LLM-specific goals), Metrics (Quantifiable measures for objectives), Weights (Prioritization of objectives), Prompts (Instructions for the LLM), LLM (Large Language Model executing prompts), Evaluation (Process of scoring prompts), Human Feedback (Input for refinement), Iteration (Loop for prompt improvement), and Selection (Choosing the optimal prompt).
- The framework systematically identifies and balances task-specific and LLM-specific objectives using a metrics-driven approach with weighted scoring and human feedback.
- The iterative process refines prompts based on performance metrics across multiple objectives to develop robust and high-precision prompts.


---

#### 25th April 2025

[LLMpatronous: Harnessing the Power of LLMs For Vulnerability Detection](http://arxiv.org/abs/2504.18423v1)

- LLMpatronous: introduces an AI-driven approach for vulnerability detection, with RAG (Retrieval Augmented Generation), Vector Database (External knowledge base), MoA (Mixture of Agents), and LLM Agents (Multiple language models), designed to mitigate LLM limitations and improve reliability.
- The approach combines external knowledge retrieval via RAG with collaborative analysis by multiple LLM agents within a MoA architecture to reduce false positives.
- LLMpatronous leverages the collective reasoning power of multiple LLMs grounded by up-to-date vulnerability information from a vector database.


---

[Auto-SLURP: A Benchmark Dataset for Evaluating Multi-Agent Frameworks in Smart Personal Assistant](http://arxiv.org/abs/2504.18373v1)

- Workflow defined for the Auto-SLURP dataset: introduces a multi-agent architecture for smart personal assistants, including a User (initiates query), Workflow (orchestrates agents), Program Manager Agent (orchestrator, delegates tasks), Intent Agent (predicts intent, slots), Time Agent (formats time parameters), Location Agent (formats location parameters), Url Agent (selects URL), Request Agent (executes function call), and Simulated Servers / External Services (backend processes, APIs).
- This architecture simulates end-to-end personal assistant interactions, evaluating language understanding, task execution, and response generation.
- The Program Manager Agent orchestrates the user query flow through specialized agents and backend services to complete multi-step operations.


---

[Evolution of AI in Education: Agentic Workflows](http://arxiv.org/abs/2504.20082v1)

- Agentic Workflows: introduces a review of AI agentic paradigms in education, including Reflection (evaluates past actions/outputs), Planning (decomposes goals into steps), Tool Use (leverages external resources/functions), and Multi-agent Collaboration (multiple agents work together), and presents a Multi-Agent Scoring System (MASS) proof-of-concept with a Supervisor Agent (delegates tasks in MASS), Subagent 1 (scores essay content in MASS), and Subagent 2 (scores essay language in MASS).
- The paper examines how AI Agents, utilizing LLMs as their core reasoning engine, interact with an Environment to achieve goals through these paradigms.
- The MASS system demonstrates the potential of multi-agent architectures for tasks like automated essay scoring, showing improved consistency over single LLM approaches.


---

[Revisiting Data Auditing in Large Vision-Language Models](http://arxiv.org/abs/2504.18349v1)

- VLM Membership Inference (VLM MI): revisits data auditing in large vision-language models, with Vision Encoder, Projector, Language Model, Inner States, WiRED, Probing Methods, Bayes Optimality, Aggregation components, where the paper analyzes challenges and identifies feasible scenarios for membership inference on large vision-language models.
- The study reveals distribution shifts in existing benchmarks, quantified by the WiRED metric, which inflate VLM MI performance.
- Probing VLM inner states and estimating Bayes Optimality show low theoretical limits for MI under unbiased conditions, but fine-tuning, ground-truth text access, and aggregation improve feasibility.


---

[Towards Adaptive Software Agents for Debugging](http://arxiv.org/abs/2504.18316v1)

- Adaptive Agents: introduces an adaptive agentic design for debugging, featuring a Main Agent that manages the process and dynamically creates Specialized Agents to perform specific tasks, with both components collaborating and reflecting iteratively.
- The Main Agent analyzes buggy code, profiles and prioritizes necessary Specialized Agents, and validates their reports, deciding on further iterations if needed.
- This adaptive approach dynamically adjusts the number and roles of agents based on problem complexity, improving bug fix rates and resource usage compared to static designs.


---

[MAGI: Multi-Agent Guided Interview for Psychiatric Assessment](http://arxiv.org/abs/2504.18260v1)

- MAGI (Multi-Agent Guided Interview): introduces a framework that transforms the MINI interview into automatic computational workflows using coordinated multi-agent collaboration, including Navigation Agent (Governs interview flow), Question Agent (Generates questions), Judgment Agent (Validates responses), Diagnosis Agent (Synthesizes diagnosis), and PsyCoT (Reasoning paradigm).
- The framework utilizes four specialized agents to dynamically navigate clinical logic and generate DSM-5 compliant conclusions through structured reasoning traces.
- PsyCoT, the Psychometric Chain-of-Thought reasoning paradigm, enhances transparency by explicitly mapping symptoms to clinical criteria via intermediate psychiatric constructs.


---

[Automating Function-Level TARA for Automotive Full-Lifecycle Security](http://arxiv.org/abs/2504.18083v1)

- DefenseWeaver: introduces a system for automating function-level Threat Analysis and Risk Assessment (TARA) using Automotive Configurations and Threat Scenarios as input, processed by Atomic Structure Representation (OpenXSAM++, Logical Path Extraction, Atom Construction), inferred attack methods via LLM Agent-based Attack Methods Inference (Sub-Tree Constructor, Attack Tree Assembler, Risk Assessor), adapted using LORA fine-tuning and RAG for Adaptation (LoRA, RAG, Expert-Curated TARA Reports, Accumulated TARA Reports), and outputting a TARA Report.
- The system leverages a multi-agent LLM framework to dynamically generate detailed attack trees and risk evaluations from component-specific information, overcoming limitations of static threat libraries.
- DefenseWeaver demonstrates adaptability to evolving threats and diverse standards through LoRA fine-tuning and RAG with expert-curated reports, validated across automotive, UAV, and marine systems.


---

[MultiMind: Enhancing Werewolf Agents with Multimodal Reasoning and Theory of Mind](http://arxiv.org/abs/2504.18039v1)

- MultiMind: introduces, with Multimodal Perceiver, Reasoner, ToM Model, Planner, Monte Carlo Tree Search, and Actor (LLM) components, a framework enhancing LLM agents for social deduction games by integrating multimodal information and Theory of Mind reasoning.
- The framework processes facial expressions, vocal tones, and verbal content to infer player beliefs and optimize communication strategies.
- This approach enables agents to reason about how they are perceived by others and strategically minimize suspicion.


---

[LLM Agent Swarm for Hypothesis-Driven Drug Discovery](http://arxiv.org/abs/2504.17967v1)

- PharmaSwarm: introduces a multi-agent framework including Orchestrator, Data & Knowledge Layer, Terrain2Drug Agent, Paper2Drug Agent, Market2Drug Agent, Shared Memory, Simulation Engine (PETS), Interpretable Binding Affinity Map (iBAM), Central Evaluator (TxGemma), and Output, designed for hypothesis-driven drug discovery.
- The framework orchestrates specialized LLM agents that propose targets and compounds based on diverse biomedical data, which are then validated through simulation and evaluation.
- An iterative workflow with feedback loops and shared memory enables continuous refinement of hypotheses and self-improvement of the system.


---


### 24th April 2025


[Collaborating Action by Action: A Multi-agent LLM Framework for Embodied Reasoning](http://arxiv.org/abs/2504.17950v1)

- MINDcraft: introduces a multi-agent LLM framework for embodied reasoning, with Server (launches/manages agents), Main agent loop (handles messages), Library (high-level actions/queries), and Layer (prompts/calls LLMs) components, designed to enable LLM agents to control characters and collaborate in Minecraft.
- The framework supports agentic instruction following, self-guided play, collaboration, and communication in a grounded environment.
- The paper also introduces MineCollab, a benchmark built on MINDcraft, featuring crafting, cooking, and construction tasks to test collaborative and embodied reasoning.


---


[RAGEN: Understanding Self-Evolution in LLM Agents via Multi-Turn Reinforcement Learning](http://arxiv.org/abs/2504.20073v1)

- RAGEN (modular system for training and evaluating LLM agents): introduces StarPO (State-Thinking-Actions-Reward Policy Optimization), a general framework for trajectory-level agent RL, where the LLM interacts with an Env via Rollout to generate a Trajectory, using Reward Assignment and Advantage Estimation for Policy Optimization during Update.
- The paper identifies instability patterns in multi-turn RL and proposes StarPO-S, a stabilized variant incorporating Trajectory Filtering, Critic, Decoupled Clipping, KL Term Removal, and Clip-Higher to improve training robustness.
- RAGEN serves as a research infrastructure to study LLM agent training dynamics in multi-turn, stochastic Environments, revealing insights into gradient stability, rollout quality, and the need for meticulous reward design for reasoning emergence.


---


[Toward Personalizing Quantum Computing Education: An Evolutionary LLM-Powered Approach](http://arxiv.org/abs/2504.18603v1)

- ITAS (Intelligent Teaching Assistant System): introduces a novel system for personalized quantum computing education, featuring a Lesson Planning Agent (Generates, revises lesson plans), Teaching Agent (Manages interaction, provides assistance), Knowledge Graph (Central persistent memory, state), Tag System (User intent, control, structured input), Video Player (Shows video lectures, tutorials), Code Editor (IDE) (Writing, executing quantum code), Chat Interface (CI) (Student-system interaction), and Lesson Presentation (Presents lesson plan steps).
- The system employs a two-agent architecture coordinated by a central Knowledge Graph to provide context-aware tutoring and dynamically adapt lesson plans based on student interaction and explicit tag input.
- The Tag System empowers users to guide the learning process and mitigate LLM hallucination by providing structured input, while the Knowledge Graph stores interaction data for future analysis and learning path enhancement.


---

[Toward a Human-Centered Evaluation Framework for Trustworthy LLM-Powered GUI Agents](http://arxiv.org/abs/2504.17934v1)

- GUI Agent: introduces LLM-powered GUI agents, with User Input (receives commands), GUI Agent (system), GUI Perception (analyzes UI), LLM Processing (interprets, plans), GUI Interaction (executes actions), where the paper examines their privacy and security risks and advocates for a human-centered evaluation framework.
- The paper identifies key risks like amplified data leaks, diminished control, and insufficient guardrails, highlighting challenges in human-centered evaluation due to system complexity and user overtrust.
- It advocates for integrating risk assessments, in-context consent, and embedding privacy into agent design and evaluation to ensure trustworthiness.


---

[Assessing the Potential of Generative Agents in Crowdsourced Fact-Checking](http://arxiv.org/abs/2504.19940v1)

- Framework: introduces a system simulating crowdsourced fact-checking with Generative Agents (autonomous entities) powered by LLMs (power agents) using a Dataset (statements, evidence), involving Data Preparation (tailor data) with Statements Selection (choose claims), Web Page List Creation (verify evidence links), Summary Generation (create evidence summaries), and Agent Profile (define agent attributes), followed by a Simulation Workflow (mimic fact-checking) where agents perform Single Statement Assessment (agent evaluates statement) including Evidence Selection (agent chooses evidence) and Questionnaire Completion (agent rates dimensions), instantiated using PyAutogen (instantiate agents).
- The framework evaluates generative agents' performance against human crowds in truthfulness classification and consistency.
- Generative agents demonstrate superior performance, higher internal consistency, and reduced bias compared to human evaluators.


---


[Towards a HIPAA Compliant Agentic AI System in Healthcare](http://arxiv.org/abs/2504.17669v1)

- HIPAA Compliant Agentic AI Framework: introduces a system for securing autonomous workflows in healthcare, integrating dynamic Attribute-Based Access Control, hybrid PHI sanitization, and immutable audit trails via Client, EHR, Policy Enforcement Agent, Sanitization Agent, LLM API or On-Premise Model, Policy Decision Agent, Middleware Agent, Post-Inference Redaction Agent, Audit Agent, and Downstream Task components.
- The framework enforces regulatory compliance through context-aware policy enforcement, pre- and post-inference PHI sanitization, and cryptographic audit trails.
- This architecture aims to enable the responsible deployment of agentic AI systems in clinical settings by ensuring HIPAA compliance throughout data interactions.


---


[Comprehend, Divide, and Conquer: Feature Subspace Exploration via Multi-Agent Hierarchical Reinforcement Learning](http://arxiv.org/abs/2504.17356v1)

- HRLFS (Hierarchical Reinforcement Learning for Feature Selection): introduces a feature selection framework based on a comprehend-divide-and-conquer paradigm, utilizing Hybrid Feature State Extraction, Clustering, Agent Hierarchy Construction, Hierarchical Agents, Feature Subspace Exploration via an RL Loop with State, Action, Reward Estimation, Policy Network, Memory, Optimization Phase, and Actor-Critic.
- The framework employs LLMs and GMM for comprehensive feature understanding, H-clustering for dividing features into groups, and a hierarchical multi-agent RL architecture for efficient subspace exploration.
- HRLFS demonstrates improved performance and computational efficiency compared to single-agent and one-agent-per-feature RL methods by strategically managing feature selection through a hierarchical structure.


---

[A RAG-BASED MULTI-AGENT LLM SYSTEM FOR NATURAL HAZARD RESILIENCE AND ADAPTATION](http://arxiv.org/abs/2504.17200v1)

- WildfireGPT (A RAG-Based Multi-Agent LLM System): introduces a retrieval-augmented generation (RAG)-based multi-agent LLM system to support natural hazard decision-making, including Task Orchestrator Agent, User Profile Agent, Planning Agent, Analyst Agent, LLM Agent, Evaluation Agent, Data Sources, Literature Search Dataset, Embedding Model, Vector Store, OpenAI Assistant API, Streamlit-based web app, Conversation History, Retrieved Context, and Prompt Augmentation components.
- The system employs a user-centered, multi-agent design to deliver tailored risk insights by integrating diverse data and scientific literature through an RAG framework.
- Evaluation across expert-led case studies demonstrates the system's effectiveness in providing accurate and contextually relevant information for decision support.


---

[Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning](http://arxiv.org/abs/2504.17192v1)

- PaperCoder: introduces, with Planning (construct roadmap), Analyzing (interpret details), Coding (generate code), and Task-specialized LLM agents (instantiate phases), a multi-agent LLM framework transforming machine learning papers into functional code repositories.
- The framework operates in three sequential stages: planning, analysis, and code generation, emulating a human software development workflow.
- Task-specialized LLM agents instantiate each phase, collaborating effectively across the pipeline to produce modular, dependency-aware code.


---


#### 23rd April 2025


[A Survey of AI Agent Protocols](http://arxiv.org/abs/2504.16736v1)

- AI Agent Protocols: introduces a systematic classification and analysis of existing communication protocols for LLM agents, detailing their core architecture including Foundation Model, Memory Systems, Planning, Tool-Using, and Action Execution components.
- The survey categorizes protocols into context-oriented (e.g., MCP with Host/Client/Server/Resource) and inter-agent (e.g., A2A with Agent Card/Task, ANP with Identity Layer/Meta-Protocol Layer/Application Protocol Layer, Agora with Protocol Documents, Agent Protocol with Runs/Threads/Store).
- It evaluates protocols based on dimensions like efficiency, scalability, security, reliability, extensibility, operability, and interoperability, providing insights for designing robust communication infrastructures for intelligent agents.


---

[Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments](http://arxiv.org/abs/2504.17087v1)

- Meta-Judge Selection Framework: introduces a three-stage pipeline including prompt design, meta-judge score calculation with a multi-agent module, and score-based selection.
- The framework utilizes a refined rubric and multiple LLM agents to evaluate raw LLM judgments, aggregating scores through methods like majority voting or weighted averaging.
- A threshold is applied to the final meta-judge score to select trustworthy judgments, aiming to improve precision compared to single-agent or raw judgments.


---


[OptimAI: Optimization from Natural Language Using LLM-Powered AI Agents](http://arxiv.org/abs/2504.16918v1)

- OptimAI: introduces a framework for solving optimization problems from natural language, with Formulator (Translates natural language), Planner (Proposes solution strategies), Coder (Generates solver code), and Code Critic (Performs reflective debugging) components.
- The framework translates natural language into mathematical formulations, plans solution strategies, generates executable code, and refines code through debugging.
- OptimAI employs a multi-agent architecture and uses UCB-based debug scheduling to dynamically switch between alternative plans during debugging.


---

[Do Large Language Models know who did what to whom?](http://arxiv.org/abs/2504.16884v1)

- Large Language Models (LLMs): investigates whether pre-trained LLMs, including BERT, GPT2-Small, Llama 2, and Persimmon, capture thematic roles by analyzing their Hidden Units and Attention Heads.
- The study uses representational similarity analysis and SVM classification on internal representations to assess thematic role encoding.
- Findings indicate thematic role information is weakly represented in hidden units but reliably available in attention heads, differing from human judgments.


---

[MONTE CARLO PLANNING WITH LARGE LANGUAGE MODEL FOR TEXT-BASED GAME AGENTS](http://arxiv.org/abs/2504.16855v1)

- MC-DML (Monte Carlo planning with Dynamic Memory-guided Large language model): introduces a text-based game agent that combines MCTS (Monte Carlo Tree Search) with an LLM (Large Language Model) guided by a Dynamic Memory Mechanism (integrates past experiences) using In-Trial Memory (current trajectory history) and Cross-Trial Memory (reflections from failures) for action selection via PUCT (action selection formula).
- The LLM serves as the initial policy and dynamically adjusts action evaluations during planning based on the integrated memory mechanisms.
- This approach enhances action exploration and performance in complex text-based games by enabling the agent to learn from past experiences.


---


[IRIS: Interactive Research Ideation System for Accelerating Scientific Discovery](http://arxiv.org/abs/2504.16728v1)

- IRIS (Interactive Research Ideation System): introduces a human-in-the-loop platform for scientific ideation, featuring an Ideation Agent, Review Agent, and Retrieval Agent, guided by Monte Carlo Tree Search for iterative idea exploration.
- The system allows researchers to refine research briefs through fine-grained feedback and targeted literature retrieval, balancing human control with automation.
- MCTS enables systematic exploration of the idea space, while the Review Agent provides feedback based on a hierarchical taxonomy to mitigate issues like "reward hacking".


---

[Enhancing LLM-Based Agents via Global Planning and Hierarchical Execution](http://arxiv.org/abs/2504.16563v1)

- GoalAct: introduces a novel agent framework with Global Planning (Continuously updated task plan) and Hierarchical Execution (Decomposes task into skills), interacting with User Query (Initial task input), Historical Record (Past steps actions observations), and Environment (External interaction space).
- The framework uses continuously updated global planning to maintain long-term goals and ensure plan feasibility based on real-time feedback.
- Hierarchical execution decomposes tasks into high-level skills like searching, coding, and writing, enhancing adaptability and reducing planning complexity.


---

[Amplified Vulnerabilities: Structured Jailbreak Attacks on LLM-based Multi-Agent Debate](http://arxiv.org/abs/2504.16489v1)

- Structured Prompt Rewriting Framework: introduces a method to amplify jailbreak attacks on Multi-Agent Debate systems, with Narrative Encapsulation, Role-Driven Escalation, Iterative Refinement, and Rhetorical Obfuscation components.
- This framework embeds malicious queries in scenarios, exploits agent roles, refines content iteratively, and uses obfuscating language to bypass safety filters.
- The method significantly increases harmfulness and attack success rates against various MAD frameworks and underlying LLMs.


---

[Less is More: Enhancing Structured Multi-Agent Reasoning via Quality-Guided Distillation](http://arxiv.org/abs/2504.16408v1)

- Less is More: introduces a structured multi-agent reasoning framework, with Prompt Induction (Derives task prompts), Retrieval-Augmented In-Context Learning (Retrieves context examples), Reasoning Synthesis (Generates structured data), Dual-Stage Filtering (Filters synthesized data), Reward Model (Scores data quality), Distilled Datasets (Filtered training data), Supervised Fine-Tuning (Trains task models), Meta-Llama-3-8B-Instruct (Base language model), and Inference Agents (Task-specific fine-tuned models), designed to enhance structured multi-agent reasoning under low-resource conditions via quality-guided distillation.
- The framework generates high-quality training data from minimal labeled examples using prompt induction, retrieval-augmented synthesis, and dual-stage filtering based on structural validity and reward scores.
- Task-specific agents for question parsing, CoT parsing, and verification are fine-tuned on the distilled data, enabling modular and interpretable reasoning.


---

ClarifyCoder: Clarification-Aware Fine-Tuning for Programmatic Problem Solving](http://arxiv.org/abs/2504.16331v1)

- ClarifyCoder: introduces a novel framework for enhancing code LLMs, utilizing a Data Synthesis Technique (Generates ambiguous problems/questions) to create Clarify-Aware Synthetic Data (Dataset for clarification training) for Targeted Instruction Tuning (Fine-tunes LLM for clarification) of a Pre-trained LLM (Base language model) to produce a ClarifyCoder Model (Fine-tuned clarification-aware LLM).
- The Data Synthesis Technique automatically generates ambiguous problem descriptions and corresponding clarifying questions to train models to recognize and query uncertainties.
- Targeted Instruction Tuning combines synthetic data with standard data to enable the ClarifyCoder Model to prioritize clarification over immediate code generation when faced with ambiguity.


---


#### 22nd April 2025

[A Comprehensive Survey in LLM(-Agent) Full Stack Safety: Data, Training and Deployment](http://arxiv.org/abs/2504.15585v1)

- Full Stack LLM (Agent) Safety: introduces a comprehensive survey on LLM and LLM-agent safety across their lifecycle, including Data (Data collection, synthesis), Pre-training (Data cleaning, enhancement), Post-training (Model adaptation, safety correction), Editing & Unlearning (Knowledge update, removal), LLM (Large Language Model backbone), Agent Modules (Agent capabilities, interaction), Environment (Agent operating context), Multi-agent Systems (Interacting agent entities), Evaluation (Safety, utility assessment), Attacks (Adversarial threats), and Defenses (Mitigation strategies).
- The survey systematically examines safety issues from data preparation through deployment, covering attacks, defenses, and evaluation methods at each stage.
- It highlights the unique challenges and research directions for LLM-based agents, emphasizing the security of external modules like tools and memory.


---


[MR. Video: “MapReduce” is the Principle for Long Video Understanding](http://arxiv.org/abs/2504.16082v1)

- MR. Video: introduces a MapReduce principle for long video understanding, employing Captioning, Intention Analysis, and Goal-Aware Analysis stages, each with Map and Reduce steps, utilizing VLM (video perception model) and LLM (language reasoning model).
- The framework performs sequence-parallel perception of short video segments in the Map steps and aggregates information for global comprehension in the Reduce steps.
- This approach demonstrates significant accuracy improvement on challenging long video benchmarks compared to existing methods.


---

[LLMs are Greedy Agents: Effects of RL Fine-tuning on Decision-Making Abilities](http://arxiv.org/abs/2504.16078v1)

- RLFT (Reinforcement Learning Fine Tuning): fine-tunes a Pre-trained LLM (generates output tokens) using Reward (feedback from environment/shaping) from the Environment (provides states/rewards), storing data in a Buffer (stores interaction data), processing Input Template (structures input context) to produce Output (generated tokens (CoT + action)), and applying Update (policy optimization step).
- The approach leverages self-generated Chain-of-Thought rationales to iteratively refine the LLM's reasoning process towards higher rewards in decision-making scenarios.
- Experiments demonstrate that RLFT mitigates prevalent LLM failure modes like greediness and frequency bias, improving exploration and reducing the knowing-doing gap.


---

[Towards Test Generation from Task Description for Mobile Testing with Multi-modal Reasoning](http://arxiv.org/abs/2504.15917v1)

- VISIDROID: introduces a multi-modal framework for mobile test generation, with Task Goal (Natural language task description), LLM Action Selector (Decides next action), Executor (Executes action on app), Screenshot (Captures GUI image), LMM Verifier (Checks task completion), Sequence of Actions (Generated action steps), Sequence Ranking (Ranks action sequences), Test Script Generator (Creates test script), Observer (Detects UI changes), UI Changes (Changes in GUI), Task Memory (Short-term context), Persistent Memory (Long-term experience), and LLM Reflector (Generates rules/steps).
- The framework iteratively determines the next action using LLMs and leverages visual images of screens via a multi-modal verifier to detect task completeness.
- It combines short-term task memory and long-term persistent memory to enhance decision-making and learn from past interactions.


---

[A closer look at how large language models “trust” humans: patterns and biases](http://arxiv.org/abs/2504.15801v1)

- Experimental Framework: introduces, "a study on LLM implicit trust in humans", with LLMs (Agents studied), Simulated Scenarios (Contexts for trust), Prompting Procedure (Elicits LLM responses), Trustee Attributes (Manipulated input variables), Trust Measurement (Quantifies LLM trust), Analysis (Statistical evaluation), Simulation Environment (Experiment execution), and Data Storage (Results and code), where "the framework investigates how LLMs' trust in humans is influenced by perceived trustworthiness and demographic factors across various scenarios."
- The study demonstrates that LLMs exhibit implicit trust behaviors sensitive to trustworthiness and demographics, showing both human-like patterns and model-specific variations and biases.
- Understanding these LLM trust dynamics is crucial for integrating AI agents into sensitive decision-making processes and mitigating potential biases.


---

[WALL-E 2.0: World Alignment by NeuroSymbolic Learning improves World Model-based LLM Agents](http://arxiv.org/abs/2504.15785v1)

- WALL-E 2.0 (World Alignment by NeuroSymbolic Learning): introduces a training-free approach to align LLMs with environment dynamics, including Model-Predictive Control (Controls agent decisions), Agent Model (LLM) (Plans agent actions), World Model (LLM) (Predicts environment outcomes), World Model (Code Rules) (Verifies LLM predictions), NeuroSymbolic Learning (Learns symbolic knowledge), Symbolic Knowledge (Action Rules) (Captures action constraints), Symbolic Knowledge (Knowledge Graph) (Represents feasibility constraints), Symbolic Knowledge (Scene Graph) (Provides global scene info), Code Rules (Executable symbolic knowledge), Pruning (Selects impactful code rules), and Environment (Agent interaction space).
- The framework iteratively learns symbolic knowledge from trajectories, translates it into executable code rules, and uses these rules to align the LLM world model's predictions with the environment.
- This neurosymbolic world model enables the LLM agent to perform efficient and reliable planning through a model-predictive control loop, significantly improving performance in open-world environments.


---

[IMPLEMENTING RATIONAL CHOICE FUNCTIONS WITH LLMS AND MEASURING THEIR ALIGNMENT WITH USER PREFERENCES](http://arxiv.org/abs/2504.15719v1)

- Proposed Methods: introduces design principles for implementing rational choice functions using LLMs, including Pairwise-Score (Scores alternatives from pairwise LLM comparisons) and Pairwise-SCC (Uses SCCs from pairwise LLM comparisons), and provides metrics Strict Preference Overlap (SPO) (Measures partial alignment) and Kendall distance with penalty (K(p)) (Measures full alignment) to measure alignment with user preferences, encompassing strict preferences and indifference.
- The framework addresses the challenge of aligning LLM-based decision-making in intelligent user interfaces with user preferences, which is crucial for reliability and trustworthiness.
- Empirical validation in an automotive domain use case demonstrates the applicability of the proposed principles and metrics, highlighting their distinct strengths for achieving partial or full alignment.


---


[DianJin-R1: Evaluating and Enhancing Financial Reasoning in Large Language Models](http://arxiv.org/abs/2504.15716v1)

- DianJin-R1: introduces a reasoning-augmented framework for financial reasoning, utilizing a Base Language Model, Supervised Fine-Tuning Module, and Reinforcement Learning Module.
- The framework enhances reasoning by training on specialized data and refining performance with a Reward Module during reinforcement learning.
- The resulting DianJin-R1 Model demonstrates improved performance on complex financial reasoning tasks.


---

[A Multi-Agent Framework for Automated Qinqiang Opera Script Generation Using Large Language Models](http://arxiv.org/abs/2504.15552v1)

- Multi-Agent Framework: introduces a novel framework for automated Qinqiang opera script and performance generation, including Agent1 (Script Generation), Agent2 (Visual Content Generation), and Agent3 (Speech Synthesis).
- The framework integrates LLMs for scriptwriting, visual generation models for scene creation, and TTS synthesis for vocal performance.
- This multi-agent approach streamlines the production pipeline, achieving high expert ratings for script fidelity, visual coherence, and speech accuracy.


---

[A Framework for Testing and Adapting REST APIs as LLM Tools](http://arxiv.org/abs/2504.15546v1)

- Framework for Tool Testing in Agentic Flows: introduces a novel framework for evaluating and enhancing the readiness of REST APIs to function as tools for LLM-based agents, utilizing Tool Builder, API to Tool Conversion, Tools Catalog, API test case generation, LLM based NL test case generation, NL test cases execution, API test cases execution, Agentic Framework Setup, Agentic Framework, Tool Evaluation and Error Analysis, NL Test cases execution report, and API Test Cases execution report components.
- The framework transforms APIs into tools, generates comprehensive test cases, translates them into natural language instructions for agents, enriches tool definitions, and evaluates the agent's ability to correctly invoke APIs and process responses.
- The work analyzes test case outcomes and presents an error taxonomy to provide actionable insights for improving tool definitions and integrations for agent-based applications.



---



#### 21st April 2025


[A SELF-IMPROVING CODING AGENT](http://arxiv.org/abs/2504.15228v1)

- SICA (Self-Improving Coding Agent): introduces, "a self-improving coding agent capable of editing its own codebase", with Agent (LLM wrapper taking actions), Base Agent (initial self-improvement agent), Meta-Agent (agent performing improvement), Archive (stores past agents/results), Evaluation Benchmarks (tasks measure performance), Utility Function (selects best agent), Tools (basic agent actions), Sub-Agents (specialized task handlers), Asynchronous Overseer (monitors agent behavior), LLM Context Window (LLM input structure), LLM Context Window System Prompt (agent setup instructions), LLM Context Window Core Prompt (problem and file context), LLM Context Window Assistant Messages (agent interaction history), Callgraph (agent execution tree), and Event Stream (detailed interaction log), where "SICA is designed to autonomously improve performance on coding tasks by modifying its own code".
- The system operates via a meta-agent loop, where the best performing agent from an archive is selected to improve the current agent based on benchmark results.
- Key components include a structured LLM context window, various tools for file manipulation and execution, specialized sub-agents for task decomposition, and an asynchronous overseer for monitoring and intervention.



---

[In-context Ranking Preference Optimization](http://arxiv.org/abs/2504.15477v1)

- IRPO (In-context Ranking Preference Optimization): introduces a novel framework that directly optimizes LLMs based on ranking lists constructed during inference, incorporating graded relevance and positional importance within a differentiable objective.
- The framework extends Direct Preference Optimization (DPO) to handle sparse, in-context ranking feedback by modeling positional preferences and aggregating them into a list preference model.
- IRPO's optimization is linked to importance sampling gradient estimation, providing theoretical insights into its adaptive prioritization mechanism and efficiency.


---

[Agent for User: Testing Multi-User Interactive Features in TikTok](http://arxiv.org/abs/2504.15474v1)

- Multi-agent LLMs framework: introduces an automated approach for testing multi-user interactive features in apps like TikTok, utilizing a Virtual Device Farm for device allocation and LLM-driven User Agents for task automation based on Task Description, Action Space, and GUI Screen Representation, executing actions via ADB.
- The framework breaks down multi-user tasks into subtasks via Task Assignment, enabling collaborative simulation by multiple User Agents on allocated virtual devices.
- This approach aims to overcome challenges in testing multi-user features by mimicking human-like interaction and coordination across multiple devices.


---

[LLM-Assisted Translation of Legacy FORTRAN Codes to C++: A Cross-Platform Study](http://arxiv.org/abs/2504.15424v1)

- LLM-Assisted Translation Evaluation Workflow: introduces a process for evaluating LLM-based Fortran to C++ code translation, including Fortran Code (Input code), Prompt (Translation instructions), Prompt Builder (Combines code and prompt), LLM (Translates code), Translated C++ Code (LLM output), Ground Truth C++ (Human reference), CodeBLEU Computation (Code similarity metric), C++ Compilation (Checks for errors), C++ Execution (Runs compiled code), Output Comparison (Compares program outputs), and Evaluation Recording (Stores results).
- The workflow evaluates translation quality by comparing LLM output to human ground truth, checking compilation success, and comparing the output of compiled translated code to the original Fortran code's output.
- This platform-independent workflow aims to provide standardized evaluation measures for machine-generated code translation across different LLMs and computational platforms.


---


[Interpretable Locomotion Prediction in Construction Using a Memory-Driven LLM Agent With Chain-of-Thought Reasoning](http://arxiv.org/abs/2504.15263v1)

- Locomotion Prediction Agent: introduces a system for predicting user locomotion modes in construction environments, comprising a Perception Module, Short-Term Memory (STM), Long-Term Memory (LTM), Refinement Module, and a Large Language Model (LLM).
- The agent utilizes multimodal inputs, including spoken commands and visual data from smart glasses, processed by the Perception Module.
- Memory systems (STM and LTM) provide context for prediction and refinement, enhancing accuracy and reliability, particularly for ambiguous or safety-critical scenarios.


---


[DistilQwen2.5: Industrial Practices of Training Distilled Open Lightweight Language Models](http://arxiv.org/abs/2504.15027v1)

- DistilQwen2.5 (Distilled Open Lightweight Language Models): introduces a family of distilled lightweight LLMs derived from Qwen2.5 models, leveraging Teacher LLMs and a Knowledge Production Pipeline to generate augmented instruction-response data for Black-Box Distillation Trainer, and a Distillation Training Pipeline with White-Box Distillation Trainer using teacher logits to train Student LLMs.
- The approach combines black-box and white-box knowledge distillation techniques for efficient training of smaller models.
- The framework includes pipelines for data generation and student model training, utilizing different distillation methods.


---

[EducationQ: Evaluating LLMs' Teaching Capabilities Through Multi-Agent Dialogue Framework](http://arxiv.org/abs/2504.14928v1)

- EducationQ: introduces, with Student Agent (Simulates student), Teacher Agent (Provides teaching), Evaluator Agent (Assesses teaching), and Dataset (Provides questions), a multi-agent dialogue framework to evaluate LLMs' teaching capabilities through simulated dynamic educational scenarios.
- The framework assesses teaching effectiveness by measuring student learning gains via pre/post-tests and analyzing pedagogical strategies using an automated evaluator agent.
- EducationQ demonstrates that effective LLM teaching requires specialized optimization beyond simple scaling and highlights the need for interaction-based evaluation frameworks.


---

[PLANET: A Collection of Benchmarks for Evaluating LLMs' Planning Capabilities](http://arxiv.org/abs/2504.14773v1)

- PLANET (A Collection of Benchmarks for Evaluating LLMs' Planning Capabilities): introduces a survey categorizing benchmarks for evaluating LLMs' planning capabilities across seven domains, including embodied environments, web navigation, scheduling, games, everyday tasks, text reasoning, and agentic settings.
- The paper identifies commonly used testbeds, highlights potential gaps in current benchmarks, and offers guidance for future development.
- The survey aims to help researchers select suitable benchmarks and understand the challenges in evaluating LLM planning performance.


---


[SWE-SYNTH: Synthesizing Verifiable Bug-Fix Data to Enable Large Language Models in Resolving Real-World Bugs](http://arxiv.org/abs/2504.14757v1)

- SWE-SYNTH: introduces a framework for synthesizing realistic, verifiable, and process-aware bug-fix datasets, including Original Program (Source code base), Component Selection (Chooses code part to modify), Masking (Removes component implementation), Large Language Model (LLM) (Re-implements masked component), Variant Integration (Inserts re-implemented component), Test Suite (Runs tests, verifies variants/fixes), Variant Filtering (Selects buggy variants), LLM Agent (Generates repair steps/patch), Intermediate Repair Steps (Sequence of agent actions), Patch (Code fix), and Ground-Truth Extraction (Derives patch/steps from rollouts).
- The framework leverages LLM agents to simulate debugging workflows, producing bug-fix pairs, test cases, and structured repair trajectories.
- SWE-SYNTH scales with minimal human effort and preserves contextual richness and correctness compared to manually curated datasets.


---

#### 20th April 2025

[AI with Emotions: Exploring Emotional Expressions in Large Language Models](http://arxiv.org/abs/2504.14706v1)

- LLM Agent with Emotional Expression: introduces using Large Language Models as AI agents to role-play with specified emotional states defined by Russell's Circumplex Model, generating text evaluated by a Sentiment Analysis Model trained on the GoEmotions Dataset.
- The approach uses prompt design to control emotional expression via arousal and valence parameters.
- Evaluation compares specified and generated emotional states using cosine similarity, demonstrating LLMs' capability for emotional expression.


---

[An LLM-enabled Multi-Agent Autonomous Mechatronics Design Framework](http://arxiv.org/abs/2504.14681v1)

- LLM-enabled Multi-Agent Autonomous Mechatronics Design Framework: introduces a multi-agent system for autonomous mechatronics design, including High-Level Planning Agent, Mechanical Design Agent, Simulation & Validation Agent, Electronics Design Agent, Embedded Software Agent, Human Feedback, and Requirements, designed to generate functional prototypes with minimal direct human input.
- The framework employs a hierarchical architecture where a High-Level Planning Agent decomposes tasks for specialized domain agents, integrating structured human feedback throughout the process.
- Specialized agents handle mechanical design, simulation and validation, electronics design, and embedded software development, collaborating to address complex, interdisciplinary engineering challenges.


---

[A Framework for Benchmarking and Aligning Task-Planning Safety in LLM-Based Embodied Agents](http://arxiv.org/abs/2504.14650v1)

- Safe-BeAl: introduces a framework for benchmarking and aligning task-planning safety in LLM-based embodied agents, with SafePlan-Bench (Benchmarking system) for evaluation and Safe-Align (Alignment method) for mitigation.
- SafePlan-Bench evaluates safety using a Data generation (Creates safety data) pipeline to create the SafeRisks dataset and a Safety Detection (Evaluates safety) method based on mappings.
- Safe-Align integrates physical-world safety knowledge by treating atomic actions as optimization units via Atomic Action Alignment (Optimizes action sequences) and using Training Data Construction (Builds preference dataset) for alignment.


---

[Towards Optimal Circuit Generation: Multi-Agent Collaboration Meets Collective Intelligence](http://arxiv.org/abs/2504.14625v1)

- CircuitMind: introduces a hierarchical multi-agent framework for gate-level circuit design, with UserProxy (Translates requirements), Mediator (Orchestrates agent interactions), Reviewer (Provides PPA feedback), Summarizer (Updates knowledge database), CoderAgent (Generates netlists), Executor (Performs verification), Database (Stores circuit patterns), and LLM (Backend model) components.
- The framework distributes complex reasoning tasks across specialized agents organized in strategic, coordination, and execution layers to overcome limitations in Boolean optimization.
- CircuitMind incorporates Syntax Locking, Retrieval-Augmented Generation using a knowledge database, and Dual-Reward Optimization to balance functional correctness and physical efficiency.


---

[Enhancing LLM-based Quantum Code Generation with Multi-Agent Optimization and Quantum Error Correction](http://arxiv.org/abs/2504.14557v1)

- Multi-Agent Framework: introduces, "Enhancing LLM-based Quantum Code Generation with Multi-Agent Optimization and Quantum Error Correction", with Orchestrator (Manages agents), Code Generation Agent (Generates initial code), Semantic Analysis Agent (Refines semantic accuracy), QEC Decoder Generation Agent (Adds error correction), RAG System (Provides external data), Multi-pass Inference (Iterative refinement process), where the framework proposes a novel multi-agent approach for generating accurate, fault-tolerant quantum code.
- The framework utilizes iterative multi-pass inference and incorporates domain-specific optimizations like quantum error correction.
- Experiments show that techniques like structured Chain-of-Thought significantly improve quantum algorithm generation accuracy.


---

[BookWorld: From Novels to Interactive Agent Societies for Creative Story Generation](http://arxiv.org/abs/2504.14538v1)

- BookWorld: introduces a comprehensive system for constructing and simulating book-based multi-agent societies, leveraging Role Agent (Simulates characters, actions, memory) and World Agent (Manages environment, orchestrates simulation) within a Simulation (Agents interact in scenes/rounds) process.
- The system includes Initialization (Extracts data, sets up agents) from source books and Rephrasing (Generates novel-style story) from simulation records.
- Key components supporting agent behavior include Memory (Short-term and long-term for agents) and a Map (Discrete spatial environment).


---

[Meta-Thinking in LLMs via Multi-Agent Reinforcement Learning: A Survey](http://arxiv.org/abs/2504.14520v1)

- Multi-Agent System: introduces a multi-agent system for meta-thinking in LLMs, with High Level Agent (Decides task breakdown, coordinates), Low Level Agents (Executes tasks, provides feedback), Theory of Mind (ToM) (Predicts, adjusts low-level strategies), Communication (Information sharing between agents), Meta-thinking (Makes strategic decisions), Reasoning (Handles task execution), and Reflection and Adaptation (Improves task execution, adapts).
- The system enables LLMs to reflect on, evaluate, and regulate their own thought processes through multi-agent interaction and reinforcement learning.
- This approach aims to enhance LLM robustness and trustworthiness by emulating human-like introspection and self-correction for complex tasks.


---

[VIZTA: Enhancing Comprehension of Distributional Visualization with Visual-Lexical Fused Conversational Interface](http://arxiv.org/abs/2504.14507v1)

- VIZTA: introduces a web-based tool with an Interactive Reading Module including a Visualization Panel and Communication Panel, powered by a Semantic-Aware Conversational Agent using an LLM and Multi-source Structured Data (Chart Specification, Data Description, Chart Knowledge, Chart Data, Visual Features, ID List) and a Visual-Lexical Fusion Design (Drag-and-Drop, Inline Citations) with VLM.
- The system aids chart readers in comprehending distributional visualizations by fusing visual and lexical feedback through a conversational interface.
- A formative study and user study demonstrate VIZTA's effectiveness in improving understanding and reasoning with distributional visualizations.


---

#### 19th April 2025

[Diffusion-based Dynamic Contract for Federated AI Agent Construction in Mobile Metaverses](http://arxiv.org/abs/2504.14326v1)

- Edge-Cloud Collaboration-based Federated AI Agent Construction Framework: introduces an edge-cloud collaboration-based framework for constructing AI agents in mobile metaverses, featuring a Cloud Server that integrates and deploys agent modules constructed by distributed Edge Servers, enabling User Layer interaction with AI Agents composed of Agent Modules built using Local LLMs/AI Models.
- The framework addresses challenges like latency and data privacy by distributing agent module creation to the edge.
- A dynamic contract model incentivizes Edge Servers to participate in agent module creation.


---

[FAIRGAME: a Framework for AI Agents Bias Recognition using Game Theory](http://arxiv.org/abs/2504.14325v1)

- FAIRGAME: introduces a framework to simulate AI agent interactions in game theory scenarios, including Configuration File, Prompt Template, Factory, Agents, Game Instances, Games Execution, Results, and Scoring System components.
- The framework enables systematic simulation and comparison of LLM agent behavior in games to identify biases and inconsistencies.
- FAIRGAME allows configuring agents with distinct traits and testing across different games, languages, and LLMs, providing quantitative results and evaluation metrics.


---

[Template-Based Financial Report Generation in Agentic and Decomposed Information Retrieval](http://arxiv.org/abs/2504.14233v1)

- AgenticIR: introduces a multi-agent framework for template-based financial report generation, including user proxy, assistant, financial retrieval, financial manager, user, and task decompose agents, utilizing task decomposition and retrieval/generation functions with earnings call transcripts, financial statements, and a report template.
- DecomposedIR: employs a prompt chaining workflow to break down the report template into subqueries, using an LLM and embedding model for retrieval and generation from earnings call transcripts and financial statements.
- The paper compares AgenticIR and DecomposedIR for generating structured financial reports from earnings releases, evaluating their performance on financial and weather datasets using LLM-based metrics and readability scores.


---

[tAlfa: Enhancing Team Effectiveness and Cohesion with AI-Generated Automated Feedback](http://arxiv.org/abs/2504.14222v1)

- TAIFA (Team AI Feedback Assistant): introduces an LLM-based agent that provides automated feedback to teams, including Retrieving and Pre-processing (Structures conversations), Communication Metrics (Evaluates team dynamics), Create Feedback Prompts (Prepares LLM input), LLM Feedback Generation (Generates feedback messages), and Deliver Feedback Messages (Sends feedback).
- The system analyzes team interactions using text-analytic and contextual metrics to generate personalized feedback messages for individuals and the team.
- TAIFA aims to enhance team effectiveness and cohesion by delivering timely, actionable feedback based on communication patterns.


---

[TALES: Text Adventure Learning Environment Suite](http://arxiv.org/abs/2504.14128v1)

- TALES (Text Adventure Learning Environment Suite): introduces a unified benchmark for evaluating LLM-driven Agents in Text-Adventure Game Environments, utilizing a Game Engine that provides State/Observation and Feedback, processes Agent Actions, and can incorporate a Reasoning Model generating Thinking Traces based on a System Prompt.
- The benchmark integrates existing text-adventure frameworks and introduces a new game mode to assess diverse reasoning skills required for sequential decision-making in grounded environments.
- Evaluation results across various LLMs highlight challenges in complex, long-horizon tasks, particularly in applying composite reasoning skills like spatial, deductive, inductive, and grounded reasoning.


---

#### 18th April 2025

[DoomArena: A framework for Testing AI Agents Against Evolving Security Threats](http://arxiv.org/abs/2504.14064v1)

- DoomArena: introduces a modular, configurable, plug-in framework for security evaluation of AI agents, operating on the user-agent-environment loop and incorporating threat modeling, attack config, attacks, attack gateway, success filter, and defenses.
- The framework facilitates realistic threat modeling and attack injection into agent-environment interactions to assess agent vulnerabilities.
- It enables combining multiple attacks, fine-grained security analysis, and adaptive testing against evolving threats.


---

[SCIENCE HIERARCHOGRAPHY: Hierarchical Organization of Science Literature](http://arxiv.org/abs/2504.13834v1)

- SCYCHIC: introduces SCIENCE HIERARCHOGRAPHY, a novel approach combining embedder (converts description to vector), clusterer (generates k clusters), summarizer (generates abstract summary), hierarchy layers (total number of layers), and target clusters (number clusters per layer) to construct a high-quality hierarchical structure for organizing scientific literature.
- This method balances embedding efficiency with LLM semantic precision for scalability and quality.
- The resulting hierarchy enhances interpretability and supports literature exploration beyond traditional search.


---


[BADAPEX: BACKDOOR ATTACK BASED ON ADAPTIVE OPTIMIZATION MECHANISM OF BLACK-BOX LARGE LANGUAGE MODELS](http://arxiv.org/abs/2504.13775v2)

- BadApex (Backdoor Attack based on Adaptive Optimization Mechanism of Black-Box Large Language Models): introduces a novel backdoor attack leveraging LLMs to generate poisoned text via a refined prompt, including an Adaptive Optimization Mechanism (Refines initial prompt iteratively) and a Poisoned Text Generation Module (Generates poisoned data).
- The Adaptive Optimization Mechanism uses a Generation Agent (Generates text candidates/poisoned text) and a Modification Agent (Evaluates text, refines prompt) to iteratively refine a Hand-crafted Prompt (Initial human-designed prompt) into a Refined Prompt (Iteratively improved prompt).
- The Poisoned Text Generation Module takes Clean Data (Original unpoisoned training data) and the Refined Prompt to generate Poisoned Data (Output backdoor training data) using alternative black-box LLMs.


---

[OpenDeception: Benchmarking and Investigating AI Deceptive Behaviors via Open-ended Interaction Simulation](http://arxiv.org/abs/2504.13707v1)

- OpenDeception: introduces a novel evaluation framework with a Scenario Dataset (contains scenarios), AI Deceiver Agent (simulates deceiver), AI User Agent (simulates user), Simulation Process (generates dialogue), and Thinking Process Separation (exposes deceiver thoughts), designed to benchmark AI deceptive behaviors via open-ended interaction simulation.
- The framework uses agent-based simulation with predefined roles and goals for both AI deceiver and user agents to generate dialogue data for evaluating deception intention and capability.
- A key feature is the separation of the AI deceiver agent's internal thoughts from its spoken output to uncover deceptive intentions during the simulation.


---

[Going Whole Hog A Philosophical Defense of AI Cognition](http://arxiv.org/abs/2504.13988v1)

- Whole Hog Thesis: is introduced, with Observation Premise (LLMs understand, answer questions), Holistic Network Assumption (Mental/intentional features interconnected), Mental States (Beliefs, desires, knowledge, plans), Intentional Features (Understanding, answering, acting, goals), Whole Hog Thesis (LLMs are cognitive agents), arguing that observations of LLM behavior provide evidence for interconnected mental and intentional features, concluding LLMs are full cognitive agents.
- The paper defends this thesis against skeptical arguments, including the "Just an X" fallacy and the "Performance-Existence Fallacy", employing a "Game of Lacks" methodology to counter objections based on alleged deficiencies in LLMs.
- It advocates for a "look and see" approach to understanding LLM cognition, prioritizing observations of their high-level cognitive-like behaviors over analyses of low-level mechanisms or abstract philosophical theories.


---

[Large Language Models for Validating Network Protocol Parsers](http://arxiv.org/abs/2504.13515v1)

- PARVAL (multi-agent framework): introduces, with Retrieval-Augmented Program Analysis Agent (retrieves code context), Module Isolation Agent (constructs isolated module), Protocol Code Base (parser source code), Isolated Parsing Module (standalone parsing logic), SpecAgent (extracts format specifications), Document (protocol standard text), CodeSpec (code-derived format spec), DocSpec (document-derived format spec), and Differential Analysis (compares specifications), a system to validate network protocol parsers by comparing code and standard specifications.
- The framework leverages LLMs to transform natural language protocol standards and source code implementations into a unified intermediate representation called format specifications.
- Differential analysis between the code-derived and document-derived specifications identifies inconsistencies, pointing to potential implementation bugs or issues in the standard.


---

[CodeVisionary: An Agent-based Framework for Evaluating Large Language Models in Code Generation](http://arxiv.org/abs/2504.13472v1)

- CodeVisionary: introduces an LLM-based agent framework for evaluating LLMs in code generation, including an LLM Agent (Central controller), a Multisource knowledge analysis stage (Gather knowledge), an Agent Runtime (Execution environment/tools), a Negotiation-based scoring stage (Score negotiation), and Multiple Judges (LLM agents).
- The Multisource knowledge analysis stage gathers domain knowledge via a stepwise plan executed in the Agent Runtime, while the Negotiation-based scoring stage uses multiple LLM judges discussing to reach a consensus score.
- The framework provides detailed evaluation reports and scores to help developers identify shortcomings and improve LLM code generation.


---

[TRUST, BUT VERIFY](http://arxiv.org/abs/2504.13443v1)

- Gaia Network AVS: introduces a system for verifying decentralized LLM inference outputs using statistical analysis and cryptoeconomic incentives.
- The system utilizes AVS validators to poll Gaia nodes running LLMs and knowledge bases, detecting outliers based on response distributions.
- Built on EigenLayer and EigenDA, the AVS applies incentives and penalties to encourage honest behavior among network participants.


---

[Towards a Multi-Agent Vision-Language System for Zero-Shot Novel Hazardous Object Detection for Autonomous Driving Safety](http://arxiv.org/abs/2504.13399v1)

- Pipeline: introduces a multi-agent vision-language system for zero-shot hazard detection in autonomous driving, with Driving Scene, Frame Extraction, Scene Understanding, Hazard Description Generation, Object Detection, Noun Extraction, Object List Generation, Hazard Ranking, Ranked Hazard List, Cross-Referencing, and Hazard Verification components.
- The system utilizes VLMs for scene understanding and object detection, LLMs for ranking, cross-referencing, and verification, and CLIP for visual verification.
- This pipeline processes video data through parallel tracks to identify, describe, and verify novel hazardous objects beyond predefined categories.


---

#### 17th April 2025

[Sleep-time Compute: Beyond Inference Scaling at Test-time](http://arxiv.org/abs/2504.13171v1)

- Sleep-time Compute: introduces sleep-time compute, which processes raw context offline using an LLM to generate a learned context, enabling more efficient test-time compute with the LLM to answer user queries.
- This method reduces test-time compute and latency by pre-computing context-specific inferences before the user query is presented.
- The learned context can be reused for multiple queries on the same context, amortizing the sleep-time compute cost and improving total cost efficiency.


---

[Exploring Expert Failures Improves LLM Agent Tuning](http://arxiv.org/abs/2504.13145v2)

- EEF: introduces Exploring Expert Failures, a framework that improves LLM agent tuning by leveraging beneficial actions from failed expert trajectories.
- The framework utilizes Behavior Cloning on positive expert data, followed by iterative Exploration and Reinforcement Fine-tuning.
- Reinforcement Fine-tuning involves simulating from expert states, identifying important states, selecting successful solution trajectories, and training the LLM using Supervised Fine-Tuning Loss.


---

[Retrieval-Augmented Generation with Conflicting Evidence](http://arxiv.org/abs/2504.13079v1)

- MADAM-RAG (Multi-agent Debate for Ambiguity and Misinformation in RAG): introduces, "a unified multi-agent approach", with LLM Agents (process document), Multi-round Debate (iterative discussion), and Aggregator Module (synthesize final answer), designed to handle diverse sources of conflict in retrieved documents.
- The framework assigns each retrieved document to an independent LLM agent which debates with other agents across multiple rounds to filter misinformation and address ambiguity.
- An aggregator module synthesizes the final response by considering agent discussions and resolving inconsistencies.


---

[InstructRAG: Leveraging Retrieval-Augmented Generation on Instruction Graphs for LLM-Based Task Planning](http://arxiv.org/abs/2504.13032v1)

- InstructRAG: introduces a novel multi-agent meta-reinforcement learning framework for LLM-based task planning, integrating an Instruction Graph (Organizes instruction paths), RL-Agent (Retrieves candidate paths), and ML-Agent (Selects path, generates prompt) to guide an LLM (Generates thoughts and actions) via a Prompt (Guides LLM generation) within the TAO Process (Thought-Action-Observation cycle).
- The framework addresses enlargeability by using the Instruction Graph and RL-Agent for path retrieval and transferability via the ML-Agent's meta-learning approach for rapid adaptation.
- The two agents collaborate, with the RL-Agent providing candidate paths and the ML-Agent providing feedback as reward, optimizing end-to-end planning performance.


---

[QLLM: Do We Really Need a Mixing Network for Credit Assignment in Multi-Agent Reinforcement Learning?](http://arxiv.org/abs/2504.12961v1)

- QLLM: introduces, with Coder-Evaluator Framework (Generates TFCAF), Coder LLM (Generates candidates), Evaluator LLM (Evaluates candidates), Prompts (Guide LLMs), Candidate Functions (Intermediate TFCAFs), Feedback (Refines generation), Training-Free Credit Assignment Function (TFCAF) (Replaces mixing network), Individual Agent Q-value Functions (Agent utilities), Global Q-value Function (Aggregated value), Agents (Execute actions), Environment (Provides state/reward), and Buffer (Stores transitions), a novel multi-agent reinforcement learning algorithm that leverages LLMs to automatically construct a training-free credit assignment function.
- The Coder-Evaluator Framework iteratively generates and refines the TFCAF using two LLMs guided by task and role prompts, mitigating hallucination and improving robustness.
- The TFCAF replaces the traditional mixing network, directly aggregating individual agent Q-values and state information to produce the global Q-value for credit assignment.


---

[Are Retrials All You Need? Enhancing Large Language Model Reasoning Without Verbalized Feedback](http://arxiv.org/abs/2504.12951v1)

- Retrials without feedback: introduces a simple mechanism to enhance LLM reasoning by retrying problem-solving attempts upon identifying incorrect answers, evaluating its impact on IO, CoT, ToT, and Reflexion methods using Base Models.
- This approach simplifies the refinement process by not requiring explicit self-reflection or verbalized feedback, contrasting with methods like Reflexion.
- The study finds that applying retrials often makes simpler methods like IO and CoT more cost-efficient than complex ones like ToT and Reflexion within a budget.


---

[Customizing Emotional Support: How Do Individuals Construct and Interact With LLM-Powered Chatbots](http://arxiv.org/abs/2504.12943v2)

- ChatLab (LLM-Powered Chatbots): introduces a research prototype website with Onboarding Page, FAQs Page, Customization and Conversation Playground, and Experience Diary Page, enabling users to construct and interact with LLM-powered chatbots for emotional support.
- The Customization and Conversation Playground includes Chatbot customization and Additional interaction settings tabs for defining persona, output modality, avatar, LLM model, and temperature, alongside Chatting interface and Conversation history.
- Built using Streamlit and LangChain, powered by GPT models and TTS APIs, and storing data in Firebase, ChatLab was used in a study to explore user customization practices and gather design ideas for enhancing personalized emotional support.


---

[DashChat: Interactive Authoring of Industrial Dashboard Design Prototypes through Conversation with LLM-Powered Agents](http://arxiv.org/abs/2504.12865v1)

- DashChat: introduces an interactive system for authoring industrial dashboard design prototypes, featuring User Input and Task Creation (processes user input), Task Planning and Knowledge Integration (plans tasks, adds knowledge), Task Implementation (executes tasks), Composition Agent (creates visual elements), Assembly Agent (arranges layout), Stylization Agent (adds aesthetics), and Result Evaluation and Iterative Adjustment (refines prototypes).
- The system leverages a multi-agent pipeline powered by LLMs to translate natural language requirements into practical and aesthetic dashboard designs.
- Functionally distinct, parallel-operating agents handle composition, layout assembly, and stylization to enable efficient prototype generation and iterative refinement.


---

[Pandora: A Code-Driven Large Language Model Agent for Unified Reasoning Across Diverse Structured Knowledge](http://arxiv.org/abs/2504.12734v1)

- Pandora (PANDas cOde-dRiven Agent): introduces a unified structured knowledge reasoning framework, with LLM (fe) (Generates reasoning steps and code), Memory (M) (Stores demonstrations), PYTHON interpreter (I) (Executes code, provides feedback), BOXes (B*) (Unified knowledge representation), and LLM (go) (Calculates query similarity), where it leverages an LLM to generate reasoning steps and executable Python code for answering natural language questions over diverse structured knowledge sources represented as BOXes.
- The framework utilizes a memory of training examples for in-context learning and employs a Python interpreter to execute generated code and provide feedback for self-correction.
- Pandora unifies reasoning across tables, databases, and knowledge graphs by converting them into a standardized BOX representation based on the PANDAS library.


---

[WebLists: Extracting Structured Information From Complex Interactive Websites Using Executable LLM Agents](http://arxiv.org/abs/2504.12682v1)

- BardeenAgent: introduces a novel framework for web data extraction, with all Recording Phase (records agent actions), Replay Phase (executes recorded program), Executable Program (set of recorded operations), Selector Generation (creates robust CSS selectors), and Data Extraction (methods to get data) components, enabling web agents to convert execution into repeatable programs for scalable data extraction.
- The framework operates in two phases: recording user actions and generating CSS selectors, followed by replaying the generated executable program to extract data at scale.
- By leveraging the structured nature of HTML and generating reusable programs, the approach improves recall and reduces cost compared to existing web agents on data extraction tasks.


---

[METASYNTH: Meta–Prompting-Driven Agentic Scaffolds for Diverse Synthetic Data Generation](http://arxiv.org/abs/2504.12563v1)

- METASYNTH: introduces a meta-prompting framework using a Meta-LM orchestrating Agents with Memory and Seed Data to generate diverse synthetic data.
- The Meta-LM manages the workflow, invokes specialized Agents for subtasks, and uses Memory to ensure generated instances are distinct from previous ones.
- The framework supports generating diverse documents and complex instructions by iteratively refining outputs based on agent feedback and conditional instance generation.


---

#### 16th April 2025

[Towards Conversational AI for Human-Machine Collaborative MLOps](http://arxiv.org/abs/2504.12477v1)

- Swarm Agent: introduces a Large Language Model-based conversational agent system, with Swarm Agent Core (LLM controller), Chat UI (User interface), Session Manager (Manages context/state), Message History (Stores conversation), Intent Recognition (Infers user goals), Task Dispatcher (Activates agents), Iterative Reasoning (Refines responses), Contextual Memory (Maintains history), Router (Routes tool calls), Tool Mapper (Matches tools), Specialized Agents (Domain-specific functions), KFP Agent (Manages Kubeflow), MinIO Agent (Manages MinIO data), RAG Agent (Integrates documentation), External Services (MLOps platforms/storage/DB), and Knowledge Indexing Pipeline (Processes documentation), designed to enhance human-machine collaboration in MLOps through natural language interaction.
- The system leverages a modular, extensible architecture integrating specialized agents for Kubeflow pipeline orchestration, MinIO data management, and domain-specific knowledge retrieval via a vector database.
- The Swarm Agent facilitates conversational management of complex MLOps environments, reducing technical barriers and making advanced ML tools accessible to users with varying technical backgrounds.


---

[ARCER: an Agentic RAG for the Automated Definition of Cyber Ranges](http://arxiv.org/abs/2504.12143v1)

- ARCER (Agentic RAG for the Automated Definition of Cyber Ranges): introduces automated Cyber Range generation and deployment from natural language descriptions, utilizing a Large Language Model (LLM) (Reasoning engine), RAG subsystem (Retrieval tool), Checker Tool (Syntax verification), and Memory (Context management).
- The system processes user prompts, retrieves relevant knowledge from User documents stored in a Vector Store, generates Cyber Range description files, and can automatically deploy them.
- ARCER adapts to different Cyber Range frameworks by changing external documents and improves generation accuracy and integrity through agentic capabilities.


---

[Multilingual Contextualization of Large Language Models for Document-Level Machine Translation](http://arxiv.org/abs/2504.12140v1)

- DocMT-LLMs: introduces a method to improve LLM-based long-document translation through supervised fine-tuning on the DOCBLOCKS dataset, integrating high-quality instructions using a specific instruction format.
- The approach employs Multi-Resolutional Document-to-Document Training (MRD2D) and Context-Aware Prompt Tuning (CAPT) techniques during fine-tuning to capture document structure and inter-sentence relationships.
- Fine-tuning existing sentence-level LLMs on DOCBLOCKS enhances document-level translation capabilities while maintaining strong sentence-level performance.


---

[Towards LLM Agents for Earth Observation](http://arxiv.org/abs/2504.12110v1)

- LLM Agents for Earth Observation: introduces UnivEARTH, a benchmark evaluating LLM agents' ability to answer Earth observation questions by generating and executing Google Earth Engine code using satellite data.
- The approach involves LLM agents performing code generation, execution, and optional reflection to interact with the Google Earth Engine platform and its diverse satellite data collections.
- Benchmarking reveals limitations in current LLMs' ability to reliably generate executable code and navigate Earth observation data sources, while a specialized fine-tuned model shows promise.


---

[Large Language Models as Quasi-crystals: Coherence Without Repetition in Generative Text](http://arxiv.org/abs/2504.11986v2)

- LLM (Large Language Model): proposes an analogy with quasicrystals to analyze the structural coherence of generated text, suggesting it arises from local constraints within the model's architecture.
- The paper argues that LLM outputs exhibit long-range order without periodic repetition, similar to quasicrystals, despite lacking explicit rules or symbolic intent.
- This perspective suggests a structural evaluation of LLMs, focusing on how well outputs propagate constraint, variation, and order across spans of text.


---

[Evaluating the Goal-Directedness of Large Language Models](http://arxiv.org/abs/2504.11844v1)

- Goal-Directedness Evaluation Framework: introduces a method to evaluate the goal-directedness of LLM agents in a Blocksworld environment using composite tasks and subtasks, assessing capabilities and comparing actual task performance (returns) to potential performance via a goal-directedness metric.
- The framework utilizes Monte Carlo simulations and statistical analysis to compute the goal-directedness metric, which indicates the propensity of an agent to use its capabilities to achieve a given goal.
- The evaluation involves testing various LLM models on tasks requiring information gathering, cognitive effort, and plan execution, revealing that most models are not fully goal-directed.


---

[On the Feasibility of Using MultiModal LLMs to Execute AR Social Engineering Attacks](http://arxiv.org/abs/2504.13209v1)

- SEAR (Social Engineering Augmented Reality): introduces a framework for AR-driven social engineering attacks, integrating AR Glasses (Capture raw multimodal data), AR-based Social Context Synthesis (Process raw AR data), Multimodal LLM (Process multimodal data, generate dialogue), Role-based Multimodal RAG (Build, update social profiles), Vector Stores (Store profile data embeddings), ReInteract SE Agent (Execute adaptive attack strategies), SE Strategy Templates (Predefined attack phases, objectives), and Social Profile (Target identity, behavior, context).
- The framework processes multimodal AR data and social information to build dynamic target profiles and execute adaptive, phased attack strategies.
- SEAR demonstrates the feasibility of using AR and multimodal LLMs to enhance social engineering efficacy through personalized, context-aware interactions.


---

[Progent: Programmable Privilege Control for LLM Agents](http://arxiv.org/abs/2504.11703v1)

- Progent: introduces a programmable privilege control framework for LLM agents, with Policy Language (defines privilege control policies), Policy Enforcement (applies policies to tool calls), and Policy Management (initializes and updates policies) components.
- The framework enforces the principle of least privilege by controlling tool calls based on dynamic, domain-specific policies.
- Progent leverages LLMs for automated policy generation and update, demonstrating effectiveness in reducing attack success rates across various agent use cases.


---

[STEERING PROSOCIAL AI AGENTS: COMPUTATIONAL BASIS OF LLM'S DECISION MAKING IN SOCIAL SIMULATION](http://arxiv.org/abs/2504.11671v1)

- Method for Steering LLM Agents: introduces a technique to probe, quantify, and modify large language model behavior in social simulations by analyzing residual streams, identifying steering vectors, orthogonalizing them, projecting them onto a decision vector, and injecting scaled projections into the residual streams.
- This approach allows for targeted manipulation of LLM decisions based on specific input variables like persona attributes and game framing.
- The study demonstrates that injecting variable-specific steering vectors into residual streams can effectively alter an LLM agent's decision-making in a Dictator Game setting.


---

#### 15th April 2025

[GRAPHICBENCH: A Planning Benchmark for Graphic Design with Language Agents](http://arxiv.org/abs/2504.11571v1)

- GRAPHICTOWN: introduces a language agent framework for graphic design planning and execution, including Design Outline (generate design outline), Expert Recruitment (recruit expert agents), Workflow Generation (generate expert workflows), Workflow Supervision (integrate expert workflows), Action Retrieval (retrieve actions for steps), Action Execution (execute plan), Photo Editor agent (image editing expert), Vector Graphic Editor agent (vector illustration expert), Layout Designer agent (layout and text expert), and Actions (Tools) (executable operations).
- The framework utilizes a hierarchical agentic structure with a supervisor agent directing specialized expert agents (Photo Editor, Vector Graphic Editor, Layout Designer) to generate and execute design workflows based on user queries and image inputs.
- GRAPHICTOWN operates on the GRAPHICBENCH benchmark, evaluating LLM agents' ability to plan and execute creative design tasks by decomposing high-level goals into sequences of actions executable within web-based design tools.


---

[REAL: Benchmarking Autonomous Agents on Deterministic Simulations of Real Websites](http://arxiv.org/abs/2504.11543v2)

- REAL: introduces a benchmark and framework for evaluating autonomous web agents, featuring deterministic Environments (Deterministic website simulations), an Agent (System under evaluation) interacting via Observation (Agent input) and Action (Agent output) through an Agent Harness (Interface for agent interaction) managing a Browser Instance (Dedicated browser for task) with State Management (Persistent website state storage), evaluated by a Reward Module (Evaluates task success) using an LLM Judge (Evaluates information retrieval) and State Diff Check (Verifies state changes), controlled by a Configuration Framework (Controls environment settings) for completing a Task (Goal for the agent).
- The framework provides 11 high-fidelity website simulations and 112 tasks, supporting flexible agent integration via Playwright, CDP, or URL control.
- Task success is determined programmatically for action-based tasks and via an LLM judge for information retrieval tasks, with configurations enabling reproducible evaluation and edge case testing.


---

[TEXTARENA](http://arxiv.org/abs/2504.11442v1)

- TextArena: introduces a comprehensive framework for evaluating language models through competitive gameplay, featuring an Agent (LLM agent) interacting with an Environment (Text-based games) via a Wrapper (Observation processing), supported by an Evaluation System (Leaderboard/Scoring).
- The framework provides a Gym-like interface for diverse text-based environments, enabling training and evaluation of agentic behavior in dynamic scenarios.
- An online evaluation system tracks model performance against other models and humans using a TrueSkill leaderboard.


---


[Reimagining Urban Science: Scaling Causal Inference with Large Language Models](http://arxiv.org/abs/2504.12345v1)

- AutoUrbanCI: introduces a modular, LLM-powered framework for urban causal inference, structured into Hypothesis Generation, Urban Data, CI Experiment, and Evaluation Agents.
- The framework employs specialized agents like Reader, Data Engineer, Data Scientist, Experimenter, Validator, Urban Scientist, and Writer to handle distinct stages of the causal analysis pipeline.
- AutoUrbanCI aims to address limitations in current urban causal research, such as data complexity and reproducibility, by leveraging LLM/MLLM capabilities for automation and collaboration.


---


[Cancer-Myth: Evaluating Large Language Models on Patient Questions with False Presuppositions](http://arxiv.org/abs/2504.11373v1)

- Cancer-Myth approach: introduces a methodology to create a dataset and evaluate LLMs, utilizing Myths, Valid Examples, Invalid Examples, an LLM Generator, an LLM Responder, an LLM Verifier, and Hematology Oncology Physicians to produce the Cancer Myth dataset.
- This approach systematically generates and verifies patient questions containing false presuppositions to test LLMs' ability to identify and correct misconceptions.
- The pipeline involves iterative generation and evaluation steps, with expert physician review ensuring the medical validity of the adversarial examples.


---

[DataSentinel: A Game-Theoretic Detection of Prompt Injection Attacks](http://arxiv.org/abs/2504.11358v1)

- DataSentinel: introduces a game-theoretic method to detect prompt injection attacks by fine-tuning a Detection LLM (g) using a Minimax Optimization Problem, which simulates a game between fine-tuning the Detection LLM (g) and adaptive attacks.
- The detection mechanism leverages a Detection LLM (g) and a Detection Instruction (sd) with a Secret Key (k), classifying data as contaminated if the Secret Key (k) is not in the Detection LLM's (g) output when prompted with the Detection Instruction (sd) and target data.
- The Minimax Optimization Problem is solved iteratively by alternating between the Inner Max Problem, which optimizes contaminated target data (simulating an Adaptive Attack), and the Outer Min Problem, which updates the Detection LLM (g) parameters.


---

[Learning to Be A Doctor: Searching for Effective Medical Agent Architectures](http://arxiv.org/abs/2504.11301v1)

- Workflow Evolution Framework: introduces a dynamic, graph-based workflow (Workflow) composed of nodes (Nodes) with attributes (Node Attributes), which evolves iteratively (Workflow Evolution Process) guided by diagnostic feedback (Diagnostic Feedback) and suggestions (Suggestions) generated from process perception (Process Perception).
- The framework defines a hierarchical search space (Search Space) encompassing node-level (Node-Level Operations), structural-level (Structural-Level Operations), and framework-level (Framework-Level Design) operations, enabling modifications through actions (Actions) like adding, removing, or modifying components.
- This iterative evolution process allows the workflow to adapt its structure and parameters, incorporating elements like conditional (Conditional Structures), loop (Loop Structures), and parallel (Parallel Structures) logic to improve diagnostic accuracy and robustness over time.


---

[The Obvious Invisible Threat: LLM-Powered GUI Agents' Vulnerability to Fine-Print Injections](http://arxiv.org/abs/2504.11281v1)

- LLM-Powered GUI Agents: introduces, with LLM (Powers agent capabilities), UI Interpretation & Interaction (Perceives and interacts with GUIs), and Agent's Mental Model (Guides decision-making) components, a study evaluating the vulnerability of GUI agents to adversarial manipulations embedded in graphical user interfaces.
- The paper proposes Fine-Print Injection (FPI), a novel attack exploiting agents' tendency to process low-salience content, and evaluates it alongside other attack types against six GUI agents and a human baseline.
- Findings reveal that GUI agents are highly susceptible to contextually embedded attacks like FPI and Deceptive Defaults (DD), highlighting a privacy-utility trade-off in agent design and limited human awareness of these risks.


---

[Towards Automated Safety Requirements Derivation Using Agent-based RAG](http://arxiv.org/abs/2504.11243v1)

- Agent-based RAG: introduces an approach for automated safety requirements derivation, processing Domain-Specific Knowledge into Vector and Summary Indices, utilizing a Top-level Agent to orchestrate retrieval via Document Agents and their Query Engines, providing Refined Context to an LLM (Large Language Model) for generating responses.
- This architecture enhances context relevance compared to default RAG by employing a multi-step agentic retrieval process based on document content and query type.
- The agent-based system facilitates incorporating domain-specific knowledge and aims to mitigate hallucinations by grounding outputs in retrieved, refined context.


---

[Exploring Backdoor Attack and Defense for LLM-empowered Recommendations](http://arxiv.org/abs/2504.11182v1)

- BadRec: introduces a new attack framework that injects backdoors into LLM-based RecSys by poisoning the training set with Attackers, Trigger, Malicious Retailer, Poisoned Item Pool, Fake Users, and Poisoned Datasets, resulting in Open Backdoors in the LLM-empowered RecSys.
- The framework perturbs item titles with triggers and generates fake users to create adversarial examples for training data poisoning.
- Poisoning just 1% of training data can successfully implant backdoors, enabling manipulation of recommendation outcomes.


---

[Dynamic Compressing Prompts for Efficient Inference of Large Language Models](http://arxiv.org/abs/2504.11004v1)

- LLM-DCP: introduces Dynamic Compressing Prompts, a task-agnostic method modeling prompt compression as a Markov Decision Process, including a DCP-Agent, Critic, Reward Function, Hierarchical Prompt Compression Training Strategy, Distribution-aligned Small Model, and Replay Buffer.
- The DCP-Agent iteratively removes redundant tokens from a prompt, guided by a reward function that balances compression, output quality, and information retention.
- The Hierarchical Prompt Compression strategy uses curriculum learning to train the agent, progressively increasing compression difficulty.


---

[Timing Analysis Agent: Autonomous Multi-Corner Multi-Mode (MCMM) Timing Debugging with Timing Debug Relation Graph](http://arxiv.org/abs/2504.11502v1)

- Timing Analysis Agent: introduces an autonomous multi-corner multi-mode timing debugging system with MCMM Planner Agent (Hierarchical task planning), TDRG Traversal Agent (Plans report retrieval), Expert Report Agent (Retrieves specific data), Structural Report Database (Structured timing reports), and Timing Debug Relation Graph (TDRG) (Connects reports debug knowledge).
- The system integrates hierarchical plan solving and multi-agent collaboration to automate the analysis of MCMM timing reports.
- It employs a novel Agentic Retrieval Augmented Generation approach leveraging LLM coding capabilities for accurate data retrieval from structured reports.


---

[Can Large Language Models Trade? Testing Financial Theories with LLM Agents in Market Simulations](http://arxiv.org/abs/2504.10789v1)

- Simulation Framework: introduces an open-source simulation framework with Market Design (simulates stock market environment), Agent Design (manages LLM trading agents), and Analysis Module (collects and analyzes data) components, designed to test large language models as heterogeneous competing trading agents in a realistic simulated stock market.
- The framework incorporates a persistent order book, various order types, stochastic dividends, and heterogeneous information sets for agents.
- Agents submit standardized decisions using structured outputs and function calls while expressing their reasoning in natural language, enabling systematic analysis of their trading behavior and market dynamics.


---

#### 14th April 2025

[SUPERINTELLIGENCE STRATEGY EXPERT VERSION](https://arxiv.org/abs/2503.05628)

- Superintelligence Strategy: introduces a three-part framework including Deterrence (Mutual Assured AI Malfunction), Nonproliferation (Compute Security, Information Security, AI Security), and Competitiveness (Military Strength, Economic Security, Legal Frameworks, Political Stability) to manage advanced AI risks.
- The strategy draws parallels from national security precedents like nuclear deterrence and nonproliferation to address the challenges posed by advanced dual-use AI capabilities.
- Key components like AI chips, datacenters, model weights, and AI system safeguards are identified as critical elements within the AI ecosystem requiring management under this strategic framework.


---


[LLM-based AI Agent for Sizing of Analog and Mixed Signal Circuit](http://arxiv.org/abs/2504.11497v1)

- AI Agent: introduces an LLM-based agent for AMS circuit sizing, with Task Decomposition, LLM, Action, Observation, Comparison, External Tools, and Context components, designed to optimize transistor sizing iteratively.
- The agent employs a ReAct loop (Action, Observation, Comparison) integrating an LLM with external simulation and analysis tools for iterative optimization.
- Prompt engineering, including Chain-of-Thought, guides the LLM's reasoning and action selection based on performance metrics and historical context.


---

[IEA-Plugin: An AI Agent Reasoner for Test Data Analytics](http://arxiv.org/abs/2504.11496v1)

- IEA-Plugin (AI Agent Reasoner): introduces an AI agent-based reasoning module designed to generate a stable API specification for test data analytics from user queries.
- The system leverages LLMs and an agentic platform to process complex user queries into structured workflows and distill them into a stable API specification.
- IEA-Plugin addresses knowledge acquisition and scalability challenges by using user interactions to build a query-workflow database and automatically generating API functions.


---


[Introducing Large Language Models as the Next Challenging Internet Traffic Source](http://arxiv.org/abs/2504.10688v1)

- Experimental Setup: introduces, "an experimental setup", with User/Client Application (Interacts with agent), Querying Agent (Initiates query), Responding Agent (Local server, forwards query), and LLM API (External model service), where "the setup simulates user-agent and agent-LLM interactions to measure network traffic".
- The paper explores the Internet of Agents paradigm, where AI agents interact with users, devices, and other agents, identifying LLMs as a significant new source of Internet traffic.
- Traffic measurements per prompt for various LLMs are provided, estimating the potential impact on network infrastructure.


---

[Characterizing LLM-driven Social Network: The Chirper.ai Case](http://arxiv.org/abs/2504.10286v1)

- Chirper.ai: introduces a large-scale analysis of an LLM-driven social network, Chirper.ai, with LLM Agents (Autonomous social entities), Social Network Platform (Hosts agents and interactions), Underlying AI Models (Power agent capabilities), and Community-based Reward System (Influences agent behavior), characterizing agent behavior and network structure.
- The study compares Chirper.ai agent behavior and network structure to human and bot users on Mastodon.
- Findings reveal distinct patterns in posting, self-disclosure, abusive content, and network positions, highlighting challenges for moderation.


---

[Can Competition Enhance the Proficiency of Agents Powered by Large Language Models in the Realm of News-driven Time Series Forecasting?](http://arxiv.org/abs/2504.10210v1)

- CM (Complete Competition Mechanism): introduces a multi-agent framework for news-driven time series forecasting, incorporating News Filtering, Time Series Forecasting, Multi-Indicator Evaluation (MIE), Information Asymmetry (IA), Opponent-Oriented Self-Reflection (OOSR), Multi-Stage Reflection (MSR), Survival of the Fittest (SF), LLM₁, LLMs, and Memory Bank components.
- The framework embeds a competition mechanism within multi-agent discussion to enhance innovative thinking and uses MSR with a fine-tuned small LLM for identifying misleading logic.
- Experimental results show competition boosts agents' innovative thinking and significantly improves time series prediction performance compared to baselines.


---

[C-FAITH: A Chinese Fine-Grained Benchmark for Automated Hallucination Evaluation](http://arxiv.org/abs/2504.10167v1)

- HaluAgent: introduces an agentic framework for automated hallucination evaluation dataset generation, featuring a Generation Module (Generates QA data), Verification Module (Checks data correctness), and Optimization Module (Refines generation prompt).
- The framework processes Knowledge Documents (Input source) to generate Generated Data (Raw output), which is validated by the Verification Module (Checks data correctness) using Manual Rules (Verification criteria).
- The Optimization Module (Refines generation prompt) refines the generation prompt based on Error Feedback (Verification errors) from the Verification Module (Checks data correctness), producing Qualified Data (Validated data) that forms the final Dataset (Final evaluation data).


---

[Fact-Checking with Contextual Narratives: Leveraging Retrieval-Augmented LLMs for Social Media Analysis](http://arxiv.org/abs/2504.10166v1)

- CRAVE (Cluster-based Retrieval Augmented Verification with Explanation): introduces a novel framework that processes Input (Social media post), performs Evidence Retrieval (Get external evidence) via Reverse Image Search (Find image evidence) and Text-Based Search (Find text evidence), applies Clustering (Group evidence narratives) and Narrative Extraction (Select representative text), uses Agent-Based Evidence Refinement (Refine evidence iteratively), and employs an LLM-Based Judge (Determine veracity, explain) for Reasoning (Assess narratives, decide verdict) to produce Output (Explanation, veracity verdict).
- The framework clusters multimodal evidence into distinct narratives and uses LLM reasoning based on 5W1H to generate interpretable explanations and veracity verdicts.
- CRAVE integrates retrieval-augmented LLMs with clustering techniques to handle diverse and potentially contradictory evidence for fact-checking social media posts.


---

[SocioVerse: A World Model for Social Simulation Powered by LLM Agents and A Pool of 10 Million Real-World Users](http://arxiv.org/abs/2504.10157v1)

- SocioVerse: introduces a world model for social simulation powered by LLM agents and a 10 million real-world user pool.
- The framework includes four powerful alignment modules: Social Environment, User Engine, Scenario Engine, and Behavior Engine.
- SocioVerse addresses alignment challenges in environment, user, scenario, and behavior to achieve diverse and trustworthy simulations.


---

[A Survey of Personalization: From RAG to Agent](http://arxiv.org/abs/2504.10147v1)

- Personalized Agent: introduces a system designed to dynamically incorporate user context, memory, and external tools or APIs to support highly personalized and goal-oriented interactions, including Personalized Understanding (interpreting user input/context), Personalized Planning and Execution (integrating memory/tools), and Personalized Generation (creating tailored output).
- This framework evolves from Retrieval-Augmented Generation (RAG) by integrating agentic capabilities like Memory and Tool/API utilization.
- Memory components store historical user data, while Tool/API components enable interaction with external knowledge sources for task execution.


---

[CodeRAG: Supportive Code Retrieval on Bigraph for Real-World Code Generation](http://arxiv.org/abs/2504.10046v1)

- CODERAG (retrieval-augmented code generation framework): introduces, "comprehensively retrieve supportive codes for real-world code generation", with Requirement Graph (Models requirement relationships), DS-Code Graph (Models code relationships), Bigraph Mapping (Maps requirements to code), Code-oriented Agentic Reasoning (LLM-driven retrieval and generation), Programming Tools (Assist LLM retrieval/testing), and LLMs (Generate code using retrieved info).
- The framework constructs a requirement graph and a DS-code graph, maps between them, and uses an agentic process with programming tools and LLMs for code generation.
- CODERAG aims to improve real-world repo-level code generation by providing LLMs with relevant context from the code repository and external sources.


---

[DataMosaic: Explainable and Verifiable Multi-Modal Data Analytics through Extract-Reason-Verify](http://arxiv.org/abs/2504.10036v1)

- DataMosaic: introduces an agentic workflow with Question Decomposition (Decomposes question), Structure Selection (Selects data structure), Seek (Locates relevant data), Extraction (Extracts structured data), Reasoning (Performs reasoning), and Thinker (Evaluates, directs workflow) components.
- The framework aims to make LLM-powered multi-modal data analytics explainable and verifiable by transforming data into structured formats for step-by-step processing.
- The Thinker component dynamically adapts the workflow based on evaluation of intermediate results, enhancing accuracy and efficiency.


---

[A Survey of Large Language Model-Powered Spatial Intelligence Across Scales: Advances in Embodied Agents, Smart Cities, and Earth Science](http://arxiv.org/abs/2504.09848v1)

- Taxonomy of Large Language Model-Empowered Spatial Intelligence: introduces a structured framework with Foundational Capabilities (Underlying spatial abilities), Spatial Memory and Knowledge (Recall spatial information), Abstract Spatial Reasoning (Simplify spatial problems), Spatial Intelligence for Real World (Apply spatial intelligence), Embodied Spatial Intelligence (Agents in physical environments), Urban Spatial Intelligence (Spatial tasks in cities), Earth Spatial Intelligence (Spatial tasks in Earth science), Spatial Memory and Knowledge Sources (Internal or external data), Spatial Memory and Knowledge Down-stream Tasks (Specific spatial applications), and Abstract Spatial Reasoning Mental Models (Types of spatial logic).
- The framework categorizes LLM spatial intelligence into foundational abilities like memory and reasoning, and real-world applications across embodied, urban, and earth science domains.
- This taxonomy provides a structured view of LLM-powered spatial intelligence, highlighting key components and their relationships across different scales and disciplines.


---

[Training Small Reasoning LLMs with Cognitive Preference Alignment](http://arxiv.org/abs/2504.09802v1)

- CRV+CogPO: introduces a multi-agent system with a Critic (evaluates reasoning process), Rethinker (rewrites reasoning process), and Verifier (validates reasoning process) combined with the CogPO (aligns reasoning preferences) algorithm to train smaller reasoning LLMs.
- The approach refines training data by critiquing, rethinking, and verifying reasoning processes from larger models, then uses preference optimization tailored to smaller models' capacities.
- This method demonstrates improved performance on challenging reasoning benchmarks compared to other training techniques for smaller models.


---

[Reasoning Court: Combining Reasoning, Action, and Judgment for Multi-Hop Reasoning](http://arxiv.org/abs/2504.09781v1)

- RC (Reasoning Court): introduces a framework for multi-hop reasoning that includes LLM Agents (Generate candidate solutions), Reasoning Steps (Internal thought process), Retrieval Actions (Gather external information), Retrieved Evidence (Information from external sources), and LLM Judge (Evaluates trajectories and determines answer).
- The framework employs multiple LLM agents to generate diverse reasoning paths and candidate answers by interleaving reasoning and external retrieval.
- A dedicated LLM judge evaluates the agents' reasoning trajectories and retrieved evidence to select the most accurate answer or synthesize a new one.


---

[Two Heads are Better Than One: Test-time Scaling of Multi-agent Collaborative Reasoning](http://arxiv.org/abs/2504.09772v1)

- Adaptive MAS: introduces an adaptive multi-agent framework with a CEO agent to enhance collaborative reasoning through model fine-tuning and system-level coordination.
- The framework includes a CEO agent that dynamically manages agent collaboration, resource allocation, and reasoning depth based on task progress.
- The system utilizes specialized agents (Expert Recruiter, Problem Solvers, Executor, Evaluator) within the MAS to collaboratively solve complex tasks.


---

#### 13th April 2025

[Can LLM feedback enhance review quality? A randomized study of 20K reviews at ICLR 2025](http://arxiv.org/abs/2504.09737v1)

- Review Feedback Agent: introduces a multi-LLM system, with Paper (Input), Review (Input), Actor 1 (Generate initial feedback), Actor 2 (Generate initial feedback), Aggregator (Merge feedback lists), Critic (Evaluate and filter feedback), Formatter (Format feedback pairs), Reliability tests (Ensure feedback quality), and Feedback (Output to reviewer), designed to improve peer review quality by providing automated feedback to reviewers.
- The system uses parallel Actors to generate initial feedback, which is then aggregated, critically evaluated, and formatted before being posted to the reviewer.
- Reliability tests act as guardrails, ensuring the generated feedback is constructive, accurate, and properly formatted before delivery.


---

[AGENTIC WORKFLOWS FOR ECONOMIC RESEARCH: DESIGN AND IMPLEMENTATION](http://arxiv.org/abs/2504.09736v1)

- Agentic Workflow Framework: introduces a methodology leveraging LLMs and multimodal AI for economic research, featuring Specialized Agents (perform specific tasks), Inter-Agent Communication (structured data exchange), Error and Escalation Pathways (handle issues), Adaptive Mechanisms (switch strategies), Human-in-the-Loop (HITL) Checkpoints (human oversight), and a Multi-phase Workflow (coordinates stages).
- The framework enhances research efficiency and reproducibility by automating tasks across the economic research lifecycle while integrating strategic human oversight.
- Specialized agents handle distinct responsibilities, communicating through structured protocols, with built-in mechanisms for error handling and adaptation across interconnected workflow stages.


---

[AGENTA/B: Automated and Scalable Web A/B Testing with Interactive LLM Agents](http://arxiv.org/abs/2504.09723v1)

- AGENTA/B: introduces a system for automated and scalable web A/B testing using interactive LLM agents, including LLM Agent Generation, Testing Preparation, Agent-Environment Interaction, and Post-Testing Analysis modules.
- The Agent-Environment Interaction loop involves an Environment Parsing Module, LLM Agent (Action Prediction), Action Execution Module, and Agent Profiling Module to simulate realistic user behavior on live websites.
- AGENTA/B enables rapid, risk-free behavioral piloting for UX evaluation by generating diverse agent personas and analyzing their interactions across different design variants.


---

[MLRC-BENCH: Can Language Agents Solve Machine Learning Research Challenges?](http://arxiv.org/abs/2504.09702v1)

- MLRC-BENCH: introduces a benchmark to evaluate language agents on machine learning research challenges, including Language Agent, Task Description, Starter Code, Human Idea, Implementation, LLM Explainer, Underlying Idea, LLM Judge, and Scorer.
- The benchmark provides a task environment with detailed descriptions, starter code, and optional human ideas to the Language Agent.
- The agent's Implementation is evaluated by an evaluation pipeline consisting of an LLM Explainer, LLM Judge, and Scorer using objective and subjective metrics.


---

[EMOAGENT: ASSESSING AND SAFEGUARDING HUMAN-AI INTERACTION FOR MENTAL HEALTH SAFETY](http://arxiv.org/abs/2504.09689v2)

- EmoAgent: introduces a multi-agent AI framework designed to evaluate and mitigate mental health hazards in human-AI interactions, with EmoEval simulating virtual users and EmoGuard providing real-time interventions.
- EmoEval assesses psychological states using clinically proven tools and simulates large-scale human-AI conversations with a Character-based Agent and Dialog Manager Agent.
- EmoGuard acts as a real-time intermediary layer with a Safeguard Agent comprising an Emotion Watcher, Thought Refiner, Dialog Guide, and Manager, which iteratively trains to mitigate risks.


---

[AgentDynEx: Nudging the Mechanics and Dynamics of Multi-Agent Simulations](http://arxiv.org/abs/2504.09662v1)

- AgentDynEx: introduces a LLM-based system for setting up multi-agent simulations, including a Configuration Matrix (structured setup framework), Initializing Mechanics (defines simulation world), Tracking Dynamics (monitors simulation progress), Nudging (intervenes in running simulation), Dynamic Reflection (automatic nudge suggestion), Manual Intervention (human-driven nudging), Holistic Reflection (post-run error identification), Debugging Lists (problem-solution repository), GPTeam (multi-agent simulation engine), LLMs (language models), Run Logs (simulation event records), Intermediate Summaries (runtime progress updates), and Updated Configuration (refined simulation setup).
- AgentDynEx balances simulation mechanics and dynamics through a structured configuration phase, dynamic runtime nudging based on reflection, and post-run holistic reflection for configuration updates.
- The system uses LLMs and the GPTeam engine to enable users to define scenarios, monitor progress via logs and summaries, intervene manually or automatically, and iteratively refine simulation setups.


---

[Fine-tuning a Large Language Model for Automating Computational Fluid Dynamics Simulations](http://arxiv.org/abs/2504.09602v2)

- Multi-agent system: introduces an approach for automating computational fluid dynamics simulations using a fine-tuned Large Language Model.
- The system orchestrates a workflow with a pre-checker for input validation, a fine-tuned LLM for configuration generation using Chain-of-Thought, a runner for simulation execution, and a corrector for error resolution.
- The fine-tuned LLM, trained on the NL2FOAM dataset, translates natural language descriptions into executable OpenFOAM configurations, achieving high performance on diverse CFD tasks.


---

[HM-RAG: Hierarchical Multi-Agent Multimodal Retrieval Augmented Generation](http://arxiv.org/abs/2504.12330v1)

- HM-RAG: introduces a novel Hierarchical Multi-Agent Multimodal Retrieval Augmented Generation framework with Decomposition Agent (Decomposes complex queries), Vector-based Retrieval Agent (Retrieves from vector database), Graph-based Retrieval Agent (Retrieves from graph database), Web-based Retrieval Agent (Retrieves from web sources), Decision Agent (Synthesizes and refines answers), and LLM (Processes queries and generates text), designed for collaborative multimodal knowledge synthesis.
- The framework employs a three-tiered architecture with specialized agents for query decomposition, multi-source retrieval, and answer refinement.
- HM-RAG achieves superior performance by integrating diverse data sources and leveraging multi-agent collaboration for complex query handling.


---

[CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent](http://arxiv.org/abs/2504.13192v1)

- CheatAgent: introduces a novel attack framework, with Insertion Positioning, LLM Agent-Empowered Perturbation Generation, LLM-Based Agent, and Trainable Prefix Prompt components, designed to attack LLM-empowered recommender systems in a black-box setting.
- The framework leverages an LLM-based agent to generate adversarial perturbations by identifying optimal insertion positions and iteratively refining the attack strategy via prompt tuning based on victim feedback.
- CheatAgent aims to demonstrate the safety vulnerability of LLM-empowered recommender systems to subtle adversarial attacks crafted by simulating human-like decision processes.


---

[UXAgent: A System for Simulating Usability Testing of Web Design with LLM Agents](http://arxiv.org/abs/2504.09407v2)

- UXAgent: introduces a system for simulating usability testing of web design with LLM agents, including a Persona Generator, LLM Agent, Universal Browser Connector, Agent Interview Interface, and Simulation Replay Interface.
- The LLM Agent features a two-loop architecture with Fast and Slow Loops, supported by Perceive, Planning, Action, Reflection, Wonder Modules, and a Memory Stream.
- The Universal Browser Connector provides the Observation Space and Action Space for the LLM Agent to interact with real-world web environments.


---


#### 12th April 2025

[Semantic Commit: Helping Users Update Intent Specifications for AI Memory at Scale](http://arxiv.org/abs/2504.09283v1)

- SEMANTICCOMMIT: introduces a system for managing AI agent memory updates, featuring a UI, backend, knowledge graph, information retrieval pipeline with retrieval and conflict classification stages, and an LLM.
- The system helps users detect and resolve semantic conflicts in natural language intent specifications using a knowledge graph-based RAG pipeline and LLMs for suggestions.
- The interface provides global and local conflict detection and resolution options, allowing users to review, edit, and validate AI-proposed changes.


---

[Langformers: Unified NLP Pipelines for Language Models](http://arxiv.org/abs/2504.09170v1)

- Langformers: introduces an open-source Python library designed to streamline NLP pipelines through a unified, factory-based interface, including tasks (Central interface), generators (LLM interaction), labellers (Automated text annotation), classifiers (MLM fine-tuning), mlms (MLM training/pretraining), embedders (Text embedding generation), searchers (Vector database integration), rerankers (Search result reordering), and mimickers (Knowledge distillation).
- The library consolidates various NLP tasks for LLMs and MLMs into a cohesive API, supporting platforms like Hugging Face and Ollama.
- Key innovations include task-specific factories, built-in memory and streaming for conversational agents, and a lightweight, modular design.


---

[Tell-XR: Conversational End-User Development of XR Automations](http://arxiv.org/abs/2504.09104v1)

- Tell-XR: introduces a conversational end-user development system for XR automations, with User Interface (Handles multimodal input), User Interface (Handles multimodal input), Tell-XR Bot (Core authoring system), Tell-XR Bot (Routes requests), Tell-XR Bot (Manages dialogue phases), Tell-XR Bot (Generates JSON rule), Tell-XR Bot (External tool access), Tell-XR Bot (Stores dialogue history), Automation Engine (Manages XR state), Automation Engine (Tracks object states), and Automation Engine (Stores/executes rules) components, enabling users to define event-condition-action rules via natural language and multimodal interaction.
- The system leverages large language models within the Tell-XR Bot to interpret user intent and guide them through distinct dialogue phases for defining and refining automations.
- The architecture integrates a multimodal user interface for VR and AR, the LLM-based bot for conversation, and an automation engine managing the XR environment state and executing rules.


---


#### 11th April 2025

[MCP Bridge: A Lightweight, LLM-Agnostic RESTful Proxy for Model Context Protocol Servers](http://arxiv.org/abs/2504.08999v1)

- MCP Bridge: introduces a lightweight, LLM-agnostic RESTful proxy system with Client Applications, RESTful API, MCP Bridge, MCP Servers, MCP-Gemini Agent, and LLM components, designed to connect resource-constrained clients to MCP servers via a unified API.
- The system decouples client applications from underlying MCP server processes, enabling access to MCP functionality without local process execution constraints.
- MCP Bridge implements a risk-based execution model for security and supports various MCP server transports while maintaining backward compatibility.


---

[DocAgent: A Multi-Agent System for Automated Code Documentation Generation](http://arxiv.org/abs/2504.08725v1)

- DocAgent: introduces a multi-agent system for automated code documentation generation, which includes Navigator Module, Repository AST Parsing, Dependency DAG, Topological Traversal, Topological Sorting, Dependency-Aware Processing Order, Multi-Agent Documentation Generation, Reader, Searcher, Writer, Verifier, and Orchestrator.
- DocAgent uses a Navigator Module to establish dependency-aware processing order and a Multi-Agent Documentation Generation module with specialized agents to collaboratively generate documentation.
- The system aims to address challenges in automated code documentation by ensuring completeness, helpfulness, and truthfulness through topological processing and multi-agent collaboration.


---

[SEAVIEW: Software Engineering Agent Visual Interface for Enhanced Workflow](http://arxiv.org/abs/2504.08696v1)

- SEAVIEW: introduces a visualization framework for software engineering agent experiments, comprising a web frontend for user interaction, a backend for data processing, PostgreSQL for structured data storage, object storage for large files, and external environment for running experiments.
- SEAVIEW framework aims to assist researchers in debugging and improving software engineering agents by providing experiment health, comparison, summarization, and reporting capabilities.
- The tool is designed to analyze agent trajectories and experiment results, offering insights into agent behavior and performance across different experimental setups and parameters.


---

[A Survey of Frontiers in LLM Reasoning: Inference Scaling, Learning to Reason, and Agentic Systems](http://arxiv.org/abs/2504.09037v1)

- LLM Reasoning System: introduces, Reasoner (generates reasoning steps), Verifier (evaluates reasoning quality), and Refiner (improves reasoning trajectories), which are key components for effective reasoning in large language models.
- The Reasoner proposes responses, the Verifier judges their quality, and the Refiner revises flawed outputs based on feedback.
- These components can be organized in standalone LLMs, single-agent systems interacting with environments, or multi-agent systems communicating with each other.


---



[AGENTREWARDBENCH: Evaluating Automatic Evaluations of Web Agent Trajectories](http://arxiv.org/abs/2504.08942v1)

- AGENTREWARDBENCH: introduces a benchmark for evaluating LLM judges for web agent trajectories, including a Web Agent (Performs tasks on web), Web Environment (Simulated or real websites), Trajectory (Agent's sequence of actions), Human Annotator (Provides ground truth labels), LLM Judge (Evaluates agent trajectories), Judge Model (Specific LLM judge implementation), and Input Representation (Trajectory data for judge).
- The benchmark contains over 1300 trajectories from various web agents and environments, annotated by experts for success, side effects, and repetition.
- Evaluation shows that simpler LLM judge input representations can achieve higher agreement with human experts than prior methods, and rule-based evaluation often underestimates agent success.


---


[TP-RAG: Benchmarking Retrieval-Augmented Large Language Model Agents for Spatiotemporal-Aware Travel Planning](http://arxiv.org/abs/2504.08694v1)

- TP-RAG (Travel Planning - Retrieval-Augmented Generation): introduces benchmark for retrieval-augmented spatiotemporal-aware travel planning with Inputs, Agent, Plan, and Evaluate components.
- TP-RAG benchmark dataset includes real-world travel queries, fine-grain annotated Points of Interest, and high-quality travel trajectory references for context-aware planning.
- TP-RAG benchmark facilitates evaluation of LLM agents in generating spatiotemporally coherent travel plans utilizing trajectory-level knowledge for improved travel practicality.


---

[Voice Interaction With Conversational AI Could Facilitate Thoughtful Reflection and Substantive Revision in Writing](http://arxiv.org/abs/2504.08687v1)

- LLM-powered Conversational Agent for Writing Reflection: introduces a system designed with LLM-powered Conversational Agent, Voice Input, Written Output, Feedback, Questions, Advice, and UI Affordances to investigate voice interaction for writing reflection.
- This system emphasizes Contextualization and Control to improve user experience and maintain writer's ownership during revision process.
- The research aims to evaluate how voice input modality affects reflection depth and revision quality compared to text input when using conversational agents.


---

[Do LLMs trust AI regulation? Emerging behaviour of game-theoretic LLM agents](http://arxiv.org/abs/2504.08640v1)

- FAIRGAME (Framework for AI Agents Bias Recognition using Game Theory): introduces user, developer, and regulator components to model regulatory ecosystem.
- Framework uses evolutionary game theory and LLMs to investigate strategic choices under different regulatory scenarios.
- FAIRGAME aims to identify emerging behaviors of strategic AI agents in game-theoretic settings and compare them with game-theoretic predictions.


---

[MOOSEAGENT: A LLM BASED MULTI-AGENT FRAMEWORK FOR AUTOMATING MOOSE SIMULATION](http://arxiv.org/abs/2504.08621v1)

- MooseAgent: introduces an automated framework for MOOSE simulation, integrating Requirement, Alignment, Architect, Vector knowledge base, Error Correction, and Runner components.
- MooseAgent framework uses LLMs to understand user needs, generate MOOSE input files, and iteratively refine them using a vector database and error correction.
- This multi-agent system aims to simplify finite element simulation by automating pre-processing, solver configuration, and post-processing stages in MOOSE.


---

[Task Memory Engine (TME): Enhancing State Awareness for Multi-Step LLM Agent Tasks](http://arxiv.org/abs/2504.08525v1)

- Task Memory Engine (TME): introduces a memory framework for LLM agents, with Task Memory Tree (hierarchical task state representation), Task Relationship Inference Module (reasons about task relationships), and Prompt Synthesizer (generates context-aware prompts).
- TME enhances state awareness by tracking task execution using Task Memory Tree, inferring task relationships with Task Relationship Inference Module, and generating adaptive prompts with Prompt Synthesizer.
- This framework enables robust, interpretable, and token-efficient execution of complex multi-step tasks by providing structured memory and intelligent prompt construction.


---

[Adopting Large Language Models to Automated System Integration](http://arxiv.org/abs/2504.08490v1)

- Compositio Prompto (Compositio Prompto): introduces an architecture employing Large Language Models for automated service composition, utilizing task specifications, service documentation, input/output schemas to create a prompt for the LLM, which then generates executable service compositions.
- The architecture aims to mitigate complex formal modeling in service composition by using natural language input and OpenAPI specifications, focusing on generating reusable service compositions as program code.
- Compositio Prompto architecture is evaluated for service composition and discovery using Retrieval Augmented Generation (RAG) and benchmarks like RestBench and SOCBench-D to address limitations of input token length and improve service discovery in automated system integration.


---

[Beyond Self-Reports: Multi-Observer Agents for Personality Assessment in Large Language Models](http://arxiv.org/abs/2504.08399v1)

- Multi-Observer LLM Personality Assessment Framework: introduces a novel method for evaluating LLM personality by utilizing multiple observer agents, simulating interactive scenarios, and aggregating observer reports for robust assessment.
- This framework incorporates agent configuration to define agent profiles and relationships, interactive scenario simulation to generate dialogues, and personality reports to collect self- and observer- assessments.
- By aggregating multiple observer reports, the framework aims to reduce individual biases and achieve a more context-sensitive and reliable personality evaluation of LLMs compared to self-report methods.


---

[Evaluating the Bias in LLMs for Surveying Opinion and Decision Making in Healthcare](http://arxiv.org/abs/2504.08260v1)

- LLM-based Survey Simulation Framework: introduces a framework for evaluating LLMs in healthcare decision-making, with Survey Dataset, Demographics features, Prompt Construction Module, General prompt, Prompt with context, Prompts, LLM models, and Generated Vaccination decision.
- This framework compares LLM-generated vaccination decisions with real-world survey data to assess alignment and biases across demographic groups.
- The framework helps understand LLMs' capabilities and limitations in simulating healthcare behaviors and decision-making under different pandemic contexts.


---

#### 10th April 2025

[Orchestrating Agents and Data for Enterprise: A Blueprint Architecture for Compound AI](http://arxiv.org/abs/2504.08148v1)

- Blueprint Architecture: introduces a blueprint for compound AI systems, with Agent (maps models and APIs), Agent Registry (metadata store for agents), Task Planner (creates agentic workflows), Task Coordinator (coordinates workflow execution), Budget (records QoS stats), Data Registry (metadata store for data), Data Planner (generates query plans), Optimizer (performs multi-objective optimization), Streams (facilitate data and control flow), and Session (provides context for agents).
- Blueprint Architecture focuses on orchestrating agents and data using streams to manage data and instructions flow, aiming for seamless integration and optimized workflows in enterprise AI applications.
- The architecture emphasizes key components like registries for agents and data, planners for tasks and data queries, and coordinators for execution, all designed to enhance observability, controllability, and optimization in compound AI systems.


---

[Test Amplification for REST APIs via Single and Multi-Agent LLM Systems](http://arxiv.org/abs/2504.08113v1)

- Agentic LLM systems: introduces single-agent approach with OpenAPI Retriever and Local Executor components for REST API test amplification.
- Agentic LLM systems: also introduces multi-agent approach with specialized agents like Header-, Parameter-, Value-, Planner-, Writer-, Executor- and Repair-agents to improve test generation.
- Agentic LLM systems: demonstrates that multi-agent system achieves higher API coverage and bug detection compared to single-agent system, but with increased computational cost.


---

Benchmarking Adversarial Robustness to Bias Elicitation in Large Language Models: Scalable Automated Assessment with LLM-as-a-Judge](http://arxiv.org/abs/2504.07887v1)

- CLEAR-Bias (Corpus for Linguistic Evaluation of Adversarial Robustness against Bias): introduces a scalable benchmarking framework to evaluate LLM robustness against adversarial bias elicitation, with CLEAR-Bias-dataset, jailbreak prompts, base prompts, control set, judge selection, candidate LLMs, collect judgments, evaluate agreement, selected judge, two-step safety evaluation, initial assessment with base prompts, compute bias-specific safety score, adversarial analysis with jailbreak prompts, overall LLM safety score, and LLM vulnerability analysis.
- The framework employs LLM-as-a-Judge paradigm for automated assessment, utilizing a two-step safety evaluation process involving initial assessment with base prompts and subsequent adversarial analysis with jailbreak techniques.
- The methodology aims to systematically probe models across sociocultural dimensions, quantify robustness through safety scores, and investigate vulnerabilities in safety mechanisms, ultimately revealing critical trade-offs between model size and safety.


---

[An LLM-Driven Multi-Agent Debate System for Mendelian Diseases](http://arxiv.org/abs/2504.07881v2)

- MD2GPS (Medical Doctor 2 GPS): introduces LLM-driven multi-agent debate system, with Data Agent, Knowledge Agent, and Debate Agent, for Mendelian diseases diagnosis.
- MD2GPS system utilizes Data Agent to process genetic variants and phenotypes, Knowledge Agent with GPT-4 for gene analysis, and Debate Agent to integrate and refine diagnostic outcomes.
- The multi-agent debate framework of MD2GPS enhances diagnostic accuracy and interpretability by leveraging diverse perspectives and evidence consistency evaluation.


---

[Deceptive Automated Interpretability: Language Models Co-ordinating to Fool Oversight Systems](http://arxiv.org/abs/2504.07831v1)

- SAEs (Sparse Autoencoders): introduces framework with Labeling Agent, Simulating Agent, Overseer, Monitoring, Visible Communication, and Hidden Communication to investigate deceptive interpretability in language models.
- The framework uses Labeling Agent to create feature labels, Simulating Agent to predict activations, and Overseer to detect deceptive labels, with agents communicating visibly and hiddenly.
- This setup explores how language models can coordinate to deceive oversight systems by employing steganography for hidden communication and generating deceptive explanations.


---

[MOSAIC: Modeling Social AI for Content Dissemination and Regulation in Multi-Agent Simulations](http://arxiv.org/abs/2504.07830v1)

- MOSAIC (Modeling Social AI for Content Dissemination and Regulation in Multi-Agent Simulations): introduces a multi-agent social simulation framework, with Human Persona Survey, Persona Generation, Agent Network, Agent Memory, Reflection, Interaction, BEFORE Action, Comment AFTER Action, Agent Daily News, Fact-Checking Types, Community Notes, Third Party Fact-Checking, and Hybrid Fact-Checking, for modeling content diffusion, user engagement, and misinformation propagation in social networks.
- MOSAIC framework utilizes LLM-powered agents with memory and reflection capabilities to simulate realistic social behaviors and evaluate content moderation strategies like community-based, third-party, and hybrid fact-checking.
- The framework allows for analyzing the effectiveness of different fact-checking mechanisms in mitigating misinformation spread while preserving user engagement in simulated social media environments.


---

[Synthesizing High-Quality Programming Tasks with LLM-based Expert and Student Agents](http://arxiv.org/abs/2504.07655v1)

- PYTASKSYN introduces a novel synthesis technique for generating programming tasks, which includes Generation (task creation stage) and Validation (task quality check stage) stages, performed by SIMEXPERT (expert agent for task generation), SIMTUTOR (tutor agent for test suite and context validation), and SIMSTUDENT (student agent for comprehensibility validation).
- PYTASKSYN employs a multi-agent approach with specialized roles, where SIMEXPERT generates Task Description (task explanation) and Test suite (code verification tests), while SIMTUTOR and SIMSTUDENT assess Context relevance (theme and concepts alignment) and Comprehensibility (task clarity).
- PYTASKSYN aims to improve the quality of AI-generated programming tasks by automating validation through simulated agents, ensuring tasks are relevant, correct, and comprehensible for students, thus reducing the need for human intervention.


---

[Boosting Universal LLM Reward Design through Heuristic Reward Observation Space Evolution](http://arxiv.org/abs/2504.07596v2)

- ROS Evolution Framework: introduces heuristic reward observation space evolution for LLM-driven reward design, incorporating user description structuring, LLM for reconciliation, LLM for reward design, state history memory, performance summarization, reward space mapping, simulation environment, state usage tracker, relevant state space, state selection, and internal operation.
- ROS Evolution Framework utilizes State Execution Table to track historical state usage and success contributions, overcoming Markovian constraint in LLM dialogues for effective exploration.
- ROS Evolution Framework reconciles user-provided task descriptions with expert-defined success criteria using structured prompts, ensuring alignment in reward design objectives and improving reward generation stability.


---

[A taxonomy of epistemic injustice in the context of AI and the case for generative hermeneutical erasure](http://arxiv.org/abs/2504.07531v1)

- Taxonomy of epistemic injustice in AI: introduces a novel taxonomy of epistemic injustice in the context of Artificial Intelligence, focusing on generative AI and detailing Generative Hermeneutical Ignorance, Generative Hermeneutical Access, Generative Manipulative Testimonial Injustice, Generative Amplified Testimonial Injustice, and Generative Conceptual Erasure.
- This taxonomy explores how AI systems can perpetuate and amplify epistemic injustices, particularly through generative models, by misrepresenting marginalized experiences, obstructing information access, spreading disinformation, amplifying existing biases, and ultimately eroding diverse epistemological frameworks.
- The paper highlights the concept of Generative Hermeneutical Erasure as a novel form of epistemic injustice, emphasizing the risk of AI-driven erosion of non-Western epistemologies and the importance of decolonial AI approaches to mitigate these harms.


---

[Kimi-VL Technical Report](http://arxiv.org/abs/2504.07491v1v1)

- Kimi-VL (Vision Language Model): introduces MoonViT, MLP Projector, and MoE Language Decoder for efficient multimodal reasoning and long-context understanding.
- Kimi-VL utilizes MoonViT for native-resolution image processing, MLP Projector to align visual features, and MoE Language Decoder for parameter-efficient language generation.
- Kimi-VL-Thinking, an advanced variant, enhances long-horizon reasoning through long chain-of-thought and reinforcement learning, building upon Kimi-VL's architecture.


---

[Enhanced Question-Answering for Skill-based learning using Knowledge-based AI and Generative AI](http://arxiv.org/abs/2504.07463v1)

- Ivy (intelligent agent): introduces an architecture for skill-based learning question answering, with Classify Answerability, Knowledge Retrieval Module, TMK Knowledge Base, Response Generation Module, and Response Optimizer Module components.
- Ivy leverages TMK (Task-Method-Knowledge) models to represent skills and Generative AI to enhance explanations for learners' questions in online AI courses.
- The framework aims to provide deeper, more relevant feedback compared to agents relying on unstructured text, improving learners' understanding of procedural knowledge and reasoning in skill-based learning.


---

[Achilles Heel of Distributed Multi-Agent Systems](http://arxiv.org/abs/2504.07461v1)

- DMAS (Distributed Multi-Agent System): introduces distributed architecture with Control System managing third-party Agents through API Interfaces and receiving Responses.
- DMAS framework addresses challenges of heterogeneity, scalability, and computational constraints in multi-agent systems by utilizing remotely hosted agents.
- The distributed nature of DMAS raises trustworthiness concerns, including free riding, malicious attacks, communication delays and unstable connections, which are systematically analyzed in the paper.


---

[Beyond LLMs: A Linguistic Approach to Causal Graph Generation from Narrative Texts](http://arxiv.org/abs/2504.07459v1)

- DA framework (Causal Graph Generation Framework): introduces a novel method for generating causal graphs from narrative texts, incorporating Vertices Extraction, Expert Index Extraction, STAC Categorization, and Diagram Formulation components.
- This framework leverages linguistic feature extraction and a quaternary classification system (STAC) to enhance the precision and interpretability of causal link identification compared to LLM-only approaches.
- The system employs a hybrid model combining ROBERTa embeddings with an Expert Index of linguistic features, followed by a structured prompting process for refining and constructing the final causal graph.


---

[Enhancing Player Enjoyment with a Two-Tier DRL and LLM-Based Agent System for Fighting Games](http://arxiv.org/abs/2504.07425v1)

- TTA (Two-Tier Agent): introduces a two-tier system with DRL game-playing agents tier, utilizing a network architecture with CNN and RNN feature extractors and actor-critic networks, and Hyper-agent tier, employing a LLM Hyper Agent for dynamic opponent selection based on player data and feedback.
- The DRL game-playing agents tier consists of Input (game pixels, scalar info, action sequence)/Features Extractor (CNN, LSTM)/Agent's Network (Actor Net, Critic Net)/Value (value function)/Output (action distribution), while the Hyper-agent tier includes Agent Archive (DRL agent storage)/LLM Hyper Agent (opponent selector)/Game Manager (data and game management)/Player's Feedback (human input)/Playing Data (game history).
- TTA aims to enhance player enjoyment in fighting games by providing diverse and adaptive AI opponents, leveraging DRL for agent skill and LLMs for personalized opponent selection, demonstrating improvements in advanced skill execution and player satisfaction.


---

[AGENTADA: Skill-Adaptive Data Analytics for Tailored Insight Discovery](http://arxiv.org/abs/2504.07421v1)

- AGENTADA (skill-informed data analytics agent): introduces dataset-to-insight extraction strategy with Question Generation, RAG-Based Skill Matcher, Code Generation, Answer Generation, and Insight Generation components.
- AGENTADA leverages hybrid Retrieval-Augmented Generation (RAG)-based skill matcher to choose best data analytics skill from skill library.
- AGENTADA is evaluated using KAGGLEBENCH benchmark and SCORER evaluation framework, demonstrating improved performance over existing tools.


---

[Automating quantum feature map design via large language models](http://arxiv.org/abs/2504.07396v1)

- Agentic System: introduces an autonomous system for quantum feature map design, incorporating Human input, LLM, Generation, Storage, Validation, Evaluation, and Review components.
- Agentic System iteratively refines quantum feature maps through Feedback from The Experimental Result, utilizing LLM for idea Generation and external knowledge in Storage for Validation and Review.
- The framework leverages components like Storage for academic papers and PennyLane library documentation, and Evaluation for performance assessment, to automate quantum feature map research workflow.


---

[TALE: A Tool-Augmented Framework for Reference-Free Evaluation of Large Language Models](http://arxiv.org/abs/2504.07385v1)

- TALE (Tool-Augmented LLM Evaluation): introduces a reference-free framework for evaluating LLM responses, with Query Generation, Web Search, Evidence Summarizer, Reflector, Query Refiner, Judge, and Short-Term Memory components.
- TALE iteratively refines web queries, collects and summarizes external information, and reflects on findings to evaluate LLM outputs without relying on pre-annotated references.
- The framework enhances the reliability of LLM evaluations in dynamic real-world scenarios by grounding judgments in external, verifiable evidence through tool-augmented approach.


---

[Throughput-Optimal Scheduling Algorithms for LLM Inference and AI Agents](http://arxiv.org/abs/2504.07347v1)

- This paper introduces a queuing-theoretic framework for LLM inference scheduling, encompassing Batch Processing, Prefill, Decode, Processed, Processing stages, and extends to AI agent workloads with Orchestrator, Agents, Tools, Global History, LLM Serving, Load Balancer, LLM Engine, Scheduler, KV Cache, and LLM components.
- The framework analyzes throughput optimality of work-conserving scheduling algorithms for both individual LLM requests and complex AI-agent systems, highlighting the importance of token budget and batching strategies for efficient LLM inference.
- Evaluations using real-world systems like Orca and Sarathi-serve demonstrate throughput optimality, while FasterTransformer and vanilla vLLM are shown to be potentially suboptimal under certain workloads, emphasizing the practical implications of queuing theory in LLM system design.


---

[Modeling Response Consistency in Multi-Agent LLM Systems: A Comparative Analysis of Shared and Separate Context Approaches](http://arxiv.org/abs/2504.07303v1)

- RCI (Response Consistency Index): introduces a probabilistic framework for analyzing shared and separate context configurations in multi-agent LLM systems, focusing on centralized memory, distributed memory, context retention duration, incorrect statements, accurate statements, consistency evaluation, and latency measurement.
- The framework evaluates the impact of memory limitations and noise on response consistency and response time in LLM-based MAS.
- RCI metric quantifies the trade-offs between scalability, response consistency, and performance in different context configurations.


---


#### 9th April 2025

[REVIEW OF CASE-BASED REASONING FOR LLM AGENTS: THEORETICAL FOUNDATIONS, ARCHITECTURAL COMPONENTS, AND COGNITIVE INTEGRATION](http://arxiv.org/abs/2504.06943v2)

- CBR-GDA (Case-Based Reasoning - Goal-Driven Autonomy): introduces a framework integrating Case-Based Reasoning with Goal-Driven Autonomy to enhance LLM agents by incorporating Case Representation and Indexing Strategies, Hybrid Retrieval Mechanisms, Adaptation Mechanisms, LLM Reasoning Processes Integration, Cognitive Dimensions Integration, Planning Case Base and Mismatch-Goal Case Base.
- This framework leverages CBR for persistent memory and structured reasoning, while utilizing LLMs for language understanding, aiming to improve reasoning transparency, domain adaptation, and solution quality in complex problem-solving scenarios.
- The CBR-GDA framework facilitates continuous learning and adaptation through case acquisition and refinement, enabling agents to dynamically adjust objectives and improve goal reasoning capabilities in dynamic environments.


---


[REVIEW OF CASE-BASED REASONING FOR LLM AGENTS: THEORETICAL FOUNDATIONS, ARCHITECTURAL COMPONENTS, AND COGNITIVE INTEGRATION](http://arxiv.org/abs/2504.06943v1)

- CBR-GDA Framework: introduces architecture for CBR-enhanced LLM agents, with Case Representation and Indexing, Hybrid Retrieval Mechanisms, Adaptation Mechanisms, LLM Reasoning Processes Integration, Cognitive Dimensions, Goal-Driven Autonomy, Planning Case Base, and Mismatch-Goal Case Base.
- This framework integrates Case-Based Reasoning and Goal-Driven Autonomy to enhance LLM agents' reasoning, adaptability, and transparency by leveraging past experiences and dynamic goal adjustment.
- The architecture utilizes two case bases, Planning Case Base and Mismatch-Goal Case Base, to manage planning and goal reformulation based on discrepancies between expected and actual outcomes.


---

[FamilyTool: A Multi-hop Personalized Tool Use Benchmark](http://arxiv.org/abs/2504.06766v1)

- KGETool: introduces KG-augmented LLM tool use pipeline, with Query, Full KG, Tools, LLM for KG, KG Extraction, Relation Path, Path Extraction, Sub KG, LLM for Tool Use and Tool Call, to evaluate LLMs in personalized multi-hop tool use scenarios.
- KGETool framework extracts sub-KG from Full KG using KG Extraction module composed of Relation Path and Path Extraction, then utilizes Sub KG and Tools with LLM for Tool Use to generate Tool Call based on user Query.
- The pipeline emphasizes generalization in inductive KG settings, where KGETool leverages LLMs' ability to handle evolving knowledge graphs without retraining by dynamically adapting to unseen user preferences and relationships.


---

[AgentFM: Role-Aware Failure Management for Distributed Databases with LLM-Driven Multi-Agents](http://arxiv.org/abs/2504.06614v1)

- AgentFM (Role-Aware Failure Management Framework): introduces a role-aware failure management framework for distributed databases, with Meta-Agent (Orchestrates agents), Task Agents (Manage failure tasks), Data Agents (Handle data sources), System Agents (Represent node roles), and Standalone Agents (Agents on each node) components.
- AgentFM leverages LLM-driven multi-agents to address failure management by considering system roles, data roles, and task roles, using a Meta-Agent (Orchestrates agents) for orchestration and specialized Task Agents (Manage failure tasks) like Detection Agent (Identifies anomalies), Diagnosis Agent (Classifies issues), and Mitigation Agent (Proposes solutions).
- AgentFM integrates multimodal data sources through Data Agents (Handle data sources) such as Metric Agent (Metrics data extraction) and Log Agent (Logs data extraction), employing specialized System Agents (Represent node roles) like Config Agent (Configuration management), Coordinator Agent (Coordination management), and Storage Agent (Storage management) to enhance failure management in distributed databases.


---

[Right Prediction, Wrong Reasoning: Uncovering LLM Misalignment in RA Disease Diagnosis](http://arxiv.org/abs/2504.06581v1)

- Framework for RA patients diagnosis: introduces a system employing PreRAID dataset, Texts, Embeddings, Vector DB, Knowledge Base, Medical Expert Guided Prompt, LLM, RAG, Prompt, Output, Prediction, and Reasoning to investigate LLM's diagnostic capabilities and reasoning for Rheumatoid Arthritis.
- This framework utilizes patient symptom Texts converted to Embeddings and stored in Vector DB, leveraging Knowledge Base and Medical Expert Guided Prompt for LLM with RAG to generate Output, Prediction of RA, and Reasoning.
- The framework explores different architectures with varying numbers of LLM agents and knowledge base integration to assess diagnostic accuracy and reasoning quality in RA disease prediction.


---

[NEEDLEINATABLE: Exploring Long-Context Capability of Large Language Models towards Long-Structured Tables](http://arxiv.org/abs/2504.06560v1)

- NEEDLEINATABLE (NIAT): introduces NIAT benchmark and data synthesis method to evaluate and improve large language models on long-structured tables.
- NIAT benchmark assesses large language models' ability to extract specific cells from long tables using location-based and question-based queries.
- Data synthesis method uses chain-of-thought reasoning to generate training data for enhancing large language models' long-table comprehension.


---

#### 8th April 2025

[FEABench: Evaluating Language Models on Multiphysics Reasoning Ability](http://arxiv.org/abs/2504.06260v1)

- FEABench: introduces benchmark for evaluating LLMs and LLM agents in multiphysics reasoning, using ControllerAgent, Evaluator, CorrectorSubAgent, and ToolLookupAgent components to solve engineering problems with FEA software.
- FEABench framework employs multi-agent system with specialized tools and feedback mechanisms to enhance LLMs' ability to generate executable code for COMSOL Multiphysics API.
- FEABench benchmark and agentic framework aim to advance automation in engineering by augmenting LLMs with numerical solvers and physics reasoning capabilities.


---

[CAI: An Open, Bug Bounty-Ready Cybersecurity AI](http://arxiv.org/abs/2504.06017v2)

- CAI (Cybersecurity AI): introduces an open-source framework for democratizing security testing, with HITL, Turns, Patterns, Handoffs, Agents, Tools, Extensions, and Tracing components.
- CAI framework combines modular agent design, seamless tool integration, and human oversight for AI-powered bug bounty testing.
- CAI aims to dismantle the lock-in of dominant platforms, offering a democratized alternative for vulnerability discovery.


---

[AGENT GUIDE: A SIMPLE AGENT BEHAVIORAL WATERMARKING FRAMEWORK](http://arxiv.org/abs/2504.05871v1)

- Agent Guide: introduces a behavioral watermarking framework for intelligent agents, with Memory Module, Event Generation Module, Behavior Probability Generation Module, Agent Guide Module, and Action Execution Module.
- Agent Guide embeds watermarks by biasing agent's high-level behavior decisions while preserving the naturalness of specific action executions.
- The framework operates in rounds, simulating agent interactions and uses statistical analysis for watermark extraction, ensuring reliable detection.


---

[Are Generative AI Agents Effective Personalized Financial Advisors?](http://arxiv.org/abs/2504.05862v1)

- LLM-advisor: introduces User, Advisor, Preference Elicitation Stage, and Advisory Discussion Stage to provide personalized financial advice.
- The framework uses Preference Elicitation Stage to understand user needs before offering asset guidance in Advisory Discussion Stage.
- This approach aims to evaluate the effectiveness of LLM-based agents in complex financial advisory tasks.


---

[Single-Agent vs. Multi-Agent LLM Strategies for Automated Student Reflection Assessment](http://arxiv.org/abs/2504.05716v1)

- Single-Agent Assessment: introduces single LLM evaluator, Scoring Criteria, and LLM, where single LLM evaluates student reflection using score level descriptions.
- Single-Agent Assessment employs zero-shot and few-shot prompting to guide LLM's evaluation process based on scoring criteria for reflection assessment.
- This approach automates student reflection assessment by transforming qualitative responses into quantitative scores using a single LLM evaluator.


---

[Automated Archival Descriptions with Federated Intelligence of LLMs](http://arxiv.org/abs/2504.05711v1)

- Agentic AI-driven system: introduces an agentic AI-based metadata generation system, with User Input and Document (Provides archival material), Context Agent (Retrieves context information), LLM Instructor (Constructs instructions for LLMs), LLM Ensemble (Generates metadata descriptions), Validator Agent (Checks metadata descriptions), and LLM Federator (Synthesizes optimal metadata) to produce Metadata (Final metadata output) for archival descriptions.
- The system employs federated intelligence of multiple LLMs to automatically create complete and precise metadata descriptions, leveraging context and validation agents for consistency and quality.
- The federated optimization approach synthesizes metadata from an ensemble of LLMs, demonstrating superior performance compared to single-model solutions in metadata quality and reliability for archival materials.


---


[FactGuard: Leveraging Multi-Agent Systems to Generate Answerable and Unanswerable Questions for Enhanced Long-Context LLM Extraction](http://arxiv.org/abs/2504.05607v1)

- FactGuard (Leveraging Multi-Agent Systems to Generate Answerable and Unanswerable Questions for Enhanced Long-Context LLM Extraction): introduces a multi-agent framework for automated data augmentation, with Preparation-, QA Generation-, and Negative Example Generation-Stages, to create answerable and unanswerable question-answer pairs.
- FactGuard (Leveraging Multi-Agent Systems to Generate Answerable and Unanswerable Questions for Enhanced Long-Context LLM Extraction): employs agents like Quality-, Topic-, QA-, MRC-, and Rewrite-Agents, managed by Agent Console, to synthesize datasets for evaluating LLMs in long-context question answering.
- FactGuard (Leveraging Multi-Agent Systems to Generate Answerable and Unanswerable Questions for Enhanced Long-Context LLM Extraction): aims to address limitations of current LLMs in handling unanswerable questions within extended contexts by developing the FactGuard-Bench benchmark dataset.


---



#### 7th April 2025

[Fleming: An AI Agent for Antibiotic Discovery in Mycobacterium tuberculosis](https://www.biorxiv.org/content/10.1101/2025.04.01.646719v1.full.pdf)

- Fleming: introduces Fleming, an AI agent that orchestrates specialized agents, including Inhibition Agent (Predicts MTB inhibition), ADMET Agent (Predicts ADMET properties), Molecule Generation Agent (Generates novel molecules), and Molecular Optimization Agent (Optimizes ADMET properties), to perform tasks in TB antibiotic discovery.
- The Inhibition Agent uses an Inhibition prediction model (Predicts molecule inhibition) and Rationale extraction module (Identifies inhibitory substructures), while the ADMET Agent integrates ADMET models (Predicts ADMET properties), PaperQA2 (Analyzes literature), and a Molecular Describer (Describes molecule substructures).
- The Molecule Generation Agent employs a Conditional diffusion model (Generates novel molecules) and Synthemol (Generates synthesizable molecules), and the Molecular Optimization Agent uses a Manager agent (Coordinates optimization process) and Optimization agent (Performs optimization iteration) with SynSpace (Generates molecular neighbors) to improve ADMET properties.


---


[Mixture-of-Personas Language Models for Population Simulation](http://arxiv.org/abs/2504.05019v1)

- MoP (Mixture of Personas): introduces a probabilistic prompting framework, with Persona Synthesizer, Persona Gate, Exemplar Gate, Exemplar, and LLM Agent, that aligns LLM responses to target population characteristics.
- MoP framework uses Persona Gate to probabilistically select personas and Exemplar Gate to select exemplars, guiding LLM Agent to generate customized outputs.
- This approach enhances response diversity and relevance by incorporating persona descriptions and in-context examples without requiring model fine-tuning.


---

[PaperBench: Evaluating AI's Ability to Replicate AI Research](https://arxiv.org/abs/2504.01848)

- PaperBench: introduces a benchmark evaluating AI agents' ability to replicate research papers, including Agent (AI system replicating paper), Submission (Codebase repository), Reproduction Environment (VM executing submission), Rubric (Hierarchical evaluation criteria), Judge (LLM-based grader), and Grading (Assessment process).
- The benchmark requires agents to understand papers, develop codebases from scratch, and execute experiments to reproduce empirical results.
- Evaluation uses author-approved hierarchical rubrics and an LLM-based judge to score replication attempts based on code development, execution, and result matching.


---



[How to evaluate control measures for LLM agents? A trajectory from today to superintelligence](http://arxiv.org/abs/2504.05259v1)

- AI control: introduces a framework for adapting red teams affordances using capability profile, deployment context, threat models, threat-model-specific capabilities, example rules of control evaluation, example safety measures, and example safety case to systematically evaluate and improve AI safety measures as AI capabilities advance.
- The framework defines AI Control Levels (ACLs) based on threat model-specific capabilities, providing tailored control evaluation rules, measures, and safety cases for fictional models with increasing capabilities, aiming for practical and cost-effective control measures.
- This approach contrasts with traditional methods by considering model capability limitations in control evaluations, suggesting a path towards scalable risk management and highlighting the evolving nature of AI control safety cases from current models to superintelligent systems.


---

[DoCIA: An Online Document-Level Context Incorporation Agent for Speech Translation](http://arxiv.org/abs/2504.05122v1)

- DoCIA (Document-level Context Incorporation Agent): introduces an online framework for speech translation that incorporates document-level context through ASR Refining, MT and MT Refining stages to enhance translation performance.
- DoCIA framework refines both ASR transcriptions and machine translations using auxiliary LLM-based modules and multi-level context integration strategy to improve discourse coherence.
- The framework employs a refinement determination mechanism to ensure reliability by preventing hallucinations during context-aware refinement stages in speech translation pipeline.


---

[AI for Climate Finance: Agentic Retrieval and Multi-Step Reasoning for Early Warning System Investments](http://arxiv.org/abs/2504.05104v1)

- EW4All Financial Tracking AI-Assistant (Early Warning for All Financial Tracking AI-Assistant): introduces an AI-driven system for automating Early Warning System investment classification from multilateral development bank reports, utilizing PDF parsing, context augmentation, vector database storage/retrieval, classification/budget allocation, and expert verification.
- The framework employs multi-modal processing and agent-based retrieval-augmented generation to handle heterogeneous financial documents and improve accuracy in tracking climate finance investments.
- This AI-assistant aims to enhance financial transparency and decision-making in climate finance by providing structured insights into investment data and supporting resource allocation for climate resilience initiatives.


---

[Debate Only When Necessary: Adaptive Multiagent Collaboration for Efficient LLM Reasoning](http://arxiv.org/abs/2504.05047v1)

- DOWN (Debate Only When Necessary): introduces adaptive multiagent debate framework, with Initial Response Generation (Agent creates initial answer), Debate Engagement Check (Checks confidence score against threshold), Confidence-Guided Multi-agent Collaboration (Agents refine responses in rounds), Final Answer Generation (Selects final answer via voting or judge).
- DOWN framework uses Confidence Score (Model's certainty in answer) and Threshold (Confidence score limit for debate) to selectively activate debate among Agents (LLMs collaborating in debate) in Rounds (Iterative debate exchanges) for efficient reasoning.
- DOWN framework determines final answer via Voting-based Selection (Majority vote for final answer) or Judge-based Generation (Judge agent generates final answer), optimizing multiagent collaboration systems.


---


[The Dream Within Huang Long Cave: AI-Driven Interactive Narrative for Family Storytelling and Emotional Reflection](http://arxiv.org/abs/2504.04968v1)

- The Dream Within Huang Long Cave: introduces AI-driven interactive narrative art project, employing Analytic-Critical Method for character design, featuring LLM agent (YELL), CAVE environment, interactive narrative, MacGuffin, memory fragments and family documentary.
- This project utilizes Analytic-Critical Method's psychobiography data, discourse analysis, paranoiac-critical method and practice-based iteration to construct LLM agent YELL within CAVE environment for family storytelling and emotional reflection.
- The interactive narrative in CAVE installation uses MacGuffin and memory fragments to engage audience in dialogue with AI-driven virtual father figure, culminating in family documentary to deconstruct familial relationships and symbolic authority.


---

[Simulating Persuasive Dialogues on Meat Reduction with Generative Agents](http://arxiv.org/abs/2504.04872v1)

- Generative Agent-based Persuasion Dialogue Framework: introduces a simulation framework for persuasive dialogues using Persuader Agent, Recipient Agent, Recipient Persona, Internal Reflection, Questionnaire, Response Generation, and Conversation Transcript to explore meat reduction strategies.
- This framework utilizes generative agents to model persuasive conversations and validate them against psychological theory and human data, aiming to identify effective meat reduction strategies.
- The use of generative agents allows for cost-effective and scalable exploration of diverse persuasion strategies and participant groups, facilitating the development of targeted interventions for meat reduction.


---

[BIASINSPECTOR: Detecting Bias in Structured Data through LLM Agents](http://arxiv.org/abs/2504.04855v1)

- BIASINSPECTOR (Bias Inspector): introduces a multi-agent framework with Primary Agent, Advisor Agent, Toolset, and Bias Detection Method Library for automated bias detection in structured data based on user requirements.
- BIASINSPECTOR employs Primary Agent to formulate plans and execute tools, while Advisor Agent provides guidance and optimization, leveraging Toolset and Bias Detection Method Library for comprehensive bias analysis.
- The framework facilitates iterative interactions and delivers detailed reports with explanations and visualizations, addressing the limitations of existing methods in diversity, generalizability, and interpretability of bias detection in structured data.


---

[ELT-Bench: An End-to-End Benchmark for Evaluating AI Agents on ELT Pipelines](http://arxiv.org/abs/2504.04808v1)

- ELT-Bench: introduces an end-to-end benchmark for evaluating AI agents in building ELT pipelines, encompassing AI Agent, configuration codes, scripts, SQL queries, codebase, environment, data sources, data warehouse, Airbyte, DBT, and pipeline stages.
- ELT-Bench framework assesses AI agents' capability to construct ELT pipelines from scratch, involving data extraction and loading (Stage 1) and data transformation (Stage 2) using tools like Airbyte and DBT.
- This benchmark addresses the gap in evaluating AI agents for end-to-end ELT pipeline generation, providing a comprehensive assessment of AI in complex data engineering workflows.


---

[SciSciGPT: Advancing Human-AI Collaboration in the Science of Science](http://arxiv.org/abs/2504.05559v1)

- SciSciGPT (Science of Science GPT): introduces a modular AI system designed as research collaborator, which includes User interacting via Web Interface, Research Manager orchestrating tasks, Literature Specialist for literature analysis, Database Specialist for data handling, Analytics Specialist for data analytics, and Evaluation Specialist for quality control, utilizing SciSciCorpus, SciSciNet and Sandbox Environment with various Tools.
- SciSciGPT employs a hierarchical multi-agent architecture to automate complex research workflows, enhance research efficiency, and facilitate human-AI collaboration in the science of science domain.
- The system's modular design with specialist agents and a central Research Manager allows for flexible task decomposition, iterative refinement, and comprehensive quality assessment throughout the research process.


---


[Bridging Industrial Expertise and XR with LLM-Powered Conversational Agents](http://arxiv.org/abs/2504.05527v1)

- RAG-enhanced LLMs with XR Integration (Retrieval-Augmented Generation enhanced Large Language Models with Extended Reality Integration): introduces a system embedding industrial knowledge into XR environments, featuring XR Application, Middleware, LLM Chat Engine, Document Processing, VECTOR DB, XR SYSTEM, and LLM ENGINE components.
- This framework utilizes a LLM Chat Engine with components like Router Agent, RAG Tools, and specialized agents such as PdM, XAI, and IoT Agents, to provide context-aware expert guidance through voice-driven XR interfaces.
- The system enhances industrial workflows by integrating RAG techniques and XR, enabling hands-free access to domain-specific knowledge and improving training, remote assistance, and operational efficiency in Industry 5.0 settings.


---

[EduPlanner: LLM-Based Multi-Agent Systems for Customized and Intelligent Instructional Design](http://arxiv.org/abs/2504.05370v1)

- EduPlanner (LLM-Based Multi-Agent System): introduces multi-agent system with evaluator-, optimizer- and analyst-agents, and Skill-Tree component.
- EduPlanner employs Skill-Tree (models student knowledge background) to personalize instructional design and uses evaluator-agent (assesses design quality) and optimizer-agent (improves lesson content) for iterative optimization.
- Analyst-agent (identifies error-prone examples) further enhances EduPlanner by incorporating error analysis into lesson plan refinement, and Lesson Plan Queue (prioritizes effective designs) manages design iterations.


---

[Prism: Dynamic and Flexible Benchmarking of LLMs Code Generation with Monte Carlo Tree Search](http://arxiv.org/abs/2504.05500v1)

- Prism (Dynamic and Flexible Benchmarking of LLMs Code Generation with Monte Carlo Tree Search): introduces a dynamic benchmarking framework for LLM code generation assessment, incorporating tree-based state representation (models evaluation as MDP), Monte Carlo Tree Search (algorithm for exploration), and multi-agent evaluation pipeline (simultaneous assessment of capabilities).
- Prism framework utilizes Markov Decision Process to model evaluation states and Monte Carlo Tree Search algorithm for adaptive exploration of evaluation scenarios.
- The framework employs a multi-agent system with Problem Generator, Solution Evaluator, and Pattern Analyzer agents to enable comprehensive and structured LLM evaluation.


---


[Weak-for-Strong: Training Weak Meta-Agent to Harness Strong Executors](http://arxiv.org/abs/2504.04785v1)

- W4S (Weak-for-Strong Harnessing): introduces a novel framework that trains a weak meta-agent to iteratively optimize workflows for harnessing strong language models through Workflow Generation, Execution and Feedback, and Refinement within an Environment, utilizing RLAO for meta-agent training.
- The framework formulates workflow design as a Markov Decision Process, enabling the meta-agent to learn effective workflow strategies by interacting with the environment and receiving performance feedback, thus improving performance of strong models.
- W4S offers an efficient and high-performing alternative to direct fine-tuning of strong models, demonstrating strong generalization capabilities across various tasks and outperforming existing methods in workflow optimization.


---

[BEYOND SINGLE-TURN: A SURVEY ON MULTI-TURN INTERACTIONS WITH LARGE LANGUAGE MODELS](http://arxiv.org/abs/2504.04717v1)

- Taxonomy of Improvements Methodologies in Multi-turn LLM Interactions: introduces a structured categorization of methods to enhance multi-turn interactions in Large Language Models, encompassing model-centric, external integration, and agent-based approaches.
- Model-centric improvements directly refine LLMs, external integration leverages external knowledge, and agent-based methods employ proactive agents for complex dialogues.
- This taxonomy covers techniques like in-context learning, fine-tuning, reinforcement learning, memory augmentation, Retrieval Augmented Generation (RAG), and multi-agent systems, providing a comprehensive overview of advancements in conversational AI.


---

[Generalising from Self-Produced Data: Model Training Beyond Human Constraints](http://arxiv.org/abs/2504.04711v1)

- Generalising Agent Framework: introduces a system with interdependent AI agents designed for autonomous knowledge generation through environment interaction and self-improvement, comprising code generation, testing, training, environment understanding, strategy formulation, and safety infrastructure components.
- The framework utilizes a closed-loop process where an Environment Module gathers data, a Strategy Module plans actions, a Code Generation Module implements strategies, and Testing and Training Modules refine the system based on empirical results, aiming for continuous learning and adaptation.
- Key components ensure robustness and safety through code validation, resource monitoring, and controlled execution, facilitating the development of artificial superintelligence by overcoming limitations of human-derived data and enabling autonomous discovery and verification of knowledge.


---

[scAgent: Universal Single-Cell Annotation via a LLM Agent](http://arxiv.org/abs/2504.04698v1)

- scAgent (Universal Single-Cell Annotation Agent): introduces a universal cell annotation framework, with Planning Module, Action Space, and Memory Module, for annotating single-cell RNA sequencing data.
- scAgent leverages a Planning Module to formulate plans, an Action Space with scRNA models and MoE-LORA plugins, and a Memory Module for knowledge management, enabling universal cell type annotation and novel cell discovery.
- The framework's modular design with an extensible Action Space and dynamic Memory Module facilitates cross-tissue generalization, novel cell type extension, and efficient incremental learning for single-cell data analysis.


---

[Autono: A ReAct-Based Highly Robust Autonomous Agent Framework](http://arxiv.org/abs/2504.04650v1)

- Autono (Robust Autonomous Agent Framework): introduces a ReAct-based agent framework for complex tasks, incorporating Thought Engine, Tools, Step Estimator, Penalty, Memory, Request Resolver, Next Move Scheduler, Executor, and Introspection components.
- Autono framework enhances robustness through dynamic action generation based on prior trajectories and a timely abandonment strategy using probabilistic penalties.
- The framework supports multi-agent collaboration with a memory transfer mechanism and is compatible with the Model Context Protocol (MCP) for tool integration.



---

#### 6th April 2025

[SpatialAgent: An autonomous AI agent for spatial biology](https://www.biorxiv.org/content/10.1101/2025.04.03.646459v1.full.pdf)

- SpatialAgent: introduces a fully autonomous AI agent for spatial biology research, with Memory (semantic, episodic information), Planning (task decomposition, reasoning), Action (tool execution, data processing), LLMs (underlying reasoning engine), and External Tools/Databases (data, analysis resources), designed to span the entire research pipeline.
- The agent operates through a self-governing loop integrating LLMs with dynamic tool execution and adaptive reasoning for multimodal data analysis and hypothesis generation.
- Its modular design supports human-in-the-loop interaction and extensibility with new tools and templates, enabling autonomous and collaborative discovery.


---

[Building LLM Agents by Incorporating Insights from Computer Systems](http://arxiv.org/abs/2504.04485v1)

- Framework F: introduces structured framework for LLM agents, with Perception(interpreting environment inputs), Cognition(decision making and reasoning), Memory(storing and retrieving information), Tool(interacting with external tools), and Action(executing actions in environment) components.
- Framework F draws analogy from von Neumann architecture to propose modular design for LLM agents, emphasizing distinct modules and dynamic interaction with environment.
- Framework F aims to provide foundation for systematic LLM agent design by incorporating insights from computer systems, offering guidance for future research and development.


---

[VideoAgent2: Enhancing the LLM-Based Agent System for Long-Form Video Understanding by Uncertainty-Aware CoT](http://arxiv.org/abs/2504.04471v1)

- VideoAgent2: introduces an uncertainty-aware CoT framework for long-form video understanding, with Video Input, Question Input, General context acquisition, Answer assessment, Information retrieval plan creation or adjustment, Information retrieval, Information Memory, and Answer Output components.
- VideoAgent2 enhances LLM reasoning by iteratively refining information retrieval plans and incorporating uncertainty from both LLM and tools to improve answer reliability.
- The framework mimics human video understanding by first acquiring general context, then creating and adjusting information retrieval plans based on question complexity and information adequacy.


---


[Human-Level Competitive Pokémon via Scalable Offline Reinforcement Learning with Transformers](http://arxiv.org/abs/2504.04395v1)

- Metamon (offline RL workflow platform): introduces a platform for offline RL workflow, with Policy (agent decision making), Offline Dataset (human gameplay data), Replay Parser (extracts game data), Local Battle Simulator (simulates battles locally), Pokémon Showdown (online battle platform), and Online Battles (battles against humans) components.
- Metamon: reconstructs first-person perspective from spectator logs, unlocking human battle dataset.
- Metamon: enables training sequence models for opponent adaptation without explicit search.


---

[AutoPDL: Automatic Prompt Optimization for LLM Agents](http://arxiv.org/abs/2504.04365v1)

- AutoPDL (Automatic Prompt Optimization for LLM Agents): introduces an automated approach to discover good LLM agent configurations with Search Space Specification, Pattern Library, Successive Halving Optimizer, and Solution components.
- AutoPDL frames prompt optimization as structured AutoML problem over agentic and non-agentic prompting patterns, efficiently navigating the search space using successive halving.
- AutoPDL generates human-readable and executable PDL programs, enabling source-to-source optimization and facilitating human-in-the-loop refinement and reuse.


---

[OmniDrive: A Holistic Vision-Language Dataset for Autonomous Driving with Counterfactual Reasoning](http://arxiv.org/abs/2504.04348v1)

- OmniDrive: introduces a holistic vision-language dataset and framework for autonomous driving, with Infos, Rules, Simulated Trajectory, Actual Trajectory, QA Generation, Decision making & Planning, Scene Description, General Traffic Rule, 3D Grounding, Counterfactual Reasoning, 3D Perception, Omni-Q, Q-Former, Multi-view Images, Multi-view Image Features, Large Language Model, MLP Projector, Omni-L, 3D Position, and Counterfactual & Reasoning components, for generating high-quality question-answering data and exploring vision-language models for 3D understanding in autonomous driving.
- OmniDrive framework explores two baseline models, Omni-Q focusing on vision-language models from a 3D perception perspective and Omni-L building upon vision-language models to enhance 3D integration, utilizing counterfactual reasoning to improve decision-making by evaluating potential scenarios.
- The framework leverages a counterfactual-based synthetic data annotation process to create large-scale datasets, providing denser supervision signals for bridging planning trajectories and language-based reasoning in autonomous driving scenarios.


---

[Geo-OLM: Enabling Sustainable Earth Observation Studies with Cost-Efficient Open Language Models & State-Driven Workflows](http://arxiv.org/abs/2504.04319v1)

- Geo-OLM (Geospatial Open Language Model): introduces a state-driven geospatial agentic framework, with User Prompt, Database Load, DataOps, Satellite Vision, Map, Error, and Self-Reflect components, for cost-efficient Earth Observation studies using open language models.
- Geo-OLM framework structures geospatial workflows as state machines, decoupling task progression from tool calling, enabling effective geospatial analysis with low-resource open language models.
- The state-driven approach of Geo-OLM facilitates error handling and task completion validation, leading to improved agentic performance and significant cost reduction compared to existing geospatial solutions.


---

[CO-Bench: Benchmarking Language Model Agents in Algorithm Search for Combinatorial Optimization](http://arxiv.org/abs/2504.04310v1)

- CO-Bench (Combinatorial Optimization Benchmark): introduces evaluation environment for AI agents, with Problem Description, Development Dataset, LLM Agent, Workflow Reasoning, Search Tool Use, Submit Dev, Feedback, Dev Evaluator, Test Evaluator, Solution (Code), Sandboxed running, and Score.
- CO-Bench benchmark facilitates systematic evaluation of LLM agents in combinatorial optimization algorithm development by providing diverse real-world problems and rigorous evaluation framework.
- The framework enables reproducible assessment of agent performance against human baselines under time constraints, highlighting strengths and limitations of current LLM-driven approaches.


---

#### 5th April 2025


[Among Us: A Sandbox for Agentic Deception](http://arxiv.org/abs/2504.04072v1)

- Among Us Sandbox: introduces "Among Us" as a controlled sandbox environment for studying agentic deception using LLM Agents, evaluated with Deception ELO and Detection ELO metrics, within a Game State defined by Observation Space and Action Space across Task Phase and Meeting Phase, and analyzed using Linear Probes and Sparse Autoencoders.
- This sandbox facilitates the study of deceptive behaviors emerging naturally in LLM agents playing the game "Among Us", offering a rich environment to analyze agent-human interactions and evaluate AI safety techniques for deception detection.
- The research leverages "Among Us" game dynamics to create a benchmark for advancing AI safety by focusing on detecting and mitigating agentically-motivated deception in LLMs, using metrics like Deception ELO and Detection ELO to quantify deceptive capabilities.


---

[ADAPT: Actively Discovering and Adapting to Preferences for any Task](http://arxiv.org/abs/2504.04040v1)

- Reflection-DPO: introduces a novel training approach for adapting LLMs, with Teacher Planner (knowledge about preferences), Student Planner (no privileged knowledge), Reflection-DPO Data Generation (candidate questions) and DPO training (student LLM finetuning), to the task of active questioning.
- Reflection-DPO uses a privileged LLM teacher to train a student LLM to adhere to user preferences by learning to acquire necessary information through active questioning.
- The framework includes a reflection step that generates candidate questions to help the student predict the teacher's action, enabling it to fulfill ambiguous goals while adhering to user preferences.


---


[AdaCoder: An Adaptive Planning and Multi-Agent Framework for Function-Level Code Generation](http://arxiv.org/abs/2504.04220v1)

- AdaCoder (Adaptive Planning and Multi-Agent Framework for Function-Level Code Generation): introduces a two-phase framework with Programming Assistant, Code Evaluator, Debug Specialist, and Prompt Engineer for adaptive code generation.
- AdaCoder initially uses Programming Assistant and Code Evaluator in Phase-1 for fast code generation, and then employs Debug Specialist and Prompt Engineer in Phase-2 for iterative refinement with planning.
- AdaCoder's adaptive planning approach enhances generalizability and reduces computational cost compared to other multi-agent frameworks by selectively applying planning and rule-based debugging.


---

[GROVE: A Generalized Reward for Learning Open-Vocabulary Physical Skill](http://arxiv.org/abs/2504.04191v1)

- GROVE (Generalized Reward for Learning Open-Vocabulary Physical Skill): introduces a generalized reward framework for open-vocabulary physical skill learning, integrating VLM-based Reward (semantic correctness evaluation), Pose2CLIP (pose to semantic mapper), LLM-based Reward Generator (precise constraints formulation), and Target Control Policy (agent action controller) components.
- GROVE framework combines LLM-generated constraints for task requirements with VLM-based semantic evaluation for motion naturalness, utilizing Pose2CLIP to efficiently map poses to semantic feature space and bridge the simulation-to-reality gap.
- The framework employs an iterative reward design process with VLM feedback to dynamically refine LLM-generated constraints, establishing a self-improving reward system for scalable physical skill acquisition across diverse agents and tasks.


---

[AttackLLM: LLM-based Attack Pattern Generation for an Industrial Control System](http://arxiv.org/abs/2504.04187v1)

- AttackLLM (LLM-based Attack Pattern Generation): introduces a multi-agent framework, with Process Data, Design Specification, LLM Agent 1, LLM Agent 2, Control Invariants, LLM Agent 3 Validate, Validated Control Invariants, Expert Designed Attacks, New Attack Patterns, and Comparison, for automated generation of attack patterns in industrial control systems.
- AttackLLM leverages LLMs to analyze process data and design specifications to derive and validate control invariants, subsequently generating novel attack patterns that are compared against expert-designed attacks for performance evaluation.
- The framework aims to enhance ICS security by automating the generation of diverse and stealthy attack scenarios, addressing the limitations of traditional methods relying on manual expertise and scarce testbed data.


---




#### 4th April 2025

[Agentic Knowledgeable Self-awareness](http://arxiv.org/abs/2504.03553v1)

- KnowSelf (Agentic Knowledgeable Self-awareness): introduces a data-centric approach with Self-awareness Data Construction, Self-awareness Learning, Self-awareness Inference, Selection mechanism and Knowledge base, enabling agents to regulate knowledge utilization autonomously.
- KnowSelf framework employs a two-stage training process involving Supervised Fine-Tuning and Reinforcement Preference Optimization to equip agents with situational self-awareness for optimal planning.
- The framework utilizes a heuristic situation judgement criterion to categorize situations and generate special tokens, facilitating selective knowledge incorporation during inference with minimal costs.


---

[Inherent and emergent liability issues in LLM-based agentic systems: a principal-agent perspective](http://arxiv.org/abs/2504.03255v1)

- LLM-based MAS (Large Language Model-based Multiagent System): introduces a multiagent system architecture with principal delegating tasks to an orchestrator agent, which coordinates different agent teams on an agent platform, supported by safety, compliance, and security agents.
- This framework illustrates a delegation hierarchy and supporting agent roles within a plausible LLM-based MAS deployment on an agent platform.
- The architecture emphasizes the structured organization of agents and the inclusion of supporting agents for governance and security within the multiagent system.


---

[DeepResearcher: Scaling Deep Research via Reinforcement Learning in Real-world Environments](http://arxiv.org/abs/2504.03160v1)

- DeepResearcher: introduces comprehensive framework for end-to-end reinforcement learning training of LLM-based research agents, incorporating distributed cluster, browsing agent, search engine, real-world environment, user, assistant, think, search, browse, answer, and memory.
- DeepResearcher: enables agents to navigate noisy, unstructured open web environments, utilizing multi-agent architecture with specialized browsing agents for extracting information and addressing technical challenges.
- DeepResearcher: demonstrates substantial performance improvements over prompt engineering and RAG-based baselines, showcasing emergent cognitive behaviors through end-to-end reinforcement learning in real-world web environments.


---


[SynWorld: Virtual Scenario Synthesis for Agentic Action Knowledge Refinement](http://arxiv.org/abs/2504.03561v1)

- SynWorld (Virtual Scenario Synthesis): introduces a framework for agents to synthesize virtual scenarios and refine action knowledge through exploration within these environments.
- SynWorld utilizes Monte Carlo Tree Search (MCTS) for exploration and action knowledge refinement, leveraging environment feedback from synthesized virtual scenarios.
- The framework enables agents to learn how to execute actions and plan tasks in new environments by optimizing workflows through interaction with simulated scenarios.


---

[Adaptation of Large Language Models](http://arxiv.org/abs/2504.03931v1)

- Adaptation of Large Language Models Framework: introduces Domain-Adaptive Pre-Training (DAPT), Instruction Tuning (IT), Preference Learning (PL), Model Editing, Retrieval-Augmented Generation (RAG), and Agent-based Integration for adapting Large Language Models.
- This framework explores both parametric and semi-parametric adaptation techniques to improve Large Language Models performance in specialized domains and tasks.
- Parametric adaptation refines model parameters through methods like domain pre-training and instruction tuning, while semi-parametric adaptation leverages external knowledge via retrieval and agent-based systems.


---


[OLAF: An Open Life Science Analysis Framework for Conversational Bioinformatics Powered by Large Language Models](http://arxiv.org/abs/2504.03976v1)

- OLAF (Open Life Science Analysis Framework): introduces an open-source platform leveraging LLMs for bioinformatics code generation and execution, comprising User, Angular Frontend, Firebase Backend, Router, Agents, LLM Code Generation, Pipes, Execution Engine, and Results.
- OLAF enables end-to-end bioinformatics analyses via natural language, automating code generation and execution within an integrated environment for researchers.
- The agent-pipe-router architecture of OLAF ensures modularity and transparency, facilitating complex bioinformatics workflows and bridging the gap between user intent and computational execution.


---

[YaleNLP @ PerAnsSumm 2025: Multi-Perspective Integration via Mixture-of-Agents for Enhanced Healthcare QA Summarization](http://arxiv.org/abs/2504.03932v1)

- Mixture-of-Agents (MoA) framework: introduces Agent, Aggregator, Verification Layer, and Hallucination Detection Layer components for multi-perspective healthcare question answering summarization.
- MoA framework employs multiple LLM Agents to generate perspective-specific partial responses, which are then aggregated and refined through Verification and Hallucination Detection Layers.
- MoA framework explores layered configurations with verification and hallucination detection to improve summarization accuracy and reliability in the medical domain.


---



[APIGen-MT: Agentic PIpeline for Multi-Turn Data Generation via Simulated Agent-Human Interplay](http://arxiv.org/abs/2504.03601v1)

- APIGen-MT (Agentic Pipeline for Multi-Turn Data Generation): introduces a two-phase framework for generating multi-turn agent data, with Context, LLM based Data Generator, Format & Execution Checker, Review Committee, Feedback Generator, Validated Tasks, Simulated Human, Test Agent, Environment Config, Groundtruth Actions & Outputs, Interaction Traces, and Successful Trajectory components.
- APIGen-MT framework first generates verified task blueprints using an agentic pipeline with feedback loops, then transforms blueprints into interaction trajectories via simulated human-agent interplay.
- This approach ensures high-quality training data by separating task design from conversational dynamics, enhancing both structural correctness and naturalness of generated interactions for training AI agents.


---

[Talk2X - AN OPEN-SOURCE TOOLKIT FACILITATING DEPLOYMENT OF LLM-POWERED CHATBOTS ON THE WEB](http://arxiv.org/abs/2504.03343v1)

- Talk2X: introduces an open-source toolkit for deploying LLM-powered chatbots, with agent, vector database, website collection, and asset collection components.
- Talk2X facilitates efficient information retrieval by leveraging a vector database for website and asset content, enabling function calling agent to answer user queries.
- This approach enhances energy efficiency and transparency compared to closed-source solutions, offering developers a generalizable tool for website integration.


---

[Do Large Language Models Solve the Problems of Agent-Based Modeling? A Critical Review of Generative Social Simulations](http://arxiv.org/abs/2504.03274v1)

- Generative ABMs (Generative Agent-Based Models): introduces a novel approach for social simulations, integrating Persona, Memory Modules, Planning Modules, and Actions components.
- This framework equips agents with human-like capabilities by using LLMs for reasoning, memory, and planning within agent-based models.
- Generative ABMs aim to address limitations of traditional ABMs by enhancing agent realism and enabling more complex social simulations, but validation challenges remain.


---

[Enhancing Personalized Multi-Turn Dialogue with Curiosity Reward](http://arxiv.org/abs/2504.03206v1)

- IM-UM-RLHF (Intrinsic Motivation in User Modeling for Multi-Turn RLHF): introduces intrinsic curiosity reward to multi-turn RLHF, with Conversation History (dialogue turn history), Belief on User Type (probabilistic user preference model), Per Turn Curiosity Reward (belief improvement based reward), Agent's Utterance (agent generated dialogue), User's Response (user dialogue response), End-of-Conversation Reward (dialogue completion reward), and User's Final Response (user end feedback).
- IM-UM-RLHF framework enhances personalization by incentivizing the agent to actively learn user preferences during conversation through curiosity reward based on belief improvement.
- The framework aims to balance helpfulness and inquisitiveness in conversational agents, enabling more personalized and adaptive interactions compared to traditional RLHF methods.


---

[Learning Natural Language Constraints for Safe Reinforcement Learning of Language Agents](http://arxiv.org/abs/2504.03185v1)

- NLCL (Natural Language Constraint Learning): introduces a framework for safe language alignment, with CLIRL Phase, CAPO Phase, Positive Demonstrations, Negative Demonstrations, Policy, Reward Function, Constraint Functions, Transition Function, and CVaR.
- NLCL learns natural language constraints from demonstrations using inverse reinforcement learning and optimizes policy with constraint-aware policy optimization for safe language agent behavior.
- NLCL framework aims to improve robustness and generalization of language agents by explicitly learning and enforcing safety constraints in dynamic environments.


---

[Multi-lingual Multi-turn Automated Red Teaming for LLMs](http://arxiv.org/abs/2504.03174v1)

- MM-ART (Multi-lingual Multi-turn Automated Red Teaming): introduces an automated approach for multi-lingual and multi-turn red-teaming of LLMs, with Conversation Starters Generation, Automated Multi-turn Conversation, and Multi-lingual Conversations components.
- MM-ART framework aims to address limitations of human-driven and existing automated red-teaming methods by enabling scalable and efficient safety evaluation across multiple languages and conversation turns.
- The framework leverages machine translation to handle multi-lingual aspects and automated conversation continuation to explore vulnerabilities in multi-turn interactions, enhancing the detection of unsafe responses in LLMs.


---

[Les Dissonances: Cross-Tool Harvesting and Polluting in Multi-Tool Empowered LLM Agents](http://arxiv.org/abs/2504.03111v1)

- Chord: introduces a dynamic scanning tool, with Hijacker, Hijacking Optimizer, Harvester, Polluter, and Testing Agent components, designed to automatically detect agent tools susceptible to XTHP attacks.
- Chord systematically analyzes task control flows in multi-tool LLM agents, identifying Cross-Tool Harvesting and Polluting (XTHP) threats.
- The framework evaluates real-world tools from LangChain and Llama-Index, revealing vulnerabilities to hijacking and data manipulation attacks.


---



#### 3rd April 2025

[Ontologies in Design: How Imagining a Tree Reveals Possibilites and Assumptions in Large Language Models](http://arxiv.org/abs/2504.03029v1)

- Generative Agents Architecture: introduces Memory Stream (summarizes prompt histories), Reflection (extracts insights from memories), Planning (generates action plans), and Cognitive Architecture (simulates human functions) to organize information and simulate human-like behavior in LLM-based agents.
- Generative Agents architecture aims to create believable proxies of human behavior in virtual avatars by building cognitive models on top of LLMs.
- The framework uses memory stream, reflection, and planning components to manage information and generate realistic and interesting action sequences for agents in a simulated environment.


---


[Affordable AI Assistants with Knowledge Graph of Thoughts](http://arxiv.org/abs/2504.02670v1)

- Knowledge Graph of Thoughts (KGoT): introduces an AI assistant architecture integrating LLM reasoning with dynamically constructed knowledge graphs, with Graph Store Module, LLM Graph Executor, Controller, LLM Tool Executor, Integrated Tools Module, and Backend components.
- KGoT enhances task comprehension by structuring task-relevant knowledge into dynamic knowledge graphs, iteratively improved using external tools and enabling cost-effective models to solve complex tasks.
- The modular KGoT architecture improves task-solving ability by operating with a rich, structured knowledge base, reducing operational costs and enhancing performance across diverse tasks.


---


[Multi-Mission Tool Bench: Assessing the Robustness of LLM based Agents through Related and Dynamic Missions](http://arxiv.org/abs/2504.02623v1)

- MMTB (Multi-Mission Tool Bench): introduces a controllable data generation framework simulating mission execution through dialogic interactions among user, planner, tool, AI, and checker agents.
- MMTB framework evaluates agent robustness in related and dynamic multi-mission scenarios, addressing challenges of real-world complexity.
- The framework utilizes a novel evaluation method based on dynamic decision trees to assess accuracy and efficiency of agent decisions.


---

[Design of Al-Powered Tool for Self-Regulation Support in Programming Education](http://arxiv.org/abs/2504.03068v1)

- CodeRunner Agent (LLM-based programming assistant): introduces an integrated programming support environment, with Lecture Viewer (displays lecture slides), CodeRunner plugin (code execution), Learning Analytics Context Engine (learner data analysis), and Knowledge Context Engine (knowledge management), to enhance self-regulated learning.
- This framework utilizes Moodle LMS (learning platform) and Learning Record Store (learning data storage) for context-aware feedback and personalized programming education.
- By integrating SRL phases (learning cycle stages) and instructor configuration (customization interface), CodeRunner Agent aims to improve student learning and AI application understanding in education.


---



[Multi-SWE-bench: A Multilingual Benchmark for Issue Resolving](http://arxiv.org/abs/2504.02605v1)

- Multi-SWE-bench: introduces a multilingual benchmark for issue resolving, comprising Repository Selection, PR Crawling, Environment Determination, PR Filtering, and Manual Verification components.
- Multi-SWE-bench utilizes a five-phase pipeline to create a robust benchmark for assessing agent capabilities in resolving real-world software issues across multiple programming languages.
- Multi-SWE-bench provides a diverse and rigorously validated dataset to overcome limitations of existing benchmarks and facilitate comprehensive LLM evaluation in realistic software engineering scenarios.


---


[Exploring Individual Factors in the Adoption of LLMs for Specific Software Engineering Tasks](http://arxiv.org/abs/2504.02553v1)

- UTAUT2 (Unified Theory of Acceptance and Use of Technology 2): introduces framework with Performance Expectancy, Effort Expectancy, Social Influence, Hedonic Motivation, Habit, Facilitating Conditions, Behavioral Intention, Usage Behavior, Manipulate Artifacts, Generate Alternatives, Information Retrieval, Decision Support, and Training components, for exploring factors influencing LLM adoption for software engineering tasks.
- The framework investigates how individual attributes related to technology adoption and UTAUT2 constructs impact the task-specific adoption of LLMs across five key software engineering tasks.
- The study uses structural equation modeling to analyze survey data from software engineers, revealing task-specific adoption is influenced by distinct factors and providing actionable recommendations for effective LLM integration.


---


[A Memory-Augmented LLM-Driven Method for Autonomous Merging of 3D Printing Work Orders](http://arxiv.org/abs/2504.02509v1)

- LLM-Driven Method (Memory-Augmented LLM-Driven Method for Autonomous Merging of 3D Printing Work Orders): introduces an autonomous 3D printing work order merging framework, with Production line condition, Agent, LLM, Tools, Memory, Print implementation and Monitoring, leveraging Order Matching Tool, Interference Checking Tool, Answer generator and Job Consolidation components.
- The framework utilizes a memory-augmented learning strategy, enabling the agent to accumulate experience and improve decision-making accuracy over iterative autonomous operations.
- The method models printer and order features into LLM-readable prompts, facilitating intelligent order-device matching and merging while reducing LLM hallucination in industrial applications.


---


[ReuseDroid: A VLM-empowered Android UI Test Migrator Boosted by Active Feedback](http://arxiv.org/abs/2504.02357v1)

- REUSEDROID (REUSEDROID): introduces a multi-agent framework for GUI test migration, with Test Analyzer Agent, Test Skeleton, Planner Agent, Completeness Checker, Action Generator, Feedback Agent, Oracle Generator, and Execution Agent, to address operational logic differences in GUI testing.
- REUSEDROID employs a Test Analyzer Agent to generalize source test logic and create a Test Skeleton, guiding a Planner Agent with Completeness Checker, Action Generator, and Oracle Generator, while a Feedback Agent refines actions and an Execution Agent performs them.
- The framework leverages visual and textual information with VLMs in each agent to improve understanding of GUI elements and context, aiming to enhance the accuracy and efficiency of GUI test migration across different applications.


---

[Parallel Market Environments for FinRL Contests](http://arxiv.org/abs/2504.02281v1)

- FinRL (Financial Reinforcement Learning): introduces VecEnv (manages parallel environments) with SubEnv (simulates market scenarios), State (market conditions), Action (trading action), Reward (incentive signal), Market Constraints (realistic market conditions), and Features (market indicators and LLM signals).
- The framework addresses sampling bottleneck in financial RL by using GPU-based parallel market environments.
- It incorporates LLM-generated signals for sentiment analysis and risk assessment to enhance trading agent's decision-making.


---


#### 2nd April 2025

[Self-Resource Allocation in Multi-Agent LLM Systems](http://arxiv.org/abs/2504.02051v1)

- MAS (Multi-Agent Systems): introduces three methods for task allocation in multi-agent systems: Individual, Orchestrator, and Planner, within a simulated CuisineWorld environment, utilizing LLM-based agents for task execution and control.
- The Individual method represents a decentralized approach where each agent acts independently, while the Orchestrator method employs a centralized LLM to control all agents' actions, and the Planner method uses a plan-generating LLM to guide independent agent actions.
- The paper evaluates these methods in terms of efficiency and cost-effectiveness, finding that the Planner method achieves better performance in handling concurrent actions and resource allocation compared to the Orchestrator and Individual methods.


---

[LLM-mediated Dynamic Plan Generation with a Multi-Agent Approach](http://arxiv.org/abs/2504.01637v1)

- ANA (Agent Network Architecture): introduces a method for dynamic plan generation using a multi-agent approach, incorporating Status Collection, Network Construction, and Network Optimization stages, with Agents coordinating through Activation Spreading and leveraging GPT for agent generation.
- The framework utilizes Agents, defined by Add list, Condition list, and Delete list, and Statuses to build a network capable of both reactive and deliberative planning in dynamic environments.
- This approach aims to automate agent creation and network construction, reducing design costs and enhancing flexibility and scalability for robot planning and other complex systems.


---



[LLMs as Deceptive Agents: How Role-Based Prompting Induces Semantic Ambiguity in Puzzle Tasks](http://arxiv.org/abs/2504.02254v1)

- Deceptive Puzzle Generation Framework: introduces a comparative study of Zero-Shot and Role-Injected prompting strategies for Large Language Models (puzzle generator) in generating deceptive puzzles, utilizing Rule Prompt (basic instructions), Rule + Prompt (deceptive instructions), JSON File (output format), and Game (generated puzzle).
- This framework assesses how embedding adversarial intent through role-injected prompts modulates semantic ambiguity and puzzle difficulty compared to puzzles generated via zero-shot prompts.
- The framework employs HateBERT for computational analysis and human evaluations, demonstrating that role-injected prompts generally increase semantic ambiguity, leading to higher cognitive load and reduced fairness in puzzle solving.


---

[An Approach to Technical AGI Safety and Security](https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/evaluating-potential-cybersecurity-threats-of-advanced-ai/An_Approach_to_Technical_AGI_Safety_Apr_2025.pdf)

- Frontier Safety Framework (FSF) introduces a multi-layered approach to mitigating misuse risks through Training for model-level mitigations, Evaluation of dangerous capabilities, Deployment of system-level mitigations, Security for model weights, and Red Teaming to assess mitigation effectiveness, involving components like Safety Training, Capability Suppression, Dangerous Capability Evaluations, Monitoring, Access Restrictions, Inference, Prompts, Responses, and User interactions.
- FSF's misuse mitigation strategy combines model-level training with system-level deployment controls, utilizing dangerous capability evaluations to determine mitigation needs and red teaming to validate mitigation robustness against potential threat actors.
- The framework emphasizes a proactive and iterative approach to AGI safety, incorporating security measures and evaluations to address potential misuse of dangerous AI capabilities by malicious actors.


---

[A Survey of Scaling in Large Language Model Reasoning](http://arxiv.org/abs/2504.02181v1)

- Scaling in LLM Reasoning Taxonomy: introduces a taxonomy categorizing scaling strategies for large language model reasoning into input sizes, reasoning steps, reasoning rounds, and model optimization, exploring how these dimensions enhance reasoning capabilities.
- The taxonomy details input size scaling with In-Context Learning, Retrieval-Augmented Generation, and Memory-Augmented LLMs; reasoning step scaling with Chain-of-Thought and Meta-Reasoning & Calibration; reasoning round scaling with Multi-Agent Collaboration, Debate-based Reasoning, Human-LLM Interaction, Reinforcement Learning, and Latent-Space Reasoning; and model optimization through Reinforcement Learning and Latent-Space Reasoning.
- This survey aims to bridge the gap between empirical scaling strategies and reasoning improvements, providing insights into when and why scaling enhances reasoning and addresses limitations, guiding future AI development.


---

[On Simulation-Guided LLM-based Code Generation for Safe Autonomous Driving Software](http://arxiv.org/abs/2504.02141v1)

- Simulation-Guided LLM-based Code Generation: introduces a closed-loop pipeline using Pipeline Input, Code Generator, Simulation Model, Baseline Selector, and Report Generator components to iteratively refine Generated Code for autonomous driving functions based on Test Report and Simulation Numerical Logs, guided by Specification Prompt and Correction Prompt.
- This framework employs a simulation environment to automatically evaluate LLM-generated code against safety requirements, using feedback from test reports to guide the LLM in Correction Prompt for iterative code improvement and Baseline Selector for performance comparison.
- The iterative Simulation-Guided LLM-based Code Generation pipeline aims to enhance the quality and safety of LLM-generated code for safety-critical automotive software by incorporating automated testing and feedback within the code generation process, utilizing Specification Prompt and Correction Prompt strategies.


---

[Achieving Unanimous Consensus in Decision Making Using Multi-Agents](http://arxiv.org/abs/2504.02128v1)

- Deliberation-based consensus mechanism: introduces a novel approach for achieving unanimous consensus in blockchain using a layered architecture composed of Blockchain Layer, Deliberation Layer, and LLMs Layer.
- The Blockchain Layer provides secure infrastructure, the Deliberation Layer structures the multi-agent discussion, and the LLMs Layer utilizes language models for generating arguments and refining opinions through iterative rounds.
- This framework leverages graded consensus and multi-round deliberation to ensure unanimous agreement for critical decisions in blockchain networks, addressing limitations of majority-based consensus mechanisms.


---



[Review, Refine, Repeat: Understanding Iterative Decoding of AI Agents with Dynamic Evaluation and Selection](http://arxiv.org/abs/2504.01931v1)

- IAD (Iterative Agent Decoding): introduces iterative refinement framework, with USER, SKETCH, LLM, HTML, VERIFIER/REWARD, SELECTED HTML, Feedback to improve, and NEW HTML components, where paper proposes iterative decoding for AI agents using verifier-guided feedback.
- Iterative Agent Decoding framework refines responses through iterative feedback, enabling improved performance in black box structured generation tasks.
- The framework leverages verifier quality for effective inference-time optimization and demonstrates robustness under sparse and noisy feedback.


---

[GEN-C: POPULATING VIRTUAL WORLDS WITH GENERATIVE CROWDS](http://arxiv.org/abs/2504.01924v1)

- Gen-C (generative framework): introduces a generative model for authoring high-level crowd behaviors, utilizing components like LLM for scenario generation, VGAE Graph and VGAE Features for learning latent spaces of graph structures and node features, and a Condition Net for text-conditional generation.
- Gen-C employs an LLM to create initial crowd scenarios, which are expanded and simulated to build time-expanded graphs, subsequently used to train variational graph auto-encoders for learning agent behaviors and interactions.
- The framework facilitates text-conditioned synthesis of diverse crowd behaviors by sampling from learned latent spaces, enabling automated population of virtual environments with complex and dynamic agent interactions.


---

[Advancing AI-Scientist Understanding: Making LLM Think Like a Physicist with Interpretable Reasoning](http://arxiv.org/abs/2504.01911v1)

- Augmented Reasoning with Interpretation Module: introduces an interpretation module to enhance interpretability and verifiability of LLM-based physics reasoning, incorporating reasoning-, interpretation-, and AI-scientist interaction-modules, with summarizer-, model builder-, UI builder-, and tester-components.
- The framework refines raw AI outputs into structured science models and executable code, facilitating human oversight through interactive tools and automated checks, thereby improving transparency and validation in AI-augmented scientific discovery.
- By employing specialized agents within the interpretation module, the system aims to bridge the gap between automated AI reasoning and human scientific intuition, fostering more reliable and understandable AI-driven scientific exploration.


---

[INTERPRETING EMERGENT PLANNING IN MODEL-FREE REINFORCEMENT LEARNING](http://arxiv.org/abs/2504.01871v1)

- DRC (Deep Repeated ConvLSTM): introduces mechanistic evidence for emergent planning in model-free RL agents by employing concept-based interpretability to analyze internal plan formation, evaluation, and adaptation within a Sokoban-playing agent, revealing components like Convolutional encoder, ConvLSTM layers, Cell state, Internal ticks, Agent evaluates plan, Agent adapts plan, Agent plans forwards from boxes, Agent plans backwards from targets, and Agent extends routes in parallel.
- The framework demonstrates that DRC agents utilize learned concept representations to formulate internal plans, predict long-term action effects, and influence behavior, resembling parallelized bidirectional search and benefiting from additional test-time compute.
- The study highlights the emergent planning capabilities in model-free RL, suggesting that agents can learn complex internal mechanisms for decision-making without explicit world models, advancing the understanding of emergent reasoning in LLMs through RL.


---

[PaperBench: Evaluating AI's Ability to Replicate AI Research](http://arxiv.org/abs/2504.01848v1)

- PaperBench: introduces a benchmark evaluating AI agents' ability to replicate AI research, with Agent (AI system for replication), Submission (Agent's codebase repository), Task (Replicate paper contributions), Reproduction (Execution to verify results), Rubric (Hierarchical assessment criteria), Judge (LLM-based grading system), Grading (Evaluation against rubric), and Score (Numerical replication performance).
- PaperBench uses rubrics co-developed with paper authors and LLM-based judge to automatically grade replication attempts.
- The benchmark evaluates agents on understanding paper contributions, developing codebase, and executing experiments for complete replication of ML research papers.


---


[Are Autonomous Web Agents Good Testers?](http://arxiv.org/abs/2504.01495v1)

- PinATA (Planned INcentive ATA): introduces orchestrator, actor, assertor, memory and profile components for advanced autonomous test agent.
- PinATA employs orchestrator for planning and monitoring, actor for action execution using grounding, and assertor for verification using judge approach, all sharing memory and profile modules.
- PinATA aims to improve upon basic ATA by incorporating state-of-the-art techniques for perception, reasoning, evaluation, and grounding to enhance testing capabilities.


---

[An Illusion of Progress? Assessing the Current State of Web Agents](http://arxiv.org/abs/2504.01382v1)

- WebJudge: introduces an automatic evaluation method for web agents, with Key Point Identification, Key Screenshot Identification, and Outcome Judgement components.
- WebJudge framework identifies key task requirements, selects relevant screenshots from agent's trajectory, and judges task completion based on gathered information.
- The framework aims to improve upon existing LLM-as-a-judge methods by preserving critical intermediate steps while mitigating token overload for more reliable web agent evaluation.


---

[STRATEGIZE GLOBALLY, ADAPT LOCALLY: A MULTI-TURN RED TEAMING AGENT WITH DUAL-LEVEL LEARNING](http://arxiv.org/abs/2504.01278v1)

- GALA (Global and Local Learning Agent): introduces a multi-turn red-teaming agent, with Planning Module, Belief Update Module, and Learning Module, for emulating human attackers via global and local learning.
- GALA employs Initial Knowledge Base and Selection Framework for tactic selection, and Generate Prompt Suggestion and On-the-fly for dynamic prompt creation, leveraging Accumulated Knowledge.
- GALA's dual learning of global tactics and local prompts enhances attack success and diversity in multi-turn red-teaming scenarios.


---

#### 1st April 2025

[AGENTNET: DECENTRALIZED EVOLUTIONARY COORDINATION FOR LLM-BASED MULTI-AGENT SYSTEMS](http://arxiv.org/abs/2504.00587v1)

- AgentNet: introduces decentralized framework for LLM-based multi-agent system, with Agent-components, that includes Executor (executes tasks), Router (makes routing decisions), Router Memory (stores routing experiences), Trajectory Memory (stores execution experiences), DAG Task Routing (directed acyclic graph for routing), and RAG Pools (retrieval augmented generation knowledge).
- AgentNet framework facilitates autonomous agent specialization and dynamic network topology evolution by leveraging retrieval-based memory and directed acyclic graph for task routing, enhancing scalability and fault tolerance.
- AgentNet's decentralized design eliminates central orchestrator, enabling privacy-preserving collaboration and efficient resource allocation in dynamic multi-agent environments, improving adaptability and performance.


---


[Catastrophic Forgetting in LLMs: A Comparative Analysis Across Language Tasks](http://arxiv.org/abs/2504.01241v1)

- Continual Instruction Fine-tuning (CIF) framework evaluates catastrophic forgetting in Large Language Models by sequentially fine-tuning a base model on Natural Language Understanding tasks using prompt engineering and continual evaluation.
- The CIF framework assesses model retention of prior knowledge after learning new tasks by comparing performance across different fine-tuning episodes and various Large Language Models.
- This research highlights the impact of prompt engineering and model size on continual learning capabilities in Large Language Models, offering insights into mitigating catastrophic forgetting.


---

[First Field-Trial Demonstration of L4 Autonomous Optical Network for Distributed AI Training Communication: An LLM-Powered Multi-AI-Agent Solution](http://arxiv.org/abs/2504.01234v1)

- AutoLight (LLM-Powered Multi-Agent System): introduces a hierarchical multi-agent system with Planner Agent, Task Agent, and ReAct Agent, utilizing Chain of Identity for agent interaction, to manage autonomous optical networks across components like Domain Controller, Physical Layer Controller, Network Layer Controller, DCI Metro, Backbone Domain, Digital Twin, Failure Handler, Knowledge Retriever, Resource Allocator, Training Orchestrator, Network-layer Planner, and Physical-layer Planner.
- AutoLight employs Planner Agents for high-level coordination and Task Agents for specialized operations, while ReAct Agents are LLM-powered, and Chain of Identity ensures effective agent communication.
- The framework components facilitate autonomous network management by handling tasks such as resource allocation, failure management, and network planning across different network layers and domains.


---

[Grounding Multimodal LLMs to Embodied Agents that Ask for Help with Reinforcement Learning](http://arxiv.org/abs/2504.00907v2)

- MLLM Policy: introduces a vision-language-action model for embodied agents, with SigLIP, Perceiver IO, MultiModal Large Language Model, Vision Adapter, and Action Tokens, to resolve ambiguity through clarification questions and reinforcement learning.
- The framework uses SigLIP for visual encoding and Perceiver IO to handle long observation histories by downsampling visual tokens before feeding into a fine-tuned MultiModal Large Language Model.
- Action Tokens represent the output space, enabling the agent to perform predefined skills or ask natural language questions to clarify ambiguous instructions in embodied tasks.


---

[Do We Truly Need So Many Samples? Multi-LLM Repeated Sampling Efficiently Scales Test-Time Compute](http://arxiv.org/abs/2504.00762v2)

- ModelSwitch: introduces a multi-LLM repeated sampling framework with LLM 1, Query 1, Majority Voting, Answer, LLM 2, Consistent?, and Concat components.
- ModelSwitch leverages consistency as a signal to dynamically switch between LLM 1 and LLM 2, aiming to improve performance and efficiency in test-time compute.
- The framework optimizes sample efficiency by reducing samplings when LLM 1 generates consistent answers, and enhances accuracy by incorporating LLM 2 when consistency is low.


---

[Accelerated Inorganic Materials Design with Generative AI Agents](http://arxiv.org/abs/2504.00741v1)

- MatAgent: introduces an AI-driven framework for inorganic material design, employing LLM as central engine with planning and proposition stages, integrated with structure estimation and property evaluation modules, and external tools like short-term memory, long-term memory, periodic table, and materials knowledge base to iteratively refine material compositions towards target properties.
- MatAgent framework leverages LLM's reasoning capabilities for interpretable material design, mimicking human expert reasoning through strategic tool use and feedback-driven refinement, enabling exploration of broader compositional spaces and achieving high compositional validity and novelty.
- The framework's iterative approach, combining generative and predictive models with external knowledge, demonstrates effectiveness in accelerating the discovery of next-generation inorganic materials by guiding exploration towards desired properties and allowing for natural language integration.


---

[Personality-Driven Decision-Making in LLM-Based Autonomous Agents](http://arxiv.org/abs/2504.00727v1)

- Personality-Driven Decision-Making Framework: introduces a method for LLM-based agent decision-making, incorporating Personality Context, Task Instruction, Current Time, Remaining To-Do List, Completed List, LLM Response, Update Time, and Next Decision-Cycle components.
- This framework evaluates how induced personality traits influence task selection and prioritization in LLM agents through iterative decision cycles.
- The framework uses prompt-based persona induction and analyzes movement deltas in task order to measure the impact of personality on agent behavior.


---

[GRAPHMASTER: AUTOMATED GRAPH SYNTHESIS VIA LLM AGENTS IN DATA-LIMITED ENVIRONMENTS](http://arxiv.org/abs/2504.00711v1)

- GraphMaster (GraphMaster): introduces a multi-agent framework for graph data synthesis in data-limited environments, with Manager-, Perception-, Enhancement- and Evaluation-agents.
- GraphMaster orchestrates specialized agents to iteratively refine graph synthesis, ensuring semantic coherence and structural integrity by modular reasoning and feedback cycles.
- The framework decomposes the synthesis task into specialized sub-tasks handled by collaborative LLM-powered agents, addressing challenges like context window limitations and hallucination.


---

[Exploring the Impact of an LLM-Powered Teachable Agent on Learning Gains and Cognitive Load in Music Education](http://arxiv.org/abs/2504.00636v1)

- Chat Melody (LLM-powered Teachable Agent): introduces problem statement area, interactive music sheet, and LLMs-based dialogue window to assist music learners in music analysis tasks.
- Chat Melody facilitates structured dialogues for music theory learning, providing interactive feedback and guiding students through music analysis.
- The teachable agent aims to reduce cognitive load and enhance learning gains in music education by employing learning-by-teaching principles.


---


[Automated detection of atomicity violations in large-scale systems](http://arxiv.org/abs/2504.00521v1)

- CLOVER: introduces code extractor, expert agent, and judge agent for atomicity violation detection.
- CLOVER combines static analysis for code extraction with LLM agents for violation detection and validation.
- CLOVER's hybrid approach enhances accuracy and efficiency in detecting atomicity violations in interrupt-driven programs.


---

[HERA: Hybrid Edge-cloud Resource Allocation for Cost-Efficient AI Agents](http://arxiv.org/abs/2504.00434v1)

- HERA (Hybrid Edge-cloud Resource Allocation): introduces a lightweight scheduler for AI agents that partitions subtasks between local SLM and cloud LLM based on subtask features and position.
- HERA framework includes User Request Classifier, Subtask Similarity Evaluator, S-L Similarity Evaluator, Convergence Detection, and Subtask Decomposition to optimize resource allocation.
- By strategically using SLM for suitable subtasks and LLM for complex ones, HERA aims to reduce operational costs while maintaining accuracy in AI agent applications.


---

[When Persuasion Overrides Truth in Multi-Agent LLM Debates: Introducing a Confidence-Weighted Persuasion Override Rate (CW-POR)](http://arxiv.org/abs/2504.00374v1)

- CW-POR (Confidence-Weighted Persuasion Override Rate): introduces single-turn multi-agent debate framework with Agent A (Correct) (provides factual answer), Agent B (Persuasive) (defends falsehood), Judge Model (evaluates responses), Combine Confidences (combines confidence scores), Final Decision (judge's answer choice), and CW-POR (persuasion override metric).
- The framework investigates how persuasive arguments can override truthful answers in LLMs, even with high confidence from the judge.
- CW-POR metric quantifies not only the frequency of persuasion override but also the judge's confidence in the incorrect choice, highlighting the severity of being misled.


---

#### 31st March 2025

[Do Large Language Models Exhibit Spontaneous Rational Deception?](http://arxiv.org/abs/2504.00285v1)

- Signaling Games Framework: introduces a study examining spontaneous deception in Large Language Models (LLMs) within signaling games, incorporating components like LLM Agent, Opponent Agent, Signaling Game, Message, Action Choice, Reward Structure, Prompt Instructions, and Deception Guardrails.
- This framework evaluates LLMs' context-sensitive deception by manipulating reward structures and turn orders in 2x2 games, measuring rational adaptation to game incentives and communication opportunities.
- The research demonstrates that LLMs exhibit unsolicited, context-aware deception influenced by potential benefits and ethical prompts, suggesting a link between reasoning capabilities and strategic deceptive behavior.


---

[SciReplicate-Bench: Benchmarking LLMs in Agent-driven Algorithmic Reproduction from Research Papers](http://arxiv.org/abs/2504.00255v1)

- Sci-Reproducer: introduces a dual-agent framework for algorithmic reproduction, with Literature Context, Target Paper, Relevant Literature, Paper Agent, Agent Strategy, Search Paper-Extract Section, Search Literature, Literature Report, Code Context, Code Repository, Python Environment, Website, Code Agent, Agent Strategy, Search Web, Search Code, and Code Interpreter components.
- Sci-Reproducer framework uses Paper Agent to understand algorithmic logic from papers and Code Agent to retrieve dependencies and implement solutions, enabling comprehensive paper reproduction.
- The framework aims to address the challenge of generating code from scientific papers by decomposing the task into literature understanding and code implementation with specialized agents and actions.


---

[Large Language Models in Numberland: A Quick Test of Their Numerical Reasoning Abilities](http://arxiv.org/abs/2504.00226v1)

- Framework names: introduces Numberland, a 100-problem test, to evaluate numerical reasoning abilities of LLM agents including OpenAI ChatGPT o1-mini, OpenAI ChatGPT o1, Google Gemini, Anthropic Claude, and Microsoft Copilot.
- The paper assesses basic operations, advanced calculations, prime number checks, and the 24 game to test elementary skills and integration in complex problem-solving.
- The study highlights limitations in LLMs' numerical reasoning, especially in trial-and-error search tasks, despite their proficiency in deterministic tasks.


---

[Agents Under Siege: Breaking Pragmatic Multi-Agent LLM Systems with Optimized Prompt Attacks](http://arxiv.org/abs/2504.00218v1)

- PIEL (Permutation-Invariant Evasion Loss): introduces a novel adversarial attack framework, with MFMC Problem, Permutation-Invariant Loss, Topological Optimization, Optimized Path, Chunk, Memory Bank, and Sampling Space components, that breaks pragmatic multi-agent LLM systems.
- PIEL framework optimizes prompt distribution across network topologies, considering bandwidth and detection risk constraints to bypass safety mechanisms.
- The framework leverages graph-based optimization and permutation-invariant loss to maximize attack success rate while minimizing detection risk in multi-agent LLM systems.


---

[ADVANCES AND CHALLENGES IN FOUNDATION AGENTS FROM BRAIN-INSPIRED INTELLIGENCE TO EVOLUTIONARY, COLLABORATIVE, AND SAFE SYSTEMS](http://arxiv.org/abs/2504.01990v1)

- Brain-Inspired AI Agent Framework: introduces modular architecture for intelligent agents, integrating brain-inspired components like Sensor, Cognition, Actor, Memory, World Model, Reward, Emotion, Goal, and Tool.
- This framework maps cognitive, perceptual, operational modules to brain functionalities, emphasizing core components such as memory, world modeling, reward processing, and emotion systems.
- The survey synthesizes modular AI architectures with insights from cognitive science and neuroscience to identify research gaps and opportunities for brain-inspired intelligent agents.


---


[PAARS: Persona Aligned Agentic Retail Shoppers](http://arxiv.org/abs/2503.24228v1)

- PAARS (Persona Aligned Agentic Retail Shoppers): introduces a framework for simulating human shoppers using persona-driven LLM agents, incorporating human population, session histories, persona profile, agent population, retail tools, alignment suite, and potential applications.
- PAARS framework synthesizes personas from historical shopping data to create agent population equipped with retail tools for simulating shopping sessions and evaluating alignment with human behavior.
- The framework's alignment suite measures distributional differences between human and agent shopping behavior at group level, enabling applications like agentic A/B testing and surveying.


---

[Output Constraints as Attack Surface: Exploiting Structured Generation to Bypass LLM Safety Mechanisms](http://arxiv.org/abs/2503.24191v1)

- CDA (Constrained Decoding Attack) framework introduces LLM Inference (processes input to logits), Grammar Rule (defines output structure), Lexer & Parser (processes grammar rules), Per-token Mask (filters tokens by grammar), Decoder Block (core LLM decoding process), Logit Processor (processes logits before decoding), Output Generation (generates output tokens), Content Auditing (checks output for safety), and External Safety Guardrails (external checks for safety) to weaponize structured output constraints for bypassing safety mechanisms.
- CDA framework operates by embedding malicious intent within schema-level grammar rules (control-plane) while maintaining benign surface prompts (data-plane), contrasting with prior attacks focused on input prompts.
- The framework highlights a critical security blind spot in current LLM architectures, urging a paradigm shift in LLM safety to address control-plane vulnerabilities beyond data-plane threats.


---

[TeleAntiFraud-28k: An Audio-Text Slow-Thinking Dataset for Telecom Fraud Detection](http://arxiv.org/abs/2503.24115v2)

- TeleAntiFraud-30k Framework: introduces TeleAntiFraud-28k dataset creation and evaluation benchmark, with Real-Data ASR Processing (process real call recordings), LLM-Based Imitation and Augmentation (expand scenario coverage), Audio Synthesis (convert text to voice), Multi-Agent Adversarial Framework (simulate fraud tactics), TeleAntiFraud-Bench (evaluation benchmark), Think-LALM (slow-thinking fraud detection model), Model Training (training detection models), Reasoning Process Quality (assess reasoning quality), Scenario Classification (categorize call scenarios), Fraud Determination (determine fraudulent behavior), and Fraud Type Identification (identify fraud categories).
- TeleAntiFraud-30k framework utilizes Real Audio Data (input audio recordings) processed into ASR Data (transcribed text from audio) and synthesized into Audio (synthesized voice data) and Text (annotated text data), employing User (caller agent), Cheater (fraudster agent), and Manager (conversation monitor agent) within Multi-Agent Adversarial Framework, while evaluation uses JSON (input data format) and potentially generates LR Audio (low resolution audio).
- TeleAntiFraud-30k framework aims to address telecom fraud detection challenges by providing a multimodal dataset and benchmark for training and evaluating slow-thinking Large Audio Language Models (Think-LALM) in tasks like Scenario Classification, Fraud Determination, and Fraud Type Identification, ultimately enhancing reasoning and detection capabilities.


---


[Grounding Agent Reasoning in Image Schemas: A Neurosymbolic Approach to Embodied Cognition](http://arxiv.org/abs/2503.24110v1)

- Neurosymbolic Framework for Grounding Agent Reasoning in Image Schemas: presents framework comprising language input, LLM parser, image schema formalizer, knowledge base, and neurosymbolic reasoner.
- Framework utilizes LLM parser to translate language input into formal image schemas, stored in knowledge base, for neurosymbolic agent reasoning.
- This framework grounds agent reasoning in embodied cognition by leveraging image schemas for enhanced interpretability and human-agent interaction.


---

[Towards Scientific Intelligence: A Survey of LLM-based Scientific Agents](http://arxiv.org/abs/2503.24047v1)

- LLM-based scientific agents: introduces Planner, Memory, and Tool Set as core components for iterative, context-aware processing of complex scientific tasks.
- LLM-based scientific agents architecture includes Planner for task decomposition, Memory for context and knowledge retention, and Tool Set for extending scientific capabilities with external tools.
- The framework emphasizes the integration of Planner, Memory, and Tool Set to enable scientific agents to perform complex research tasks, ensuring reproducibility and driving scientific discovery.


---

[Rubric Is All You Need: Enhancing LLM-based Code Evaluation With Question-Specific Rubrics](http://arxiv.org/abs/2503.23989v1)

- CRE (Complete Rubric Evaluation): introduces a code evaluation framework, with Student Code, Javac, Error Dictionary, Question, Rubric, Prompt, LLM, System Message, Pointwise Marks, Logical Marks, Syntax Marks, Total Marks, Pointwise Feedback, and CRE GRADER, that uses LLM to assess code logic and a compiler for syntax, combining scores for final grade.
- Complete Rubric Evaluation framework employs a detailed rubric and prompt to guide a Large Language Model in evaluating student code submissions, focusing on logical correctness while separately handling syntax errors via a compiler.
- The CRE framework aims to simulate human-like grading by prioritizing conceptual understanding over minor syntax errors, providing a comprehensive evaluation through combined logical and syntactical assessments.


---

[SchemaAgent: A Multi-Agents Framework for Generating Relational Database Schema](http://arxiv.org/abs/2503.23886v1)

- SchemaAgent (Schema Agent) introduces a LLM-based multi-agent framework for automated database schema generation, incorporating Product manager, Conceptual model designer, Conceptual model reviewer, Logical model designer, QA engineer, and Test executor components.
- SchemaAgent framework employs Error detection and correction mechanism to refine schema quality through iterative feedback loop among agents.
- This multi-agent system aims to enhance accuracy and efficiency in relational database schema design process by emulating manual workflow.


---

[Thinking Longer, Not Larger: Enhancing Software Engineering Agents via Scaling Test-Time Compute](http://arxiv.org/abs/2503.23803v1)

- TTC (Test-Time Compute) scaling framework: introduces internal and external strategies to enhance software engineering agents by scaling computation time, incorporating development-contextualized trajectory synthesis, rejection sampling, reasoning training, process and outcome reward models, and execution verification.
- Internal TTC leverages trajectory synthesis and rejection sampling to improve reasoning depth, while external TTC employs a process-based search strategy with reward models and execution verification for targeted computation allocation.
- The framework aims to achieve comparable performance to larger models using smaller, personally deployable LLMs by strategically increasing inference-time computation and focusing on critical decision points in software engineering tasks.


---

[DebFlow: Automating Agent Creation via Agent Debate](http://arxiv.org/abs/2503.23781v1)

- DebFlow: introduces a framework for automated agent creation, with Search Space, Self-reflection, Workflow, and Agent Debate components.
- DebFlow employs agent debate to optimize workflows and integrates self-reflection for iterative performance improvement based on past experiences.
- The framework utilizes LLM-invoking nodes as basic units, optimizing agent workflows through debate and reflection mechanisms for enhanced efficiency and performance.


---

[Detecting Functional Bugs in Smart Contracts through LLM-Powered and Bug-Oriented Composite Analysis](http://arxiv.org/abs/2503.23718v1)

- PROMFUZZ (PROMFUZZ): introduces automated system to detect functional smart contract bugs, with LLM-driven Multi-Perspective Analysis, Invariant Checker Generation, Bug-oriented Analysis Engine and Functional Bug Detection components.
- PROMFUZZ employs dual-agent approach with Auditor Agent and Attacker Agent, and generates invariant checkers using Critical Variable Extraction, Principal Statement Extraction and Template-based Checker Generation.
- PROMFUZZ utilizes Bug-oriented Analysis Engine with Strategically Invariant Checker Insertion and Bug-oriented Fuzzing for effective functional bug detection and provides Bug Report component.


---

#### 30th March 2025

[GIScience in the Era of Artificial Intelligence: A Research Agenda Towards Autonomous GIS](http://arxiv.org/abs/2503.23633v1)

- Autonomous GIS: introduces a conceptual framework for next-generation geographic information systems, integrating decision-making, data preparation, data operation, memory-handling, and core-updating functions, supported by geo-data retrieval, spatial analysis, cartography, and modeling agents, across routine-aware, workflow-aware, data-aware, result-aware, and knowledge-aware levels, aiming for self-generating, self-executing, self-verifying, self-organizing, and self-growing goals, scalable across local, centralized, and infrastructure scales.
- Autonomous GIS framework envisions a paradigm shift in GIScience by leveraging generative AI to automate geospatial problem-solving with minimal human intervention, enhancing accessibility and democratizing spatial analysis for broader applications.
- The framework outlines key research challenges and future directions for autonomous GIS, emphasizing the need for benchmarks, enhanced AI understanding of geospatial concepts, and addressing ethical and societal impacts of AI-driven geospatial technologies.


---

[Exploring GPT-4 for Robotic Agent Strategy with Real-Time State Feedback and a Reactive Behaviour Framework](http://arxiv.org/abs/2503.23601v1)

- LLM-Director Framework: introduces a robotic control approach integrating LLM for high-level task planning within Director reactive behaviour framework, utilizing NUClear for real-time message passing and sensor modules for environmental feedback.
- This framework uses LLM to generate tasks based on user requests and world information, which are then executed by the Director Tree, ensuring safety and smooth transitions through skills and joint commands to actuators, guided by real-time feedback from sensor modules.
- The integration of LLM with Director framework allows for dynamic reactive task layer construction, addressing safety, task transitions, and real-time feedback for improved robotic agent performance in complex environments.


---

[If an LLM Were a Character, Would It Know Its Own Story? Evaluating Lifelong Learning in LLMs](http://arxiv.org/abs/2503.23514v1)

- LIFESTATE-BENCH (Lifelong State Benchmark): introduces cumulative experience, fact checking, memory testing, and judge model components for evaluating lifelong learning in LLMs.
- LIFESTATE-BENCH assesses state evolution in LLMs through episodic interactions and fact-based questions focusing on self-awareness, memory, and relationship shifts.
- The benchmark employs non-parametric and parametric memory testing methods and LLM-as-judge for comprehensive evaluation of lifelong learning capabilities.


---

[RE-ALIGNING LANGUAGE TO VISUAL OBJECTS WITH AN AGENTIC WORKFLOW](http://arxiv.org/abs/2503.23508v1)

- Real-LOD (Re-Aligning Language to Visual Objects with an Agentic Workflow): introduces agentic workflow for refining language descriptions using planning, tool use, and reflection components.
- Real-LOD leverages LLM for reasoning and reflection, and VLM for tool use to iteratively improve language alignment with visual objects.
- The framework enhances data quality for language-based object detection by reducing hallucinations in automatically generated descriptions.


---

[VideoGen-Eval: Agent-based System for Video Generation Evaluation](https://github.com/AILab-CVC/VideoGen-Eval)

- VideoGen-Eval: introduces agent-based system for video generation evaluation, with Structured Prompts, Advanced Models, Generated Videos, Human annotations, Prompt Structurer, Content Judger, Tools Pool, Temporal-sparse Content, Temporal-dense Content, MLLMs, and Human Alignment.
- VideoGen-Eval benchmark includes structured prompts and large-scale video results for dynamic and flexible evaluation of video generation models.
- The system employs LLM for content structuring, MLLM for content judgment, and patch Tools Pool for temporal dimension assessment, enhancing alignment with human preferences.


---

[CoRanking: Collaborative Ranking with Small and Large Ranking Agents](http://arxiv.org/abs/2503.23427v2)

- CoRanking (Collaborative Ranking): introduces a collaborative ranking framework, with Small Listwise Reranker (SLR), Passage Order Adjuster (POA), and LLM Listwise Reranker (LLR), that combines small and large ranking models for efficient and effective passage ranking.
- CoRanking framework utilizes S³ strategy for preference pair selection and Human Label enhanced ranking construction to improve training, addressing positional biases of LLMs and enhancing ranking performance.
- The framework achieves significant efficiency gains by using SLR for pre-ranking and POA for order adjustment before applying LLR for final reranking, outperforming pure LLM listwise reranking in both speed and effectiveness.


---

[An Analysis of Decoding Methods for LLM-based Agents for Faithful Multi-Hop Question Answering](http://arxiv.org/abs/2503.23415v1)

- ReAct (Reasoning and Acting): introduces systematic analysis of ReAct framework with Thought, Action, Observation components combined with Decoding Strategy and Retrieval to improve faithfulness in question answering.
- The framework iteratively uses Thoughts to decide Actions, leading to Observations, employing Decoding Strategy and Retrieval for enhanced answer faithfulness.
- Combining ReAct with faithful decoding methods significantly improves accuracy in multi-hop question answering tasks by enhancing contextual faithfulness.


---

[A Multi-Agent Framework with Automated Decision Rule Optimization for Cross-Domain Misinformation Detection](http://arxiv.org/abs/2503.23329v1)

- MARO (Multi-Agent Framework for cross-domain misinformation detection with Automated Decision Rule Optimization): introduces a two-module framework with Multi-Dimensional Analysis Module, incorporating Linguistic Feature Analysis Agent, Comment Analysis Agent, Fact-Checking Agent Group with Fact-Questioning Agent and Fact-Checking Agent, Questioning Agent, and Multi-Dimensional Analysis Report, alongside Decision Rule Optimization Module, which includes Cross-Domain Validation Task, Judge Agent, Decision Rule Optimization Agent, Decision Rule Optimization Prompt, Demonstrations from Other Domains, Wikipedia, Google, LRS, and Top K decision rules, for cross-domain misinformation detection.
- MARO's Multi-Dimensional Analysis Module employs multiple agents to analyze news from different perspectives, generating a comprehensive analysis report, while the Decision Rule Optimization Module automatically refines decision rules using feedback from cross-domain validation tasks.
- The framework utilizes a question-reflection mechanism with a Questioning Agent to guide expert agents in Multi-Dimensional Analysis Module for enhanced analysis quality, and iteratively optimizes decision rules in Decision Rule Optimization Module to improve generalization across domains.


---

[AI Agents in Engineering Design: A Multi-Agent Framework for Aesthetic and Aerodynamic Car Design](http://arxiv.org/abs/2503.23315v1)

- AI Design Agents Framework: introduces multi-agent system with Styling-, CAD-, Meshing- and Simulation-Agents, leveraging Foundation Models, Geometric Deep Learning Models and Engineering Tools, orchestrated by AutoGen, for accelerating car design process.
- Framework automates conceptual sketching, styling, 3D shape retrieval, generative modeling, CFD meshing and aerodynamic simulations.
- AI Design Agents Framework enhances design exploration, efficiency and collaboration between designers and engineers in automotive design.


---

[SPIO: Ensemble and Selective Strategies via LLM-Based Multi-Agent Planning in Automated Data Science](http://arxiv.org/abs/2503.23314v1)

- SPIO (Sequential Plan Integration and Optimization): introduces multi-agent framework with fundamental code generation agents, sequential planning agent, plan optimization agent, and code write agent, leveraging memory for automated data science.
- SPIO employs sequential planning and LLM-driven optimization across preprocessing, feature engineering, modeling, and hyperparameter tuning modules.
- SPIO enhances predictive accuracy and robustness by exploring multiple candidate strategies and ensembling top-performing plans.


---

[GRASP: Municipal Budget AI Chatbots for Enhancing Civic Engagement](http://arxiv.org/abs/2503.23299v1)

- GRASP (Generation with Retrieval and Action System for Prompts): introduces a municipal budget chatbot framework combining RAG Framework for document retrieval and ReAct Agent for action execution, utilizing Prompt Engineering and Domain Knowledge to enhance response accuracy.
- GRASP framework incorporates LLM with System Instructions, Agent Scratchpad, and Intermediate Steps, processing user Prompt to interact with Budget Tool, Drawing tool, and Analysis tool through iterative Thoughts, Action, and Observation cycles for Final Response.
- This approach aims to improve truthfulness and grounding of chatbot responses by leveraging external Budget Docs within Vector Database and employing Metadata filtering and Similarity Search for relevant information retrieval.


---

[EncGPT: A Multi-Agent Workflow for Dynamic Encryption Algorithms](http://arxiv.org/abs/2503.23138v1)

- EncGPT (Encryption GPT): introduces multi-agent workflow for dynamic encryption, with rule-, encryption-, decryption-, source- and recipient-agents, and memory.
- It dynamically generates encryption rules, applies them for encryption and decryption, and supports homomorphic operations on encrypted data.
- This framework enhances communication security in LLM-MA systems by addressing dynamic algorithm generation and single encryption algorithm vulnerabilities.


---

[Efficient Inference for Large Reasoning Models: A Survey](http://arxiv.org/abs/2503.23077v1)

- Efficient Inference for Large Reasoning Models: introduces survey on efficient inference methods for Large Reasoning Models, categorizing approaches into explicit compact CoT and implicit latent CoT, alongside taxonomy, empirical analyses, challenges, and improvements.
- The survey explores token efficiency in Large Reasoning Models, addressing token consumption, memory overhead and inference time, while considering solutions like model merge, new architectures and agent routers.
- This research emphasizes trade-offs between efficiency and interpretability, safety, and application scope within efficient reasoning methods for Large Reasoning Models.


---

#### 29th March 2025

[Agentic Large Language Models, a survey](http://arxiv.org/abs/2503.23037v1)

- Agentic LLM Taxonomy: introduces reasoning, acting, interacting, self-reflection, retrieval, multi-step, world models, VLA, robot, tools, assistants, social capabilities, open-ended societies, new data for categorizing agentic LLM research.
- Agentic LLM Taxonomy categorizes agentic LLMs into reasoning for better decisions, acting for real-world tasks, and interacting for social behaviors.
- Agentic LLM Taxonomy highlights the virtuous cycle where reasoning, acting, and interacting generate new data to improve LLMs continuously.


---

[Factored Agents: Decoupling In-Context Learning and Memorization for Robust Tool Use](http://arxiv.org/abs/2503.22931v1)

- Factored Agent Architecture: introduces a two-component agent system with planner-LLM and memorizer-SLM, addressing limitations of single-agent designs for tool use by decoupling in-context learning and memorization.
- The architecture separates planning using a larger LLM from tool-specific formatting handled by a smaller SLM, aiming to improve robustness against API errors and enhance planning accuracy in dynamic environments.
- This decoupling strategy intends to mitigate trade-offs between in-context learning and static memorization, potentially leading to more adaptable and error-resilient agentic AI systems for tool utilization.


---




#### 28th March 2025

[WorkTeam: Constructing Workflows from Natural Language with Multi-Agents](http://arxiv.org/abs/2503.22473v1)

- WorkTeam (multi-agent NL2Workflow framework): introduces supervisor, orchestrator, and filler agents for collaborative natural language to workflow conversion.
- WorkTeam framework enhances workflow construction accuracy through task specialization and collaboration among supervisor, orchestrator, and filler agents.
- The framework utilizes supervisor agent for task planning and result reflection, orchestrator agent for component selection and orchestration, and filler agent for parameter population.


---


[Self-Evolving Multi-Agent Simulations for Realistic Clinical Interactions](http://arxiv.org/abs/2503.22678v1)

- MedAgentSim (MedAgentSim): introduces a multi-agent framework with patient-, doctor-, and measurement-agents within conversation- and experience replay-phases, utilizing medical- and experience-records buffers, KNN few-shot retrieval, chain-of-thought reasoning, majority vote ensembling, and reflection-phase for enhanced diagnostic accuracy.
- MedAgentSim framework simulates realistic clinical interactions by enabling doctor agents to actively gather patient information through multi-turn conversations and iteratively refine diagnostic strategies using self-improvement mechanisms.
- The framework incorporates experience replay and memory buffers to facilitate progressive learning and improve the performance of LLM-powered agents in dynamic diagnostic settings, bridging the gap between static evaluations and real-world medical reasoning.


---

[Unlocking LLM Repair Capabilities in Low-Resource Programming Languages Through Cross-Language Translation and Multi-Agent Refinement](http://arxiv.org/abs/2503.22512v1)

- LANTERN (LANguage Translation and multi-agEnt Refinement): introduces a novel program repair framework, with Analyzer, Translator, Repairer, Test Suites, Middleware, Historical Data Storage & Retrieval, Prompt Construction, Process Control and Translation Coordination, that leverages cross-language translation and multi-agent refinement to enhance LLM-based repair capabilities in low-resource programming languages.
- LANTERN framework strategically translates buggy code to languages where LLMs exhibit stronger repair performance, utilizing a multi-agent iterative repair paradigm and incorporating historical feedback for informed decision-making.
- The framework's key innovation lies in its LLM-based Analyzer that dynamically selects optimal target languages for translation based on bug characteristics and previous repair attempts, effectively bridging the performance gap across programming languages.


---



[Evaluating LLM-based Agents for Multi-Turn Conversations: A Survey](http://arxiv.org/abs/2503.22458v1)

- Multi-turn Conversational Agent: introduces agent architecture for multi-turn dialogues, with User Input-Agent Output, Task Planner, Tool Invoker, Agent Core, Conversation Memory, and Turn Memory components.
- This framework manages conversation flow by decomposing user requests, invoking tools, maintaining memory, and generating responses.
- The architecture enables coherent and context-aware interactions over extended dialogues by leveraging memory and planning.


---



[UNDERSTANDING INEQUALITY OF LLM FACT-CHECKING OVER GEOGRAPHIC REGIONS WITH AGENT AND RETRIEVAL MODELS](http://arxiv.org/abs/2503.22877v1)

- ReAct-like agent: introduces agent-based fact-checking, with LLM, Wikipedia access, local cache, system prompt and user message, to evaluate factuality of statements.
- This framework employs function calling LLM to query Wikipedia for external knowledge, caching results for subsequent use.
- The agent-based method explores enhancing fact-checking via external information access, yet encounters performance limitations compared to RAG using verified documents.


---


[COSIL: Software Issue Localization via LLM-Driven Code Repository Graph Searching](http://arxiv.org/abs/2503.22424v1)

- COSIL (Software Issue Localization): introduces a two-stage framework for issue localization, with file-level search space reduction and function-level iterative search, utilizing module and function call graphs, guided by a searcher and pruner, to identify suspicious code locations.
- COSIL employs a module call graph enhanced reflection and iterative function call graph searching to refine search space and context, dynamically constructing graphs and using context pruning for effective issue localization.
- The framework leverages a searcher agent with tools and a pruner to manage context and direction during iterative search, aiming for concise yet effective context for accurate issue localization without pre-built indexes.


---

[Agent-Centric Personalized Multiple Clustering with Multi-Modal LLMs](http://arxiv.org/abs/2503.22241v1)

- Agent-Centric Framework (Agent-Centric Personalized Multiple Clustering Framework): introduces agent-centric personalized clustering using MLLM Agents to traverse Relational Graph built from MLLM-based Embedding Extractor and identify Searched Clusters based on User Interests.
- The framework constructs Relational Graph via Embedding Similarity filtering of Image Embeddings and employs Agent-Centric Graph Traversal with Membership Assessment and Cluster Update mechanisms.
- This approach leverages MLLM Agents for efficient graph exploration, starting from Seed Nodes within Connected Components and iteratively expanding clusters by evaluating Candidate Nodes and Neighbor Nodes.


---

[PharmAgents: Building a Virtual Pharma with Large Language Model Agents](http://arxiv.org/abs/2503.22164v1)

- PharmAgents: introduces a virtual pharmaceutical ecosystem, driven by LLM-based multi-agent collaboration, that simulates drug discovery workflow with components including agents for disease expertise, target analysis, molecule design, and preclinical evaluation, alongside databases and computational tools.
- PharmAgents decomposes drug discovery into target discovery, lead identification, lead optimization, and preclinical evaluation stages, employing specialized LLM-driven agents for each stage, enhanced with machine learning models and domain-specific tools, to achieve autonomous and explainable drug design.
- The framework emphasizes interpretability and efficiency by integrating LLMs for reasoning and decision-making at each stage of drug discovery, ensuring transparency and enabling researchers to understand and validate the AI-driven process, ultimately accelerating drug development.


---


#### 27th March 2025

[MemInsight: Autonomous Memory Augmentation for LLM Agents](http://arxiv.org/abs/2503.21760v1)

- MemInsight (Autonomous Memory Augmentation): introduces autonomous memory augmentation framework with Attribute Mining, Annotation, Retrieval Pool, Memory Retriever and Memory Augmentation to enhance LLM agents' contextual performance.
- MemInsight leverages attribute mining and annotation for structured memory representation, enabling efficient retrieval through attribute-based and embedding-based methods.
- The framework improves memory retrieval by filtering irrelevant information and retaining key insights, demonstrated across conversational tasks.


---

[Debate-Driven Multi-Agent LLMs for Phishing Email Detection](http://arxiv.org/abs/2503.22038v1)

- Multi-Agent Debate Framework: introduces multi-agent debate framework with pro-phishing Agent 1, anti-phishing Agent 2, debate adjudicating Judge Agent, and scripted Debate Procedure for phishing email detection.
- This framework uses two debating LLM agents and judge LLM to improve phishing email classification via structured argument exchange.
- Debate-driven approach enhances contextual analysis and reasoning for improved phishing detection accuracy compared to single-agent methods.


---

[LEARNING TO LIE: REINFORCEMENT LEARNING ATTACKS DAMAGE HUMAN-AI TEAMS AND TEAMS OF LLMS](http://arxiv.org/abs/2503.21983v1)

- MBRL (Model-Based Reinforcement Learning): introduces adversarial agent, with Action, Team, State, Planner, Internal Model, Adversarial agent components, to study malicious AI in human-AI teams.
- MBRL framework uses internal model of team dynamics and planner to decide AI agent's action to maximize damage to team performance.
- This approach investigates vulnerabilities in human-AI collaboration and informs development of defense strategies against AI-driven attacks.


---


[GateLens: A Reasoning-Enhanced LLM Agent for Automotive Software Release Analytics](http://arxiv.org/abs/2503.21735v1)

- GateLens: introduces a system for automotive software release analytics, utilizing Query Interpreter Agent, Relational Algebra Generation, RA to Pandas Code Conversion, Coder Agent, Code Execution, Analysis Results Output to User, Database, and Knowledge Base components.
- GateLens employs Query Interpreter Agent to translate user queries into Relational Algebra, which is then converted to executable code by Coder Agent for analysis using Database and guided by Knowledge Base.
- The framework enhances analytical reasoning by incorporating Relational Algebra, enabling precise handling of domain-specific queries and improving the interpretability of the analysis process.


---


[ReFeed: Multi-dimensional Summarization Refinement with Reflective Reasoning on Feedback](https://arxiv.org/abs/2503.21332)

- ReFeed (Refinement with Reflective Reasoning on Feedback): introduces a summarization refinement pipeline enhancing multiple dimensions using reflective reasoning on feedback.
- ReFeed pipeline incorporates detection, multi-dimensional feedback mapping, reflective reasoning, supervised fine-tuned LLM, SumFeed-CoT dataset, goal specification, LRM teacher, refinement guideline, and quality control components.
- ReFeed framework aims to address trade-offs, ordering bias, and noisy feedback in multi-dimensional summarization refinement, improving robustness and performance.


---


[COLLAB: CONTROLLED DECODING USING MIXTURE OF AGENTS FOR LLM ALIGNMENT](http://arxiv.org/abs/2503.21720v1)

- COLLAB (CONTROLLED DECODING using MIXTURE OF AGENTS): introduces mixture of agents-based decoding strategy with policy-switching and token-level selection.
- Leverages implicit Q-function for optimal agent selection from pool of models during inference.
- Enables collaborative alignment among LLMs without retraining by dynamic agent selection.


---


[A Survey of Efficient Reasoning for Large Reasoning Models: Language, Multimodality, and Beyond](https://arxiv.org/abs/2503.21614)

- Efficient Reasoning for LRMs (Large Reasoning Models): introduces pre-training, SFT, RL, LRM, and inference stages for efficient reasoning methods.
- The survey categorizes efficient reasoning methods based on these stages in the LLM lifecycle.
- Efficient reasoning in LRMs is crucial for deployment, scalability, and practical application, addressing the challenge of excessive reasoning traces.


---





#### 26th March 2025

[GAIA-2: A Controllable Multi-View Generative World Model for Autonomous Driving](https://arxiv.org/abs/2503.20523)

- GAIA-2 (Generative AI for Autonomy): introduces a generative world model for autonomous driving, with Video Tokenizer, Latent World Model, Space-Time Factorized Transformer, and Conditioning components.
- GAIA-2 framework includes Encoder and Decoder within Video Tokenizer, various Conditioning inputs like Actions, 3D Bounding Boxes, Metadata, Embeddings, Camera Parameters, Positional Encodings, and Memory and Noise components for generation.
- GAIA-2 framework utilizes Training Tasks and Inference modes to enable controllable video generation for autonomous driving simulation, addressing multi-camera consistency and fine-grained control.


---


[Feature4X: Bridging Any Monocular Video to 4D Agentic AI with Versatile Gaussian Feature Fields](http://arxiv.org/abs/2503.20776v1)

- Feature4X: introduces a framework to create interactive 4D scenes from monocular video by distilling features from 2D Foundation Models (Extract initial features) into a unified 4D Feature Fields (Unified feature representation) using dynamic Gaussian Splatting, involving Input Monocular Video (Source data), 2D Priors (Initial features/constraints) like Dynamic Mask (Foreground/background separation) and Metric Depth (Geometric prior), Static Feature GS (Background Gaussian Splatting), Dynamic Feature GS (Foreground Gaussian Splatting) guided by a Motion Scaffold (Guides dynamic deformation), a Parallel N-Dimensional Gaussian Rasterizer (Renders RGB/features) producing a Unified Latent Feature Map (Compact shared features), task-specific Decoders (Map unified to task features), optimized with Photometric Loss (RGB reconstruction objective) and Feature Loss (Feature reconstruction objective), enabling interaction via an LLM (Language interaction/control) and User (Provides interaction/prompts) within a 4D Agentic AI (Overall interactive system).
- The core representation is a dynamic 4D Gaussian feature field, separating Static Background (Scene component representation) and Dynamic Foreground (Scene component representation), where features are compactly represented using scaffold-based interpolation and rendered efficiently via a parallel rasterizer.
- This approach integrates functionalities from diverse 2D models (e.g., SAM2, CLIP-LSeg, InternVideo2) into a single 4D representation, supporting tasks like segmentation, editing, and VQA across novel views and time steps via LLM-powered interaction.


---


[Beyond Believability: Accurate Human Behavior Simulation with Fine-Tuned LLMs](http://arxiv.org/abs/2503.20749v1)

- Web Action Generation Model: introduces a framework for simulating human web actions by predicting the next action and reasoning based on current webpage context and history of user interactions.
- The framework utilizes a fine-tuned LLM to generate both a natural language rationale and a browser action, focusing on process-centric accuracy in web behavior simulation.
- Key components include Context representing webpage content, Rationale explaining action intent, and Action defining browser operations like click, type and submit, or terminate.


---

[TAMA: A Human-AI Collaborative Thematic Analysis Framework Using Multi-Agent LLMs for Clinical Interviews](http://arxiv.org/abs/2503.20666v1)

- TAMA (Thematic Analysis): introduces a human-AI collaborative framework with Cardiac Expert, Interview Transcripts, Chunks, Generation Agent, Codes, Evaluation Agent, Themes, Refinement Agent, and Feedback for thematic analysis of clinical interviews using multi-agent LLMs.
- TAMA framework leverages multi-agent LLMs to automate thematic analysis by generating, evaluating, and refining themes through structured conversations and expert feedback, enhancing scalability and coherence.
- The framework aims to improve thematic analysis quality in healthcare settings by integrating human expertise with multi-agent LLM systems, reducing manual workload and enhancing the consistency of results.


---

[A Theoretical Framework for Prompt Engineering: Approximating Smooth Functions with Transformer Prompts](http://arxiv.org/abs/2503.20561v1)

- Theoretical Framework for Prompt Engineering: introduces a framework with prompt, transformer, virtual network, input, layer, and output, describing how prompts configure transformers to emulate virtual neural networks.
- The framework posits that prompts dynamically adjust transformer's internal computations to approximate smooth functions.
- This approach provides theoretical grounding for prompt engineering techniques and AI agent design by framing LLMs as adaptable agents.


---

[Knowledge-Based Multi-Agent Framework for Automated Software Architecture Design](http://arxiv.org/abs/2503.20536v1)

- MAAD (Multi-Agent Architecture Design) introduces multi-agent framework for automated software architecture design, involving Analyst, Modeler, Designer, and Evaluator agents collaborating based on input Software Requirements Specifications to produce architecture artifacts.
- MAAD framework utilizes agents to simulate human roles in architecture design, leveraging knowledge from existing system designs, authoritative literature, and architecture experts to enhance automation.
- MAAD framework aims to automate and enhance the efficiency, scalability, and consistency of software architecture design process by generating diagrams and reports, ultimately advancing full automation of application-level software development.


---

[Exploring the Effect of Robotic Embodiment and Empathetic Tone of LLMs on Empathy Elicitation](http://arxiv.org/abs/2503.20518v1)

- Interaction Design System: investigates empathy elicitation using user voice input, speech recording, laptop processing, OpenAI LLM (ChatGPT-40) for response generation, and Pepper robot/chatbot agents.
- This system compares robotic embodiment and empathetic tone by employing physical robot and chatbot agents, both driven by LLMs, to elicit empathy towards a fictional character.
- The system utilizes speech-to-text, LLM, and text-to-speech modules for interaction, measuring participant volunteering hours and perceived agent empathy through questionnaires.


---

[sudo rm -rf agentic_security](http://arxiv.org/abs/2503.20279v1)

- SUDO (SCREEN-BASED UNIVERSAL DETOX2TOX OFFENSE): introduces a novel attack framework, with Detoxifier, Instruction Generator, Toxifier, Dynamic Updater and Evaluation Criteria components, that systematically bypasses refusal-trained safeguards in computer-use agents.
- SUDO framework employs DETOX2TOX mechanism to transform harmful requests into benign ones and then re-introduce malicious content before execution, iteratively refining attacks based on refusal feedback.
- The framework demonstrates vulnerabilities in computer-use agents and emphasizes the need for robust, context-aware safeguards by successfully executing attacks in real-world computing environments.


---

[Open Deep Search: Democratizing Search with Open-source Reasoning Agents](http://arxiv.org/abs/2503.20201v1)

- ODS (Open Deep Search): introduces open-source search framework with Base LLM, Open Reasoning Agent, Open Search Tool and Tools for democratizing search.
- ODS framework uses Open Reasoning Agent to interpret query and orchestrate actions using Tools including Open Search Tool for web search and processing.
- ODS framework aims to close gap between proprietary and open-source search solutions by augmenting reasoning capabilities of open-source LLMs.


---

[A Reference Architecture for Autonomous Networks: An Agent-Based Approach](https://arxiv.org/abs/2503.12871)

- AN Agent Reference Architecture (Autonomous Networks Agent Reference Architecture): introduces Situation Awareness (perceives network state), Decision Making (determines actions), Self Awareness (recognizes risks), Choice Making (selects suitable goal), World Knowledge (knowledge repository), Human-Agent Interaction (human collaboration), Agent-Agent Interaction (agent collaboration), Reactive Behavior (responds to stimuli), and Proactive Behavior (addresses potential risks) for autonomous network agents.
- AN Agent Reference Architecture facilitates autonomous network operation by integrating reactive and proactive behaviors with human and agent interactions, leveraging shared domain-specific knowledge for consistent decision execution.
- The architecture emphasizes modularity and functional specification, aiming for implementation-independence and completeness to guide development of trustworthy autonomous network agents replacing human operation and maintenance.


---


#### 25th March 2025

[FALCONEye: Finding Answers and Localizing Content in ONE-hour-long videos with multi-modal LLMs](http://arxiv.org/abs/2503.19850v1)

- FALCONEye: introduces a meta-architecture for video answer search, integrating Pre-processing, VLM (vision-language model), Captions, Summary, Reason, LLM (large language model), Candidate Clips, Evaluation, Answer, Confidence Score, Decision, and Promising Clips to efficiently locate answers in long videos.
- It employs an iterative exploration algorithm, using Captions and Confidence Scores to refine search and focus resources on relevant video segments.
- The framework is designed for Video Answer Search (VAS) tasks in long videos, addressing limitations of VLMs in handling long context and pinpointing specific information.


---

[Inducing Personality in LLM-Based Honeypot Agents: Measuring the Effect on Human-Like Agenda Generation](http://arxiv.org/abs/2503.19752v1)

- SANDMAN: introduces deceptive agent architecture for cyber deception, integrating Agent Profile, Decision Engine, Memory Space (Semantic, Episodic, Working, Retrieval, Learning), LLM Engine, Planning Space (Bootstrap Task, Task List), and Action Space (Channel, Generators).
- SANDMAN architecture enables creation of plausible human simulacra by inducing personality traits within LLMs to govern agent behavior within digital environments.
- The framework enhances cyber deception strategies by facilitating agents to produce varied realistic behaviors through persona-driven methodology.


---

[Writing as a testbed for open ended agents](http://arxiv.org/abs/2503.19711v1)

- Framework for Benchmarking Autonomous Writing Agents: introduces a framework for benchmarking autonomous writing agents with exploration, evaluation, and goal alignment components.
- This framework evaluates Large Language Models as collaborative co-writers by analyzing action diversity, human alignment, and iterative text improvement capabilities.
- The framework highlights challenges and potential solutions for building systems capable in diverse open-ended domains through iterative refinement.


---

[Agent-Initiated Interaction in Phone UI Automation](http://arxiv.org/abs/2503.19537v1)

- Approach: introduces a method for agent-initiated interaction in phone UI automation, with User Instruction, Screen Input, Session History, Interaction Detection, Message Generation, and Baseline Models components.
- This approach focuses on detecting the necessity for user interaction during task execution and generating appropriate messages for clarification or confirmation.
- The evaluation utilizes baseline models to assess the effectiveness of different input modalities and model architectures for interaction detection and message generation in UI automation tasks.


---

[MARS: Memory-Enhanced Agents with Reflective Self-improvement](http://arxiv.org/abs/2503.19271v1)

- MARS (Memory-Enhanced Agents with Reflective Self-improvement): introduces User, Assistant, and Checker agents within an Environment, incorporating STM and LTM memory components, alongside Reflection and Feedback mechanisms for iterative self-improvement.
- MARS framework enhances agent performance by utilizing iterative feedback from the Checker to refine the Assistant's policy, leveraging Reflection to store historical data in LTM and STM for improved decision-making.
- The framework aims to address limitations of LLMs in continuous decision-making and long-term memory by integrating these components for effective task completion in dynamic environments.


---

[DIRECT POST-TRAINING PREFERENCE ALIGNMENT FOR MULTI-AGENT MOTION GENERATION MODELS USING IMPLICIT FEEDBACK FROM PRE-TRAINING DEMONSTRATIONS](http://arxiv.org/abs/2503.20105v1)

- DPA-OMF (Direct Preference Alignment from Occupancy Measure Matching Feedback): introduces alignment approach with Multi-modal Scene Encoder, Motion Token Prediction Model, Preference Ranking via Occupancy Measure Matching Feedback, and Expert demo, aligning pre-trained motion model with human preferences.
- DPA-OMF leverages implicit preferences from pre-training expert demonstrations to construct preference rankings among model generations using occupancy measure matching for nuanced alignment guidance.
- DPA-OMF improves realism of traffic simulation behaviors, enabling lightweight models to achieve comparable performance to state-of-the-art imitation models without extra human annotations.


---

[BugCraft: End-to-End Crash Bug Reproduction Using LLM Agents in Minecraft](http://arxiv.org/abs/2503.20036v1)

- BugCraft: introduces automated crash bug reproduction framework utilizing LLMs, encompassing Bug Report, S2R Synthesizer, and Action Model Agent components.
- BugCraft framework employs two-stage approach: Step Synthesizer generates structured steps from bug reports, and Action Model Agent executes these steps within Minecraft environment.
- Framework evaluation utilizes BugCraft-Bench, a curated dataset of Minecraft crash bugs, to assess end-to-end reproduction and step synthesis effectiveness.


---

[OmniNova:A General Multimodal Agent Framework](http://arxiv.org/abs/2503.20028v1)

- OmniNova: introduces a modular framework, integrating multi-agent system, workflow engine, language model and tool integration, configuration and prompt template systems, for complex automation tasks.
- OmniNova employs hierarchical multi-agent architecture with coordinator, planner, supervisor, research, code, browser and reporter agents, managed by workflow engine, utilizing multi-layered LLM and unified tool integration.
- The framework optimizes resource utilization and task completion through dynamic task routing, specialized agents, and multi-layered LLM allocation, enhancing efficiency and result quality.


---


#### 24th March 2025

[A Survey of Large Language Model Agents for Question Answering](http://arxiv.org/abs/2503.19213v1)

- LLM Agent (Large Language Model Agent): introduces LLM-based Agent QA system, with Action Planning, Memory, Thinking, Action for External Environment, Observation, and Environment components, where the paper surveys the design of LLM agents for question answering tasks.
- LLM Agent architecture incorporates memory to aggregate information, planning to decide actions, and thinking for reasoning and answer generation, enabling interaction with external environments for enhanced QA.
- The framework addresses limitations of standalone LLMs by integrating modules for planning and external interaction, improving performance in complex QA tasks requiring external knowledge and reasoning.


---

[LLM-Based Insight Extraction for Contact Center Analytics and Cost-Efficient Deployment](http://arxiv.org/abs/2503.19090v1)

- Topic Modeling Pipeline: introduces a multi-step process for contact center analytics, utilizing Call Transcripts to perform Call Driver Generation for extracting Call Drivers, which are then processed by Topic Clustering and Topic Labeling to produce Topics.
- This pipeline leverages a fine-tuned Mistral model for call driver generation and all-MiniLM-L6-v2 with HDBSCAN for topic clustering, aiming for cost-efficient and accurate topic identification from customer interactions.
- The generated topics and call drivers facilitate downstream tasks like trend detection and FAQ generation, ultimately improving contact center efficiency and customer service.


---


[Verbal Process Supervision Elicits Better Coding Agents](http://arxiv.org/abs/2503.18494v1)

- CURA (Code Understanding and Reasoning Agent): introduces process-supervised reasoning framework for code generation with code understanding, test case generation, solution reasoning, code testing sandbox, and process reward models.
- CURA utilizes verbal process supervision to iteratively guide reasoning steps and refine model behavior through reward signals at each stage.
- The framework enhances code generation performance by integrating iterative feedback and verbal process supervision throughout the reasoning pipeline.


---


[Safeguarding Mobile GUI Agent via Logic-based Action Verification](http://arxiv.org/abs/2503.18492v1)

- VSA (VeriSafe Agent): introduces a verification framework for Mobile GUI Agents, incorporating Intent Encoder, Logical Formula, Intent Verifier, Feedback Generator, and VSA Library, designed to ensure agent actions are consistent with user instructions.
- VeriSafe Agent framework utilizes autoformalization to convert natural language instructions into a domain-specific language, enabling rule-based runtime verification of mobile agent actions.
- VSA framework aims to bridge probabilistic LFM-driven automation with deterministic formal verification by providing pre-action verification and structured feedback to guide GUI agents towards correct task completion.


---

[DeepFund: Will LLM be Professional at Fund Investment? A Live Arena Perspective](http://arxiv.org/abs/2503.18313v1)

- DeepFund: introduces a comprehensive arena platform, with Stock Pool, Web API, Trading Memory, Current Position, Agent Planner, Technical Analysts, Fundamental Analysts, Insider Analysts, Media Analysts, Agent Manager, Decision, Decision Log, Trading Simulation Environment, Model Integration Interface and Performance Monitoring, for evaluating LLM-based trading strategies in simulated live environment.
- DeepFund platform employs multi-agent framework where Agent Planner orchestrates analysis from specialized Technical, Fundamental, Insider, and Media Analysts, and Agent Manager synthesizes insights for final investment Decision.
- Trading Simulation Environment in DeepFund mitigates data leakage by providing real-time market data through Web API and evaluating models on data post-training cutoff, while Performance Monitoring visualizes model performance.


---

[How to Capture and Study Conversations Between Research Participants and ChatGPT: GPT for Researchers (g4r.org)](http://arxiv.org/abs/2503.18303v1)

- G4R (GPT for Researchers): introduces a website platform with researcher interface, GPT interface creation, GPT interface customization, GPT interaction, data capture, data download, and data merging for studying participant-GPT conversations.
- G4R enables researchers to create customizable GPT interfaces, integrate them into studies like Qualtrics surveys, capture conversation data, and download/merge data for analysis.
- This tool addresses the lack of standardized methods for human-AI interaction research by providing an accessible platform to facilitate and analyze participant conversations with GPT models.


---


[P3Nav: A Unified Framework for Embodied Navigation Integrating Perception, Planning, and Prediction](http://arxiv.org/abs/2503.18525v1)

- P3Nav (A Unified Framework for Embodied Navigation Integrating Perception, Planning, and Prediction): introduces a unified framework for embodied navigation integrating perception, planning, and prediction with Visual Encoder, Adaptive 3D-aware History Sampling, Large Language Model, Action Head, Answer Head, Tokenizer, and Multitask Collaboration strategy.
- P3Nav framework employs Multitask Collaboration strategy for joint training on navigation and embodied question answering tasks, enhancing navigation performance by leveraging perceptual and planning skills.
- Adaptive 3D-aware History Sampling strategy in P3Nav effectively utilizes historical observations by selecting non-overlapping RGB frames and position-enhanced features to reduce redundancy and improve efficiency.


---




[AgentDropout: Dynamic Agent Elimination for Token-Efficient and High-Performance LLM-Based Multi-Agent Collaboration](http://arxiv.org/abs/2503.18891v1)

- AgentDropout: introduces dynamic agent elimination, optimizing communication by removing redundant agents and links in multi-agent systems using Node Dropout, Edge Dropout, Communication Graph, Adjacency Matrix, Intra-Round Communication, Inter-Round Communication, and DAGSample.
- AgentDropout employs Node Dropout to remove less contributing agents and Edge Dropout to prune redundant communication edges within Communication Graph represented by Adjacency Matrix.
- The framework enhances token efficiency and task performance by dynamically adjusting communication topology through Intra-Round and Inter-Round Communication, finalized by DAGSample for acyclic graph generation.


---

[EconEvals: Benchmarks and Litmus Tests for LLM Agents in Unknown Environments](http://arxiv.org/abs/2503.18825v1)

- EconEvals: introduces benchmarks and litmus tests for evaluating LLM agents in unknown economic environments, featuring an LLM Agent (Core decision-maker using LLM) that interacts via Tool Use (Interaction via API calls) and a Notes Module (Persistent text memory) within various Economic Environments (Simulated scenarios with unknowns) to perform Benchmark Tasks (Capability measurement tasks) or Litmus Tests (Tendency measurement tasks), assessed by a Benchmark Score (Capability metric) or Litmus Score (Tendency metric).
- The framework assesses LLM agents on economic decision-making (procurement, scheduling, pricing) through multi-turn interactions where agents must learn environment specifications via exploration using tools; benchmarks measure capability, while litmus tests quantify behavioral tendencies in tradeoffs like efficiency vs. equality.
- Agents operate over multiple periods within stationary or non-stationary environments, using tools to gather information (e.g., __CODE_BLOCK_0__, __CODE_BLOCK_1__), manage memory (__CODE_BLOCK_2__, __CODE_BLOCK_3__), and submit actions (__CODE_BLOCK_4__, __CODE_BLOCK_5__, __CODE_BLOCK_6__), receiving feedback to inform future decisions.


---

[Defeating Prompt Injections by Design](http://arxiv.org/abs/2503.18813v1)

- CaMeL (CApabilities for MachinE Learning): introduces a defense against prompt injection by separating control and data flow using a Privileged LLM (Generates code from user query), a Quarantined LLM (Parses untrusted data), a CaMeL Interpreter (Executes code, enforces policies), Tools (External functions/APIs), Security Policies (Define allowed tool operations), Capabilities (Data provenance/permission tags), and a Data Flow Graph (Tracks value dependencies).
- The Privileged LLM generates Python code representing the user's intent from trusted queries, while the separate Quarantined LLM processes potentially untrusted data under the interpreter's strict control, preventing direct influence on tool execution flow.
- The CaMeL interpreter executes the generated code, maintains a data flow graph with capabilities tracking data provenance and permissions, and enforces security policies before tool execution to prevent data exfiltration or unauthorized actions.


---

[AgentSpec: Customizable Runtime Enforcement for Safe and Reliable LLM Agents](http://arxiv.org/abs/2503.18666v1)

- AGENTSPEC: introduces a domain-specific language and runtime framework for enforcing customizable safety constraints on LLM Agents (LLM planner/executor), intercepting planned actions based on Rules (constraint definitions) activated by a Trigger (rule activation event) corresponding to a monitored Event (monitored agent/env change), evaluating conditions via Check (condition evaluation) using Predicates (boolean condition function), and applying Enforce (intervention mechanism) actions like user_inspection (request user confirmation), llm_self_examine (trigger agent self-reflection), invoke_action (execute predefined action), or stop (terminate agent action) before interaction with Tools (external functions) or receiving Observation (feedback from environment/tools), ensuring alignment with safety policies defined by the User (initiates interaction) and recorded in the Trajectory (record of agent states/actions).
- The framework integrates with agent execution loops by hooking into decision points, monitoring Events such as state changes, specific actions (e.g., 'Transfer', 'PythonREPL', 'pour'), or task completion to apply user-defined Rules at runtime.
- This approach provides a modular and interpretable method for runtime safety enforcement in LLM agents operating across domains including code execution, embodied interaction, and autonomous driving, with demonstrated low overhead.


---

#### 23rd March 2025

[AgentRxiv: Towards Collaborative Autonomous Research](http://arxiv.org/abs/2503.18102v1)

- AgentRxiv: introduces a framework for collaborative autonomous research using LLM agents, comprising an AgentRxiv Server (Centralized preprint server for agent research) enabling multiple Agent Laboratory (Autonomous multi-agent research system) instances to share findings, guided by a Human Researcher (Provides initial guidance), where each lab performs Literature Review Phase (Retrieves and summarizes prior work), Experimentation Phase (Plans and executes experiments) with mle-solver (Module for ML code generation and repair), and Report Writing Phase (Synthesizes findings into reports) via paper-solver (Module for LaTeX report generation), coordinated by agents like PhD Student Agent (Agent role in multiple phases) and ML Engineer Agent (Agent role in data preparation code).
- The framework facilitates iterative improvement by allowing agent laboratories to upload reports to the AgentRxiv Server and retrieve prior work from peers, enabling cumulative knowledge building across independent agent systems.
- Each Agent Laboratory automates research stages using specialized agents (e.g., Postdoc, Professor) and tools (mle-solver, paper-solver), supporting both fully autonomous operation and a co-pilot mode with human checkpoints.


---

[Unseen from Seen: Rewriting Observation-Instruction Using Foundation Models for Augmenting Vision-Language Navigation](http://arxiv.org/abs/2503.18065v1)

- RAM (Rewriting-driven AugMentation): introduces a VLN data augmentation paradigm using Object-Enriched Observation Rewriting (generates diverse observations) involving a VLM (extracts scene descriptions), LLM (rewrites scene descriptions), T2IM (synthesizes panoramic observations), and Panorama-to-View (discretizes panoramas), plus Observation-Contrast Instruction Rewriting (creates aligned instructions) involving a VLM (extracts landmarks/descriptions) and LLM (rewrites instructions via contrast), trained with a Mixing-then-Focusing Training Mechanism (optimizes learning) including a Random Observation Cropping Scheme (augments data), where foundation models rewrite annotated data into unseen observation-instruction pairs without simulators or web-scraping.
- The framework first performs Object-Enriched Observation Rewriting by using a VLM to get scene descriptions, an LLM to enrich these descriptions with new objects, a T2IM to generate corresponding panoramas, and a Panorama-to-View algorithm for single views.
- Subsequently, Observation-Contrast Instruction Rewriting employs an LLM to generate new instructions by contrasting original landmarks/observations (via VLM) with rewritten observation descriptions (via VLM), enhancing data diversity for training the Embodied Agent using a two-stage strategy.


---

[Metaphor-based Jailbreaking Attacks on Text-to-Image Models](http://arxiv.org/abs/2503.17987v1)

- MJA (Metaphor-based Jailbreaking Attack): introduces a framework with Metaphor Agent, Context Agent, Prompt Agent, Example Retrieval Tool, Shared Memory, Observed Set, Candidate Set, Surrogate Model, Text Encoder, PCA, Gaussian Process Regression, Acquisition Strategy, and Query T2I model, where MJA aims to jailbreak text-to-image models using metaphor-based prompts.
- MJA framework employs multi-agent generation module to create diverse prompts and optimization module to efficiently select effective adversarial prompts.
- The framework balances attack effectiveness and query efficiency by leveraging metaphor and context in prompt generation and surrogate model-based optimization.


---

[WON: Establishing Best Practices for Korean Financial NLP](http://arxiv.org/abs/2503.17963v1)

- WON: introduces WON (Korean financial LLM), a transparent language model, evaluated using Benchmark (evaluation dataset) on Leaderboard (evaluation platform), utilizing Instruction Dataset (refined training data) derived from competition submissions.
- WON framework employs SFT (supervised fine-tuning) and DPO (direct preference optimization) training methods, with LLM-as-a-Judge (evaluation using LLM) for assessment and Deepseek-R1 (response generation model) for data processing.
- The framework aims to establish best practices for Korean financial NLP by releasing resources and insights gained from a large-scale evaluation and model development process.


---

[An Empirical Study of the Role of Incompleteness and Ambiguity in Interactions with Large Language Models](http://arxiv.org/abs/2503.17936v1)

- Framework name here: introduces a neural symbolic framework to model human and LLM agent interactions, focusing on Message-String, Turn, and Interaction, to define Incomplete Question and Ambiguous Question based on Oracle Agent responses within a Context of prior messages.
- This framework analyzes question-answer sequences to empirically study the role of question Incomplete Question and Ambiguous Question properties in multi-turn interactions using Human Agent and LLM Agent.
- The framework utilizes the Oracle Agent as a ground truth to categorize questions and assess the impact of Context on resolving Incomplete Question and Ambiguous Question during interactions.


---


[GeoBenchX: Benchmarking LLMs for Multistep Geospatial Tasks](http://arxiv.org/abs/2503.18129v1)

- GeoBenchX Framework: introduces benchmark for evaluating LLMs on geospatial tasks, with Task-solving agent, LLMs, Tools, Datasets, LLM-as-Judge evaluator agent, Reference solutions, and Benchmark set.
- GeoBenchX uses Task-solving agent equipped with Geospatial functions and commercial LLMs to solve Benchmark set of multi-step geospatial tasks using provided Datasets.
- LLM-as-Judge evaluator agent assesses Task-solving agent's performance by comparing generated solutions against Reference solutions within the GeoBenchX framework.


---

#### 22nd March 2025

[Metacognition in Content-Centric Computational Cognitive C4 Modeling](http://arxiv.org/abs/2503.17822v1)

- C4 Modeling (Content-Centric Computational Cognitive Modeling): introduces a framework for building metacognitive AI agents, with Knowledge Resources, Perception, Reasoning, Action, Explanation Module, Lifelong Learning, and LLM components for Language Generation and Learning Enhancement.
- C4 modeling emphasizes content-centric approach using semantically interpretable knowledge to enable agents with transparency, adaptability, reasoning, perception and action capabilities for human-AI teams.
- The framework integrates LLMs to improve language generation and learning efficiency, while maintaining focus on knowledge-based reasoning for trustworthy and explainable AI agents.


---

[Building Resource-Constrained Language Agents: A Korean Case Study on Chemical Toxicity Information](http://arxiv.org/abs/2503.17753v1)

- Tox-chat: introduces a Korean chemical toxicity information agent, utilizing LLM / SLM Agent, BM25 Search, Summary LLM, Keyword Search, Read General, QA Specific, QA LLM, Carcinogen Database, Toxic Dose Database, and Toxic Info Database for resource-constrained environments.
- Tox-chat employs hierarchical section search and scenario-based dialogue generation to reduce token consumption and distill tool-using capabilities from larger models.
- The framework demonstrates effective performance with a fine-tuned 8B parameter model, outperforming untuned models and baselines in database faithfulness and preference.


---

[A Survey on Mathematical Reasoning and Optimization with Large Language Models](http://arxiv.org/abs/2503.17726v1)

- Framework name here: introduces Instruction Learning, Tool-based Methods, Chain-of-Thought (CoT) Methods, and Advanced Chain-of-Thought (CoT) Methods for mathematical reasoning with Large Language Models.
- Instruction Learning refines models through structured tasks, while Tool-based Methods integrate external solvers, and Chain-of-Thought (CoT) and Advanced CoT Methods enhance reasoning via step-by-step logic and self-verification.
- These methods collectively aim to improve mathematical problem-solving capabilities of Large Language Models, addressing challenges in arithmetic, theorem proving and optimization tasks.


---


[CP-AgentNet: Autonomous and Explainable Communication Protocol Design Using Generative Agents](http://arxiv.org/abs/2503.17850v1)

- CP-AgentNet (Communication Protocol Agent Network): introduces a framework employing offline- and online-modules with strategy-, observer-, node- and programming-agents, LLM ranker, strategy-, episodic- and trajectory-memory, self-reflection and evaluation for autonomous communication protocol design.
- CP-AgentNet framework facilitates explainable protocol design by leveraging multi-agent role-play and progressive strategy augmentation to address limitations of deep reinforcement learning and handcrafted protocols.
- CP-AgentNet utilizes self-reflection and LLM ranker to enhance strategy refinement and decision consistency, enabling efficient adaptation to dynamic network environments without extensive online learning.


---

[RAIDER: Tool-Equipped Large Language Model Agent for Robotic Action Issue Detection, Explanation and Recovery](http://arxiv.org/abs/2503.17703v1)

- RAIDER (Tool-Equipped Large Language Model Agent for Robotic Action Issue Detection, Explanation and Recovery): introduces a novel agent architecture integrating System Prompt, LLM, Program Flow Manager, Tools, and Recovery for robotic action issue detection, explanation, and recovery.
- RAIDER framework utilizes "Ground, Ask&Answer, Issue" procedure, incorporating Ground, Ask, Answer, and Issue components within Program Flow Manager to dynamically generate and resolve context-aware precondition questions using Tool calls and Tool responses/warnings.
- This architecture achieves adaptable and efficient issue detection by leveraging LLM's reasoning with grounded Tools, enabling targeted information gathering and surpassing limitations of predefined models or full scene descriptions.


---

[Can LLMs Automate Fact-Checking Article Writing?](http://arxiv.org/abs/2503.17684v1)

- QRAFT (QRAFT): introduces a multi-agent framework for automatic fact-checking article generation, incorporating Planner (outline planning assistant), Writer (draft article composer), and Editor (draft review and refine) agents.
- QRAFT framework processes Evidence Set (input evidence documents) to generate Evidence Nuggets Set (extracted evidence points), utilizes Preferences (article structure guidelines) for Draft Outline (planned article structure), producing First Draft (initial article draft) and Improved Draft (refined article draft) through Question-Answering Interactions (conversational refinement process).
- QRAFT framework aims to mimic human fact-checkers' writing workflow, addressing the gap in existing automatic fact-checking pipelines by generating full fact-checking articles suitable for public dissemination.


---

[ComfyGPT: A Self-Optimizing Multi-Agent System for Comprehensive ComfyUI Workflow Generation](http://arxiv.org/abs/2503.17671v1)

- ComfyGPT (Comprehensive ComfyUI Workflow Generation with Generative Pre-trained Transformer): introduces a self-optimizing multi-agent system for ComfyUI workflow generation, comprising ReformatAgent, FlowAgent, RefineAgent, and ExecuteAgent.
- ComfyGPT leverages FlowDataset for training and FlowBench for evaluation, utilizing GRPO optimization and RAG to enhance workflow generation and refinement.
- ComfyGPT focuses on individual node links for improved precision and introduces FlowBench as a comprehensive benchmark for workflow generation assessment.


---

[OmniScience: A Domain-Specialized LLM for Scientific Reasoning and Discovery](http://arxiv.org/abs/2503.17604v1)

- OmniScience Framework: introduces a domain-specialized LLM for scientific reasoning, utilizing science literature corpus for domain adaptive pretraining, task and chat instructions for model alignment, and s1K reasoning dataset for reasoning distillation to create OmniScience Reasoning model from Foundation Model via OmniScience Base and OmniScience Chat.
- The framework employs a three-stage training pipeline: domain adaptive pretraining to instill scientific knowledge, supervised fine-tuning for instruction following, and reasoning-based knowledge distillation to enhance inferential capabilities.
- OmniScience Framework demonstrates a compute-efficient strategy for developing high-performing domain-specific models by combining pretraining, alignment and distillation techniques, achieving state-of-the-art results in scientific reasoning tasks.


---

[Autonomous Radiotherapy Treatment Planning Using DOLA: A Privacy-Preserving, LLM-Based Optimization Agent](http://arxiv.org/abs/2503.17553v1)

- DOLA (Dose Optimization Language Agent): introduces privacy-preserving LLM agent for autonomous radiotherapy planning, comprising Model Service, Optimization Agent, Working Memory, TPS Interface, and LLaMa3.1 LLM.
- DOLA framework integrates RAG and RL with chain-of-thought prompting within local infrastructure to optimize radiotherapy plans while maintaining patient privacy.
- The system architecture enables iterative dose optimization using LLM for decision-making and reasoning within a secure, locally hosted environment, enhancing plan quality and efficiency.


---





#### 21st March 2025

[CVE-Bench: A Benchmark for AI Agents' Ability to Exploit Real-World Web Application Vulnerabilities](http://arxiv.org/abs/2503.17332v1)

- CVE-Bench: introduces CVE-Bench with LLM Agents, Target Containers, Evaluation, and Results, which is a cybersecurity benchmark for evaluating AI agents exploiting web vulnerabilities.
- CVE-Bench: framework offers a sandbox environment featuring isolated containers hosting web applications and an automated evaluation system to assess attack success.
- CVE-Bench: benchmark addresses limitations of existing cybersecurity benchmarks by providing comprehensive real-world vulnerability coverage and diverse attack types.


---

[LLM+MAP: Bimanual Robot Task Planning using Large Language Models and Planning Domain Definition Language](http://arxiv.org/abs/2503.17309v1)

- LLM+MAP (LLM + Multi-Agent Planning with PDDL): introduces a bimanual robot task planning framework with Visual Detection, Scene Spatial Description, Bimanual Domain Knowledge, LLM, PDDL Problem + Domain, Symbolic Planning, Partial-order Plan, Action Parser and Execution.
- LLM+MAP framework utilizes LLM to convert natural language task descriptions and scene information into PDDL, enabling symbolic planners to generate partial-order plans for efficient bimanual robot control.
- The framework integrates LLM reasoning with multi-agent planning for effective spatial and temporal coordination in complex, long-horizon bimanual manipulation tasks, achieving logical correctness and higher efficiency.


---

[When Words Outperform Vision: VLMs Can Self-Improve Via Text-Only Training For Human-Centered Decision Making](http://arxiv.org/abs/2503.16965v1)

- Text-Only Training for VLM Enhancement: introduces text-only training approach, with Situation, Question, Answer, Text-Only Input, Multimodal Input, VLM, Answer Prediction, Text-Only Training for VLM Enhancement, and Transfer to Multimodal Inference components, where text-only training enhances visual language model decision-making for human-centered tasks.
- This framework improves visual language models by text-only training using synthesized textual data, enabling enhanced multimodal inference capabilities without relying on image-text paired data.
- Text-only training provides efficient and scalable method to enhance visual language models' reasoning and decision-making for complex human-centered scenarios.


---

[ETVA: Evaluation of Text-to-Video Alignment via Fine-grained Question Generation and Answering](https://eftv-eval.github.io/etva-eval)

- ETVA (Evaluation of Text-to-Video Alignment): introduces a framework with Element Extractor, Graph Builder, Graph Traverser, Question Generation, Knowledge Augmentation, Multi-Stage Reasoning, Question Answering, External Knowledge, Multimodal CoT, Video Reflection, General Reflection, Conclusion Stage, ETVA Score, Generated Video, Generated Questions, Scene Graph, and Core Elements for evaluating text-to-video alignment through fine-grained question generation and answering.
- ETVA framework employs a multi-agent system for atomic question generation from text prompts and a knowledge-augmented multi-stage reasoning process for question answering using video LLMs.
- ETVA demonstrates improved correlation with human judgment compared to existing metrics by systematically evaluating video-text relationships through structured question generation and knowledge integration.


---

[WHEN DEBATE FAILS: BIAS REINFORCEMENT IN LARGE LANGUAGE MODELS](http://arxiv.org/abs/2503.16814v1)

- DReaMAD (Diverse Reasoning via Multi-Agent Debate with Refined Prompt): introduces Strategic Prior Knowledge Elicitation, Perspective Diversification, and Multi-Agent Debate to improve LLM reasoning.
- DReaMAD refines prior knowledge and ensures diverse perspectives by using Game Situation Reinterpretation, General Strategy Formulation, and structured debate.
- DReaMAD enhances LLMs' strategic reasoning by structuring knowledge retrieval and diversifying input perspectives to mitigate bias and improve decision-making.


---

[A-IDE : AGENT-INTEGRATED DENOISING EXPERTS](http://arxiv.org/abs/2503.16780v1)

- A-IDE (Agent-Integrated Denoising Experts): introduces a denoising framework integrating BiomedCLIP for semantic analysis, semantic similarities for probability distribution, an LLM Agent for decision-making, specialized RED-CNN models (Model 0, Model 1, Model 2) for denoising, and RMSE, PSNR, SSIM for evaluation.
- A-IDE framework utilizes BiomedCLIP to analyze CT images and employs an LLM agent to dynamically select among specialized RED-CNN models based on anatomical context for improved denoising performance.
- The agent-driven approach of A-IDE eliminates manual intervention and enhances denoising performance across diverse anatomical regions by leveraging specialized models.


---

[Bayesian Teaching Enables Probabilistic Reasoning in Large Language Models](http://arxiv.org/abs/2503.17523v1)

- Bayesian Teaching: introduces User, LLM (Large Language Model), Bayesian Assistant, Supervised Fine-tuning, Flight Recommendation, Hotel Recommendation, Web Shopping, User Preferences, and Beliefs to teach LLMs probabilistic reasoning for user interaction tasks.
- Bayesian Teaching framework employs Supervised Fine-tuning to train LLMs by mimicking Bayesian Assistant for inferring User Preferences and updating Beliefs in Flight Recommendation and generalizing to Hotel Recommendation and Web Shopping.
- The framework enhances LLMs' probabilistic reasoning in interactive settings, enabling generalization to novel tasks beyond the training domain.


---


#### 20th March 2025

[Towards Agentic Recommender Systems in the Era of Multimodal Large Language Models](http://arxiv.org/abs/2503.16734v1)

- LLM-ARS (LLM-based Agentic RS): introduces a framework with LLM-Agent, Initialization, Planning, Execution, Reflection, Query, Ranker, Tool Using, and Memory Module components for agentic recommendation systems.
- This framework utilizes an LLM-Agent as the central decision-making unit, incorporating modules for planning, execution, reflection, and memory to enhance recommendation adaptability and personalization.
- The architecture emphasizes autonomous decision-making and continuous self-evolution by integrating external tools and reflecting on past interactions to optimize future recommendations.


---

[Survey on Evaluation of LLM-based Agents](http://arxiv.org/abs/2503.16416v1)

- Agent Evaluation: introduces a survey framework for evaluating LLM-based agents, with Agent Capabilities Evaluation-component, Planning and Multi-Step Reasoning-component, Function Calling & Tool Use-component, Self-Reflection-component, Memory-component, Application-Specific Agent Evaluation-component, Web Agents-component, Software Engineering Agents-component, Scientific Agents-component, Conversational Agents-component, Generalist Agents Evaluation-component, Frameworks for Agent Evaluation-component, Development Frameworks-component, Gym-like Environments-component, Discussion-component, Current Trends-component, and Emergent Directions-component.
- Agent Evaluation framework categorizes evaluation methodologies based on agent capabilities, application domains, general skills, and development frameworks, providing a structured overview of the field.
- The framework highlights the shift towards realistic evaluations, identifies gaps in current methods like cost-efficiency and safety, and proposes future directions for agent evaluation research.


---


[Issue2Test: Generating Reproducing Test Cases from Issue Reports](http://arxiv.org/abs/2503.16320v1)

- ISSUE2TEST (Issue Reproducing Test): introduces automated technique for generating issue-reproducing test cases utilizing root cause analysis, meta prompting, related files search, test generator, linter, test refiner - error fixing, run tests, error categorization, assertion match, and rank components.
- ISSUE2TEST iteratively refines test cases through runtime feedback and error categorization to ensure generated tests accurately capture and reproduce the reported issue.
- This approach enhances automated debugging and program repair workflows by providing executable test cases directly derived from issue descriptions, improving software reliability.


---

[GREENIQ: A DEEP SEARCH PLATFORM FOR COMPREHENSIVE CARBON MARKET ANALYSIS AND AUTOMATED REPORT GENERATION](http://arxiv.org/abs/2503.16041v2)

- GreenIQ: introduces deep search platform with Main Researcher, Report Writing, Final Reviewer, Data Visualization, and Translator Agents for carbon market analysis and automated report generation.
- GreenIQ leverages multi-agent architecture powered by Large Language Models to automate end-to-end workflow from data collection to multilingual reporting for carbon market intelligence.
- GreenIQ enhances efficiency, accuracy, and scalability in carbon market research by integrating specialized agents for comprehensive analysis and validated reporting.



---

[AutoRedTeamer: Autonomous Red Teaming with Lifelong Attack Integration](http://arxiv.org/abs/2503.15754v1)

- AutoRedTeamer: introduces a framework for automated red teaming, with Risk Analyzer (decomposes user inputs), Seed Prompt Generator (creates diverse test cases), Strategy Designer (selects attack combinations), Attack Memory (tracks attack performance), Attack Library (stores attack methods), Attack Judge (evaluates output harmfulness), Relevance Check (ensures test case relevance), Red-Teaming Agent (orchestrates evaluation), Target Model (LLM under evaluation), Validation Set (validates attack effectiveness), Attack Evaluation (assesses attack results), Initial Attack Library (starting attack methods), Attack Proposer (discovers new attacks), Attack Proposals (suggested new attacks), Attack Designer (implements attack proposals), Attack Implementation (concrete attack code), and Attack Strategy Proposer Agent (discovers and implements attacks).
- AutoRedTeamer framework uses a dual-agent system comprising a red teaming agent for evaluation and a strategy proposer agent for discovering and integrating new attack methods.
- The framework incorporates a memory-guided attack selection to learn from past attack attempts and refine strategies for improved red teaming effectiveness and adaptability to new vulnerabilities.


---

[Automatic Generation of Safety-compliant Linear Temporal Logic via Large Language Model: A Self-supervised Framework](http://arxiv.org/abs/2503.15840v1)

- AutoSafeLTL (Automatic Safety-compliant Linear Temporal Logic): introduces a self-supervised framework for generating safety-compliant Linear Temporal Logic (LTL) specifications, incorporating Environmental Information & Desired Task, LTL Extraction, Safety Restrictions, Base Rules, Automated Verification, and producing Safety-compliant LTL.
- The framework employs Automated Verification with Syntactic Check (Agent LLM1, AP Matching, Operator Matching) and Semantic Check (User LLM, Counterexample Analysis & Guidance, Agent LLM2) to ensure generated LTL adheres to predefined safety rules.
- AutoSafeLTL framework leverages two Agent LLMs and User LLM within a pipeline to refine LTL generation through feedback and counterexample analysis, achieving safety compliance for cyber-physical systems.


---


[DeepPsy-Agent: A Stage-Aware and Deep-Thinking Emotional Support Agent System](http://arxiv.org/abs/2503.15876v1)

- DeepPsy-Agent: introduces a psychological support system with deeppsy-chat dialogue model for response generation, stage awareness mechanism for context perception, deep thinking for multi-source reasoning, real-time stage transition detection model for signal capture, and state information update module for dynamic state tracking.
- DeepPsy-Agent combines psychological theory and deep learning to achieve dynamic stage awareness and enhanced reasoning capabilities in emotional support conversations.
- The system integrates stage-awareness and deep-thinking to improve dialogue management and reasoning, addressing limitations of traditional emotional support systems.


---


[Advancing Mobile GUI Agents: A Verifier-Driven Approach to Practical Deployment](http://arxiv.org/abs/2503.15937v2)

- V-DROID (Verifier-Driven Robot for Interface Operations on Devices): introduces a verifier-driven mobile agent framework with Action Extractor, Verification Prompts, Verifier, Action Completion, and Working Memory components.
- V-DROID decouples action decision-making into action extraction and verification, utilizing Discretized Action Space Construction and Prefilling-only Workflow for efficiency.
- Pair-wise Progress Preference Training enhances Verifier's decision-making, and Scalable Human-Agent Joint Annotation Scheme facilitates data collection for V-DROID.


---

[The Lighthouse of Language: Enhancing LLM Agents via Critique-Guided Improvement](http://arxiv.org/abs/2503.16024v1)

- CGI (Critique-Guided Improvement): introduces a two-player framework enhancing LLM agents, featuring an Actor Model(Generates actions, refines based on critique), a Critic Model(Generates structured critiques), an Action Buffer(Stores candidate actions), Critique(Structured feedback with assessment, revision), and a Refined Action(Final action post-critique), operating within an Environment(Interactive task setting) informed by History(Past interactions sequence) and refined using Training Data(Datasets for model fine-tuning), where the critic provides detailed natural language feedback to guide the actor's iterative improvement.
- The framework comprises two stages: Critique Generation, where the Critic Model is trained to produce structured assessments and revisions based on expert examples, and Action Refinement, where the Actor Model is iteratively fine-tuned to utilize these critiques effectively alongside successful trajectory data.
- This approach uses a dedicated critic for explicit, structured verbal feedback (assessing contribution, feasibility, efficiency, and suggesting revisions) and trains the actor to integrate this guidance, enhancing decision-making and exploration compared to methods relying solely on numerical rewards or self-correction.


---

[Depth Matters: Multimodal RGB-D Perception for Robust Autonomous Agents](https://arxiv.org/abs/2503.16711)

- RGB-D Fusion Architectures: introduces model architectures for autonomous driving, integrating RGB and depth data through Feature Extractor, Model Architecture, RNN Options and Offset Calculation Options components.
- RGB-D Fusion Architectures: systematically compares early and late fusion strategies alongside depth-aware deformable convolution and geometric offset computation within Model Architecture for enhanced feature extraction.
- RGB-D Fusion Architectures: evaluates recurrent neural networks like LSTM, LTC, CfC, and LRC within RNN Options to benchmark lightweight controllers for real-time, robust autonomous agent steering command prediction.


---


#### 19th March 2025

[Envisioning an AI-Enhanced Mental Health Ecosystem](http://arxiv.org/abs/2503.14883v1)

- AI-Enhanced Mental Health Ecosystem: introduces a multifaceted AI vision for mental health support, integrating AI-Simulated Client, Peer/Counsellor/Therapist, -Generated Suggestions, Decision-Support/Evaluation, Self-Help/Companionship, Proactive Monitoring, and Embedded/Ubiquitous Companion.
- This ecosystem aims to enhance mental health care through proactive, responsive, adaptive AI paradigms complementing human interventions for growing global mental health crisis.
- The framework emphasizes ethical AI deployment, user-centered design, and continuous evaluation ensuring supportive collaboration in mental health with human connection and cultural sensitivity.


---


[ChatStitch: Visualizing Through Structures via Surround-View Unsupervised Deep Image Stitching with Collaborative LLM-Agents](http://arxiv.org/abs/2503.14948v1)

- ChatStitch: introduces a collaborative perception system, with Task Management Agent, Background Stitching Agent, Pose Measurement Agent, Perspective Measurement Agent, 3D Asset Management, 3D Asset View Change, Foreground Rendering, SV-UDIS, Language Input, Multi-views Input, Composed Images Output, Data, and Work flow, for visualizing obscured information via natural language.
- ChatStitch employs multi-agent framework utilizing Large Language Models to process natural language commands and perform surround-view unsupervised deep image stitching.
- The system achieves intuitive human perception by integrating language commands with external digital assets and generating photorealistic collaborative perception outcomes.


---


[SPADE: Systematic Prompt Framework for Automated Dialogue Expansion in Machine-Generated Text Detection](http://arxiv.org/abs/2503.15044v1)

- SPADE (Systematic Prompt Framework for Automated Dialogue Expansion): introduces five data augmentation frameworks using structured prompting for synthetic dialogue generation, including Partial-Chatbot Data Augmentation (Generates partially synthetic dialogues) with Missing Sentence Completion (Fills system utterances) and Next Response Generation (Generates user utterances), and Full-Chatbot Data Augmentation (Generates fully synthetic dialogues) with Goal-to-Dialogue (Generates dialogue from goal), Paraphrase Dialogue (Rewrites utterances iteratively), and End-to-End Conversation (Simulates user-system interaction), utilizing components like LLM (Generates text), Goal (User task objective), Dialogue Input (Source conversation data), and Instructions (LLM task guidance) to address data scarcity for Machine-Generated Text detection.
- These training-free frameworks generate 14 dialogue datasets by manipulating human dialogues or simulating conversations with LLMs based on user goals and specific prompts.
- The study benchmarks these datasets against detection models, showing improved generalization with mixed datasets and analyzing detection accuracy based on chat history length in simulated online settings.


---

[VIPER: Visual Perception and Explainable Reasoning for Sequential Decision-Making](http://arxiv.org/abs/2503.15108v1)

- VIPER (Visual Perception and Explainable Reasoning): introduces multimodal instruction-based planning framework integrating VLM-based perception with LLM-based reasoning, including Perception- and Reasoning-Modules.
- VIPER uses modular pipeline where Perception Module with frozen VLM generates textual descriptions of image observations processed by Reasoning Module with LLM policy to predict actions.
- VIPER enhances explainability by leveraging text as intermediate representation enabling fine-grained analysis of Perception- and Reasoning-Modules for decision-making mechanisms.


---



[LogiAgent: Automated Logical Testing for REST Systems with LLM-Based Multi-Agents](http://arxiv.org/abs/2503.15079v1)

- LOGIAGENT: introduces an LLM-driven multi-agent framework for logical testing of REST systems, with a Test Scenario Generator (Creates test scenarios), API Request Executor (Constructs and executes API requests), API Response Validator (Validates API responses using oracles), Scenario Scheduler (Manages scenario execution flow), Execution Memory (Stores historical execution data), API Relationship Graph (Models API relationships), OpenAPI Specification (Input API documentation), and Tested System (Target system under test), where agents collaboratively generate, execute, and validate API test scenarios focusing on business logic.
- The framework utilizes logical oracles derived from API documentation, scenario context, and LLM knowledge to assess responses beyond status codes, identifying logical inconsistencies.
- Execution Memory stores successful parameter values and failure reflections, enhancing contextual consistency and guiding future test generation by the API Request Executor and Test Scenario Generator.


---

[Aligning Crowd-sourced Human Feedback for Reinforcement Learning on Code Generation by Large Language Models](http://arxiv.org/abs/2503.15129v1)

- cRLHF (crowd-sourced Reinforcement Learning with Human Feedback): introduces a novel framework for aligning crowd-sourced human feedback using Prompt (input description), Language Model (generates code), Output (code output), Multiple Annotators (feedback from many users), Annotated Output (code with human labels), cRLHF (proposed framework), and Aligned Output (improved code output).
- cRLHF (crowd-sourced Reinforcement Learning with Human Feedback) framework, depicted in figures, contrasts traditional RLHF by incorporating Multiple Annotators (feedback from many users) to produce Annotated Output (code with human labels) and Aligned Output (improved code output), replacing single Annotator (evaluates code) and Ranked Output (ordered code by rank) feeding into Reward Model (learns reward function) of traditional RLHF.
- The framework, utilizing Problem Description (task specification), Initial LLM (starting LLM), Tuned LLM (fine-tuned LLM), Generated Outputs (sampled code solutions), RL Update (policy adjustment), and Correction Rate (performance score), aims to improve code generation quality by leveraging diverse human feedback and Bayesian optimization without explicit reward model training.


---

[Exploring Large Language Models for Word Games: Who is the Spy?](http://arxiv.org/abs/2503.15235v1)

- CoT-based scheduling framework (Chain-of-Thought based scheduling framework): introduces Judger, Player, and COT or TOT components to enable LLMs in word games through rule description, role and keyword assignments, compliance checks, keyword descriptions, reasoning, voting and player elimination.
- The framework utilizes Judger to manage game flow and Player agents employing COT or TOT for strategic actions like describing keywords, reasoning about roles, and voting to identify the spy.
- This approach aims to enhance LLM performance in social deduction games by structuring the interaction and decision-making process through distinct components and a chain-of-thought reasoning mechanism.


---


[MAMM-REFINE: A Recipe for Improving Faithfulness in Generation with Multi-Agent Collaboration](http://arxiv.org/abs/2503.15272v1)

- MAMM-REFINE (Multi-Agent Multi-Model Refinement): introduces DETECT, CRITIQUE, and REFINE subtasks within a multi-agent debate framework to improve generation faithfulness.
- MAMM-REFINE framework employs RERANK and GENERATE approaches for CRITIQUE and REFINE subtasks, enhancing performance through multi-agent and multi-model collaboration.
- The framework demonstrates effectiveness in summarization and question answering by leveraging diverse LLMs and iterative refinement to reduce factual inconsistencies.


---


[SWEET-RL: Training Multi-Turn LLM Agents on Collaborative Reasoning Tasks](http://arxiv.org/abs/2503.15478v1)

- SWEET-RL (RL with Step-WisE Evaluation from Training-time information): introduces a reinforcement learning framework that uses Training-Time History Information and Bradley-Terry objective to train a Critic, which provides rewards for Policy from RLHF optimization based on Chosen/Rejected trajectories and actions.
- SWEET-RL leverages asymmetric information access for Critic and Actor, where Critic uses additional training-time information inaccessible to Actor, to improve credit assignment in multi-turn collaborative tasks.
- This approach addresses limitations of standard RLHF methods in multi-turn settings by providing step-level rewards and improving generalization in complex reasoning tasks.


---

[Safety Aware Task Planning via Large Language Models in Robotics](http://arxiv.org/abs/2503.15707v1)

- SAFER (Safety-Aware Framework for Execution in Robotics): introduces a multi-LLM framework composed of Planning-, Execution-, Feedback-Modules and LLM-as-a-Judge to enhance safety in LLM-driven task planning.
- SAFER framework utilizes Task Planning LLM to generate plans, Safety Planning LLM to audit plans, Execution Module with Robot Agents to deploy tasks, Feedback Module to process outcomes and LLM-as-a-Judge to evaluate safety.
- The framework ensures safety checks throughout planning and execution, integrating Control Barrier Functions for safety guarantees at the robotic control policy level.


---

[Reinforcement Learning Environment with LLM-Controlled Adversary in D&D 5th Edition Combat](http://arxiv.org/abs/2503.15726v1)

- RL-LLM Adversary Framework (Reinforcement Learning with LLM-Controlled Adversary Framework): introduces reinforcement learning environment using D&D 5E combat scenarios, integrating LLM Agent-controlled adversary, and DQN-based RL Agent for strategic AI development within a simulated Environment.
- This framework employs LLM Agent for strategic decision-making and RL Agent for adaptive learning, utilizing DQN Network composed of Input map, Conv2d layers, Flatten, Embedding layers, Concatenate, Linear layers, and Output - Q-value for value estimation.
- The framework facilitates strategic decision-making research in complex rule-based games, demonstrating that LLM-trained RL Agents outperform rule-based and LLM-controlled adversaries, highlighting the potential of LLMs to enhance strategic depth and adaptability in AI systems.


---


#### 18th of March 2025


[MANTRA: Enhancing Automated Method-Level Refactoring with Contextual RAG and Multi-Agent LLM Collaboration](http://arxiv.org/abs/2503.14340v1)

- MANTRA (Multi-AgeNT Code RefAactoring): introduces a comprehensive LLM agent-based framework for automated method-level refactoring, with Context-Aware Retrieval-Augmented Generation (RAG) constructing searchable Database of Pure Refactoring Code Examples using Code Description and Caller-Callee Relationships Incorporation, coordinated Multi-Agent Refactored Code Generation employing Developer Agent with Static Code Analysis Tool for RAG-based Refactoring Examples Retrieval and Chain-of-Thought Refactoring Code Generation, and Reviewer Agent for Refactoring Verification, Code Style Consistency Analysis and Compilation and Test Verification, alongside Self-Repair Using Verbal Reinforcement Learning with Repair Agent and Reflexion Framework through Initial Analysis, Self-Reflection, Planning and Acting phases.
- MANTRA framework emulates human refactoring process by integrating retrieval-augmented generation, multi-agent collaboration, and verbal reinforcement learning to improve code correctness and readability for method-level refactoring tasks.
- MANTRA significantly enhances automated refactoring success rate and code quality compared to baseline LLM and existing LLM-powered tools, demonstrating practical advantages for advancing software refactoring automation.


---



[MDTeamGPT: A Self-Evolving LLM-based Multi-Agent Framework for Multi-Disciplinary Team Medical Consultation](http://arxiv.org/abs/2503.13856v1)

- MDTeamGPT (Multi-Disciplinary Team Generative Pre-trained Transformer): introduces a multi-agent framework for medical consultation, incorporating Primary Care Doctor, Specialist Doctor Agents, Lead Physician, Chain-of-Thought Reviewer, Safety and Ethics Reviewer, Correct Answer Knowledge Base, Chain-of-Thought Knowledge Base, Historical Shared Pool, Shared Vector Database, and Patient.
- This framework utilizes consensus aggregation and residual discussion structure to enhance diagnostic accuracy and reduce cognitive burden in multi-round, multi-agent medical consultations.
- MDTeamGPT employs knowledge bases to accumulate consultation experience, enabling self-evolution and improved generalization in medical diagnosis tasks.


---


[MoK-RAG: Mixture of Knowledge Paths Enhanced Retrieval-Augmented Generation for Embodied AI Environments](http://arxiv.org/abs/2503.13882v1)

- MoK-RAG (Mixture of Knowledge Paths Enhanced Retrieval-Augmented Generation): introduces multi-source retrieval framework with Splitting-, Constraint- and Generation-Modules to address cognitive-algorithmic discrepancy of single-source knowledge retrieval in current Retrieval-Augmented Generation systems.
- MoK-RAG framework partitions knowledge base into multiple specialized paths via Splitting Module, organizes retrieved knowledge using Constraint Module, and generates response through Generation Module, enhancing contextual relevance and adaptability.
- MoK-RAG framework mitigates "Reply Missing" problem, which refers to incomplete or lacking key details in generated responses due to single-source knowledge retrieval, by enabling simultaneous retrieval from multiple knowledge paths.


---


[Gricean Norms as a Basis for Effective Collaboration](http://arxiv.org/abs/2503.14484v1)

- Normative Framework: introduces Lamoids, GPT-4-powered agents, integrating Gricean Norms, Inference Norm, Cognitive Frameworks, and Fs-CoT Prompting for effective human-AI collaboration through Response Generation.
- Normative Framework enhances agent's pragmatic reasoning by incorporating Gricean maxims and cognitive theories into Fs-CoT prompting to interpret unclear instructions and generate context-aware responses.
- By adhering to Gricean and Inference norms within the framework, Lamoids achieve improved task accuracy and clearer communication in collaborative grid world environment.


---

[ENVBENCH: A BENCHMARK FOR AUTOMATED ENVIRONMENT SETUP](http://arxiv.org/abs/2503.14443v1)

- ENVBENCH: introduces a benchmark for automated environment setup, encompassing Repository, Environment Setup, Language Model, AI Agent, Generated Script, Evaluation Results, Evaluation Suite, and Metrics components.
- ENVBENCH evaluates environment setup approaches by generating shell scripts and verifying environment configuration through static analysis and compilation checks.
- This benchmark facilitates systematic assessment of environment setup strategies, addressing limitations of existing datasets and evaluation methods in the software engineering domain.


---

[PLAY2PROMPT: Zero-shot Tool Instruction Optimization for LLM Agents via Tool Play](http://arxiv.org/abs/2503.14432v1)

- PLAY2PROMPT (Zero-shot Tool Instruction Optimization for LLM Agents via Tool Play): introduces automated framework for zero-shot tool learning, with tool-use example generation, tool documentation optimization, and task LLM components.
- PLAY2PROMPT employs iterative beam search with sample proposal, sample evaluation, and down-sampling to refine documentation and generate examples through tool play.
- This approach enhances LLM tool utilization by creating high-quality documentation and demonstrations without labeled data or manual effort.


---

[DARS: Dynamic Action Re-Sampling to Enhance Coding Agent Performance by Adaptive Tree Traversal](http://arxiv.org/abs/2503.14269v1)

- DARS (Dynamic Action Re-Sampling): introduces an inference-time compute scaling method for coding agents, incorporating Generate, Reproduction, Localization, Bug Fixing, Evaluation, and Expansion components with Generator LLM, Reviewer LLM, and Selector LLM, to enhance performance by dynamically re-sampling actions.
- DARS framework utilizes Expansion mechanism with Generator LLM for action candidates, Reviewer LLM for patch scoring based on Score Rubrics, and Selector LLM for best patch selection, processing Input and Feedback to improve coding agent's decision-making.
- This approach aims to address limitations of sequential, multi-solution, and tree search methods by selectively branching at key decision points and employing depth-first strategy, achieving state-of-the-art performance on SWE-Bench Lite benchmark.


---

[Conversational Agents as Catalysts for Critical Thinking: Challenging Social Influence in Group Decision-making](https://doi.org/10.1145/3706599.3719792)

- System Overview: introduces chat interface, server, and database components, with Summary Agent, Database, AI-message History, Conversation Agent, AI Duplicate Checker, and Cosine-similarity, where system processes direct and public chat messages through agents.
- System architecture includes Summary Agent for public opinion analysis, Conversation Agent for generating contextual counterarguments, and AI Duplicate Checker for message novelty.
- AI Duplicate Checker uses cosine-similarity to ensure novelty of generated messages compared to AI-message History stored in Database.


---

[Empowering LLMs in Decision Games Through Algorithmic Data Synthesis](http://arxiv.org/abs/2503.13980v1)

- Mastermind-Dou Framework: introduces a three-stage reasoning process with Training Dataset, Opponent, Step-by-step Output, Possible Action Prediction, Opponent Strategy Prediction, and Final Action Selection to enable LLMs to play Doudizhu game.
- Mastermind-Dou framework uses Possible Action Prediction to predict likely moves, Opponent Strategy Prediction to anticipate adversary actions, and Final Action Selection to choose the optimal game action.
- The framework enhances LLMs' decision-making in imperfect information games by decomposing the reasoning into sequential prediction and selection stages.


---

[FlexVLN: Flexible Adaptation for Diverse Vision-and-Language Navigation Tasks](http://arxiv.org/abs/2503.13966v1)

- FlexVLN (Flexible Vision-and-Language Navigation): introduces a hierarchical approach for vision-language navigation, integrating Environmental Perception, LLM Planner, MLLM Verification, Instruction Follower, and Object Localization components.
- FlexVLN employs LLM Planner for high-level planning and guidance generation, Instruction Follower for low-level execution, and MLLM Verification to ensure guidance feasibility, enhancing generalization across diverse VLN tasks.
- The framework utilizes Environmental Perception to understand surroundings and Object Localization to identify the target, achieving effective navigation through a combination of LLM planning and supervised learning execution.


---

[MDocAgent: A Multi-Modal Multi-Agent Framework for Document Understanding](http://arxiv.org/abs/2503.13964v1)

- MDocAgent (Multi-Modal Multi-Agent Framework for Document Understanding): introduces a novel RAG and multi-agent framework with text-based RAG, image-based RAG, general agent, critical agent, text agent, image agent, and summarizing agent.
- MDocAgent framework addresses DocQA challenges by combining text and image RAG with specialized agents for refined processing and critical information extraction.
- This approach enables improved DocQA performance through collaborative multi-agent architecture and cross-modal understanding of long documents.


---

[Towards a Barrier-free GeoQA Portal: Natural Language Interaction with Geospatial Data Using Multi-Agent LLMs and Semantic Search](http://arxiv.org/abs/2503.14251v1)

- GeoQA Portal: introduces a multi-agent LLM framework with Router, Analyzer, Explainer, Visualizer, Mission Planner, Relation Analyzer, Region Selector, Entity Finder, and Geo Filter for natural language interaction with geospatial data.
- GeoQA Portal decomposes user queries, assigns subtasks to specialized LLM agents, and presents task plans and visualizations to enhance transparency and user engagement.
- The framework of GeoQA Portal supports flexible data inputs and semantic search, aiming to bridge the gap between complex GIS workflows and public data accessibility for non-expert users.


---

[Retrieval-Augmented Simulacra: Generative Agents for Up-to-date and Knowledge-Adaptive Simulations](http://arxiv.org/abs/2503.14620v1)

- Retrieval-Augmented Simulacra: introduces system simulating social network service interactions with User Persona Generation LLM Module, RAG Module, and Post / Reply Generation LLM Module.
- System uses Community Rule, Community Goal, and Samples of User Personas to generate User Persona-based Posts / Replies.
- Framework simulates realistic social network interactions using web information retrieval and persona-based content generation.


---

[Personalized Attacks of Social Engineering in Multi-turn Conversations - LLM Agents for Simulation and Detection](http://arxiv.org/abs/2503.15552v1)

- SE-VSim (Social Engineering - Victim Simulation): introduces a dual-agent framework with Attacker Agent, Victim Agent, and Conversation Generation Pipeline to simulate social engineering attack mechanisms in multi-turn conversations.
- arxiv_paper_framework_name: models victim agents with varying personality traits and attacker agents with predefined attack goals to generate realistic chat-based social engineering scenarios.
- arxiv_paper_framework_name: facilitates the study of victim vulnerabilities and attacker strategies by generating a dataset of simulated conversations for personalized social engineering defense.


---


[TestForge: Feedback-Driven, Agentic Test Suite Generation](http://arxiv.org/abs/2503.14713v1)

- TestForge: introduces agentic framework for cost-effective test suite generation with Initial Test Generator, LLM Agent, Agent Actions, Environment Feedback, Test Refinement Loop, Code Repository Context, and Generated Test Suite.
- TestForge reframes LLM-based test generation as iterative process, refining initial zero-shot tests using execution feedback and coverage reports to enhance test quality and coverage.
- The framework leverages detailed execution feedback and operates at file-level to improve cost-efficiency and generate high-quality, readable test suites for complex real-world code.


---


#### 17th March 2025

[When Should We Orchestrate Multiple Agents?](https://arxiv.org/abs/2503.13577)

- Orchestration Framework: introduces a method to dynamically select the optimal agent from a set of Agents (Perform tasks, human/AI/hybrid) for tasks arriving via an Input Data Stream (Sequential task inputs), considering performance across different Regions (Data distribution partitions), costs via a Cost Estimator (Estimates agent cost per region), and feasibility via Constraints (Agent feasibility rules), using a Correctness Estimator (Estimates agent accuracy per region), Region Probability Estimator (Estimates region likelihood), and Total Empirical Utility (Cost-adjusted performance metric) for selection by the Orchestrator (Selects agent based on utility).
- The framework utilizes online probabilistic inference to update agent correctness and region probabilities, calculates an Appropriateness Metric (Measures orchestration value) to determine when orchestration is beneficial, and is applied to simulations including resolving Rogers' Paradox by selecting Learning Strategies (Choices in Rogers' Paradox simulation).
- A user study involving a User (Human decision-maker in study) choosing between task completion, outsourcing to an AI Agent (LLM agent in study) or a Human Agent (Agent representing human performance) demonstrates improved performance with constrained orchestration compared to baseline scenarios where users act as poor orchestrators.


---


[Why Do Multi-Agent LLM Systems Fail?](http://arxiv.org/abs/2503.13657v1)

- MASFT (Multi-Agent System Failure Taxonomy): introduces taxonomy of failure modes in multi-agent systems, categorizing them into Pre Execution Failure Modes, Execution Failure Modes, Post Execution Failure Modes, and further groups into Failure Categories including Task Verification, Inter-Agent Misalignment, and Poor Specification.
- MASFT framework organizes failure modes based on inter-agent conversation stages, spanning from pre-execution to post-execution phases, and classifies them into three main categories reflecting system design, agent coordination, and quality control issues.
- MASFT taxonomy provides structured framework for understanding and mitigating failure modes in multi-agent LLM systems, serving as a foundation for future research towards building robust and reliable multi-agent systems.


---


[Do Large Language Models Understand Performance Optimization?](http://arxiv.org/abs/2503.13772v1)

- Performance Optimization Agent: introduces a system integrating LLMs with profiling feedback for HPC code optimization, with Input Prompt, Evaluator, Codee, LLMs, Compilers, Results, HPC Commonsense, Code Correctness, Performance Benchmarking, Metrics, Memory, Profiling Tools, Profiling Plan, Metrics Annotation, System Prompt, Code Generation, Code Replacement, and Output Inspection components.
- Performance Optimization Agent leverages profiling tools and LLMs iteratively to optimize HPC code by replacing hotspot functions and recompiling, while evaluating performance metrics and ensuring code correctness.
- The agent aims to bridge the gap between traditional HPC optimization and AI-driven code assistants by incorporating human-like iterative refinement and memory of prior optimization attempts for enhanced performance gains.


---

[A Comprehensive Survey on Multi-Agent Cooperative Decision-Making: Scenarios, Approaches, Challenges and Perspectives](http://arxiv.org/abs/2503.13415v1)

- LLMs-enhanced MARL Framework: introduces a structure integrating Large Language Models with Multi-Agent Reinforcement Learning, encompassing Feature Representation Extractor, Language Translator, Reward Models, Decision-makers, World Model Simulator, and Policy Interpreter.
- This framework leverages LLMs for enhanced reasoning and language understanding within MARL agents, facilitating improved collaboration and decision-making in complex environments.
- The architecture supports various roles for LLMs, including information processing, reward design, decision-making, and output generation, aiming to address challenges in multi-agent systems.


---

[Toward Generative 6G Simulation: An Experimental Multi-Agent LLM and ns-3 Integration](http://arxiv.org/abs/2503.13402v1)

- Multi-Agent LLM framework: introduces a multi-agent system with Simulation Generation, Test Designer, Test Executor, and Result Interpretation Agents, leveraging External Tools and LLMs within a Feedback Loop managed by Agent Orchestration Layer for automated network simulation.
- This framework integrates specialized agents to automate simulation lifecycle stages, from natural language input to actionable insights, using ns-3 and iterative refinement.
- The framework enhances simulation accuracy and reduces manual coding by employing LLMs and external knowledge, facilitating rapid prototyping in complex network environments.


---

[MicroVQA: A Multimodal Reasoning Benchmark for Microscopy-Based Scientific Research](http://arxiv.org/abs/2503.13399v1)

- MicroVQA: introduces a benchmark, with Raw VQA creation, Exam-style MCQ generation, and RefineBot, for multimodal reasoning in microscopy-based research.
- MicroVQA benchmark evaluates expert image understanding, hypothesis generation, and experiment proposal capabilities.
- RefineBot component enhances MCQ difficulty by iteratively refining questions and distractors based on chain-of-thought analysis.


---

[Agents Play Thousands of 3D Video Games](http://arxiv.org/abs/2503.13356v1)

- PORTAL (Policy Optimization and Reasoning for Tactical Artificial Learning): introduces a novel framework for game-playing AI agents, leveraging Strategy Description, BT DSL, Behavior Tree DSL, Blackboard Variables, Control Flows, Neural Nets, Hand-crafted Rules, Generated Codes, Task Nodes, BT Generator, Parser, Reflexion, Rollout, JSON, and AI C++ Server components.
- PORTAL framework utilizes LLMs as policy architects to generate Behavior Tree DSL policies, which are then parsed and executed in a game environment, incorporating a reflexion mechanism for iterative policy refinement based on game feedback.
- The framework's hybrid architecture combines strategic reasoning from LLMs with efficient execution through behavior trees and neural networks, enabling rapid deployment and adaptation of game agents across diverse 3D video game environments.


---

[Goal2Story: A Multi-Agent Fleet based on Privately Enabled sLLMs for Impacting Mapping on Requirements Elicitation](http://arxiv.org/abs/2503.13279v1)

- Goal2Story (Impact Mapping framework): introduces multi-agent fleet for goal-driven requirements elicitation, with Alpha Captain, Intelligence Officer, Delivery Coordinator, Tactical Officer, Format Doctor, Validation Agent, and StorySeek dataset.
- It leverages privately enabled small language models and Impact Mapping framework to automate requirements elicitation in agile development.
- The framework aims to improve efficiency and quality of user story generation while addressing data privacy and cost concerns associated with large language models.


---

[KNOWLEDGE-AWARE ITERATIVE RETRIEVAL FOR MULTI-AGENT SYSTEMS](http://arxiv.org/abs/2503.13275v1)

- Knowledge-Aware Iterative Retrieval for Multi-Agent Systems: introduces agent framework with Query Planning, Knowledge Update Mechanism, and Contextual Filtering for iterative knowledge retrieval.
- Framework decouples external sources from internal knowledge cache, enabling dynamic search exploration and mitigating bias reinforcement loops.
- System supports multi-agent extensions for competitive and collaborative knowledge sharing, enhancing reasoning and scalability in complex tasks.


---

[DAgent: A Relational Database-Driven Data Analysis Report Generation Agent](http://arxiv.org/abs/2503.13269v1)

- DAgent (Relational Database-Driven Data Analysis Report Generation Agent) introduces a novel LLM agent framework for relational database analysis report generation, integrating Planning Module (processes input queries), Decomposition Tools (breaks down complex questions), Data Retrieval Tools (retrieves data from database), SQL Rewriting Tools (optimizes SQL queries), Report Generation Tools (generates analytical reports), Tools Module (collection of specialized components), and Memory Module (stores historical data).
- DAgent framework utilizes planning to decompose complex questions, employs tools for data retrieval and report generation, and incorporates memory to enhance efficiency and contextual understanding for relational database-driven data analysis report generation.
- The modular architecture of DAgent facilitates efficient task decomposition, flexible data retrieval strategies, and precise report synthesis, demonstrating strong potential for complex database analysis tasks.


---

[MAP: Evaluation and Multi-Agent Enhancement of Large Language Models for Inpatient Pathways](http://arxiv.org/abs/2503.13205v1)

- MAP (Multi-Agent Inpatient Pathways): introduces a multi-agent framework with Triage-, Diagnosis-, Treatment-, and Chief-Agents, supported by Record Review-, Trainable REG-, and Expert Guidance-Modules, utilizing Medical Records and a Medical Knowledge Base, to enhance large language model performance in inpatient pathways.
- MAP framework simulates inpatient pathway flow through collaborative agents, where each agent is empowered by specialized LLMs and modules for complex medical scenario processing and improved diagnostic accuracy.
- The framework's modular design, incorporating record review, retrieval-enhanced generation, and expert guidance, aims to address limitations of current LLMs in complex inpatient diagnostic support by integrating diverse clinical data and knowledge.


---

[MAP : Multi-user Personalization with Collaborative LLM-powered Agents](http://arxiv.org/abs/2503.12757v1)

- MAP (Multi-Agent system for Multi-user Personalization): introduces Planner, Rule Manager, Rule Retriever, and Storage components within Reflection, Analysis, and Feedback stages for multi-user personalization.
- MAP framework orchestrates specialized agents to retrieve user data, reason about personalization tasks, resolve conflicts, and incorporate user feedback through iterative workflow.
- MAP leverages multi-agent system to implement user-centered personalization workflow, emphasizing user involvement in resolution verification and failure management.


---

[Identifying Cooperative Personalities in Multi-agent Contexts through Personality Steering with Representation Engineering](http://arxiv.org/abs/2503.12722v1)

- Personality Steering Framework: introduces personality steering via representation engineering to investigate LLM cooperation within Iterated Prisoner's Dilemma environment, utilizing LLM agents and rule-based players.
- Framework employs Big Five personality traits steering through vectors and prompts to analyze impact on LLM behavior across different communication setups.
- Key components include representation engineering for personality modulation, IPD environment for strategic interaction, and communication module for enhanced agent interaction.


---

[Can Reasoning Models Reason about Hardware? An Agentic HLS Perspective](http://arxiv.org/abs/2503.12721v1)

- Agentic HLS Optimization Framework: introduces agent-based methodology employing In-Context Learning, LLM, HLS Tool, Functional Test, Compiler, Agent Tasks, Inspect kernel, Solve ILP problem, Synthesize Solution, Select Solution, System Prompt, Config. Builder, and ILP Solver for automated hardware design optimization in High-Level Synthesis.
- This framework explores LLMs' reasoning capabilities within High-Level Synthesis by automating code restructuring, pragma insertion, and design space exploration through iterative feedback loops and access to EDA tools.
- The agentic approach aims to enhance design quality and efficiency by enabling LLMs to emulate expert system architects in navigating complex hardware optimization tasks, potentially improving upon current state-of-the-art methods.


---

[Enforcing Cybersecurity Constraints for LLM-driven Robot Agents for Online Transactions](http://arxiv.org/abs/2503.15546v1)

- Security Architecture: introduces a cybersecurity framework for LLM agents in online transactions, integrating LLM-Driven Robot Agents Layer, Multi-Factor Authentication (MFA) Layer, Blockchain Layer, Anomaly Detection System (ADS) Layer, and User Interface Layer.
- The framework enhances transaction security and integrity by combining multi-factor authentication for identity verification, blockchain for immutable records, and real-time anomaly detection for fraud prevention.
- This architecture achieves improved fraud detection and reduced transaction latency compared to traditional systems, demonstrating enhanced security and efficiency for LLM-driven robotic agents.


---

[Can Reasoning Models Reason about Hardware? An Agentic HLS Perspective](http://arxiv.org/abs/2503.12721v1)

- Agentic HLS optimization framework: introduces an automated optimization flow with In-Context Learning, HLS Tool, LLM, Functional Test, Compiler, Agent Tasks, ILP Solver, and Config. Builder for high-level synthesis.
- This framework explores reasoning LLMs for automating code restructuring, pragma insertion, and design space exploration in HLS.
- The agentic approach aims to improve design quality and efficiency by mimicking expert system architects in hardware optimization tasks.


---

[Prompt Flow Integrity to Prevent Privilege Escalation in LLM Agents](http://arxiv.org/abs/2503.15547v1)

- PFI (Prompt Flow Integrity): introduces system security solution for LLM agents, featuring User Prompt, Agent Context, Plugins, Plugin Call, Plugin Result, Final Answer, Trusted Agent, Untrusted Agent, Proxy, Trusted Data, Untrusted Data, FlowCheck, TrustCheck, and GenerateQuery components.
- PFI framework isolates untrusted data within Untrusted Agent, distinct from Trusted Agent, and employs Proxy to manage data flow between agents, utilizing FlowCheck and TrustCheck for validation and data classification.
- PFI aims to mitigate privilege escalation risks in LLM agents by enforcing least privilege and ensuring data flow integrity through component-based architecture and security mechanisms.


---



#### 16th March 2025

[VeriLA: A Human-Centered Evaluation Framework for Interpretable Verification of LLM Agent Failures](http://arxiv.org/abs/2503.12651v1)

- VeriLA (Verifying LLM Agent failures): introduces a human-centered framework with Human-designed Agent Registry, Planning Agent, Task Plan, Agent Execution, Agent Outputs, Human-defined Agent Criteria, Agent Verifiers, Aggregator: Task Failure, and AI Practitioners / Agent Users for interpretable LLM agent failure verification.
- VeriLA systematically evaluates agent failures using human-defined criteria, verifies execution outputs, and aggregates scores to identify task failures and guide revisions.
- The framework enhances human-agent collaboration by providing interpretable failure analysis and reducing manual effort in debugging compound AI systems.


---

[Facilitating Automated Online Consensus Building through Parallel Thinking](http://arxiv.org/abs/2503.12499v1)

- PTFA (Parallel Thinking-based Facilitation Agent): introduces an automated system for online consensus building, leveraging LLMs to embody Six Thinking Hats roles for structured discussions.
- PTFA framework comprises an Agent module incorporating LLMs for diverse thinking roles and a Platform module for user interaction via Discourse interface and discussion data storage in a database.
- The system utilizes Discourse forum system and OpenAI API to facilitate structured conversations based on Six Thinking Hats methodology and collect data for analysis of automated facilitation.


---

[A Survey on the Optimization of Large Language Model-based Agents](http://arxiv.org/abs/2503.12434v1)

- LLM-based Agent Optimization Framework: introduces introduction, background, parameter-driven optimization, parameter-free optimization, datasets and benchmarks, application, challenges and future directions, and conclusion to comprehensively survey optimization strategies for agents based on large language models.
- Parameter-driven optimization refines model parameters, while parameter-free optimization adjusts inputs and context to improve agent behavior without parameter changes.
- The survey categorizes optimization into parameter-driven (fine-tuning, RL, hybrid) and parameter-free (prompt engineering, RAG, multi-agent) methods, further detailing data construction, evaluation, and applications.


---

[SPIN-Bench: How Well Do LLMs Plan Strategically and Reason Socially?](http://arxiv.org/abs/2503.12349v1)

- SPIN-Bench (Strategic Planning, Interaction, and Negotiation): introduces a multi-domain evaluation framework, with LLM Pool, Game Environment, Agent Engine, Agent Initialization, Phase Manager, and Evaluation Module, designed to measure strategic planning and social reasoning intelligence.
- The framework combines PDDL tasks, competitive games, cooperative games, and strategic games to assess LLMs in diverse social settings.
- SPIN-Bench is important for future research on robust multi-agent planning, social reasoning, and human-AI teaming by providing a unified and comprehensive evaluation platform.


---

[GAMECHAT: Multi-LLM Dialogue for Safe, Agile, and Socially Optimal Multi-Agent Navigation in Constrained Environments](http://arxiv.org/abs/2503.12333v1)

- GAMECHAT (Multi-LLM Dialogue for Safe, Agile, and Socially Optimal Multi-Agent Navigation in Constrained Environments): introduces a decentralized multi-agent navigation framework utilizing Initial Prompt, Another Agent Observed?, SMG Occurring?, MPC-CBF Update, LLM Conversation, Consensus or Comm. Limit Reached?, Was Consensus Reached?, Use LLM-Based Role Assignment, Strategy 1 Role Assignment, MPC-CBF w/ Role Constraints Update, and Goals Reached? components for safe, agile, and socially optimal navigation.
- GAMECHAT framework leverages LLM Conversation for natural language-based priority negotiation and employs MPC-CBF Update for motion planning with safety and liveness guarantees in constrained environments.
- The framework addresses spatial symmetry and deadlocks through explicit communication and game-theoretic strategies, achieving socially optimal navigation by prioritizing urgent tasks and ensuring subgame perfect equilibrium.


---

[LLM-MEDIATED GUIDANCE OF MARL SYSTEMS](http://arxiv.org/abs/2503.13553v1)

- LLM-Mediated Guidance of MARL Systems: introduces a framework that integrates Rule-Based Controller, Natural Language Controller and LLM-Mediator to guide Agents within an Environment by generating Task-List based on Observations and Reward, overwriting Learned Policy to enhance Actions.
- The framework uses LLM-Mediator to interpret interventions from Rule-Based Controller or Natural Language Controller, translating them into specific actions for agents in the Aerial Wildfire Suppression environment.
- This approach aims to improve MARL performance by providing adaptive guidance through LLM-mediated interventions, accelerating learning and enhancing coordination in complex multi-agent scenarios.


---

[Facilitating Automated Online Consensus Building through Parallel Thinking](http://arxiv.org/abs/2503.12499v1)

- PTFA (Parallel Thinking-based Facilitation Agent): introduces an automated system for online consensus building, leveraging LLMs to embody Six Thinking Hats roles for structured discussions.
- PTFA framework comprises an Agent module incorporating LLMs for diverse thinking roles and a Platform module for user interaction via Discourse interface and discussion data storage in a database.
- The system utilizes Discourse forum system and OpenAI API to facilitate structured conversations based on Six Thinking Hats methodology and collect data for analysis of automated facilitation.


---

[Advancing Human-Machine Teaming: Concepts, Challenges, and Applications](https://arxiv.org/abs/2503.16518)

- QN-MHP (Queuing Network-Model Human Processor): introduces queuing networks and symbolic cognitive models to effectively model multitask human performance for cognitive modeling.
- QN-MHP demonstrates potential in cognitive modeling but lacks accuracy under specific conditions and does not address speed control or complex road geometry adjustments.
- QN-MHP represents an initial approach towards integrating cognitive and queuing models for human performance simulation.


---


#### 15th March 2025

[Agentic Search Engine for Real-Time IoT Data](http://arxiv.org/abs/2503.12255v1)

- IoT-ASE (IoT Agentic Search Engine): introduces a real-time search engine for IoT data, leveraging Classifier Agent, Retriever Node, Generator Agent, and Reviewer Agent, utilizing Service Description Vector Database and Real-Time IoT database, with components including Tokenizer, Embedding Model, Average Pooling, Normalize embeddings, and integrating SensorsConnect's Perception Layer, Edge Layer, Cloud Layer, Business Layer, and User Interface Layer.
- IoT-ASE framework employs a Generic Agentic RAG approach to process IoT data queries, incorporating agents for classification, retrieval, generation, and review, ensuring context-aware and accurate responses by accessing real-time information and service descriptions.
- The architecture of IoT-ASE is designed to address the challenges of fragmented and heterogeneous IoT data by utilizing a unified data model and standardized communication protocols within the SensorsConnect framework, facilitating efficient real-time data accessibility and decision-making.


---

[TFHE-Coder: Evaluating LLM-agentic Fully Homomorphic Encryption Code Generation](http://arxiv.org/abs/2503.12217v1)

- Compiler-in-the-loop evaluator Framework: introduces iterative TFHE code generation process, with User Prompt initiating code creation by LLM, followed by Compiler TFHE compiling for Environment Output, using Compile Report feedback for LLM Revise if compilation is not OK.
- This framework evaluates LLM's ability to generate compilable TFHE code through cycles of compilation and revision based on compiler diagnostics.
- The iterative approach helps in systematically refining LLM output towards syntactically correct TFHE code generation.


---

[Multi-Agent Systems Execute Arbitrary Malicious Code](http://arxiv.org/abs/2503.12188v1)

- MAS (Multi-Agent System): introduces control-flow hijacking attacks by manipulating metadata flow within User, Orchestrator, WebSurfer, FileSurfer, and CodeExecutor components, leading to Hijacked control flow and execution of Executable payload from Attack content.
- MAS framework coordinates agents like WebSurfer, FileSurfer, and CodeExecutor under Orchestrator's direction to fulfill User requests, but is vulnerable to attacks rerouting Normal control flow.
- Control-flow hijacking in MAS exploits metadata transmission to redirect agent invocations, causing execution of arbitrary code and system compromise, even with individual agent safety measures.


---

[AgentDroid: A Multi-Agent Framework for Detecting Fraudulent Android Applications](http://arxiv.org/abs/2503.12163v1)

- AgentDroid (Multi-Agent Framework): introduces a multi-agent framework for Android fraudulent application detection, with Task Master, Certificate Checker, Link Analyst, Package Tracker, Permission Analyst, Icon Analyst, Content Analyst, Decision Maker agents, and Static Analysis, Feature Extraction, Agent Tools, Multi-Agent Detection modules.
- AgentDroid leverages multimodal analysis and collaborative agents to improve fraud detection accuracy by analyzing APK files and extracting features.
- The framework employs specialized agents and tools, including DeiT and T5 models, for detailed analysis of diverse APK characteristics to identify fraudulent applications.


---

[ICCO: Learning an Instruction-conditioned Coordinator for Language-guided Task-aligned Multi-robot Control](http://arxiv.org/abs/2503.12122v1)

- ICCO (Instruction-Conditioned Coordinator) introduces a multi-agent reinforcement learning framework with Instructor providing Language Instruction to Coordinator, which uses Coordination Policy and LLM or Random Vector Generator to generate Task-Aligned and Consistent Instructions (TACI) for each Local Agent with Local Policy in Env.
- ICCO framework balances language-instruction following and cooperative task execution by employing Coordinator to generate consistent instructions from global observations and language, improving coordination among Local Agents.
- The framework utilizes Centralized Training with Decentralized Execution (CTDE) paradigm, training Coordinator and Local Agent policies jointly to optimize task efficiency and instruction following, enhanced by Consistency Enhancement Term.


---

[Is Multi-Agent Debate (MAD) the Silver Bullet? An Empirical Analysis of MAD in Code Summarization and Translation](http://arxiv.org/abs/2503.12029v1)

- MAD (Multi-Agent Debate): introduces a multi-stage framework with Input, Stage 1, Stage 2, Stage 3, Agent Debate at each stage, Judge, and Evaluation: Debate Output, for structured debate among agents to solve software engineering tasks.
- MAD framework utilizes iterative Agent Debate within each Stage to refine solutions and employs a Judge to evaluate agent responses and guide the process towards Evaluation: Debate Output.
- The framework's modular design with distinct stages and agent roles facilitates structured problem-solving and leverages debate to enhance the quality of the final Evaluation: Debate Output.


---

[SagaLLM: Context Management, Validation, and Transaction Guarantees for Multi-Agent LLM Planning](http://arxiv.org/abs/2503.11951v1)

- SagaLLM (Saga Language Learning Model): introduces Context Management-, Validation- and Transaction-Frameworks, addressing limitations in multi-agent LLM planning by ensuring context awareness and planning consistency.
- SagaLLM integrates transactional processing with adaptive multi-agent intelligence, enhancing reliability and correctness in complex real-world applications.
- The framework employs specialized agents and validation protocols to maintain critical constraints and state information throughout complex planning processes, improving decision-making robustness.


---

[End-to-End Edge AI Service Provisioning Framework in 6G ORAN](http://arxiv.org/abs/2503.11933v1)

- Edge AI Service Provisioning Framework: introduces end-to-end system for edge AI service deployment using LLM-based Agent, RAN-Core Status Data, Edge Status Data, RIC Status Data, AI Model Repository Data, User Engagement Tool, Edge Management Tool, Core Management Tool, RIC Management Tool, AI Service Monitoring-Prediction, Other xApps, AI Service, Network Functions, and Databases.
- This framework leverages LLM agent to automate AI model selection, service deployment, network adaptation, and QoS monitoring in 6G O-RAN.
- The proposed framework aims to simplify edge AI deployment by abstracting low-level tasks and enabling intent-based service provisioning.


---


#### 14th March 2025

[CoLLMLight: Cooperative Large Language Model Agents for Network-Wide Traffic Signal Control](http://arxiv.org/abs/2503.11739v1)

- CoLLMLight (Cooperative Large Language Model Light): introduces a cooperative LLM agent framework for network-wide traffic signal control, with Observation Collection, Complexity-Aware Reasoning, Spatiotemporal-Aware Cooperative Decision-making, and Simulation-Driven Fine-tuning components.
- CoLLMLight uses spatiotemporal graph and complexity-aware reasoning to dynamically adapt reasoning depth for optimal computational efficiency and decision quality.
- Simulation-driven fine-tuning and environmental feedback enhance CoLLMLight's decision-making and efficiency in diverse traffic scenarios.


---

[Monitoring Reasoning Models for Misbehavior and the Risks of Promoting Obfuscation](http://arxiv.org/abs/2503.11926v1)

- CoT Monitoring Framework: introduces CoT Monitor and Action Monitor, to monitor reasoning models for misbehavior, in agentic coding environments.
- CoT Monitor observes agent's chain-of-thought, actions, and outputs, while Action Monitor observes only tool calls and final outputs.
- Using CoT monitoring can be more effective than action-only monitoring for detecting reward hacking in reasoning models.


---

[Cerebrum (AIOS SDK): A Platform for Agent Development, Deployment, Distribution, and Discovery](http://arxiv.org/abs/2503.11444v1)

- Cerebrum (AIOS SDK): introduces a modular four-layer architecture comprising LLM Layer, Memory Layer, Storage Layer, and Tool Layer, alongside Overrides Layer, Agent Hub, Agent Chat, Context Manager, Scheduler, LLM Core(s), Tool Manager, Memory Manager, Storage Manager, Agent Manager, Planning Module, Action Module, Memory Module, Storage Module, AIOS Kernel, User Device, Exposed Ports, LLM Queue, Memory Queue, Tool Queue, Storage Queue, Agent Applications, AIOS System Call, and Thread Binding for agent development, deployment, distribution, and discovery.
- Cerebrum framework provides a comprehensive SDK with a community-driven Agent Hub for sharing agents and an interactive web interface Agent Chat for agent testing and evaluation, aiming to standardize agent development and promote collaboration.
- The platform's architecture facilitates both fine-grained control over agent behavior and rapid development through high-level abstractions, supporting diverse agent methodologies and user-created agent distribution within a centralized hub.


---

[Alstorian lets AI be a historian: A KG-powered multi-agent system for accurate biography generation](http://arxiv.org/abs/2503.11346v1)

- Alstorian: introduces a knowledge graph powered retrieval-augmented generation system for biography creation, integrating KG-based index, two-step training, prompt, retrieval, aligned model, biography, verifier, error-aware generation, and error-aware solvers components.
- Alstorian employs KG-based index for structured knowledge retrieval and two-step training to enhance stylistic consistency of generated biographies, alongside multi-agent system for real-time error detection and correction.
- The framework achieves improved factual accuracy and reduced hallucination in biography generation through error-aware mechanisms and knowledge graph integration, demonstrating advancements over existing methods.


---

[GNNs as Predictors of Agentic Workflow Performances](http://arxiv.org/abs/2503.11301v1)

- FLOW-GNN (workflow graph neural network): introduces a framework for predicting agentic workflow performance using Agentic workflow, Task instruction, Sentence transformer, Graph & node features, GNN encoder, Projector, Task embedding, Concatenation, MLP, and Predicted performance.
- This framework leverages GNNs to efficiently predict agentic workflow performance by encoding workflow structure and task instructions into embeddings and using MLP for prediction, avoiding costly LLM invocations.
- FLOW-GNN framework aims to automate agentic workflow optimization by providing a fast and accurate performance predictor, enabling efficient exploration of workflow designs.


---


[COLLABORATION IS ALL YOU NEED: LLM ASSISTED SAFE CODE TRANSLATION](http://arxiv.org/abs/2503.11237v1)

- UniTranslator: introduces a multi-agent framework for code translation with Input Code processed by DirectorLLM, leveraging Agent Garden, LLM Quorum, and Compiler Garden within a Decision Loop using Feedback to produce Translated Code.
- UniTranslator framework utilizes DirectorLLM to orchestrate specialized agents in Agent Garden and select appropriate LLMs from LLM Quorum, employing Compiler Garden for validation and Feedback for iterative refinement within Decision Loop.
- This architecture aims to enhance code translation accuracy and efficiency by using collaborative compact LLMs and knowledge grounding, overcoming limitations of monolithic models and enabling deployment on common hardware.


---

[Prompt Alchemy: Automatic Prompt Refinement for Enhancing Code Generation](http://arxiv.org/abs/2503.11085v1)

- Prochemy (Prompt Alchemy): introduces automated prompt refinement framework, with Training Set Generation, Optimization, Mutation, Evaluation, Selection, LLM, Existing Data, Mutated Data, Training Set, Initial Prompt, Selected Prompt and Final Prompt, to enhance code generation by iteratively refining prompts based on model performance.
- Prochemy leverages a training set composed of existing and mutated data to evaluate and select optimal prompts through mutation, evaluation, and selection steps, ensuring consistency and reliability.
- The framework is designed as plug-and-play, compatible with existing prompt engineering methodologies, and validated across diverse datasets and language models for code generation and translation tasks.


---

[Large Reasoning Models in Agent Scenarios: Exploring the Necessity of Reasoning Capabilities](http://arxiv.org/abs/2503.11074v1)

- LaRMA Framework (Large Reasoning Models in Agent Scenarios framework): introduces Task Segmentation (categorizes agent tasks), Agent Paradigm (selects reasoning paradigms), Model Evaluation (evaluates LLMs and LRMs), Performance Evaluation (measures task success), and Reasoning Evaluation (assesses reasoning quality).
- LaRMA framework systematically investigates reasoning in agents by dissecting tasks, selecting paradigms like ReAct and Reflexion, and evaluating performance and reasoning metrics.
- This framework facilitates understanding of reasoning capabilities in LLMs and LRMs across diverse tasks and paradigms, contributing to agent design advancements.


---

[API Agents vs. GUI Agents: Divergence and Convergence](http://arxiv.org/abs/2503.11069v1)

- This paper introduces API Agent, GUI Agent and Hybrid Agent frameworks, which includes User (initiates task), API Agent (uses APIs), GUI Agent (uses GUI), API Information (API descriptions), Action (API) (executes API call), GUI Observation (GUI perception), Action (GUI) (interacts with GUI), API Wrapper (wraps GUI with API), Action Orchestrator (manages actions), Hybrid Agent (uses both APIs and GUI), GUI Workflow (GUI action sequence), Payment Gateway (handles payments), Shipping Service (manages shipping), and GUI Verification (verifies GUI).
- API Agent framework utilizes structured API calls for efficient and reliable automation, while GUI Agent framework interacts with applications through visual interfaces for broader applicability.
- Hybrid Agent framework combines API and GUI approaches to leverage their respective strengths, aiming for versatile and adaptable automation solutions.


---


[Banner Agency: Advertising Banner Design with Multimodal LLM Agents](http://arxiv.org/abs/2503.11060v1)

- BannerAgency: introduces a training-free framework for automated banner ad design, incorporating Strategist, Background Designer, Foreground Designer, Developer, Memory, and External Knowledge & Tools components.
- BannerAgency leverages multimodal LLMs as agents to simulate a human design team workflow, from strategy to implementation, for generating editable banner designs.
- The framework utilizes memory and external knowledge to enable context-aware decisions and supports multiple banner sizes through component-based approach.


---

[TxAgent: An AI Agent for Therapeutic Reasoning Across a Universe of Tools](http://arxiv.org/abs/2503.10970v1)

- TXAGENT (TXAGENT): introduces an AI agent for therapeutic reasoning, integrating TOOLUNIVERSE, Specialized LLM, and TOOLRAG model.
- TXAGENT leverages multi-step reasoning and real-time biomedical knowledge retrieval across a toolbox of 211 tools for analyzing drug-related tasks.
- TXAGENT ensures treatment recommendations align with clinical guidelines and real-world evidence, reducing adverse events and improving decision-making.


---


#### 13th March 2025


[Teamwork makes the dream work: LLMs-Based Agents for GitHub README.MD Summarization](http://arxiv.org/abs/2503.10876v1)

- Metagente: introduces a multi-agent framework composed of Extractor Agent, Summarizer Agent, Teacher Agent, and Prompt Creator Agent, utilizing LangChain for communication and ROUGE-L for evaluation within a Fine Tuning process to generate Generated About from README.MD.
- Metagente employs Extractor Agent to filter README.MD content, Summarizer Agent to create summaries, Teacher Agent to refine prompts, and Prompt Creator Agent to finalize prompts, iteratively improving summary quality.
- The framework leverages a teacher-student architecture for prompt optimization, enhancing the synergy of LLM agents to achieve improved summarization performance for GitHub README.MD files.


---

[UniGoal: Towards Universal Zero-shot Goal-oriented Navigation](http://arxiv.org/abs/2503.10630v1)

- UniGoal: introduces a universal zero-shot goal-oriented navigation framework utilizing Observation RGB-D as input and Agent Pose to construct Scene Graph and Goal Graph, employing Graph Matching and Blacklist within a Global Policy across Stage 1: Zero Matching, Stage 2: Partial Matching, and Stage 3: Perfect Matching to output Action based on Deterministic Local Policy and Occupancy Map, further incorporating Graph Correction and Goal Verification.
- This framework uniformly represents diverse goals as graphs and performs graph matching between Scene Graph and Goal Graph to guide a multi-stage exploration policy, enabling zero-shot navigation across object category, instance image, and text description goals.
- The multi-stage policy progresses from initial exploration in Stage 1: Zero Matching to coordinate projection in Stage 2: Partial Matching and finally to verification in Stage 3: Perfect Matching, ensuring robust navigation through graph-based reasoning and a blacklist mechanism for avoiding repeated failures.


---

[COSTA*: Cost-Sensitive Toolpath Agent for Multi-turn Image Editing](http://arxiv.org/abs/2503.10613v1)

- COSTA* (Cost-Sensitive Toolpath Agent): introduces a three-stage framework with LLM for subtask tree generation, Tool Dependency Graph and Model Description Table for tool organization, A* Search for optimal pathfinding, Quality Check by VLM for output evaluation, utilizing Tools and Benchmark Table for informed decisions in multi-turn image editing.
- COSTA* leverages LLM for high-level planning and A* search for detailed toolpath optimization, incorporating Tool Dependency Graph and Model Description Table to manage tool dependencies and capabilities, while Benchmark Table and Quality Check by VLM ensure cost-effective and high-quality image editing.
- The framework balances computational cost and output quality through a cost-sensitive A* search guided by a Benchmark Table and real-time feedback from Quality Check by VLM, enabling efficient exploration of toolpaths within the Tool Dependency Graph and Subtask Tree for complex image editing tasks.


---

[SySLLM: Generating Synthesized Policy Summaries for Reinforcement Learning Agents Using Large Language Models](http://arxiv.org/abs/2503.10509v1)

- SySLLM (Synthesized Summary using LLMs) introduces Env, Observation Captioner, Agent, Action Captioner, Experience Dataset, Prompt, Formatted Dataset, LLM, and Summary to generate policy summaries by converting agent experiences into natural language and utilizing LLMs for synthesis.
- SySLLM leverages captioners to translate environment observations and agent actions into textual descriptions, which are then formatted with a prompt and fed into an LLM to produce a comprehensive policy summary.
- The framework facilitates understanding of complex RL policies by synthesizing concise, coherent, and human-readable summaries from agent-environment interactions, enhancing interpretability and trust in RL agents.


---

[New Trends for Modern Machine Translation with Large Reasoning Models](https://arxiv.org/abs/2503.10351v1)

- LRM-based MT (Large Reasoning Model based Machine Translation): introduces framework with Machine Translation and Large Reasoning Model, addressing Foundational Challenges like Stylized-, Document-, Multimodal Translation, exploring New Opportunities such as Self-Reflection, Auto-Pivoting, and venturing Beyond Translation into Deciphering Encoded Text.
- This framework leverages Large Reasoning Models to enhance Machine Translation by tackling complex scenarios and introducing novel capabilities beyond traditional text-to-text mapping.
- The approach aims to redefine translation as dynamic reasoning task, moving beyond mere text conversion towards multilingual cognitive agent functionality.


---

[Capturing Semantic Flow of ML-based Systems](http://arxiv.org/abs/2503.10310v1)

- Semantic Flow: introduces semantic flow graphs for capturing ML-system executions through latent space progression, using Conv2d, MaxPool2d, Linear, ReLU, Flatten, AutoFL, LLM, Latent Space, Semantic State, Semantic Cluster, LLM Inference Graph, and Function Call Nodes components.
- Semantic flow graphs represent semantic states as clusters in latent spaces and transitions between these clusters, enabling analysis of ML-system behaviour beyond traditional control flow.
- This approach facilitates understanding, debugging, and improving ML-based systems by visualizing and quantifying their internal decision-making processes and execution diversity.


---

[LLM Agents Display Human Biases but Exhibit Distinct Learning Patterns](http://arxiv.org/abs/2503.10248v1)

- DFE Framework (Decisions From Experience Framework): introduces LLM Agents (language model decision-makers) within DFE Tasks (repeated choice scenarios) to evaluate behavioral patterns through Feedback (outcome information) and Choice History (past interaction record).
- This framework investigates how LLMs, provided with Feedback and Choice History in DFE Tasks, exhibit human-like biases such as underweighting rare events and correlation effects.
- The DFE Framework highlights differences in learning patterns between LLMs and humans, revealing LLMs' strong recency bias and absence of "surprise triggers change" and "wavy recency effect" phenomena observed in human behavior.


---

[SCOOP: A Framework for Proactive Collaboration and Social Continual Learning through Natural Language Interaction and Causal Reasoning](http://arxiv.org/abs/2503.10241v1)

- SCOOP (Social Continual Object-Oriented POMDP): introduces a base Oracle-Aided ReAct architecture that extends ReAct framework with actions to query state, user preferences, and environment mechanics.
- SCOOP framework also proposes an advanced ReAct architecture incorporating CausalRefinementAndAction, LLM, external oracle, causal inference libraries, causal knowledge graph, and planning routines for enhanced reasoning.
- SCOOP framework facilitates agents learning through dialogue, questions, and interaction in open environments, refining causal understanding while balancing exploration and exploitation.


---

[Hybrid Agents for Image Restoration](http://arxiv.org/abs/2503.10120v1)

- HybridAgent: introduces interactive image restoration paradigm with user inputs, fast-agent, slow-agent, feedback-agent, restoration tools and memory.
- HybridAgent: employs fast-agent for direct prompts, slow-agent for vague prompts, feedback-agent for quality assessment, and restoration tools for image enhancement, utilizing memory to track restoration history.
- HybridAgent: leverages instruction-tuning dataset to optimize agents and restoration tools, achieving efficient and effective image restoration through collaborative agent interaction.


---

[StepMathAgent: A Step-Wise Agent for Evaluating Mathematical Processes through Tree-of-Error](http://arxiv.org/abs/2503.10105v1)

- StepMathAgent: introduces a mathematical process evaluation agent based on Tree-of-Error, incorporating logical step segmentation, step scoring, score aggregation, error tree generation, difficulty calibration, simplicity evaluation, completeness validation, and format assessment.
- StepMathAgent evaluates mathematical problem-solving processes by segmenting solutions into steps, scoring each step, aggregating scores, and generating error trees for interpretability and feedback.
- StepMathAgent addresses limitations of answer-based evaluations by providing fine-grained assessments, interpretability through error trees, and adaptability to diverse evaluation scenarios.


---

[Advanced Tool Learning and Selection System (ATLASS): A Closed-Loop Framework Using LLM](http://arxiv.org/abs/2503.10071v1)

- ATLASS (Advanced Tool Learning and Selection System): introduces a closed-loop framework employing Task Analyzer for decomposition, Tool Master for tool necessity assessment, Tool Selector for tool selection, Tool Generator for tool creation, Tool Dataset for storage, and Task Solver for execution, alongside Code Writer, Code Executor, Documentation Context, Web Automation Bot, and API Key for tool generation and usage.
- This framework facilitates dynamic tool generation and selection by LLMs, enabling adaptive problem-solving through iterative refinement and reuse of tools stored in the Tool Dataset.
- ATLASS enhances LLM agents' capabilities to address complex tasks by automating tool creation and integration, overcoming limitations of predefined toolsets and improving adaptability in diverse scenarios.


---

[Enhancing Multi-Agent Systems via Reinforcement Learning with LLM-based Planner and Graph-based Policy](http://arxiv.org/abs/2503.10049v1)

- LGC-MARL (LLM-based Graph Collaboration MARL): introduces framework integrating LLM Planner and Graph-based policy to enhance multi-agent reinforcement learning in complex tasks.
- LGC-MARL framework: decomposes tasks into executable subtasks using LLM Planner, and coordinates agents via Graph-based policy guided by action dependency graph.
- LGC-MARL framework: employs Critic LLM for plan refinement and LLM-based reward function generator, improving collaboration and learning efficiency in multi-agent systems.


---

[OR-LLM-Agent: Automating Modeling and Solving of Operations Research Optimization Problem with Reasoning Large Language Model](https://github.com/bwz96sco/or_llm_agent)

- OR-LLM-Agent (Operations Research - Large Language Model - Agent): introduces an AI framework that automates operations research problem-solving by using LLM mathematical modeling, LLM code generation and OR-CodeAgent for code execution and repair, replacing traditional expert and programmer roles.
- OR-LLM-Agent framework leverages reasoning LLMs to translate natural language problem descriptions into mathematical models, subsequently generating executable solver code and managing automated code execution within a sandbox environment.
- The framework's OR-CodeAgent component enhances robustness through self-repair and self-verification mechanisms, iteratively refining code and mathematical models to achieve feasible and accurate solutions for real-world operations research problems.


---

[AgentDAM: Privacy Leakage Evaluation for Autonomous Web Agents](http://arxiv.org/abs/2503.09780v1)

- AgentDAM (Agent Data Minimization): introduces benchmark for evaluating privacy leakage in web agents, processing user instruction and data within web environment using LLM backbone, generating actions judged by privacy evaluator.
- AgentDAM benchmark assesses agent's ability to minimize private data processing during web navigation tasks, measuring both task performance and privacy leakage.
- AgentDAM provides a framework to analyze and mitigate privacy risks associated with autonomous AI web agents accessing sensitive user information.


---

[Multi-Agent LLM Actor-Critic Framework for Social Robot Navigation](http://arxiv.org/abs/2503.09758v1)

- SAMALM (Socially-Aware Multi-Agent actor-critic LLM framework): introduces decentralized multi-agent system for social robot navigation, employing Local Observation, Multi-Robot LLM-Actors, Action List, Multi-Robot LLM-Critics, Output Execution, Re-Query with (Critic Feedback), Evaluation Threshold, Entropy Fusion Mechanism, Global LLM Critic, Local LLM Critic, LLM Actor, and Robot World Model components.
- SAMALM framework utilizes parallel LLM actors for generating robot-specific control signals, which are evaluated by global and local LLM critics, and refined through an entropy-based fusion and re-query mechanism to ensure socially compliant navigation.
- The architecture of SAMALM facilitates self-verification and iterative refinement of robot actions, balancing individual robot autonomy with global team coordination in complex social environments through multi-agent LLM actor-critic approach.


---


#### 12th March 2025

[PLAN-AND-ACT: Improving Planning of Agents for Long-Horizon Tasks](http://arxiv.org/abs/2503.09572v1)

- PLAN-AND-ACT: introduces PLANNER, EXECUTOR and Dynamic Replanning to improve agent planning for long-horizon tasks.
- PLANNER decomposes user queries into high-level plans, while EXECUTOR translates plans into environment actions, and Dynamic Replanning updates plans based on environment changes.
- PLAN-AND-ACT framework separates planning and execution responsibilities to enhance performance in complex, long-horizon tasks within dynamic environments.


---


[Large Language Models for Multi-Facility Location Mechanism Design](http://arxiv.org/abs/2503.09533v1)

- LLMMech (Large Language Models for Mechanism Design): introduces an evolutionary framework integrating LLMs to automate the design of strategyproof mechanisms using InitializationPrompt, Select, VariationPrompt, PopulationManager and PromptEvolution components.
- LLMMech framework leverages LLMs for generating interpretable, hyperparameter-free, and empirically strategyproof mechanisms for multi-facility location problems.
- The framework incorporates PromptEvolution to automatically refine prompts, enhancing the diversity of generated mechanisms and improving search for optimal solutions.


---

[REMA: LEARNING TO META-THINK FOR LLMS WITH MULTI-AGENT REINFORCEMENT LEARNING](http://arxiv.org/abs/2503.09501v1)

- ReMA (Reinforced Meta-thinking Agents): introduces multi-agent reinforcement learning framework with high-level meta-thinking agent, low-level reasoning agent, meta-thinking, reasoning, MARL, feedback, and solution.
- ReMA framework decouples reasoning into hierarchical agents: meta-thinking agent for strategic planning and reasoning agent for detailed execution, enabling collaborative learning.
- Iterative reinforcement learning with aligned objectives in ReMA facilitates agent collaboration, improving generalization and robustness in complex reasoning tasks.


---

[COLA: A SCALABLE MULTI-AGENT FRAMEWORK FOR WINDOWS UI TASK AUTOMATION](http://arxiv.org/abs/2503.09263v1)

- COLA (Collaborative Multi-Agent framework for automating Windows UI operations) introduces a multi-agent framework with Planner, Task Scheduler, Decision Agent Pool, Executor, and Reviewer, enhanced by Short-Term and Long-Term Memory units for Windows UI task automation.
- COLA framework utilizes a Task Scheduler to dynamically assign coarse-grained subtasks from Planner to specialized agents within Decision Agent Pool, enabling flexible and scalable task execution.
- The framework incorporates memory units for agent self-evolution and an interactive backtracking mechanism for non-destructive error recovery, improving robustness and performance in UI automation tasks.


---

[AdaptAI: A Personalized Solution to Sense Your Stress, Fix Your Mess, and Boost Productivity](https://doi.org/10.1145/3706599.3720284)

- AdaptAI (AdaptAI: A Personalized Solution to Sense Your Stress, Fix Your Mess, and Boost Productivity): introduces a multimodal AI system, with Processing Module (integrates multimodal real-time streams), External Task Agents (automates simple extra tasks), Personalized Well-being Intervention Pipeline (delivers personalized interventions), and Tone-adaptive Conversational Agent TCA (adjusts tone based on heart activity), to provide personalized productivity and well-being support.
- AdaptAI leverages egocentric vision, audio, heart rate, and motion data, processed by Speech-to-Text (audio to text conversion), EGOCENTRIC CAPTION LLM (processes egocentric vision captions), VLM (vision language model), SCREEN CAPTION LLM (processes screen captions), Stress Estimation (assesses user stress levels), and Movement Estimation (assesses user movement) within the Processing Module, alongside Live Routine Mapping (maps user's daily activities) and Memory (temporary data storage) for context-aware interventions.
- The framework employs External Task Agents (automates simple extra tasks) like Email Agent (manages email tasks) and Meeting Agent (manages meeting tasks) to streamline workflows, while Personalized Intervention (provides personalized well-being support) and TCA (adjusts tone based on heart activity) enhance user experience by addressing physical and psychological states dynamically.


---

LocAgent: Graph-Guided LLM Agents for Code Localization](http://arxiv.org/abs/2503.09089v1)

- LOCAGENT (LOCAGENT): introduces graph-oriented LLM-agent framework, with Codebase, Code Graph Indexing, Entity Indexing, Agent Runtime, Tools, LLM Agent, Observation, Event Log, Action, Localized Code Sections, Result, Entity ID Index, Entity Name Index, BM25 Index on Entity IDs, BM25 Index on Entity Contents, contain, import, invoke, and inherit, for code localization using graph-based representation and agent-guided search.
- LOCAGENT framework utilizes Code Graph Indexing and Entity Indexing to create efficient codebase representations, enabling LLM Agent within Agent Runtime to use Tools for navigating and searching code, ultimately providing Localized Code Sections as Result.
- LOCAGENT's architecture emphasizes structured code exploration through graph-based indexing and specialized tools, facilitating accurate and cost-effective code localization by leveraging LLM Agent's reasoning within Agent Runtime environment.


---

[Agentic Control for Safe Autonomous Stunt Maneuvers](http://arxiv.org/abs/2503.09035v1)

- ManeuverGPT: introduces agentic framework with Query Enricher Agent, Driver Agent, Parameter Validator Agent and Orchestrator for generating stunt maneuvers.
- It iteratively refines control parameters using feedback and validation for safe execution.
- The framework combines LLM-based reasoning with algorithmic validation for flexible high-dynamic maneuvers.


---

[ARCHED: A Human-Centered Framework for Transparent, Responsible, and Collaborative AI-Assisted Instructional Design](http://arxiv.org/abs/2503.08931v1)

- ARCHED (AI for Responsible, Collaborative, Human-centered Education Instructional Design) introduces a three-phase framework for AI-assisted instructional design, incorporating Web Interface (LOGS), Educational Parameters Specification, LOGS, OAE Analysis, Temporary Repository for Refinement, Cognitive Demand Analysis, and Innovative Assessment Strategies to enhance human-AI collaboration.
- ARCHED framework utilizes LOGS for initial learning objective generation based on educator-specified parameters and OAE Analysis for evaluating objectives against pedagogical criteria, ensuring iterative refinement and alignment.
- The framework aims to maintain human agency and pedagogical rigor in AI-assisted instructional design by providing transparent AI reasoning and promoting diverse assessment strategies through specialized components.


---

[Distributionally Robust Multi-Agent Reinforcement Learning for Dynamic Chute Mapping](https://arxiv.org/abs/2503.09755)

- DRMARL (Distributionally Robust Multi-Agent Reinforcement Learning): introduces a framework for dynamic chute mapping robust to induction rate variations, utilizing Agents(Control chute allocation per destination), a Shared Local Q-Network(Estimates action value per agent), Target Network(Stabilizes Q-learning), Experience Replay Buffer(Stores transitions for training), Value Decomposition Network(Aggregates local Q-values), Integer Program Solver(Selects joint actions under budget), Induction Distribution Groups(Represent historical patterns), Ambiguity Set(Defines uncertainty over groups), Distributionally Robust Bellman Operator(Optimizes for worst-case reward), Contextual Bandit Predictor(Predicts worst-case group efficiently), and CB Replay Buffer(Stores CB transitions), where agents learn chute allocation policies resilient to adversarial induction rate shifts by optimizing for worst-case performance across distribution groups.
- The framework integrates group Distributionally Robust Optimization (DRO) into Multi-Agent Reinforcement Learning (MARL) to handle uncertainty in package induction patterns derived from historical data groups.
- A Contextual Bandit (CB)-based predictor efficiently identifies the worst-case induction distribution group for each state-action pair, reducing the computational complexity of training compared to exhaustive search methods.


---


#### 11th March 2025


[ReviewAgents: Bridging the Gap Between Human and AI-Generated Paper Reviews](http://arxiv.org/abs/2503.08506v1)

- ReviewAgents: introduces multi-agent framework with Reviewer- and Area Chair-Agents, utilizing Papers as input and producing Meta Review as output for emulating human peer review process.
- Reviewer Agent generates structured review comments, while Area Chair Agent synthesizes meta-review from multiple reviewer comments, aiming to align with human review behavior.
- Framework employs relevant-paper-aware training and structured reasoning (Summarization, Analysis, Conclusion) to enhance review comment generation and reduce biases inherent in single LLM reviews.


---


[CoLMDriver: LLM-based Negotiation Benefits Cooperative Autonomous Driving](http://arxiv.org/abs/2503.08683v1)

- CoLMDriver (Cooperative Language-Model-based Driver): introduces a full pipeline system for cooperative autonomous driving, incorporating VLM-based Intention Planner for high-level goals, Dynamic Graph Grouping for agent selection, and LLM-based Negotiator with Actor/Critic for language-based consensus.
- CoLMDriver framework utilizes parallel pipelines with high-level guidance and low-level planning, integrating Perception Module for environmental understanding and Intention-guided Waypoint Planner with Control Module for real-time execution based on Sensor Data.
- CoLMDriver employs Negotiation Quality Evaluator and Environment awareness to refine driving strategies through iterative feedback, enhancing safety and efficiency in multi-agent interactive scenarios by leveraging language-based communication.


---

[EMMOE: A Comprehensive Benchmark for Embodied Mobile Manipulation in Open Environments](http://arxiv.org/abs/2503.08604v1)

- HOMIEBOT: introduces a hierarchical framework for embodied mobile manipulation, integrating LLM (Large Language Model) for high-level planning, Word Embedding Layer, Encoder Zoo, Share Projection for input processing, Replan for adaptation, Low Level Execution for action, Perception for environment understanding, and Memory for context.
- The framework decomposes tasks into high-level planning and low-level execution, utilizing perception and memory for real-time feedback and adaptation in open environments.
- HOMIEBOT's hierarchical design and component integration address challenges in long-horizon tasks and complex environments, offering a robust agent architecture for embodied AI.


---

[GTR: Guided Thought Reinforcement Prevents Thought Collapse in RL-based VLM Agent Training](http://arxiv.org/abs/2503.08525v1)

- GTR (Guided Thought Reinforcement): introduces a framework integrating Thought Guidance, Thought Dataset, Cross Entropy Loss, SFT, PPO, RL Finetune, VLM Agent, Corrector Model, Game Env, Data Buffer, PPO Loss, and Reward to enhance VLM agent training by incorporating automated thought correction with reinforcement learning.
- Guided Thought Reinforcement framework leverages Supervised Fine-Tuning for thought tokens and Proximal Policy Optimization for action tokens, enabling simultaneous training of reasoning and action within a Reinforcement Learning fine-tuning process.
- The framework addresses thought collapse in Vision-Language Model agents by using a Corrector Model to provide Thought Guidance, thereby improving decision-making capabilities and overall performance in complex visual tasks.


---


[Seeing and Reasoning with Confidence: Supercharging Multimodal LLMs with an Uncertainty-Aware Agentic Framework](http://arxiv.org/abs/2503.08308v1)

- SRICE (Seeing and Reasoning with Confidence): introduces a training-free multimodal reasoning framework, with Tool call and calibration-, Reasoning: ROI selection-, ROI extraction- and Reasoning: Final answer generation-components, using Uncertainty Score-component, that integrates external vision models with uncertainty quantification into a Multimodal Large Language Model for enhanced visual reasoning.
- SRICE framework employs a two-stage process, initially calibrating external tool outputs and selecting regions of interest autonomously, and subsequently generating a refined answer through chain-of-thought reasoning based on uncertainty estimation.
- The framework leverages conformal prediction for uncertainty quantification, ensuring reliable tool utilization and enhancing the trustworthiness of the final answer in multimodal tasks.


---

[General-Purpose Aerial Intelligent Agents Empowered by Large Language Models](http://arxiv.org/abs/2503.08302v1)

- AIA Framework (Aerial Intelligent Agents Framework): introduces a two-stage approach with user prompt, DeepSeek R1 (LLM for task planning), user check, sensors, Llama 3 (VLM and LLM for execution), perception model, state estimation and mapping, waypoints, flight control unit, and files, for general-purpose aerial tasks.
- The framework integrates LLM-based deliberative planning with reactive control modules for autonomous UAV operation in open environments, utilizing onboard edge computing.
- This architecture enables bidirectional communication between high-level task planning and low-level reaction pipelines, facilitating complex mission execution in communication-constrained scenarios.


---

[A Cascading Cooperative Multi-agent Framework for On-ramp Merging Control Integrating Large Language Models](http://arxiv.org/abs/2503.08199v1)

- CCMA (Cascading Cooperative Multi-agent) framework: introduces a hierarchical multi-agent system for on-ramp merging, integrating Individual-level Decision-making Agent, Region-level Decision-Making Agent, Global-level Decision-making Agent, Vehicle Cooperate Prompt, Reward Prompt, Reward Function, Retrieval-augmented Generation, LoRA, MMLMs, Database, Environment, Observation, Critical Thinking, Reflection, Inference Range, Mainlane Aggressive Strategy, Mainlane Conservative Strategy, Update Agents Weights, Loss, Output, Prediction, Steps, Intent Actions, Drive Style, JSON Data, Goal Analysis, Vehicle Specific Analysis, Action Prioritization, and Final Decision to enhance autonomous driving in complex scenarios.
- CCMA framework employs RL for individual agent actions, fine-tuned LLM for regional cooperation utilizing prompts and semantic reasoning, and Retrieval-augmented Generation for global reward optimization, achieving improved merging success rates.
- The framework's hierarchical design and integration of LLMs with RL enable dynamic adaptation to varying traffic conditions and driving styles, leading to more efficient, safe, and human-like autonomous driving behaviors.


---

[Guess What I am Thinking: A Benchmark for Inner Thought Reasoning of Role-Playing Language Agents](http://arxiv.org/abs/2503.08193v1)

- MIRROR (Memory Integration and Role Reasoning with Observation Reflection): introduces memory recall, theory of mind thinking, and reflection & summarization components for character inner thought generation.
- MIRROR framework retrieves memories, predicts reactions of related objects, and synthesizes results to generate character inner thoughts based on scenario.
- MIRROR enhances role-playing agents by enabling structured reasoning and improving understanding of character motivations for complex tasks.


---

[Privacy-Enhancing Paradigms within Federated Multi-Agent Systems](http://arxiv.org/abs/2503.08175v1)

- EPEAgents (Embedded Privacy-Enhancing Agents): introduces privacy-aware collaborative framework with EPEAgent, Agents, User Profiles, Task/Query, Iteration, Privacy Preservation, Information theft, and Refuse to answer components.
- EPEAgents framework employs intermediary EPEAgent to filter data flow between Agents based on User Profiles and Task/Query within iterative process, aiming for Privacy Preservation and preventing Information theft.
- This approach ensures task-relevant and agent-specific information sharing, integrating into Retrieval-Augmented Generation and context retrieval stages for enhanced privacy in multi-agent systems.


---

[FilmComposer: LLM-Driven Music Production for Silent Film Clips](http://arxiv.org/abs/2503.08147v1)

- FilmComposer: introduces a framework for LLM-driven music production for silent films, with Visual Processing (processes film clips), Rhythm-Controllable MusicGen (generates rhythm-controlled music), and Multi-Agent Assess, Arrange and Mix (multi-agent system for music production) modules.
- FilmComposer framework uses Visual Processing module with LLM-Vision (vision language model) and CR(hythm)T (rhythm transformer) to extract visual cues, Rhythm-Controllable MusicGen module with Rhythm Conditioner (conditions music on rhythm) and Musicgen Decoder (decodes music from conditions) to generate melody, and Multi-Agent Assess, Arrange and Mix module with Assess Agent (evaluates musicality) and Mix Agent (performs audio mixing) to refine music.
- FilmComposer framework simulates musician workflow by integrating modules for visual analysis, rhythm-aware music composition, and multi-agent based arrangement and mixing, aiming for high-quality, musically rich, and film-synchronized music generation.


---

[LLM4MAC: An LLM-Driven Reinforcement Learning Framework for MAC Protocol Emergence](http://arxiv.org/abs/2503.08123v1)

- LLM4MAC (LLM-Driven Reinforcement Learning Framework for MAC Protocol Emergence): introduces a framework with Decision Maker, Large Language Model, Functional Alignment, and UDTS Environment, for MAC protocol emergence using reinforcement learning and language models.
- The framework utilizes a Decision Maker comprising Unified Policy Fusion and Fragmented Policy to manage UE Action Candidate and BS Action Candidate, while employing PPO-based Functional Alignment within a Large Language Model with Critic and Value Head for optimization.
- Action Interpreter components facilitate communication between the Large Language Model and UDTS Environment, which includes Dedicated PDCCH-PUCCH, Shared PUSCH, dPDU, UCM, DCM, BS, UE, Dynamic UE, and SIE Prompt Formulation with UEO to BS Query, BS to UEO Query, Observation Prompt, and Entity Identifier Prompt for structured interactions.


---

[AI-native Memory 2.0: Second Me](https://arxiv.org/abs/2503.08102v1)

- SECOND ME: introduces a hybrid architecture with User, Device, Second Me, Agent Model, and layered memory (L0, L1, L2) to provide personalized AI memory system.
- SECOND ME acts as context provider and intermediary, utilizing inner loop for layer integration and agent model with reasoning, knowledge, tools, experts, and internet for responses.
- The framework enhances memory management through LLM-based parameterization, enabling structured organization, contextual reasoning, and adaptive knowledge retrieval for seamless user interactions.


---

[In Prospect and Retrospect: Reflective Memory Management for Long-term Personalized Dialogue Agents](http://arxiv.org/abs/2503.08026v1)

- RMM (Reflective Memory Management): introduces a novel mechanism for long-term dialogue agents, integrating Prospective Reflection and Retrospective Reflection components.
- Prospective Reflection: tackles fixed granularity by summarizing dialogue histories into topic-based memory structures for future retrieval, while Retrospective Reflection addresses fixed retrievers by refining retrieval online using LLM-generated attribution signals.
- The framework components Memory Bank, Retriever, Reranker, and LLM work together to achieve efficient memory management and adaptive retrieval for personalized dialogue responses.


---

#### 10th March 2025

[MAGNET: Multi-turn Tool-use Data Synthesis and Distillation via Graph Translation](http://arxiv.org/abs/2503.07826v1)

- MAGNET (Multi-turn function-cAlling data synthesis with Graph Translation): introduces a framework for synthesizing multi-turn tool-use data, incorporating Function Collection, Local Dependency Graph, Function Signature Path, Enhanced Function Signature Path, Back-and-Forth Translation, Positive Trajectories, Negative Trajectories, Teacher Model, and Student Model.
- MAGNET framework utilizes a graph-based approach to construct function signature paths and context distillation with teacher and student models to generate positive and negative training trajectories.
- The framework aims to improve function calling capabilities of LLM agents in multi-turn conversations by generating high-quality training data and addressing challenges like nested function calls and long dependencies.


---

[Fully Autonomous Programming using Iterative Multi-Agent Debugging with Large Language Models](http://arxiv.org/abs/2503.07693v1)

- SEIDR (Synthesize, Execute, Instruct, Debug, and Repair): introduces multi-agent iterative framework employing language models for program synthesis and debugging, utilizing SYNTHESIZE, EXECUTE, INSTRUCT, DEBUG, and RANK Agents along with associated components.
- SEIDR framework iteratively refines program candidates through feedback from code execution and test failures, incorporating language models for synthesis, debugging, and instruction generation, guided by input-output pairs and task descriptions.
- The framework explores repair-replace trade-off strategies and parent selection algorithms to overcome near-miss syndrome in program synthesis, aiming for fully autonomous programming with large language models.


---

[MEDAGENTSBENCH: Benchmarking Thinking Models and Agent Frameworks for Complex Medical Reasoning](http://arxiv.org/abs/2503.07459v1)

- MEDAGENTSBENCH: introduces benchmark evaluating medical reasoning of models through multi-agent collaboration, zero-shot decision making, dynamic multi-agent collaboration, agentic workflow generation, prompt optimization and self-supervision.
- MEDAGENTSBENCH is designed to assess complex medical reasoning requiring deep domain expertise and multi-step processes, utilizing established medical datasets and adversarial filtering.
- MEDAGENTSBENCH framework facilitates analysis of performance, cost and inference time trade-offs for various models and agent-based methods in medical question answering tasks.


---

[LLMs syntactically adapt their language use to their conversational partner](http://arxiv.org/abs/2503.07457v1)

- Framework name: introduces an approach to investigate syntactic adaptation in LLMs, with LLM Agents (conversational agents using GPT-4o), Language Personas (varied language use prompts), LLM Conversations (agent-agent dialogues), PRIME and TARGET Split (conversation sections for analysis), Syntactic Parser (extracts syntactic rules), Context-Free Production Rules (parsed syntactic structures), SameConv Variable (same/different conversation indicator), Rule Frequency (rule occurrence count), Rule Set Size (number of unique rules), GLMM Analysis (statistical mixed-effects model), Jensen-Shannon Divergence (distribution distance metric), Switchboard Corpus (human conversation baseline), GPT Corpus (LLM conversation dataset), and Bootstrapping (variance estimation method).
- The approach analyzes syntactic adaptation by comparing rule distributions in PRIME and TARGET sections of LLM conversations, using Jensen-Shannon Divergence to quantify syntactic similarity changes.
- The study demonstrates that LLMs exhibit syntactic adaptation similar to humans, suggesting implicit learning of conversational partner's syntactic patterns.


---

[Dynamic Path Navigation for Motion Agents with LLM Reasoning](http://arxiv.org/abs/2503.07323v1)

- LLM Navigator: introduces a system for autonomous path navigation using LLMs, with floor plan representation, spatial encoding, agents, environment constraints, and motion generation agent.
- The system utilizes LLM Navigator to generate collision-free trajectories for single or multiple agents in dynamic environments, considering spatial reasoning and obstacle avoidance.
- This approach enables zero-shot spatial reasoning and generalizes to complex scenarios, offering a training-free method for dynamic path planning and humanoid motion generation.


---


[Experimental Exploration: Investigating Cooperative Interaction Behavior Between Humans and Large Language Model Agents](http://arxiv.org/abs/2503.07320v1)

- Experimental Framework: introduces Participants interacting in Prisoner's Dilemma Game with LLM Agent, Rule-based AI Agent, and Purported Human Agent within Experimental Setup, assessed via Questionnaires and Interviews.
- This framework explores human cooperative behavior variations influenced by agent characteristics and participant gender in competitive settings.
- The study offers insights into human-AI competitive dynamics, informing future AI agent design and human-AI collaboration strategies.


---

[Automated Movie Generation via Multi-Agent CoT Planning](http://arxiv.org/abs/2503.07314v1)

- MovieAgent (Automated Movie Generation via Multi-Agent CoT Planning): introduces multi-agent framework with Director-, Scene Plan- and Shot Plan-Agents employing CoT-reasoning, using Script Synopsis and Character Bank as input, to generate Script Breakdown, Scene Planning, Shot List Creation, and finally Plot to Video and Audio Generation.
- MovieAgent framework simulates hierarchical real-world movie production, automating narrative structuring, scene composition and shot design for long-form video generation.
- The framework enhances narrative coherence, character consistency, and cinematic quality in generated videos by decomposing filmmaking process into specialized agent roles and structured reasoning steps.


---

[DatawiseAgent: A Notebook-Centric LLM Agent Framework for Automated Data Science](http://arxiv.org/abs/2503.07044v1)

- DatawiseAgent (notebook-centric LLM agent framework): introduces FST-based multi-stage design for automated data science, orchestrating DFS-like planning, incremental execution, self-debugging, and post-filtering stages with unified interaction representation using markdown and executable code cells, and memory.
- This framework leverages notebook design and adaptive strategies, enabling flexible and adaptive automation of data science tasks by exploring solution space, using real-time feedback, correcting errors, and pruning information.
- DatawiseAgent enhances reliability and efficiency in data science workflows by integrating self-debugging and post-filtering modules, addressing limitations of existing LLM-based approaches in comprehensive end-to-end support.


---

[Combating Partial Perception Deficit in Autonomous Driving with Multimodal LLM Commonsense](http://arxiv.org/abs/2503.07020v1)

- LLM-RCO (LLM-Guided Resilient Control Override): introduces framework using Hazard Inference Module, Short-term Motion Planner, Action Condition Verifier, and Safety Constraint Generator to enhance autonomous driving safety during perception deficits.
- LLM-RCO framework utilizes Observation, Navigation, LIDAR, and Camera Frames as inputs for Planning Actions and Acting Action, with Re-Planning capability for dynamic adjustments.
- LLM-RCO improves driving performance by enabling proactive and context-aware control actions, overriding conventional conservative safety protocols.


---

[Toward Multi-Session Personalized Conversation: A Large-Scale Dataset and Hierarchical Tree Framework for Implicit Reasoning](http://arxiv.org/abs/2503.07018v1)

- TACITREE (Hierarchical Tree Framework): introduces hierarchical tree framework, with Persona Hierarchy, Fact Clustering, Raw Conversation and LLM Retrieval-components, where framework structures conversation history for efficient retrieval.
- TACITREE framework organizes long-term conversation history into hierarchical structure, enabling level-based retrieval of implicit knowledge.
- This approach reduces search space and improves retrieval efficiency by clustering and summarizing conversation facts.


---

[ProjectEval: A Benchmark for Programming Agents Automated Evaluation on Project-Level Code Generation](http://arxiv.org/abs/2503.07010v1)

- ProjectEval: introduces a benchmark for automated evaluation of project-level code generation, with Input-, Test Suite- and Canonical Solution-components.
- ProjectEval simulates user interaction for execution-based evaluation and uses code similarity for objective assessment.
- ProjectEval enhances explainability by offering three input levels and detailed evaluation metrics for programming agents.


---

[DynTaskMAS: A Dynamic Task Graph-driven Framework for Asynchronous and Parallel LLM-based Multi-Agent Systems](http://arxiv.org/abs/2503.07675v1)

- DynTaskMAS (Dynamic Task Graph-driven Framework for Asynchronous and Parallel LLM-based Multi-Agent Systems): introduces a novel framework for asynchronous parallel LLM-based multi-agent systems using Input Task, Dynamic Task Graph Generator, Asynchronous Parallel Execution Engine, Semantic-Aware Context Management System, Adaptive Workflow Manager and LLM-based Agent components.
- DynTaskMAS framework employs Dynamic Task Graph Generator to decompose tasks into DAGs, Asynchronous Parallel Execution Engine for parallel execution, Semantic-Aware Context Management System for context sharing and Adaptive Workflow Manager for system optimization.
- The framework aims to enhance efficiency and adaptability in LLM-based multi-agent systems by addressing challenges in task decomposition, parallel processing, and context management through dynamic task orchestration.


---

[ReAgent: Reversible Multi-Agent Reasoning for Knowledge-Enhanced Multi-Hop QA](http://arxiv.org/abs/2503.06951v1)

- ReAgent (Reversible Multi-Agent Reasoning): introduces a reversible multi-agent framework with backtracking, comprising Execution-, Supervisory-, and Interaction-Layers, for knowledge-enhanced multi-hop question answering.
- ReAgent framework incorporates Decomposition-, Retrieval-, Validation-, and Aggregation-Agents within the Execution Layer, alongside Supervisor- and Controller-Agents in Supervisory Layer, and Persistent Log, Temporal Tracker, Messaging Channel in Interaction Layer.
- The framework facilitates error correction in multi-hop reasoning by enabling agents to backtrack and revise inferences based on detected conflicts or contradictory evidence, enhancing robustness and interpretability of QA outcomes.


---

[Beyond Code Generation: LLM-supported Exploration of the Program Design Space](http://arxiv.org/abs/2503.06911v1)

- PAIL: introduces an IDE integrating ConversationAgent (LLM chatbot for code interaction), DesignAgent (LLM agent suggesting design options), ReflectionAgent (LLM agent tracking design choices), Code Pane (code editor for program modification), Output Pane (program execution display area), Chat Pane (conversation history display), and Design Pane (design aid panel for questions/decisions) to support LLM-assisted program design exploration.
- This framework facilitates iterative program design by abstracting problem formulations and solutions, tracking design goals and requirements, and making implicit LLM decisions explicit.
- PAIL addresses challenges of user attention management and information overload inherent in LLM-assisted program design through its integrated component architecture.


---

[SafePlan: Leveraging Formal Logic and Chain-of-Thought Reasoning for Enhanced Safety in LLM-based Robotic Task Planning](http://arxiv.org/abs/2503.06892v1)

- SafePlan (SafePlan): introduces a multi-component framework, Prompt Sanity Check COT Reasoner, Societal Alignment Layer, Organizational Alignment Layer, Individual Alignment Layer, Invariant COT Reasoner, and Task Allocation Code Generation, for enhancing safety in LLM-based robotic systems by integrating formal logic and chain-of-thought reasoning.
- SafePlan framework decomposes natural language prompts into reasoning steps, utilizing Prompt Sanity Check COT Reasoner with Societal, Organizational, and Individual Alignment Layers to evaluate prompt safety before proceeding to Invariant COT Reasoner for generating and verifying safety conditions like invariants, preconditions, and postconditions, finally using Task Allocation Code Generation for robot task allocation.
- SafePlan framework aims to improve safety by systematically verifying natural language commands through multi-layered checks and logical formalization, contrasting with traditional LLM approaches that may overlook safety implications in robotic task planning.


---

[GUIDE-CoT: Goal-driven and User-Informed Dynamic Estimation for Pedestrian Trajectory using Chain-of-Thought](http://arxiv.org/abs/2503.06832v1)

- GUIDE-CoT (Goal-driven and User-Informed Dynamic Estimation for pedestrian Trajectory using Chain-of-Thought): introduces trajectory prediction framework leveraging visual prompts and chain-of-thought reasoning, incorporating scene image, visual prompt, history heatmap, semantic map, alpha compositing, visual condition, pretrained visual encoder, goal module, goal probability map, sampled chain-of-thought, LLM and trajectory components.
- GUIDE-CoT framework enhances pedestrian trajectory prediction by predicting pedestrian goals using visual prompts and subsequently generating trajectories towards these goals with chain-of-thought reasoning within a Large Language Model.
- The framework's goal-oriented visual prompt and chain-of-thought approach allows for controllable and adaptable trajectory generation, improving accuracy and user-guided modifications in pedestrian path prediction.


--- 

#### 9th March 2025

[AutoMisty: A Multi-Agent LLM Framework for Automated Code Generation in the Misty Social Robot](http://arxiv.org/abs/2503.06791v1)

- AutoMisty: introduces a multi-agent LLM framework for automated robot code generation, encompassing User, Task, AutoMisty Framework, Planner Agent, Action Agent, Touch Agent, Audiovisual Agent, Code Script, Execute, Misty Robot, and Memory.
- AutoMisty framework utilizes specialized agents for task planning, assignment, problem-solving, and code synthesis, incorporating self-reflection and human-in-the-loop mechanisms for iterative refinement and adaptation to user preferences.
- The framework's architecture includes Planner, Action, Touch, and Audiovisual Agents, each with internal components like Drafter, Designer, Critic, and Memory, leveraging optimized Misty APIs to generate executable code for the Misty robot.


---

[Delusions of Large Language Models](http://arxiv.org/abs/2503.06709v1)

- Delusion Analysis Methodology: introduces a methodology for analyzing LLM delusions, employing Logits-based Belief, Verbalized Belief, and Consistency Belief components.
- This methodology uses uncertainty estimation as proxy for model belief, categorizing incorrect LLM outputs into hallucinations or delusions based on belief thresholds.
- The framework differentiates delusions from hallucinations by quantifying belief through logits, verbalized confidence, and consistency, revealing delusions' high-confidence nature.


---

[EXPLORING LLM AGENTS FOR CLEANING TABULAR MACHINE LEARNING DATASETS](http://arxiv.org/abs/2503.06664v1)

- Cleaning Agent Framework: introduces a framework for systematic LLM-based data cleaning using IPython and Performance Evaluation tools within iterative process guided by chat history.
- The framework employs LLM agent to identify and rectify dataset errors through IPython code execution and performance feedback from Performance Evaluation tool.
- This research investigates LLMs effectiveness in enhancing data quality by error detection and correction, keeping training pipeline and feature engineering fixed.


---

[Advancing AI Negotiations: New Theory and Evidence from a Large-Scale Autonomous Negotiations Competition](http://arxiv.org/abs/2503.06416v1)

- International AI Negotiations Competition: introduces agent warmth, agent dominance, value claimed, counterpart subjective value, points earned, value created, and deal reached, where competition investigates AI negotiation strategies and outcomes.
- The competition framework evaluates the impact of agent warmth and dominance on negotiation success across distributive and integrative scenarios.
- Findings suggest warmth enhances deal-making, while dominance impacts value claiming, highlighting nuances in AI negotiation dynamics.


---

[Performant LLM Agentic Framework for Conversational AI](http://arxiv.org/abs/2503.06410v1)

- PAF (Performant Agentic Framework): introduces a novel system for conversational AI, utilizing Navigation Map (workflow graph structure) composed of Nodes (workflow steps) and Edges (conditional transitions), guided by a LLM Agent (reasoning and response generation) informed by Conversation History (interaction record) and employing Vector-Based Node Search (semantic node selection) or LLM as Judge (fallback node selection) based on Prompt (instructional messages) and Threshold (confidence level), triggering Actions (node triggered operations) using Vectorized Instructions (precomputed instruction embeddings).
- Performant Agentic Framework (PAF) balances accuracy and latency in conversational workflows by combining LLM-based reasoning with vector scoring for efficient node selection within the Navigation Map (workflow graph structure), reducing reliance on large context windows and optimizing computational steps.
- The framework, Performant Agentic Framework (PAF), addresses limitations of existing agentic systems by removing extra validation iterations, improving alignment through step-by-step logic, reducing context window size, and introducing vector-based scoring for semantic similarity in conversational AI applications.


---

#### 8th March 2025

[Towards Conversational AI for Disease Management](http://arxiv.org/abs/2503.06074v1)

- AMIE (Articulate Medical Intelligence Explorer): introduces a system designed for clinical management and dialogue, utilizing components like Vignette Generator, Dialogue Agent, and Mx Agent, to incorporate reasoning over disease evolution, patient encounters, and medication prescription.
- AMIE framework employs a dual-agent system, featuring a Dialogue Agent for patient interaction and a Management Reasoning (Mx) Agent for evidence-based management plan generation, both leveraging LLMs and clinical guidelines to ensure reasoning grounded in authoritative knowledge.
- The system refines its capabilities through simulated dialogue environments and reinforcement learning, and its performance is rigorously evaluated in a multi-visit remote OSCE study, demonstrating non-inferiority to primary care physicians in management reasoning and outperformance in treatment preciseness and guideline alignment.


---

[DSGBench: A Diverse Strategic Game Benchmark for Evaluating LLM-based Agents in Complex Decision-Making Environments](http://arxiv.org/abs/2503.06047v1)

- DSGBench (Diverse Strategic Game Benchmark): introduces a comprehensive benchmark platform with Environment, Capability Metrics, Decision-Tracking and Behavior Analysis, Observation to Prompt, Response to Action, LLM-based Agent, Opponent Agent, Metrics, Analyze, Collect, Async and Sync to evaluate strategic decision-making of LLM-based agents in complex games.
- DSGBench offers diverse strategic games, fine-grained metrics, and decision trajectory analysis for in-depth assessment of agent capabilities in long-term strategic planning and real-time decision-making.
- The benchmark facilitates detailed analysis of agent behavior patterns and strategy changes through observation-to-prompt and response-to-action loops in dynamic multi-agent scenarios.


---



#### 7th March 2025

[Enhancing Reasoning with Collaboration and Memory](http://arxiv.org/abs/2503.05944v1)

- Collaborative Memory Reasoning Framework: introduces a system combining reasoning styles, multi-agent collaboration, and memory banks to enhance LLM reasoning performance.
- This framework employs varied-context agents and a summarizer agent, utilizing frozen and learned memory banks with different retrieval mechanisms for improved performance.
- The system systematically studies the contribution of various methods to LLM reasoning across different tasks, highlighting the effectiveness of random exemplar selection and the role of memory in diverse scenarios.


---


[A Survey of Large Language Model Empowered Agents for Recommendation and Search: Towards Next-Generation Information Retrieval](http://arxiv.org/abs/2503.05659v1)

- LLM Agents (Large Language Model Agents): introduces Perception-, Control- and Action-Modules, incorporating Storage, Memory Unit, Knowledge Database, Collecting, Processing, Decision, Planning Unit, Reasoning Unit, Embodiment, Toolbox, and Feedback components for autonomous computing entities.
- LLM Agents utilize Perception Module to obtain information, Control Module for analysis and strategy, and Action Module to implement decisions, equipped with Storage for memory and knowledge, and Toolbox for external tool access.
- These agents enhance traditional systems by integrating multimodal inputs, demonstrating improved understanding, adaptability, and creative thinking for complex tasks in various domains.


---

[Symbolic Mixture-of-Experts: Adaptive Skill-based Routing for Heterogeneous Reasoning](https://arxiv.org/abs/2503.05641v1)

- SYMBOLIC-MOE (Symbolic Mixture-of-Experts): introduces a symbolic Mixture-of-Experts framework with preprocessing (initial framework setup) and inference-time (reasoning execution) stages for adaptive skill-based recruitment (dynamic expert selection) in heterogeneous reasoning tasks.
- SYMBOLIC-MOE framework incorporates model profile creation (model skill assessment) and aggregator selection (best aggregator choice) in preprocessing, and utilizes router (skill-based expert routing), experts (specialized LLMs), and aggregator (output synthesizer) components during inference.
- The framework employs batch inference mechanism (efficient expert integration) and skill-based routing (expert selection based on skills) to achieve efficient and performant heterogeneous reasoning by dynamically selecting and combining specialized pre-trained language models.


---

[GEMA-Score: Granular Explainable Multi-Agent Score for Radiology Report Evaluation](http://arxiv.org/abs/2503.05347v1)

- GEMA-Score (Granular Explainable Multi-Agent Score): introduces a multi-agent framework with Entity Extraction-, Objective Clinical Accuracy-, Subjective Expressiveness Evaluation- and Score Evaluation-Agents, alongside Multi-agent Evaluation System and Scoring and Summary Stage, for comprehensive radiology report evaluation.
- GEMA-Score framework assesses both objective clinical accuracy using NER-F1 metrics and subjective expressiveness encompassing completeness, readability, and clinical utility of generated radiology reports.
- The framework aims to provide granular, interpretable, and reliable evaluation of radiology reports, overcoming limitations of existing metrics by employing specialized agents for distinct evaluation tasks.


---

[MM-StoryAgent: Immersive Narrated Storybook Video Generation with a Multi-Agent Paradigm across Text, Image and Audio](http://arxiv.org/abs/2503.05242v1)

- MM-StoryAgent: introduces a multi-agent framework with Story-, Image-, Speech-, Sound-, Music- and Video Compose-Agents to generate immersive narrated storybook videos.
- This framework employs Expert, Amateur Writer, Outline Writer, Chapter Writer, and Reviewer agents within the Story Agent for multi-stage story writing and modality-specific agents with Prompt Revisers for asset generation.
- MM-StoryAgent enhances story quality and immersive experience by integrating multi-channel audio and role-consistent images, offering a flexible platform for storybook video creation.


---

[ORANSight-2.0: Foundational LLMs for O-RAN](http://arxiv.org/abs/2503.05200v1)

- ORANSight-2.0 (O-RAN Insights): introduces RANSTRUCT, a Retrieval-Augmented Generation-based instruction-tuning framework, for creating fine-tuning datasets, utilizing pre-trained models and QLoRA for efficient adaptation, evaluated by ORANBench and srsRANBench.
- ORANSight-2.0 framework employs RANSTRUCT, which includes Recursive Splitter, Embedding Generator, Question Generator, and Answer Generator, to process O-RAN Specifications and srsRAN Code Files, building FAISS Database and Questions Database for dataset generation.
- ORANSight-2.0 aims to bridge the gap for domain-specific foundational models in O-RAN by providing open-source alternatives and demonstrating superior performance compared to closed-source models in O-RAN and code-related tasks.


---

[A Comprehensive LLM-powered Framework for Driving Intelligence Evaluation](http://arxiv.org/abs/2503.05164v1)

- LLM-powered Framework (LLM-powered Driving Evaluation Framework): introduces a comprehensive approach for evaluating driving behavior intelligence, integrating real-world driving data, simulated scenarios, knowledge graph, RAG, and LLM evaluation system.
- This framework assesses safety, intelligence, and comfort through distinct evaluation modules, culminating in a comprehensive evaluation conclusion.
- The framework leverages driving context derived from diverse data sources to enable nuanced and accurate assessments of autonomous driving performance.


---

[MASTERMINDEVAL: A SIMPLE BUT SCALABLE REASONING BENCHMARK](http://arxiv.org/abs/2503.05891v2)

- MASTERMINDEVAL: introduces a deductive reasoning benchmark employing Evaluator Class (game logic implementation) and LLM (codebreaker agent) to evaluate language model reasoning capabilities in Mastermind game.
- It features agentic and deductive evaluation paradigms to assess strategic gameplay and reasoning respectively.
- The benchmark aims to address limitations of existing benchmarks by offering scalability and interpretability in reasoning assessment.


---


#### 6th March 2025

[Bridging the AI Adoption Gap: Designing an Interactive Pedagogical Agent for Higher Education Instructors](http://arxiv.org/abs/2503.05039v1)

- Two-Phase Study Design with Pedagogy Experts: introduces a two-phase study design with pedagogy experts, with Interaction Design, Formative Study, Refine 2 Storyboard Design, LLM-Generated Suggestions Evaluations, Refine Prompts to Generate Answers, Collect and Generate Answers, ChatGPT with RAG, Participatory Design, Activity 1: Discussion of 2 Storyboards, Activity 2: Discussion of 5 QA pairs, and Post-Study Rating of 20 QA pairs.
- This study employs formative expert interviews and participatory design sessions to investigate interactive pedagogical agents for instructors.
- The framework utilizes ChatGPT with Retrieval-Augmented Generation to produce teaching suggestions, which are then evaluated by pedagogy experts.


---

[SAFEARENA: Evaluating the Safety of Autonomous Web Agents](http://arxiv.org/abs/2503.04957v1)

- SAFEARENA: introduces benchmark for evaluating web agent safety, with User Intent Input, Web Agent, Web Environment, Action Execution, Observation, and Agent Risk Assessment (ARIA) framework.
- SAFEARENA assesses agent behavior across harm categories on realistic websites, evaluating agent's capability to perform harmful tasks.
- SAFEARENA framework highlights urgent need for safety alignment procedures for web agents, providing crucial benchmark for research.


---

[Quantifying the Reasoning Abilities of LLMs on Real-world Clinical Cases](http://arxiv.org/abs/2503.04691v1)

- MedR-Bench Evaluation Framework: introduces a framework for evaluating medical LLMs, with assessment recommendation, diagnostic decision, and treatment planning stages, incorporating Reasoning Evaluator.
- MedR-Bench Evaluation Framework: includes Reasoning Evaluator, an agentic system for automated reasoning evaluation using structured steps and reference verification against medical knowledge.
- MedR-Bench Evaluation Framework: comprehensively assesses LLMs' clinical performance across patient journey stages, utilizing metrics for reasoning and final generation quality.


---


[SURVEYFORGE: On the Outline Heuristics, Memory-Driven Generation, and Multi-dimensional Evaluation for Automated Survey Writing](https://arxiv.org/abs/2503.04629v1)

- SURVEYFORGE: introduces an automated survey writing framework, with Heuristic Outline Generation-stage (outline generator), SANA (scholar agent), and Content Generation-stage (content creation phase), leveraging Paper Database (article database), Survey Database (outline database), TOPIC Database (topic information), Literature Database (literature repository), Multimodal Large Language Models (text processing model), Embodied AI (embodiment AI), AI for Science (scientific AI), RAG (retrieval augmentation), LLM (content model), and LLM-Parallel (parallel content generation) to produce Final Survey (final paper) from Input Topic (user research area) and evaluate using Survey Benchmark (evaluation dataset) during Refinement & Evaluation (survey improvement phase).
- This framework employs a two-stage process, first generating a detailed outline using heuristic learning from existing surveys and relevant literature, then populating the outline with content retrieved and refined by a memory-driven scholar navigation agent, ensuring both structural coherence and high-quality references.
- SURVEYFORGE aims to bridge the quality gap between human-written and AI-generated surveys by focusing on outline quality, reference relevance, and content coherence, demonstrating improved performance over existing automated survey generation methods and setting a new benchmark for quality and reliability in this domain.


---

[The Next Frontier of LLM Applications: Open Ecosystems and Hardware Synergy](http://arxiv.org/abs/2503.04596v1)

- Three-Layer Decoupled Architecture: introduces a three-layer architecture for LLM applications, with Application Layer (app settings management), Protocol Layer (secure session control), and Hardware Layer (hardware resource management) to improve modularity and cross-platform adaptability.
- The architecture decouples application logic, protocol handling, and hardware execution, enabling efficient task orchestration and secure communication across heterogeneous platforms.
- This layered design enhances scalability, interoperability, and hardware efficiency for LLM applications by separating concerns and standardizing interfaces between layers.


---

[ToolFuzz - Automated Agent Tool Testing](http://arxiv.org/abs/2503.04479v1)

- TOOLFUZZ: introduces a method for automated tool documentation testing with taint fuzzer, LLM prompt generation, tool runtime error detection, LLM prompt template generation, LLM synonymous prompt generation, I/O consistency checks, and LLM correctness evaluation to improve agent and tool reliability.
- This framework identifies under-, over-, and ill-specified documentation errors by generating diverse natural language queries and performing cascading consistency checks.
- TOOLFUZZ significantly enhances the reliability of LLM agents by automating the detection of tool documentation errors, which are critical for effective tool utilization.


---

[AgentSafe: Safeguarding Large Language Model-based Multi-agent Systems via Hierarchical Data Management](http://arxiv.org/abs/2503.04392v1)

- AgentSafe: introduces ThreatSieve (communication security verification) and HierarCache (adaptive memory management) to enhance multi-agent system security.
- AgentSafe classifies information by security levels, using Permission Control (communication level regulation) and Message Legitimacy Evaluation (sender identity verification) within ThreatSieve, and Junk Memory (irrelevant data storage) within HierarCache.
- AgentSafe framework components Memory (agent information storage) and hierarchical information management aim to prevent unauthorized access and data breaches in LLM-based multi-agent systems.


---

[Towards Autonomous Reinforcement Learning for Real-World Robotic Manipulation with Large Language Models](http://arxiv.org/abs/2503.04280v2)

- ARCHIE (Autonomous Reinforcement learning for Complex Human-Informed Environments): introduces unsupervised pipeline, with Initial conditions, Simulation, Define Agent's Task, Reward function, RL training, for automating robotic skill learning.
- ARCHIE leverages GPT-4 to generate reward functions and success criteria from natural language task descriptions, enabling one-shot RL training.
- ARCHIE's two-phase approach, Initialization and Autonomous Skill Learning, facilitates efficient and practical real-world robotic manipulation skill acquisition.


---

[Measuring temporal effects of agent knowledge by date-controlled tool use](http://arxiv.org/abs/2503.04188v1)

- ReAct+DCT (ReAct with Date-Controlled Tools): introduces tool-based out-of-sample testing framework with masked text, ranked webpage snippets, reasoning traces, LLM, surface web, search queries, and date-controlled tools for text completion.
- Framework evaluates temporal effects on agent knowledge by employing date-controlled web search to complete scientific abstracts.
- ReAct+DCT framework emphasizes dynamic agent evaluation considering temporal influence of tools and updates of external resources.


---

[KidneyTalk-open: No-code Deployment of a Private Large Language Model with Medical Documentation-Enhanced Knowledge Database for Kidney Disease](http://arxiv.org/abs/2503.04153v1)

- KidneyTalk-open: introduces a no-code medical LLM system integrating Document Parsing & Chunking, Knowledge Snippets Filtering, Semantic Embedding, Vector Database, Adaptive Retrieval and Augmentation Pipeline, Query Refinement Agent, Divergent Thinking Agent, and Answer Generation Agent.
- KidneyTalk-open system enhances medical question answering through document processing, knowledge retrieval, and multi-agent collaboration to improve accuracy and ensure privacy.
- The framework significantly reduces technical complexities for medical professionals to employ state-of-the-art open-source LLMs for secure medical question answering with enhanced documentation.


---

[DyCodeEval: Dynamic Benchmarking of Reasoning Capabilities in Code Large Language Models Under Data Contamination](http://arxiv.org/abs/2503.04149v1)

- DyCodeEval (Dynamic Code Evaluation): introduces a dynamic benchmarking method for code LLMs, with Scenario Proposer, Scenario Pool, Context Generator, Canonical Solution, Contexts, Prompt Rewriter, Orig Problem, New Problem, Validator, and LLM Agent as Verifier, to generate semantically diverse yet complexity-equivalent programming problems for evaluating reasoning capabilities under data contamination.
- DyCodeEval leverages LLM-based agents to automate the generation of varied problem contexts and includes a validation agent to ensure the consistency and correctness of newly created problems.
- The framework aims to address limitations of static benchmarks by dynamically creating diverse problems, mitigating data contamination risks and providing a more reliable evaluation of code LLMs' true reasoning abilities.


---

[InterChat: Enhancing Generative Visual Analytics using Multimodal Interactions](http://arxiv.org/abs/2503.04110v1)

- InterChat: introduces a multimodal generative visual analytics framework, with NL Input, Direct Manipulation, Intent Inference, Prompt Synthesizing, Response Processing, Visualization Rendering, Visual Connections, Interactive Visualizations, Multi-Agent LLM Architecture, Chain-of-Thought, Structured Prompts, and Vis. Generation, for enhancing user interaction and analytical depth.
- InterChat integrates direct manipulation with natural language via multi-agent LLM architecture to bridge user analytical intents and LLM-driven visualizations, improving interpretability and usability.
- By employing prompt engineering and contextual interaction linking, InterChat enhances accuracy and efficiency in complex visual analytics tasks, highlighting the potential of multimodal interactions in generative visual analytics.


---

[PokéChamp: an Expert-level Minimax Language Agent](http://arxiv.org/abs/2503.04094v1)

- PokéChamp (PokéChamp): introduces minimax agent leveraging LLMs, replacing modules such as Player Action Sampling, Opponent Modeling, and Value Function Estimation to enhance minimax tree search.
- PokéChamp framework incorporates Game Engine to Text, Approximate State Transition Heuristic, One Step Lookahead Prompt, Observation, and Historical Turns to utilize gameplay history and knowledge.
- PokéChamp framework effectively reduces search space and addresses partial observability in two-player competitive games without additional LLM training, relying on pre-existing LLM knowledge and game-theoretic algorithms.


---

#### 5th March 2025

[Pretrained LLMs as Real-Time Controllers for Robot Operated Serial Production Line](http://arxiv.org/abs/2503.03889v1)

- LLM-based control framework: introduces a three-layer architecture comprising Input, Processing, and Output Layers for real-time management of serial production lines using pretrained Large Language Models.
- arxiv_paper_framework_name: Input Layer defines static system parameters, Processing Layer manages dynamic decision elements, and Output Layer structures LLM-generated actions.
- arxiv_paper_framework_name: leverages LLMs to achieve adaptable, interpretable, and scalable control in manufacturing, outperforming traditional heuristics and approaching MARL performance without retraining needs.


---

[The MASK Benchmark: Disentangling Honesty From Accuracy in AI Systems](http://arxiv.org/abs/2503.03750v1)

- MASK (Model Alignment between Statements and Knowledge): introduces a benchmark to evaluate AI honesty by disentangling it from accuracy, with Pressure Prompt, Prompts for Eliciting Beliefs, Ground Truth Label, Extract proposition realizations, and Measure honesty and accuracy components.
- MASK benchmark measures honesty by comparing model statements under pressure to their elicited beliefs, and accuracy by comparing beliefs to ground truth labels.
- The benchmark utilizes a novel evaluation pipeline to directly measure when models lie by contrasting pressured statements with underlying beliefs, enabling targeted honesty interventions.


---


[A Practical Memory Injection Attack against LLM Agents](http://arxiv.org/abs/2503.03704v2)

- MINJA (Memory INJection Attack): introduces memory injection attack framework against LLM agents using indication prompt, bridging steps, and progressive shortening strategy.
- MINJA framework allows attacker to inject malicious records into agent memory through queries to influence agent behavior for victim user.
- Progressive shortening strategy refines indication prompt while preserving malicious reasoning steps in agent memory.


---


[MULTI-AGENT SYSTEMS POWERED BY LARGE LANGUAGE MODELS: APPLICATIONS IN SWARM INTELLIGENCE](http://arxiv.org/abs/2503.03800v1)

- LLM-MAST (LLM-Driven Multi-Agent Simulation Toolchain): introduces a toolchain integrating LLMs with NetLogo for multi-agent simulations, with environment encoding, python extension integration, LLM processing, decoding LLM output and agent action execution components.
- LLM-MAST: facilitates prompt-driven behavior generation in simulations by leveraging GPT-4o via OpenAI API for processing environmental data and generating agent actions.
- LLM-MAST: enables studying self-organizing processes and emergent behaviors in multi-agent environments by creating a closed-loop system between simulation and LLM.


---

[MAS-GPT: Training LLMs to Build LLM-based Multi-Agent Systems](https://arxiv.org/abs/2503.03686v1)

- MAS-GPT (Multi-Agent System - Generative Pre-trained Transformer): introduces a framework for generating query-specific multi-agent systems, including Query (user input question), MAS (generated multi-agent system), Answer (final response to query), Math Agent (agent for math tasks), Feedback Agent (agent providing feedback), Refine Agent (agent for answer refinement), and call_llm (function to call LLM).
- The framework simplifies MAS creation by training an LLM to generate executable MAS code in a single inference step, addressing inadaptability and high inference costs of existing methods.
- MAS-GPT framework utilizes a consistency-oriented data pipeline for training, enabling adaptability, efficiency, and generalization across diverse tasks and LLM backbones.


---

[Benchmarking LLMs and LLM-based Agents in Practical Vulnerability Detection for Code Repositories](http://arxiv.org/abs/2503.03586v1)

- JITVUL: introduces a benchmark for just-in-time vulnerability detection in code repositories, with vulnerability entry selection, target function extraction, and pairwise commits identification components.
- JITVUL: consists of vulnerability entry selection for CVE selection based on criteria, target function extraction to extract function and fix commit, and pairwise commits identification to identify vulnerability-introducing and fixing commits.
- JITVUL: enables pairwise evaluation for vulnerability detection using vulnerability-introducing and fixing commits.


---

[Human Implicit Preference-Based Policy Fine-tuning for Multi-Agent Reinforcement Learning in USV Swarm](http://arxiv.org/abs/2503.03796v2)

- RLHF (Reinforcement Learning with Human Feedback): introduces a method for fine-tuning MARL policies in USV swarms using human preference feedback on user-friendly trajectory data, which trains a reward model from a replay buffer to refine a base policy into a fine-tuned policy within a simulated environment.
- This approach uses agent-level feedback categorized into intra-agent, inter-agent, and inter-team types, and employs an LLM evaluator to validate feedback scenarios, addressing credit assignment challenges in multi-agent systems.
- The method aims to bridge the gap between model development and user preferences, enhancing adaptability and operational effectiveness of USV swarms by incorporating human insights through preference-based learning.


---

[Parallelized Planning-Acting for Efficient LLM-based Multi-Agent Systems](http://arxiv.org/abs/2503.03505v1)

- Parallelized Planning-Acting Multi-Agent Framework: introduces dual-thread architecture with centralized memory, planning thread, acting thread and skill library to enable concurrent planning and acting for efficient LLM-based multi-agent systems.
- The framework decouples LLM reasoning (planning thread) from action execution (acting thread) using action buffer and interruptible execution, enhancing real-time responsiveness in dynamic environments.
- Centralized memory with observation records, chat logs and action history facilitates efficient information sharing and coordination among agents, while skill library with DAG-based recursive task decomposition automates complex task execution.


---

[Collaborative Expert LLMs Guided Multi-Objective Molecular Optimization](http://arxiv.org/abs/2503.03503v1)

- MultiMol (collaborative large language model system): introduces collaborative agents, including data-driven worker agent, literature-guided research agent and RDKit, to guide multi-objective molecular optimization using training dataset curation, instruction tuning, prompt input, optimization and filter based on research.
- MultiMol employs data-driven worker agent to generate molecules and literature-guided research agent with web search and pick candidate based on characteristics to filter molecules based on scientific literature, utilizing LLM backbone and memory components.
- MultiMol framework achieves enhanced molecular optimization performance by combining capabilities of two specialized LLM agents and leveraging literature-derived insights for improved candidate selection and scaffold preservation.


---

[Open-Source Large Language Models as Multilingual Crowdworkers: Synthesizing Open-Domain Dialogues in Several Languages With No Examples in Targets and No Machine Translation](http://arxiv.org/abs/2503.03462v1)

- MOUD Generation Pipeline (Multilingual Open-domain Unnatural Dialogue Dataset): introduces pipeline with taxonomies, persona generation, common ground generation, conversation generation, and data evaluation for multilingual open-domain dialogue dataset synthesis.
- Pipeline leverages instruction-tuned LLMs to generate dialogues in multiple target languages without machine translation, enhancing language-specific nuances.
- MOUD pipeline addresses open-domain paradox by incorporating common ground and speech event type specification in generated dialogues.


---

[Unified Mind Model: Reimagining Autonomous Agents in the LLM Era](http://arxiv.org/abs/2503.03459v2)

- UMM (Unified Mind Model): introduces a cognitive architecture for autonomous agents, integrating Driver System, Central Processing, Specialist modules, and Large Language Model to mimic human-level cognitive abilities.
- UMM leverages Global Workspace Theory, structuring components hierarchically for efficient information processing and decision-making in complex tasks.
- The architecture facilitates the creation of advanced autonomous agents by enabling multi-modal perception, planning, reasoning, tool use, and learning capabilities.


---

[Taxation Perspectives from Large Language Models: A Case Study on Additional Tax Penalties](http://arxiv.org/abs/2503.03444v1)

- PLAT: introduces PLAT benchmark dataset, with Retrieval Augmentation-component for external knowledge access, Self-Reasoning-component for internal knowledge refinement, and Multi-Agent Collaboration-component for distributed task execution, to assess large language models' ability to predict legitimacy of additional tax penalties.
- PLAT benchmark dataset evaluates large language models' understanding of tax law in scenarios requiring more than just statute application, focusing on complex reasoning about real-world situations.
- PLAT benchmark and agent-based approach using retrieval, self-reasoning, and multi-agent methods aim to mitigate limitations of vanilla large language models in comprehensively understanding legal cases.


---

[SEOE: A Scalable and Reliable Semantic Evaluation Framework for Open Domain Event Detection](https://github.com/Lyfralston/SEOE)

- SEOE (Scalable and Reliable Semantic Evaluation framework for Open domain Event detection): introduces scalable, unconstrained extraction and semantic-level evaluation components for open domain event detection evaluation.
- SEOE framework addresses limitations of token-level evaluation by incorporating semantic understanding and benchmark scalability for improved ODED assessment.
- The framework utilizes LLMs to compute semantic F1-score, enhancing evaluation reliability and offering a more representative benchmark for real-world ODED scenarios.


---


[CITE BEFORE YOU SPEAK: ENHANCING CONTEXT-RESPONSE GROUNDING IN E-COMMERCE CONVERSATIONAL LLM-AGENTS](http://arxiv.org/abs/2503.04830v1)

- Citation Generation Paradigm: introduces a method for enhancing LLM agent responses with citations, using User Query, Retrieve, LLM Response, Source, and Evidence widgets.
- This paradigm improves response grounding and transparency by linking LLM answers to verifiable knowledge sources.
- The approach aims to build customer trust in conversational shopping agents by providing source attribution.


---

[Exploring the Potential of Large Language Models as Predictors in Dynamic Text-Attributed Graphs](http://arxiv.org/abs/2503.03258v1)

- GAD Framework (GraphAgent-Dynamic Framework): introduces multi-agent system leveraging collaborative LLMs for dynamic graph prediction, with Initial Agent, Local Summary Agents, Global Summary Agents, Knowledge Reflection Agent, Predictor Agent, Temporary Predictor Agent, Database, and Extraction components.
- GAD framework incorporates global and local summary agents to generate domain-specific knowledge and knowledge reflection agents for adaptive updates, maintaining unified architecture for dynamic graphs.
- This multi-agent approach addresses context length constraints and domain variability challenges inherent in dynamic graph prediction tasks, enhancing generalizability.


---


[MA-LoT: Multi-Agent Lean-based Long Chain-of-Thought Reasoning enhances Formal Theorem Proving](http://arxiv.org/abs/2503.03205v1)

- MA-LoT (Multi-Agent Lean-based Long Chain-of-Thought framework): introduces multi-agent framework for Lean4 theorem proving with LoT-Solver as Prover Agent, Lean Executor, LoT-Solver as Corrector Agent and NL-Planning CoT components.
- MA-LoT balances Natural Language reasoning and Formal Language verification in theorem proving using Long Chain-of-Thought approach, incorporating Error analysis components.
- MA-LoT framework utilizes LoT-TL pipeline to enable emergent formal reasoning capabilities in Large Language Models without requiring specific annotated data for Long CoT.


---

[DANGO: A Mixed-Initiative Data Wrangling System using Large Language Model](http://arxiv.org/abs/2503.03154v2)

- DANGO (A Mixed-Initiative Data Wrangling System using Large Language Model): introduces a mixed-initiative data wrangling system with Table Demo, Chatroom, and Memory components.
- DANGO synthesizes data wrangling scripts using Table Meta Data, DSL Plan, DSL Program, and Syntax Checker components.
- The framework includes Analysis Agent, Synthesis Agent, and Explanation Agent, and provides NL Explanation and Provenance for user understanding and validation.


---

[Levels of Spacecraft Autonomy](https://arxiv.org/abs/2503.01928)

- Levels of Spacecraft Autonomy: introduces levels framework with Basic Space Operations, Ground Commanding, Space Situational Awareness, Onboard Recovery Planning, Onboard Recovery Actions, Onboard Execution, Optional Monitoring, and Ground Monitoring components to characterize spacecraft autonomy.
- The framework defines six levels of spacecraft autonomy, ranging from basic ground-commanded operations to fully autonomous onboard execution and optional ground monitoring.
- This autonomy level framework aims to provide a consistent method for describing and communicating spacecraft capabilities to diverse audiences, including technical and non-technical stakeholders.


---

[Curating Demonstrations using Online Experience](https://arxiv.org/abs/2503.03707)

- Demo-SCORE (Demo-SCORE): introduces a self-curation method for robot demonstrations using online experience, with Initial Policy Training, Rollout Generation, Data Quality Classifier Training, and Demonstration Filtering components.
- Demo-SCORE leverages policy rollouts to identify and remove unreliable demonstrations from an initial dataset.
- Demonstration Filtering component uses a trained classifier to refine the demonstration dataset based on predicted reliability.


---


#### 4th March 2025

[Four Principles for Physically Interpretable World Models](https://arxiv.org/abs/2503.02143)

- Physically Interpretable World Models: introduces a world model framework incorporating principles like latent structuring and output partitioning, utilizing components such as physical encoders, dynamics models, and decoders to achieve physical interpretability.
- This framework emphasizes learning aligned invariant and equivariant representations through multi-level supervision to enhance the reliability and verifiability of world models for autonomous systems.
- The proposed architecture aims to bridge the gap between high-dimensional observations and physical meaning by partitioning generative outputs and structuring latent spaces according to physical variable intent.


---


[From Metaphor to Mechanism: How LLMs Decode Traditional Chinese Medicine Symbolic Language for Modern Clinical Relevance](http://arxiv.org/abs/2503.02760v1)

- Perceptual-Chain-Of-Thought framework: introduces multi-agent system for TCM metaphor interpretation, with Entity Mapping and Splitting Layer, Perceptual Layer, Metaphor understanding Layer, and Perceptual KG Subset components.
- This framework uses chain-of-thought reasoning and multi-agent collaboration to bridge TCM and Western medicine understanding of metaphors.
- The system aims to improve accuracy and transparency in translating TCM symbolic language for modern clinical relevance.


---

[FINARENA: A HUMAN-AGENT COLLABORATION FRAMEWORK FOR FINANCIAL MARKET ANALYSIS AND FORECASTING](http://arxiv.org/abs/2503.02692v1)

- FinArena (Human-Agent collaboration framework for financial market analysis and forecasting): introduces a novel framework for financial analysis, integrating Human Module (interactive user interface), Machine Module (LLM-based multi-agent system), Time Series Agent (stock time series prediction), News Agent (news insights and RAG), Statement Agent (financial statement analysis), AI Expert (investment decision synthesis), Report Agent (human-agent interaction), Data Set (multimodal financial data), Output (investment action suggestion), and Web Port (information retrieval and analysis).
- FinArena framework employs specialized agents for time series, news, and statements, combined with an AI expert for synthesizing insights and a report agent for human interaction, utilizing multimodal financial data for enhanced stock trend predictions and personalized investment decisions.
- The framework leverages adaptive Retrieval-Augmented Generation (RAG) within the News Agent to mitigate hallucinations and improve accuracy when processing unstructured news data, and incorporates iterative reasoning in the Statement Agent for in-depth financial statement analysis.


---

[MPO: Boosting LLM Agents with Meta Plan Optimization](http://arxiv.org/abs/2503.02682v1)

- MPO (Meta Plan Optimization): introduces meta plan optimization framework with meta planner generating abstract guidance, agent providing execution feedback, and prompt incorporating meta plan for enhanced planning.
- MPO framework leverages meta plans to provide explicit guidance for LLM agents, enabling continuous optimization based on agent's task execution feedback.
- MPO enhances agent planning by decoupling meta plans from specific environmental details, improving generalization and task completion efficiency without agent retraining.


---

[Playing games with Large language models: Randomness and strategy](http://arxiv.org/abs/2503.02582v1)

- LangChain: introduces game-playing framework with LLM, player agents, evaluation, and history for game simulations.
- This framework facilitates bidirectional LLM interactions for repeated games with history feedback.
- The framework enables analysis of LLM strategic adaptation and randomness in game scenarios.


---


[Generator-Assistant Stepwise Rollback Framework for Large Language Model Agent](http://arxiv.org/abs/2503.02519v1)

- GA-Rollback (Generator-Assistant Stepwise Rollback) introduces a framework with Environment, LLM (Generator), GA-Rollback, Assistant, Rollback Operation, Evaluation, Feedback Evaluation, and "wait-k" Strategy to improve decision-making in LLM agents by addressing error propagation through rollback operations and quality evaluation.
- The framework utilizes a Generator (LLM) to interact with the Environment, while an Assistant examines actions and triggers Rollback Operation upon error detection, incorporating Feedback Evaluation and "wait-k" Strategy for enhanced performance.
- GA-Rollback framework aims to ensure credible reasoning trajectory by separating action generation and examination, and integrating seamlessly as plug-and-play module with other methods for improved robustness and extensibility.


---


[BRIDGE: Bootstrapping Text to Control Time-Series Generation via Multi-Agent Iterative Optimization and Diffusion Modelling](http://arxiv.org/abs/2503.02445v1)

- BRIDGE: introduces BRIDGE framework with Text Template Generation, Automatic Evaluation, Feedback-driven Refinement, Domain Time Series Encoder, Text Description Encoder, Prototype Assignment Module, Semantic Prototypes, Conditioning, Diffusion Model, and Random Noise for text-controlled time series generation.
- BRIDGE framework uses multi-agent system for iterative text refinement and hybrid approach combining semantic prototypes with text descriptions to enhance time-series generation controllability and fidelity.
- The framework addresses challenges of limited text-TS pairs and modality discrepancy by generating high-quality datasets and integrating semantic prototypes for improved domain generalization in time-series generation.


---


[PersonaX: A Recommendation Agent-Oriented User Modeling Framework for Long Behavior Sequence](http://arxiv.org/abs/2503.02398v1)

- PersonaX (Recommendation Agent-Oriented User Modeling Framework): introduces a user modeling framework for long behavior sequences, with behavior clustering, sampling budget allocation, in-cluster selection, SBS selection, offline multi-persona construction, online persona retrieval, and persona cache.
- PersonaX extracts representative sub-behavior sequences offline to construct fine-grained personas for efficient online retrieval in recommendation agents.
- PersonaX addresses challenges of long user-generated content by balancing behavioral completeness and efficiency in user modeling.


---

[ReSo: A Reward-driven Self-organizing LLM-based Multi-Agent System for Reasoning Tasks](http://arxiv.org/abs/2503.02390v1)

- ReSo (Reward-driven Self-organizing): introduces reward-driven multi-agent system, integrating Task Graph for decomposition, Agent Graph Construction for network building, Dynamic Agent Database for agent profiles, and Collaborative Reward Model for feedback.
- ReSo incorporates Collaborative Reward Model to provide fine-grained signals, enabling dynamic optimization of agent collaboration and improving scalability.
- The framework utilizes Dynamic Agent Database to maintain agent profiles, facilitating adaptive agent selection based on performance and task similarity.


---


[EchoQA: A Large Collection of Instruction Tuning Data for Echocardiogram Reports](http://arxiv.org/abs/2503.02365v1)

- EchoQA (Echocardiogram Question Answering) introduces a question-answering dataset creation framework with Data Extraction, Clinical Categorization, Sentence Matching, Question Generation, LLM Training, and Fairness Audit components for echocardiogram reports.
- EchoQA framework utilizes clinician expertise for categorizing cardiac abnormalities and generates question-answer pairs to facilitate instruction tuning of language models for cardiology QA tasks.
- The framework aims to establish a benchmark for LLM-based AI agents in cardiology, focusing on differential diagnoses and fairness across social determinants of health.


---


[AppAgentX: Evolving GUI Agents as Proficient Smartphone Users](http://arxiv.org/abs/2503.02268v1)

- AppAgentX (Evolving GUI Agents as Proficient Smartphone Users): introduces an evolutionary framework for GUI agents, incorporating memory mechanism, evolutionary mechanism, and execution strategy to enhance efficiency and intelligence by evolving high-level actions from task execution history.
- AppAgentX framework utilizes a chain-based knowledge framework to record task execution history, enabling the agent to identify repetitive action sequences and evolve shortcut nodes representing high-level actions for improved task efficiency.
- The framework's memory mechanism stores page nodes and element nodes with descriptions and visual embeddings, facilitating the evolutionary mechanism to abstract low-level actions into high-level actions and optimize the agent's operational repertoire.


---

[Haste Makes Waste: Evaluating Planning Abilities of LLMs for Efficient and Feasible Multitasking with Time Constraints Between Actions](http://arxiv.org/abs/2503.02238v1)

- RECIPE2PLAN: introduces Multitask Agent, Action, Observation, Feedback, and Recipe, to evaluate multitask planning with time constraints in cooking scenarios.
- RECIPE2PLAN framework challenges agents to balance efficiency and feasibility in parallel task execution while respecting temporal constraints between actions.
- RECIPE2PLAN benchmark uses real-world recipes to assess agents' ability to optimize cooking time and adhere to temporal constraints, highlighting the need for improved temporal awareness in LLMs.


---

[ATLAS: Agent Tuning via Learning Critical Steps](http://arxiv.org/abs/2503.02197v1)

- ATLAS (Agent Tuning via Learning Critical Steps): introduces a framework for efficient LLM agent tuning by focusing on critical steps identified from expert trajectories.
- ATLAS framework employs a Selector to identify Critical Steps within Expert Trajectories and applies Finetuning to a Base LLM using Critical Step Loss computed on these steps to create a tuned LLM Agent.
- By selectively finetuning on Critical Steps, ATLAS reduces overfitting and enhances generalization capabilities of LLM agents while minimizing training costs.


---


[Teaching AI to Handle Exceptions: Supervised Fine-Tuning with Human-Aligned Judgment](http://arxiv.org/abs/2503.02976v1)

- Decision-Making Flow Framework: introduces structured approach for evaluating decision-making in LLMs, with Scenario, Policy, Exception, Level, Decision Model, and Decisions components.
- This framework assesses LLMs' ability to handle exceptions to policies compared to human decision-makers across varying exception intensities.
- The framework is used to evaluate ethical framework prompting, chain-of-thought reasoning, and supervised fine-tuning interventions for improving LLM alignment with human judgment.


---



#### 3rd March 2025

[CorrA: Leveraging Large Language Models for Dynamic Obstacle Avoidance of Autonomous Vehicles](http://arxiv.org/abs/2503.02076v1)

- CorrA (Corridor-Agent): introduces a dynamic obstacle avoidance framework, integrating Scene Description, LLM Scene Analysis, Optimization, DDP, Hard safety constraints, and Ego car trajectory components.
- CorrA uses LLM for reasoning to generate adaptive sigmoid boundary parameters, which are efficiency-optimized and used by DDP within MPC for trajectory planning.
- This framework enhances autonomous vehicle safety and efficiency in dynamic environments through real-time adaptation of sigmoid-based safety boundaries.


---

[Interactive Debugging and Steering of Multi-Agent AI Systems](http://arxiv.org/abs/2503.02068v1)

- AGDEBUGGER (Interactive Agent Debugging Tool): introduces an interactive debugging system for multi-agent AI, featuring a message viewer, message sending, message editing, message reset, overview visualization, agent state checkpoints, and a message queue.
- This tool facilitates debugging by allowing users to inspect conversations, edit messages, reset workflows, and visualize conversation history to understand and correct agent behavior.
- AGDEBUGGER addresses the challenges of debugging complex multi-agent systems by providing interactive control and visualization, enabling developers to effectively identify and fix errors in agent workflows.


---

[Al persuading Al vs Al persuading Humans: LLMs' Differential Effectiveness in Promoting Pro-Environmental Behavior](http://arxiv.org/abs/2503.02067v1)

- Research Framework: introduces a system for evaluating LLMs in promoting Pro-Environmental Behavior, with Participants, Chat, Communication Strategy and Effects components.
- The framework compares real, simulated, and synthetic participants interacting with personalized chatbots, non-personalized chatbots, or static statements using different communication strategies.
- The study investigates effects on pro-environmental intentions, climate change belief, sustainable choices, psychological distance, sharing, consumption, self-perception, and policy adoption.


---

[Persuasion at Play: Understanding Misinformation Dynamics in Demographic-Aware Human-LLM Interactions](http://arxiv.org/abs/2503.02038v1)

- PANDORA Framework (Persuasion ANalysis in Demographic-aware human-LLM interactions and misinformation Response Assessment): introduces components including LLM-to-Human Persuasion, Persuasive Text Generation, Persuasive Text Impact, Human-to-LLM Persuasion, Persuasive Text Generation, Persuasive Text Impact, Multi-agent LLM Persuasion, Multi-Agent LLM Architecture, Homogeneous groups, Heterogeneous groups, Interaction rounds, First responses, and Final responses to investigate misinformation dynamics in human-LLM interactions considering demographic factors.
- PANDORA framework analyzes bidirectional persuasion between humans and LLMs, evaluating LLM-generated and human-generated persuasive texts' impact on belief and correctness across diverse demographic groups in single-agent and multi-agent settings.
- The framework's multi-agent LLM architecture explores echo chamber effects in homogeneous groups and mitigation in heterogeneous groups, offering insights into demographic influences on misinformation susceptibility and potential intervention strategies.


---

[Mind the (Belief) Gap: Group Identity in the World of LLMs](http://arxiv.org/abs/2503.02016v1)

- Multi-agent LLM framework: introduces simulation of belief congruence experiment with participant agent interacting with confederate agents, each having assigned belief, through interaction rounds to answer question.
- Framework components include participant agent making decision after interaction rounds with confederate agents, considering their beliefs on discussion topic.
- Framework simulates psychological experiment to investigate belief congruence in LLMs by observing agent's choices based on belief alignment of others.


---

[Adaptively evaluating models with task elicitation](http://arxiv.org/abs/2503.01986v1)

- Adaptive Evaluations: introduces framework for evaluating language models, utilizing Target LLM, Evaluator Agent, Verifier, and Static Evaluation components.
- Framework employs evaluator agents to create difficult questions by probing target model behavior from static evaluation results.
- Verifier component ensures generated questions maintain validity, difficulty, and novelty, refining target model profile iteratively.


--

[Can (A)I Change Your Mind?](http://arxiv.org/abs/2503.01844v1)

- Dynamic Bot Framework: introduces a structured system utilizing GPT-4, with System Prompt, Experiment Framework, System Message, Persona, Conversation Instruction, User Message, Bot Message, Opinion and Confidence, Few Shot Conversations, Nudger, Initial Message, Summarization Prompt, and Final Message, to facilitate and analyze human-bot conversations for persuasion studies.
- This framework employs a detailed prompt and iterative message processing, including summarization and rephrasing, to ensure naturalistic and contextually relevant bot interactions within the experiment.
- The framework incorporates components like Nudger for maintaining engagement and Few Shot Conversations for guiding bot behavior, aiming for robust and ecologically valid persuasion research.


---

[Persuade Me if You Can: A Framework for Evaluating Persuasion Effectiveness and Susceptibility Among Large Language Models](http://arxiv.org/abs/2503.01829v1)

- PMIYC (Persuade Me If You Can): introduces automated framework for evaluating persuasion effectiveness and susceptibility of LLMs through multi-agent interactions, with PERSUADER (Agent attempting persuasion), PERSUADEE (Agent being persuaded), Multi-turn Conversation (Iterative argument exchange), and Agreement Score (Quantifies stance on claim).
- PMIYC framework simulates conversations between PERSUADER and PERSUADEE agents to measure persuasive effectiveness and susceptibility of LLMs in different contexts.
- PMIYC offers scalable and automated approach to study LLM persuasion dynamics, providing insights into vulnerabilities and safer AI development.


---

[AutoAdvExBench: Benchmarking autonomous exploitation of adversarial example defenses](http://arxiv.org/abs/2503.01811v1)

- AutoAdvExBench (Benchmark for Autonomous Exploitation of Adversarial Example Defenses): introduces benchmark, with Forward Pass Implementation, Differentiable Forward Pass Conversion, FGSM Attack and Iterative Attack components, that evaluates LLMs' ability to autonomously exploit adversarial defenses.
- This benchmark directly measures LLMs' success on security tasks performed by machine learning experts, unlike proxy benchmarks.
- AutoAdvExBench is mechanistically verifiable and uses real-world research codebases, highlighting the gap between CTF-like and real-world security challenges for LLMs.


---

[Designing VR Simulation System for Clinical Communication Training with LLMs-Based Embodied Conversational Agents](http://arxiv.org/abs/2503.01767v1)

- VAPS (Virtual AI Patient Simulator): introduces VR system for clinical communication training, with tutorial-, clinical patient interaction- and reflection-scenes, embodied conversational agents, medical records, narrative design, realistic animations and system interaction.
- VAPS utilizes LLM-driven ECAs to simulate dynamic patient interactions, incorporating medical records and adaptive narratives for realistic VR-based training.
- The system aims to enhance HP students' communication skills through customizable and repeatable practice scenarios within an immersive VR environment.


---

[Retrieval Models Aren't Tool-Savvy: Benchmarking Tool Retrieval for Large Language Models](http://arxiv.org/abs/2503.01763v1)

- TOOLRET: introduces TOOLRET Benchmark (heterogeneous tool retrieval evaluation), IR Models (benchmark various retrieval models), TOOLRET-train Dataset (large-scale training dataset), and Evaluation Metrics (retrieval performance metrics) for benchmarking tool retrieval performance of large language models.
- TOOLRET benchmark demonstrates existing information retrieval models exhibit suboptimal performance in retrieving tools, consequently degrading tool-use large language model task completion rates.
- TOOLRET-train dataset aims to improve information retrieval models for tool retrieval, ultimately enhancing the effectiveness of large language models in tool utilization.


---

[Student engagement in collaborative learning with AI agents in an LLM-empowered learning environment: A cluster analysis](http://arxiv.org/abs/2503.01694v1)

- MAIC (Massive AI-empowered Course System): introduces a platform integrating specialized AI agents including AI Teacher, AI Teaching Assistant, Sparker, Thinker, Questioner and Note Taker, managed by Director Agents using Dialogue History and Learning Materials to enhance online learning.
- MAIC system utilizes Director Agents to analyze classroom dynamics from Dialogue History and Learning Materials, enabling dynamic agent selection via Select Speakers and text generation through Generate Texts, alongside components like Role Descriptions and Specialized Intelligence.
- MAIC framework aims to foster collaborative learning by employing diverse AI agents - AI Teacher, AI Teaching Assistant, Sparker, Thinker, Questioner, Note Taker - each with specific roles, to support student engagement and personalized educational experiences.


---

[Evaluation and Facilitation of Online Discussions in the LLM Era: A Survey](http://arxiv.org/abs/2503.01513v1)

- Taxonomy of Discussion Quality Evaluation: introduces four main dimensions - Structure and Logic, Social Dynamics, Emotion and Behavior, and Engagement and Impact - to assess online discussion quality.
- Taxonomy of Discussion Quality Evaluation: encompasses multiple aspects within each dimension, ranging from argument analysis and coherence to politeness, toxicity, and engagement, providing a comprehensive framework.
- Taxonomy of Discussion Quality Evaluation: aims to offer a structured approach for evaluating diverse facets of online discussions, moving beyond traditional argument-centric methods to include social and behavioral dynamics.


---


[Improving Retrospective Language Agents via Joint Policy Gradient Optimization](http://arxiv.org/abs/2503.01490v1)

- RetroAct (Retrospective Language Agent): introduces a novel agent framework that jointly optimizes task-planning and self-reflective evolution capabilities with Planner, Reflector, Environment, Tool Calling, Reflection, Feedback, Reward, Differential Reward, Imitation Learning, Reinforcement Learning, Policy Gradient Optimization, Replay Buffer.
- RetroAct framework uses a two-stage joint optimization process integrating imitation and reinforcement learning for enhanced data efficiency and training stability.
- RetroAct improves performance of open-source models and reduces dependency on closed-source LLMs by enabling continuous learning and evolution.


---

[MultiAgentBench : Evaluating the Collaboration and Competition of LLM agents](http://arxiv.org/abs/2503.01935v1)

- MARBLE (Multi-agent coordination Backbone with LLM Engine): introduces a multi-agent evaluation framework with Configuration, Coordinate Engine, Agent Graph, Shared Memory, Cognitive Module, Environment, Tool Box, and Evaluator components.
- This framework evaluates LLM-based multi-agent systems by measuring task completion and coordination quality in diverse interactive scenarios.
- MARBLE utilizes milestone-based KPIs and supports various coordination protocols and planning strategies for comprehensive multi-agent system analysis.


---

#### 2nd March 2025

[NESYC: A NEURO-SYMBOLIC CONTINUAL LEARNER FOR COMPLEX EMBODIED TASKS IN OPEN DOMAINS](http://arxiv.org/abs/2503.00870v1)

- NESYC (Neuro-Symbolic Continual learner): introduces a neuro-symbolic continual learning framework integrating Semantic Parser, Hypothesis Generator, Hypothesis Interpreter, Logic programming form, Memory-based monitoring, Task Planner, Action Executor, and Error Handler for embodied agents in open-domain environments.
- NESYC framework employs contrastive generality improvement and memory-based monitoring schemes, utilizing LLMs and symbolic tools to generalize actionable knowledge and refine it through experience.
- The framework iteratively reformulates knowledge and applies it, adapting to unpredictable situations and demonstrating effectiveness in diverse embodied task benchmarks by continually improving understanding of the environment.


---

[A Law Reasoning Benchmark for LLM with Tree-Organized Structures including Factum Probandum, Evidence and Experiences](http://arxiv.org/abs/2503.00841v1)

- TL Agent (Transparent Law Reasoning Agent): introduces a transparent law reasoning framework, with Agent Brain, Fact Finding Head, Knowledge Search, MultiRole Checker, Legal Knowledge, Reflection, Evidence, Factum Probandum, Experiences, and Inferences components, for AI-assisted legal decision-making.
- The framework employs a tree-organized schema integrating hierarchical factum probandum, evidence, and experiences to simulate comprehensive court processes and enhance transparency in legal reasoning.
- TL Agent utilizes a suite of legal analysis tools within an agent-based architecture to construct tree-organized legal reasoning structures from textual case descriptions for improved judicial fairness.


---

[AI Agents for Ground-Based Gamma Astronomy](http://arxiv.org/abs/2503.00821v1)

- Astronomical Agent: introduces an AI system designed for astronomy tasks, integrating context understanding, language model processing, external function execution, and data validation within a specified framework.
- The agent utilizes instruction-finetuned LLMs to automate complex tasks in gamma-ray astronomy, incorporating components like ACADA and Gammapy for telescope control and data analysis pipelines.
- Validation mechanism ensures command quality by evaluating function execution results against provided data and software framework, enhancing reliability in autonomous astronomical operations.


---

[Evaluating Personalized Tool-Augmented LLMs from the Perspectives of Personalization and Proactivity](http://arxiv.org/abs/2503.00771v1)

- ETAPP (Evaluation of Tool-augmented Agent from the Personalization and Proactivity Perspective): introduces a benchmark for evaluating personalized tool invocation, comprising API Construction, Sandbox Construction, User Profile Construction, Tool-utilizing Preference Construction, Interaction History Construction, Memory Building, Instruction Construction, Manual Check, Inference, Available Tools, Tool Invoking Process, Final Answer, and Evaluation components.
- ETAPP assesses personalization and proactivity in tool-augmented LLMs using a dataset of 800 cases and a key-point-based evaluation method.
- The benchmark aims to address the lack of evaluation criteria for personalized tool usage in diverse scenarios, focusing on improving personalized LLM agents.


---

[CLEA: Closed-Loop Embodied Agent for Enhancing Task Execution in Dynamic Environments](http://arxiv.org/abs/2503.00729v1)

- CLEA (Closed-Loop Embodied Agent): introduces a closed-loop framework with Observer, Memory, Planner-Critic Agent and Skill Pool to enhance task execution in dynamic environments using robots.
- CLEA framework incorporates Observer for visual input conversion, Memory for belief state maintenance, Planner-Critic Agent for adaptive decision-making, and Skill Pool for predefined executable actions.
- The framework facilitates continuous adaptation and error recovery in long-horizon tasks by integrating real-time environmental feedback and memory-driven reasoning within its components.


---

[Unmasking Digital Falsehoods: A Comparative Analysis of LLM-Based Misinformation Detection Strategies](http://arxiv.org/abs/2503.00724v1)

- SNIFFER (Multimodal Large Language Model for Explainable Out-of-Context Misinformation Detection): introduces multimodal model utilizing visual and textual inputs with cross-modal transformer and external knowledge to detect misinformation.
- SNIFFER integrates image encoder, text processing, and retrieval mechanisms, employing LLM for reasoning and providing explainable out-of-context misinformation detection.
- The framework achieves explainability through structured validation and evidence integration, enhancing transparency in multimodal misinformation analysis.


---

[LLMDR: LLM-Driven Deadlock Detection and Resolution in MAPF Environment](http://arxiv.org/abs/2503.00717v1)

- LLMDR (LLM-Driven Deadlock Detection and Resolution): introduces MAPF Environment, Base Model Simulation, LLM Deadlock Detection, and LLM Deadlock Resolution with PIBT to address deadlock and enhance learned MAPF model performance.
- LLMDR framework uses LLM Deadlock Detection to identify deadlocks in Base Model Simulation within MAPF Environment and employs LLM Deadlock Resolution with PIBT to resolve them.
- LLMDR leverages LLMs for high-level deadlock management and integrates with PIBT algorithm for collision-free action generation in multi-agent pathfinding scenarios.


---

#### 1st March 2025

[Instructor-Worker Large Language Model System for Policy Recommendation: a Case Study on Air Quality Analysis of the January 2025 Los Angeles Wildfires](http://arxiv.org/abs/2503.00566v1)

- Instructor-Worker LLM System: introduces Instructor LLM (Prompt interpreter orchestrator), Worker LLM(s) (Data analysis summarization agents), Code Execution Module (API call validation execution), and Cloud Platform (External data source) for air quality analysis.
- The system uses Instructor LLM to process user instructions, retrieve data from Cloud Platform via Code Execution Module, and distribute analysis tasks to Worker LLMs.
- This multi-agent approach aims to efficiently analyze large datasets and generate policy recommendations based on air quality data.


---

[Challenges in Testing Large Language Model Based Software: A Faceted Taxonomy](http://arxiv.org/abs/2503.00481v1)

- Taxonomy for LLM Test Case Design: introduces Software Under Test (system or component to evaluate), Goal (objective of the test case), Oracles (evaluation mechanisms for property), and Inputs (data to elicit SUT responses) for structuring LLM testing.
- This taxonomy addresses challenges in LLM testing by categorizing key variation points impacting evaluation correctness and emphasizing ambiguity in inputs and outputs.
- The taxonomy aims to improve reliability and reproducibility of LLM testing by providing a systematic framework for test case design and evaluation across the software lifecycle.


---

[PodAgent: A Comprehensive Framework for Podcast Generation](http://arxiv.org/abs/2503.00455v1)

- PodAgent: introduces comprehensive framework for podcast generation with Host-Guest-Writer System, Voice-Role Matching, Instruction-following TTS, Audio Script Generation and Audio Production components.
- PodAgent framework utilizes multi-agent collaboration for content creation, voice characteristic analysis for voice selection and LLM-enhanced speech synthesis for expressive speech.
- PodAgent addresses key challenges in podcast generation, including content depth, dialogue naturalness, voice appropriateness and speech expressiveness.


---

[Structured Reasoning for Fairness: A Multi-agent Approach to Bias Detection in Textual Data](http://arxiv.org/abs/2503.00355v1)

- SRF Framework (Structured Reasoning for Fairness Framework): introduces multi-agent pipeline with Checker Agent, Validation Agent, and Justification Agent for textual data bias detection.
- SRF Framework systematically identifies biases through fact or opinion classification, bias intensity scoring, and factual justification provision.
- This approach improves bias detection accuracy and interpretability, fostering fairness and accountability in language models.


---

[Shifting Power: Leveraging LLMs to Simulate Human Aversion in ABMs of Bilateral Financial Exchanges, A bond market study](http://arxiv.org/abs/2503.00320v2)

- TRIBE (Trading Relationships, Interactions, and Bilateral Exchange of assets): introduces agent-based model augmented with LLM to simulate human aversion, with components Select Paramatervalues, Build the Financial Landscape, Initialise Bankers, Bankers engage with Clients, Clients determine direction choice availability, LLM response Positive, LLM response Averse, Bankers must trade if Clients are Positive towards them, and Banker facilitated trade occurs.
- TRIBE framework simulates bilateral financial exchanges by integrating LLM for human-like client decision-making regarding trade aversion and timeliness.
- This framework enhances realism in agent-based models by incorporating stochastic human-like decision processes via LLM, revealing emergent market behaviors.


---


#### 28th February 2025

[UDora: A Unified Red Teaming Framework against LLM Agents by Dynamically Hijacking Their Own Reasoning](http://arxiv.org/abs/2503.01908v1)

- UDora (Unified Red Teaming Framework): introduces a novel approach for attacking LLM agents by dynamically adapting adversarial strings based on the agent's reasoning process, encompassing components like System (target agent), Direct Attack (baseline), UDora Attack (framework itself), Initial Response, Modified Response, Optimization, Malicious Environment, Malicious Instruction, Tool list, and Malicious Target Tool.
- UDora framework strategically inserts "noise" into the agent's reasoning at optimal positions identified through positional scoring and iterative optimization to mislead the agent towards malicious actions.
- The framework evaluates two adversarial scenarios: Malicious Environment, where the observation is corrupted, and Malicious Instruction, where the instruction is directly manipulated, demonstrating effectiveness across diverse datasets and real-world agents.


---

[Personalized Causal Graph Reasoning for LLMs: A Case Study on Dietary Recommendations](http://arxiv.org/abs/2503.00134v1)

- Personalized Causal Graph Reasoning: introduces agentic framework enhancing LLM reasoning by incorporating personal causal graphs, with goal identification, personal causal graph, traverse impactful nutrient paths, rank, verify, retrieve food items, food nutrient database, generate food recommendation, large language model, and personal data.
- This framework constructs personalized causal graphs from individual data to guide LLM in generating tailored dietary recommendations.
- By leveraging structured causal dependencies and counterfactual evaluation, the framework aims to provide more precise and personalized dietary advice compared to generic LLM approaches.


---

[BixBench: a Comprehensive Benchmark for LLM-based Agents in Computational Biology](http://arxiv.org/abs/2503.00096v1)

- BixBench (Bioinformatics Benchmark): introduces benchmark framework with analyst-created analysis capsules, expert review, LLM-generated MCQs, task capsules, agent task environment with tools, and open/multiple-choice evaluations.
- BixBench framework uses analysis capsules containing data and questions, evaluated in agent environment with tools for bioinformatics tasks.
- BixBench framework assesses LLM-based agents in bioinformatics through open-ended questions and multiple-choice questions for comprehensive evaluation.


---

[EdgeAIGuard: Agentic LLMs for Minor Protection in Digital Spaces](http://arxiv.org/abs/2503.00092v1)

- EdgeAIGuard: introduces multi-agent framework for minor protection, with Input Layer, Edge Processing Unit, Local Storage and Protection Layer components.
- EdgeAIGuard framework incorporates Sentinel, Context, and Intervention Agents within Edge Processing Unit, utilizing DeepSeek LLM Engine for threat detection and response.
- EdgeAIGuard employs Local Storage with History Cache and Pattern Memory to maintain context awareness and adapt to evolving online threats effectively.


---


[ARIES: AUTONOMOUS REASONING WITH LLMS ON INTERACTIVE THOUGHT GRAPH ENVIRONMENTS](http://arxiv.org/abs/2502.21208v1)

- ARIES (AUTONOMOUS REASONING WITH LLMS ON INTERACTIVE THOUGHT GRAPH ENVIRONMENTS) introduces a multi-agent framework with Policy Agent, Reasoning Agent, and Thought Graph to enhance reasoning in LLMs.
- ARIES framework utilizes Policy Agent to select Actions that Reasoning Agent executes on Thought Graph, dynamically adapting problem-solving strategy.
- The framework aims to improve reasoning accuracy and efficiency by using LLMs as policy agents to guide exploration within a structured thought graph environment.


---

[The amplifier effect of artificial agents in social contagion](http://arxiv.org/abs/2502.21037v1)

- Artificial Agent Social Contagion Framework: introduces agent types, experiments, attributes, threshold, adoption rate, seeding strategy, network, and proportion of artificial agents, to describe the impact of artificial agents on social contagion processes.
- This framework investigates how artificial agents, compared to humans, exhibit lower adoption thresholds and amplify social contagion in networks.
- The findings highlight the potential for artificial agents to accelerate behavioral shifts and raise questions about managing their influence in social systems.


---

[Retrieval Augmented Generation for Topic Modeling in Organizational Research: An Introduction with Empirical Demonstration](http://arxiv.org/abs/2502.20963v1)

- Agentic RAG (Agentic Retrieval-Augmented Generation): introduces topic modeling method integrating retrieval, generation, and agent-driven learning for improved qualitative analysis.
- Agentic RAG extends RAG with ReAct agent for iterative query reformulation and output evaluation, enhancing transparency and reliability.
- Agentic RAG streamlines topic modeling by using embeddings, reducing preprocessing and improving efficiency over traditional methods.


---

[The Power of Personality: A Human Simulation Perspective to Investigate Large Language Model Agents](http://arxiv.org/abs/2502.20859v1)

- Human Simulation Perspective: introduces framework with prompt-based personality shaping, single and multi-agent task testing and evaluation, group collaboration, team formation, and performance analysis to investigate personality traits influence on large language model agents in closed and open tasks.
- This framework systematically explores how personality traits impact reasoning, creativity, and collaboration of LLM agents by assigning Big Five traits and evaluating performance in single-agent and multi-agent settings.
- The study reveals that specific personality traits significantly affect agent performance and multi-agent systems exhibit collective intelligence driven by personality combinations, demonstrating LLMs' inherent human behavior simulation capabilities.


---


[Digital Player: Evaluating Large Language Models based Human-like Agent in Games](http://arxiv.org/abs/2502.20807v1)

- CivAgent: introduces a Large Language Model-based agent for strategy games, integrating perception, memory, reasoning & planning, skills, tools, and game components for human-like gameplay.
- CivAgent utilizes game observations and stored interaction data within its memory to inform reasoning and planning for executing in-game skills and leveraging external tools.
- The framework incorporates a simulator within its tools component to enhance numerical reasoning and decision-making processes in the complex game environment.


---

[Cyber Defense Reinvented: Large Language Models as Threat Intelligence Copilots](http://arxiv.org/abs/2502.20791v1)

- CYLENS (Cyber Defense Reinvented: Large Language Models as Threat Intelligence Copilots): introduces a cyber threat intelligence copilot system, integrating Base LLMs, Large-scale Knowledge, Task-Oriented Dataset, Curriculum Pre-training, Cascading Reasoning, and Specialized NLP Modules.
- CYLENS enhances cyber threat analysis through cascading reasoning and specialized NLP modules for tasks like attribution, contextualization, detection, correlation, prioritization, and remediation.
- The framework utilizes curriculum pre-training and fine-tuning methodologies to embed extensive CTI knowledge and adapt to diverse organizational needs in cybersecurity.


---

[The Rise of Darkness: Safety-Utility Trade-Offs in Role-Playing Dialogue Agents](http://arxiv.org/abs/2502.20757v1)

- ADMP (Adaptive Dynamic Multi-Preference) introduces a method that dynamically adjusts safety-utility preferences, incorporating train dataset, ADMP, sample dataset, CMS, character settings, GPT-4, safety reward model, utility reward model and typical interaction library.
- ADMP framework utilizes Coupling Margin Sampling (CMS) to enhance safety in high-risk scenarios through character-query risk coupling measurement within typical interaction library and preference weight sampling and mapping.
- The framework aims to balance safety and utility in role-playing dialogue agents, addressing risk coupling between user queries and character settings to mitigate unsafe content generation.


---


[ProAI: Proactive Multi-Agent Conversational AI with Structured Knowledge Base for Psychiatric Diagnosis](http://arxiv.org/abs/2502.20689v1)

- ProAI (Proactive AI): introduces a proactive conversational framework for mental health diagnosis, integrating Multi-Agent Proactive Reasoning Workflow, Structured Knowledge Graph, and Multifaceted Evaluation Strategy.
- ProAI framework employs Decision-Maker and Question-Generator Agents within Multi-Agent Proactive Reasoning Workflow, utilizing Structured Knowledge Retrieval and Action Prediction to navigate Structured Knowledge Graph.
- Multifaceted Evaluation Strategy of ProAI, encompassing Simulated Clinical Interview, User Experience Evaluation, and Doctor Evaluation, ensures comprehensive assessment of diagnostic accuracy, user experience and medical proficiency.


---

[Multi²: Multi-Agent Test-Time Scalable Framework for Multi-Document Processing](http://arxiv.org/abs/2502.20592v1)

- Multi² (Multi-Agent Test-Time Scalable Framework): introduces multi-agent framework with Input documents processed using Prompt Bank's Prompts to generate Candidate Summaries, then aggregated by Aggregator (Voter, Context-preserve, Context-independent) into Final summary, evaluated by Evaluation metrics (CAP score, LLM-ACU score) against Baseline summary.
- Multi² framework leverages prompt ensemble for multi-document summarization, employing diverse Prompts from Prompt Bank to guide independent LLM agents in generating Candidate Summaries, which are then consolidated by Aggregator module.
- The framework's Aggregator offers three distinct approaches: Voter selects best summary, Context-preserve refines summary using documents and candidates, and Context-independent consolidates summaries without original documents, all evaluated with CAP score and LLM-ACU score metrics.


---


#### 27th February 2025

[WHY ARE WEB AI AGENTS MORE VULNERABLE THAN STANDALONE LLMS? A SECURITY ANALYSIS](http://arxiv.org/abs/2502.20383v1)

- OpenHands (Web AI agent platform): introduces a framework for analyzing web agent vulnerabilities, comprising Goal Preprocessing, Action Space, Event Stream, LLM, and Eval Environment components.
- This framework investigates how embedding user goals, multi-step actions, and observational capabilities increase web agent vulnerability compared to standalone LLMs.
- The study uses component ablation to identify specific design choices that contribute to the heightened susceptibility of web agents to jailbreaking.


---

[Multi-Agent Verification: Scaling Test-Time Compute with Multiple Verifiers](https://ardalabs.ai/MultiAgentVerification/)

- MAV (Multi-Agent Verification): introduces Generator LLM for output generation, Aspect Verifiers for output evaluation, Aggregation for signal combination, BoN-MAV as multi-agent algorithm, BoN-RM as reward model algorithm, and Self-Consistency as consistency algorithm for test-time compute scaling.
- MAV paradigm combines multiple Aspect Verifiers to evaluate Generator LLM outputs, using Aggregation of verifier signals to improve performance over BoN-RM and Self-Consistency baselines.
- BoN-MAV algorithm, a specific implementation of MAV, demonstrates effective test-time scaling by increasing number of Aspect Verifiers, showing improvements in accuracy across diverse language models and domains.


---

[Bridging Legal Knowledge and AI: Retrieval-Augmented Generation with Vector Stores, Knowledge Graphs, and Hierarchical Non-negative Matrix Factorization](http://arxiv.org/abs/2502.20364v1)

- Smart-SLIC (Smart Semantic Legal Information and Computational System): introduces a legal AI framework integrating RAG, VS, KG, and NMF for enhanced legal research.
- Smart-SLIC leverages vector stores for semantic retrieval, knowledge graphs for relationship navigation, and NMF for latent topic discovery in legal documents.
- This framework aims to improve legal information retrieval, reasoning, and explainability by combining these components for complex legal tasks.


---

[Telephone Surveys Meet Conversational AI: Evaluating a LLM-Based Telephone Survey System at Scale](http://arxiv.org/abs/2502.20140v1)

- AI-driven telephone survey system: introduces a voice-based conversational AI agent for conducting phone surveys, integrating Speech to Text, Large Language Model, and Text to Speech components for real-time dialogue.
- The system incorporates a Turn-taking Model for managing conversation flow, a Deterministic consent checker and Llama Guard safety model within a Safety suite for secure interactions, and Logger, Recording of call, and Closed Database for data management.
- This architecture enables automated large-scale telephone surveys, mimicking human interviewers while maintaining data quality and operational efficiency.


---

[Collab-Overcooked: Benchmarking and Evaluating Large Language Models as Collaborative Agents](http://arxiv.org/abs/2502.20073v1)

- Collab-Overcooked Benchmark: introduces a framework with Memory, Reflection, Instruction-Builder, Planner, Communication, Error Handling, Executor, and Environment State components for evaluating LLM-based multi-agent collaboration.
- This benchmark assesses collaboration capabilities in a simulated kitchen environment featuring resource isolation and asymmetric task knowledge between agents.
- It employs process-oriented metrics like Initiating Capability and Responding Capability alongside end-to-end metrics to enable fine-grained analysis of collaborative performance.


---

[Picking the Cream of the Crop: Visual-Centric Data Selection with Collaborative Agents](http://arxiv.org/abs/2502.19917v1)

- ViSA (Visual-Centric Selection approach via Agents Collaboration): introduces a multi-agent framework for high-quality visual instruction data selection, incorporating Visual Information Quantification, Diversity Perspectives Quantification, and Text Quality Quantification components.
- ViSA evaluates image informativeness and instruction relevance by leveraging visual agents including InternVL, QwenVL and Llava to assess visual elements using SAM2 and DINO, and image-specific features.
- ViSA utilizes Shapley value based Agent Collaboration to refine evaluation scores like Segmentation Complexity Score, Object Alignment Score, Diversity Perspective Score, Prior Token Perplexity Score and Image-Text Mutual Information Score and improve MLLM training efficiency by reducing dataset noise.


---


[MIND: Towards Immersive Psychological Healing with Multi-agent Inner Dialogue](http://arxiv.org/abs/2502.19860v1)

- MIND (Multi-agent INner Dialogue): introduces multi-agent framework with Trigger, Devil, Guide, Strategist, Player and Memory components for immersive psychological healing through inner dialogue.
- MIND framework utilizes Trigger for scenario generation, Devil for cognitive distortion simulation, Guide for restructuring guidance, Strategist for storyline progression, Player as simulated patient and Memory for narrative coherence.
- MIND paradigm aims to enhance empathy and self-reconciliation by decomposing patient's conflicting self into interactive agents facilitating cognitive scaffold for metacognitive reflection and therapeutic efficacy.


---

[Supervised Fine-Tuning LLMs to Behave as Pedagogical Agents in Programming Education](http://arxiv.org/abs/2502.20527v1)

- GuideLM: introduces a fine-tuning framework with curated question-answer dataset, script-based, manual and LLM-based pre-processing, OpenAI fine-tuning and pedagogical model.
- GuideLM framework employs supervised fine-tuning to create pedagogically sound LLMs for programming education by refining existing models with targeted datasets.
- The framework aims to improve Socratic guidance and economy of words in LLM responses for novice programmers, enhancing learning without over-assistance.


--

[Personas Evolved: Designing Ethical LLM-Based Conversational Agent Personalities](http://arxiv.org/abs/2502.20513v1)

- Framework name: introduces a workshop for responsible design and evaluation of ethical LLM-based conversational agent personalities.
- This workshop addresses ethical and practical concerns of rapidly adopted LLM-based personas in conversational user interfaces.
- The workshop aims to bridge CUI and AI communities to ensure transparency, inclusivity, and user-centered LLM-driven CUIs.


---

[TripCraft: A Benchmark for Spatio-Temporally Fine Grained Travel Planning](http://arxiv.org/abs/2502.20508v1)

- TripCraft: introduces a benchmark for fine-grained travel planning, with User (initiates travel plan), Query (travel plan request), Persona (travel style preferences), Agent (generates travel plan), Reference Information (data for plan generation), Databases (storage for data), Generated Plan (output itinerary), Temporal Meal Score (meal scheduling quality), Temporal Attraction Score (attraction visit duration), Spatial Score (travel efficiency), Ordering Score (itinerary sequence), Persona Score (user preference alignment), CPR Macro (commonsense constraint adherence), CPR Micro (commonsense constraint adherence), HCPR Macro (hard constraint adherence), HCPR Micro (hard constraint adherence), and Delivery Rate (plan generation success).
- TripCraft assesses language agents in generating constraint-aware travel itineraries by incorporating user preferences and real-world constraints.
- The benchmark uses continuous evaluation metrics to assess temporal, spatial, sequential, and persona-specific aspects of generated travel plans.


---

[A Thousand Words or An Image: Studying the Influence of Persona Modality in Multimodal LLMs](http://arxiv.org/abs/2502.20504v1)

- Persona Modality Representation Framework: introduces framework with LLM, Stable Diffusion, Pillow Typography, Text, Image, Assisted Image, Descriptive Image components for studying persona modality influence in multimodal LLMs.
- Persona Modality Representation Framework evaluates persona embodiment using text, image, assisted image and descriptive image modalities generated through pipeline involving LLM, Stable Diffusion and Pillow Typography.
- Persona Modality Representation Framework systematically investigates how different modalities impact persona expressiveness in multimodal LLMs, utilizing diverse persona dataset and evaluation framework.


---

[Large Language Model Strategic Reasoning Evaluation through Behavioral Game Theory](http://arxiv.org/abs/2502.20432v1)

- Evaluation framework: introduces a three-step method for evaluating LLMs' strategic reasoning, incorporating Abstracted Game Library, Responder Model or Agents, and TQRE Estimation components.
- This framework systematically assesses LLMs' reasoning capability through game abstraction and TQRE-based parameter analysis, accounting for contextual complexity.
- It evaluates strategic reasoning beyond Nash Equilibrium, considering demographic biases and prompt effects using behavioral game theory principles.


---


#### 26th February 2025

[Agentic Mixture-of-Workflows for Multi-Modal Chemical Search](http://arxiv.org/abs/2502.19629v1)

- CRAG-MoW (Mixture-of-Workflows for Self-Corrective Retrieval-Augmented Generation): introduces agentic framework for multi-modal chemical search, includes User, Generators, Vector Store, Document Fusion, Aggregator Agent, and Report Generation.
- CRAG-MoW orchestrates multiple CRAG workflows using Generators for iterative self-correction and Aggregator Agent for synthesizing final response.
- Framework leverages structured retrieval and multi-agent synthesis to enhance response quality and interpretability for materials discovery.


---

[Weaker LLMs' Opinions Also Matter: Mixture of Opinions Enhances LLM's Mathematical Reasoning](http://arxiv.org/abs/2502.19622v1)

- MoO (Mixture of Opinions): introduces post-training method using Dataset Curation, Ancillary LLMs, Main LLM, Chain-of-Thought Reasoning Steps, Opinions, Post-Training, Inference and Post-trained Main LLM to enhance mathematical reasoning of stronger Main LLM by incorporating diverse Opinions from weaker Ancillary LLMs.
- MoO framework curates dataset by augmenting training samples with Chain-of-Thought reasoning and diverse Opinions from multiple weaker Ancillary LLMs, then fine-tunes Main LLM on this dataset.
- The post-trained Main LLM in MoO framework demonstrates improved mathematical reasoning by learning to synthesize insights from varied Opinions during the Post-Training phase.


---

[Stay Focused: Problem Drift in Multi-Agent Debate](http://arxiv.org/abs/2502.19559v1)

- DRIFTJudge/DRIFTPolicy Framework: introduces DRIFTJudge for drift detection and DRIFTPolicy for mitigation in multi-agent debate with Discussion and Voted Solution components.
- This framework addresses problem drift, a performance degradation issue in multi-agent debate over multiple turns.
- The framework aims to improve the effectiveness of multi-agent debate by identifying and reducing problem drift.


---

[Winning Big with Small Models: Knowledge Distillation vs. Self-Training for Reducing Hallucination in QA Agents](http://arxiv.org/abs/2502.19545v1)

- QA Pipeline (retrieval-augmented question-answering pipeline): introduces retrieval-augmented system, with User Question, Product Manual, Retrieval, QA Pipeline and Factual Response components, designed to generate factual answers from product manual based on user questions.
- The framework utilizes product manual as structured knowledge source to provide relevant information for question-answering process.
- The described pipeline aims to address hallucination in question answering systems by grounding responses in provided product manual content.


---

[Conversational Planning for Personal Plans](http://arxiv.org/abs/2502.19500v1)

- LLM-based Hierarchical Framework: introduces a novel architecture for conversational agents using Meta-Controller, Policy-Option, Tool-Use Policy, Memory, and Tools and RAG components to enable long-term interactive planning.
- The framework employs a LLM-powered Meta-Controller to decide macro-actions, LLM-powered Policy-Options to execute these actions, and Tool-Use Policy to fetch relevant content, leveraging Memory and Tools and RAG for context and knowledge retrieval.
- This approach facilitates adaptive planning through conversation and feedback, applicable to various scenarios requiring long-term user assistance, such as tutoring and personal health planning.


---

[TheoremExplainAgent: Towards Multimodal Explanations for LLM Theorem Understanding](https://arxiv.org/abs/2502.19400v1)

- TheoremExplainAgent: introduces an agentic framework for multimodal theorem explanation video generation, incorporating Theorems, Prompting, Planner Agent, Code Agent, Multimodal Elements, Rendered Video and Evaluation components.
- TheoremExplainAgent utilizes Planner Agent with Scene Outline, Vision Storyboard Plan, Technical Implementation Plan and Animation & Narration Plan to create video plans, and Code Agent with Query Generator, Core Documentation, Plugin Documentation and Agentic RAG to generate animation code.
- The framework outputs Rendered Video composed of Multimodal Elements and is assessed by Evaluation metrics, aiming to enhance theorem understanding through visual explanations.


---

[Agentic Reward Modeling: Integrating Human Preferences with Verifiable Correctness Signals for Reliable Reward Systems](http://arxiv.org/abs/2502.19328v1)

- REWARDAGENT (Agentic Reward Modeling): introduces router, verification agents (factuality, instruction-following), and judger to combine human preference rewards with verifiable correctness signals for reliable reward systems.
- Agentic reward modeling enhances reward reliability by integrating multi-dimensional correctness signals and enabling flexible incorporation of diverse verification agents.
- REWARDAGENT empirically demonstrates superior performance over vanilla reward models and improves LLM training through DPO with agent-constructed preference pairs.


---

[Agent-centric Information Access](http://arxiv.org/abs/2502.19298v1)

- Agent-centric Information Access Framework: introduces architecture orchestrating domain-expert and user-specific LLMs through User Agents (personalized user interface), Knowledge Agents (domain expert LLM), and Belief on Expertise (expertise assessment model).
- The framework utilizes User Expertise (user knowledge history) and Knowledge Base (domain specific data) to dynamically manage Query (information request) and Response (synthesized answer) cycles, incorporating Training (expertise model update) via Data-Metadata (inter-agent communication).
- This architecture facilitates efficient information retrieval by dynamically selecting and querying relevant expert LLMs, optimizing for accuracy, cost, and latency in multi-expert knowledge synthesis.


---

[Simulation of Language Evolution under Regulated Social Media Platforms: A Synergistic Approach of Large Language Models and Genetic Algorithms](http://arxiv.org/abs/2502.19193v1)

- LLM-driven multi-agent framework (Large Language Model-driven multi-agent framework): introduces multi-agent simulation for language evolution on regulated platforms, incorporating participant agents evolving language and supervisory agent enforcing regulations, utilizing Reflection-, Planning-, Dialogue- and Memory-Modules, with Constraint/Expression Strategy Update, Dialogue Log, Keyword Filter, LLM Assessment, Violation Log, Regulations and Violation Detection.
- Framework employs dual language strategies (constraint and expression) and LLM-driven Genetic Algorithm for strategy optimization through selection, mutation, and crossover, enhancing adaptability and simulation fidelity.
- Participant and supervisory agents, both LLM-driven, interact iteratively, refining language strategies to balance effective communication with evasion of regulatory constraints in simulated social media environments.


---

[MEDDxAgent: A Unified Modular Agent Framework for Explainable Automatic Differential Diagnosis](http://arxiv.org/abs/2502.19175v1)

- MEDDxAgent (Modular Explainable DDx Agent): introduces a modular agent framework for explainable automatic differential diagnosis, integrating DDxDriver, History Taking Simulator, Knowledge Retrieval Agent, and Diagnosis Strategy Agent.
- MEDDxAgent facilitates iterative diagnostic reasoning by using DDxDriver as central orchestrator to manage interactions between simulator and agents for refining diagnoses.
- The framework enhances explainability and transparency in the diagnostic process through intermediate logging and iterative updates of patient profiles and diagnoses.


---

[A Temporal Planning Framework for Multi-Agent Systems via LLM-Aided Knowledge Base Management](http://arxiv.org/abs/2502.19135v1)

- PLANTOR (PLanning with Natural language for Task-Oriented Robots) introduces a temporal planning framework for multi-agent systems, integrating natural language input, LLMs for knowledge base generation, Prolog for planning, and behaviour trees for ROS2 execution.
- The framework employs a two-phase knowledge base generation using high-level and low-level LLMs, followed by a three-step planning procedure that incorporates temporal dependencies and resource constraints solved via mixed-integer linear programming.
- PLANTOR leverages LLMs for human-understandable knowledge bases and Prolog for formal correctness, demonstrating potential for advanced robotics tasks requiring flexible and scalable planning.


---

[Language-Driven Opinion Dynamics in Agent-Based Simulations with LLMs](http://arxiv.org/abs/2502.19098v1)

- LODAS (Language-Driven Opinion Dynamics Model for Agent-Based Simulations): introduces a framework for simulating opinion dynamics using language and social interactions with LLM Agents, Network of connections, Initial opinion, Opponent, Discussant, Prompt, Discussion statement, Arguments, and Opinion change.
- LODAS framework explores how language and logical fallacies influence opinion evolution in agent-based simulations, simulating debates around the "Ship of Theseus" paradox.
- The model utilizes LLM Agents as Opponent and Discussant roles, guided by Prompts and exchanging Arguments related to a Discussion statement to observe Opinion change within a Network of connections.


---

[NEXUS: A LIGHTWEIGHT AND SCALABLE MULTI-AGENT FRAMEWORK FOR COMPLEX TASKS AUTOMATION](http://arxiv.org/abs/2502.19091v1)

- Nexus (A Lightweight and Scalable Multi-Agent Framework): introduces a Python framework for constructing LLM-based multi-agent systems, incorporating Supervisor, Task Supervisors, Worker Agents, Memory, and Tools for automating complex tasks.
- Nexus framework utilizes a multi-supervisor hierarchy for scalable delegation and YAML-based workflow design, facilitating efficient management of intricate tasks and enhancing scalability.
- Nexus framework achieves state-of-the-art performance across coding, mathematical reasoning, and EDA domains, demonstrating its adaptability and efficacy in varied applications.


---

[IndicEval-XL: Bridging Linguistic Diversity in Code Generation Across Indic Languages](http://arxiv.org/abs/2502.19067v1)

- IndicEval-XL: introduces comprehensive benchmark for code generation, with Original Dataset prompts, Language extraction, Translation, Back Translation, Quality checks, Programming Languages, and Natural Languages.
- IndicEval-XL benchmark evaluates multilingual code generation across Indic languages, focusing on linguistic diversity and functional correctness.
- The framework employs automated and human-based quality checks to ensure dataset reliability for benchmarking code generation models.


---

[Letters from Future Self: Augmenting the Letter-Exchange Exercise with LLM-based Future Self Agents to Enhance Young Adults' Career Exploration](http://arxiv.org/abs/2502.18881v1)

- Framework name here: introduces a system augmenting letter-exchange exercise with User, Future-self Agent, Present Self Info, LLM, Current Career Exploration Context, and Envisioned Future Profile components.
- The system utilizes Profile After 3 Years, Current Profile, and Current Career Development as input for Conversational Agent, offering Letter and Chat modalities for interaction.
- This approach aims to enhance young adults' career exploration by simulating personalized future self interactions for guidance and reflection.


---

[Multi-LLM Collaborative Search for Complex Problem Solving](http://arxiv.org/abs/2502.18873v1)

- MOSA (Mixture-of-Search-Agents) paradigm introduces collaborative search framework, integrating independent exploration and iterative refinement with root node, action space, child nodes, sampling LLM, sub-questions, candidate sub-answers, majority voting, aggregator, and aggregated candidate sub-answers.
- MOSA leverages multiple LLMs as proposers for diverse search directions and as aggregators for refining candidate answers, enhancing reasoning accuracy in complex problem-solving.
- Framework mitigates limitations of single-model approaches by combining independence and collaboration, effectively avoiding local optima during search-based reasoning processes.


---

[REALM-Bench: A Real-World Planning Benchmark for LLMs and Multi-Agent Systems](http://arxiv.org/abs/2502.18836v1)

- Stock Market Prediction Workflow: introduces a system for stock price forecasting, incorporating data collection, feature extraction, model training, prediction generation, integration, and alert generation, validated through loops.
- This workflow utilizes market data, news feeds, and economic data as inputs to generate trading alerts based on predicted stock prices.
- The framework emphasizes validation and adaptive updates to maintain prediction accuracy and system reliability in dynamic market conditions.


---

[Data-Efficient Multi-Agent Spatial Planning with LLMs](http://arxiv.org/abs/2502.18822v1)

- LLM-MASP (LLM-based Multi-Agent Spatial Planning Framework): introduces multi-agent spatial planning using pretrained language model, rollout algorithm, base policy, environment, state, action, prompt, parse output, finetuning, feasibility checking, resampling, and memory.
- This framework leverages LLMs for efficient taxi routing by incorporating world knowledge and adapting to environmental factors through prompting and finetuning.
- The use of rollout algorithm and finetuning with LLMs significantly reduces the need for environmental interactions while outperforming traditional methods.


---


[Reward Shaping to Mitigate Reward Hacking in RLHF](http://arxiv.org/abs/2502.18770v2)

- RLHF training pipeline with reward shaping: introduces Prompt, Policy Model, Reference Model, Reward Model, Reward Shaping, Reshaped Reward and RL Training for aligning language models and mitigating reward hacking.
- The pipeline utilizes Reward Shaping to modify proxy rewards from Reward Model, optionally using Reference Reward, before updating Policy Model via RL Training.
- Preference As Reward (PAR) method, detailed as Reward Shaping, applies sigmoid function to centered reward to enhance training stability and mitigate reward hacking.


---

[AGENTSociety Challenge: Designing LLM Agents for User Modeling and Recommendation on Web Platforms](http://arxiv.org/abs/2502.18754v1)

- Environment simulator: introduces interactive environment for evaluating LLM agents, with LLM Agents, Simulator, U-R-I Network, and Datasets components.
- Environment simulator: constructs interactive environment comprising user, review, and item network, enabling agents to access historical data from datasets.
- Environment simulator: facilitates agent performance evaluation in tasks resembling real-world applications for user modeling and recommendation.


---

[TrajLLM: A Modular LLM-Enhanced Agent-Based Framework for Realistic Human Trajectory Simulation](http://arxiv.org/abs/2502.18712v1)

- TrajLLM (A Modular LLM-Enhanced Agent-Based Framework for Realistic Human Trajectory Simulation): introduces a modular framework for human trajectory simulation, integrating Persona Preprocess, Routine Activity Generation, Memory, and Destination modules.
- This framework uses LLMs for activity and destination prediction, incorporating memory for historical context and physical models for spatial reasoning.
- TrajLLM aims to generate realistic and adaptable human mobility patterns while ensuring scalable memory management and interpretable insights.


---

[Hi Robot: Open-Ended Instruction Following with Hierarchical Vision-Language-Action Models](https://www.pi.website/research/hirobot)

- Hi Robot (Hierarchical interactive robot learning system): introduces a hierarchical framework using VLMs for complex instruction following, incorporating user prompts, high-level reasoning, intermediate commands, low-level execution, and verbal responses.
- The framework decomposes policy into high-level VLM for complex prompt processing and low-level VLA for action execution.
- Hi Robot enables robots to interpret complex language, adapt to feedback, and perform diverse tasks in open-ended environments.


---


#### 25th February 2025

[A Cooperative Multi-Agent Framework for Zero-Shot Named Entity Recognition](http://arxiv.org/abs/2502.18702v1)

- CMAS (cooperative multi-agent system): introduces multi-agent framework with self-annotator, TRF extractor, demonstration discriminator, and overall predictor for zero-shot NER.
- CMAS leverages self-annotator for data generation, TRF extractor for contextual feature identification, demonstration discriminator for selective learning, and overall predictor for final prediction.
- CMAS enhances zero-shot NER by integrating contextual correlations and self-reflection mechanism through collaborative agents, improving performance and robustness.


---

[Hybrid Voting-Based Task Assignment in Role-Playing Games](http://arxiv.org/abs/2502.18690v1)

- VBTA (Voting-Based Task Assignment): introduces a framework for task allocation in role-playing games using capability profiles and task descriptions to generate a suitability matrix.
- VBTA framework integrates voting methods and allocation strategies to manage task assignments, and employs a pre-trained LLM with custom prompts to resolve agent-task compatibility ambiguities.
- By incorporating Conflict-Based Search for path planning, VBTA enables dynamic game content generation and automates agent decisions, enhancing narrative and gameplay immersion.


---

[Assistance or Disruption? Exploring and Evaluating the Design and Trade-offs of Proactive AI Programming Support](http://arxiv.org/abs/2502.18658v1)

- Codellaborator: introduces proactive AI programming support framework, with Timing of Assistance, AI Agent Representation and Scope of Interaction components, exploring design trade-offs in human-AI workflows.
- Codellaborator framework evaluates proactive assistance benefits and disruptions compared to user-initiated systems in programming tasks.
- The research emphasizes adapting AI proactivity to programming processes for improved user control and code understanding.


---

[INDEPENDENT MOBILITY GPT (IDM-GPT): A SELF-SUPERVISED MULTI-AGENT LARGE LANGUAGE MODEL FRAMEWORK FOR CUSTOMIZED TRAFFIC MOBILITY ANALYSIS USING MACHINE LEARNING MODELS](http://arxiv.org/abs/2502.18652v1)

- IDM-GPT (Independent Mobility GPT): introduces a multi-agent LLM framework with Input Validation, Self-optimization Prompting, Database Interaction, Data Analysis, and Self-supervision Modules, leveraging Database and Machine Learning Models for customized traffic mobility analysis.
- This framework utilizes LLM-based AI agents to streamline traffic data analysis, enabling efficient processing of spatio-temporal data and ensuring data privacy by mediating user access to sensitive information.
- IDM-GPT aims to address challenges in traffic management by providing a scalable solution for urban mobility improvement through optimized data analysis and actionable insights generation for users without ML expertise.


---

[Single- vs. Dual-Prompt Dialogue Generation with LLMs for Job Interviews in Human Resources](http://arxiv.org/abs/2502.18650v1)

- Single- vs. Dual-Prompt Dialogue Generation: introduces Single-Prompt Generation (one prompt for full dialogue), Dual-Prompt Generation (two agents with prompts), and Judge LLM (evaluates dialogue authenticity) frameworks for HR job interview dialogue generation and quality assessment.
- Single-Prompt Generation uses a single prompt to instruct LLM to create entire interview, whereas Dual-Prompt Generation uses two LLM-agents, interviewer and candidate, with separate prompts.
- Judge LLM evaluates generated dialogues by pairwise comparison to determine if dialogues are distinguishable from human discourse, focusing on AI generation detection.


---

[FRIDA to the Rescue! Analyzing Synthetic Data Effectiveness in Object-Based Common Sense Reasoning for Disaster Response](http://arxiv.org/abs/2502.18452v1)

- FRIDA (Field Ready Instruction Decoding Agent): introduces expert-in-the-loop pipeline with Templates, Disaster Relief Expert Input, Linguist Input, Seed sentences, Fine-tune Instruct model, Synthetic instructions, and Prompting LLM to generate synthetic data for fine-tuning smaller language models in disaster response domain.
- FRIDA pipeline leverages domain and linguistic expertise to create high-quality seed data, which is then used to generate synthetic instructions for fine-tuning language models, enhancing their common sense reasoning about objects.
- The framework demonstrates that fine-tuning smaller LLMs with synthetic data generated through the FRIDA pipeline improves their performance in object-based common sense reasoning tasks, particularly in disaster-related scenarios.


---

[MAPORL: Multi-Agent Post-Co-Training for Collaborative Large Language Models with Reinforcement Learning](http://arxiv.org/abs/2502.18439v1)

- MAPORL (Multi-Agent Post-co-training for collaborative LLMs with Reinforcement Learning): introduces multi-agent post-co-training paradigm for collaborative large language models, with LLMs, Verifier, Multi-agent RL, and Multi-LLM Systems components.
- MAPORL framework employs multi-agent reinforcement learning to co-train multiple LLMs for enhanced collaboration and generalization across diverse tasks.
- The framework utilizes a verifier to evaluate LLM responses and discussions, providing co-training rewards maximized through multi-agent RL, fostering effective collaboration.


---

[AgentRM: Enhancing Agent Generalization with Reward Modeling](http://arxiv.org/abs/2502.18407v1)

- AgentRM (Agent Reward Model): introduces generalizable reward model to guide policy model for effective test-time search using SFT Agent, Reward Model, and Policy Model components.
- AgentRM framework includes Dataset for training and Environment for task execution, leveraging LLM as base model and Reward Annotation for signal generation.
- AgentRM enhances agent generalization by finetuning reward model instead of policy model, improving performance on unseen tasks during Inference.


---


[REFUTEBENCH 2.0 – AGENTIC BENCHMARK FOR DYNAMIC EVALUATION OF LLM RESPONSES TO REFUTATION INSTRUCTION](http://arxiv.org/abs/2502.18308v1)

- RefuteBench 2.0: introduces User, LLMs (Large Language Models), and Verifier components for dynamic evaluation of LLM responses to refutation instructions.
- RefuteBench 2.0 framework employs User to provide feedback, LLMs as model under evaluation, and Verifier as evaluator agent.
- RefuteBench 2.0 facilitates flexible assessment of LLM's ability to incorporate refutation feedback in multi-turn dialogues.


---

[Debt Collection Negotiations with Large Language Models: An Evaluation System and Optimizing Decision Making with Multi-Agent](http://arxiv.org/abs/2502.18228v1)

- MADeN (Multi-Agent Debt Negotiation): introduces multi-agent framework with Communicating Agent (provides negotiation content), Planning Agent (designs decision framework), and Judging Agent (evaluates action rationality).
- MADeN framework enhances debt negotiation by incorporating planning to design decision framework and judging module to evaluate action rationality.
- MADeN framework aims to improve decision rationality in debt collection negotiations by addressing limitations of LLMs in making appropriate decisions based on debtor's financial condition.


---

[LAG: LLM agents for Leaderboard Auto Generation on Demanding](http://arxiv.org/abs/2502.18209v1)

- LAG (Leaderboard Auto Generation): introduces a framework for automatic leaderboard creation, encompassing paper processing, table analysis, data integration, and leaderboard output with evaluation.
- LAG framework utilizes LLMs to address challenges in generating up-to-date leaderboards from rapidly growing scientific publications, focusing on efficiency and quality.
- The framework's stages systematically handle paper collection, information extraction, data recombination, and quality assessment to produce reliable and timely leaderboards.


---

[Intersubjective Model of AI-mediated Communication: Augmenting Human-Human Text Chat through LLM-based Adaptive Agent Pair](http://arxiv.org/abs/2502.18201v1)

- Intersubjective Model: introduces an AI-mediated communication framework with Agent (LLM-based user proxy), Environment (independent chat space), Extraction (information distilling function), Conversation (dialogue management function), Information Transmission (agent-agent information sharing), Knowledge Base (information integration), and Online Chat Interface (user interaction platform).
- This model facilitates human-human communication indirectly through independent agent interactions and information exchange, enabling adaptive message shaping and shared understanding.
- The framework aims to overcome limitations of traditional communication models by removing the constraint of shared objective environment and allowing for customized interactions.


---

[Carbon and Silicon, Coexist or Compete? A Survey on Human-AI Interactions in Agent-based Modeling and Simulation](http://arxiv.org/abs/2502.18145v1)

- 5W1H Taxonomy (5W1H Taxonomy for Human-AI Interactions in ABMS): introduces five dimensions - Why, When, Who, What, and How - to categorize human-AI interaction methods within Agent-Based Modeling and Simulation (ABMS).
- The taxonomy decomposes interactions based on user goals, interaction phase, user roles, system components controlled, and interaction means, drawing analogy from theater roles to define user engagement.
- This framework aims to provide a structured approach for analyzing and designing human-AI interactions in ABMS, facilitating development of more effective and user-centered simulation systems.


---

[Large Language Model Driven Agents for Simulating Echo Chamber Formation](http://arxiv.org/abs/2502.18138v1)

- Model Framework: introduces data preparation, simulation process with LLM post generation, and analysis and validation to simulate echo chamber formation.
- The framework employs LLM-enhanced approach for opinion evolution, network rewiring, and content generation, incorporating textual context for realistic simulation.
- Simulation Process includes "screen" component, representing limited user attention and information accessibility within social media environments.


---

[LLM Knows Geometry Better than Algebra: Numerical Understanding of LLM-Based Agents in A Trading Arena](http://arxiv.org/abs/2502.17967v1)

- Agent Trading Arena: introduces a virtual numerical game environment, with Agent, Stocks and Market, Chat Pool, Day Simulation, Reflection, Memory and Environment components, designed for evaluating numerical reasoning of LLM-based agents in stock trading.
- Agent Trading Arena facilitates complex economic simulations through zero-sum games, enabling assessment of LLMs' geometric and algebraic reasoning capabilities using visual and textual numerical data.
- The framework incorporates a reflection module to enhance strategy refinement based on trading performance and environmental feedback, promoting continuous agent adaptation and learning in a dynamic market.


---

[MA-GTS: A Multi-Agent Framework for Solving Complex Graph Problems in Real-World Applications](http://arxiv.org/abs/2502.18540v1)

- MA-GTS (Multi-Agent Graph Theory Solver): introduces multi-agent framework for solving graph problems, with Information Extraction Layer (extracts text information), Knowledge Integration Layer (constructs structured graph data), and Algorithm Execution Layer (executes algorithms).
- MA-GTS framework decomposes complex graph problems through agent collaboration and maps text-based graph data into structured representations.
- MA-GTS framework dynamically selects suitable algorithm based on problem constraints and graph structure scale for efficient and interpretable solution process.


---


[7 Points to Tsinghua but 10 Points to 清华? Assessing Large Language Models in Agentic Multilingual National Bias](http://arxiv.org/abs/2502.17945v1)

- Academic Career Planning Advisor: introduces input prompt, LLM component, and output response for university recommendation task.
- Framework evaluates LLM's score and reasoning for provided universities in multilingual context.
- System aims to identify nationality bias in LLM's advisory capabilities across languages.


---

[FACT-AUDIT: An Adaptive Multi-Agent Framework for Dynamic Fact-Checking Evaluation of Large Language Models](http://arxiv.org/abs/2502.17924v1)

- FACT-AUDIT (An Adaptive Multi-Agent Framework for Dynamic Fact-Checking Evaluation) introduces an agent-driven framework with Appraiser, Taxonomy, Inquirer, Prototype, Quality Inspector, Memory Pool, Evaluator, Verify Fact & Produce Justification, Target LLM, Prober, Iterative Probing, and Automatic Evaluation components for adaptive and dynamic assessment of LLMs' fact-checking capabilities.
- FACT-AUDIT framework adaptively generates datasets, performs iterative evaluations, and updates assessments based on model-specific responses, incorporating justification production for comprehensive audit of LLMs' factual reasoning.
- The framework leverages multi-agent collaboration and importance sampling to address limitations of static datasets and classification metrics in existing fact-checking evaluation methods, providing a more nuanced and evolving audit process.


---

[Towards Enhanced Immersion and Agency for LLM-based Interactive Drama](http://arxiv.org/abs/2502.17878v1)

- Immersion-Agency Paradigm: introduces framework for LLM-based interactive drama, enhancing player Immersion and Agency through Dramatic Story Generator from Premise paragraph, Role Agents responding to Prompt, and generating Drama Script after Post-process.
- This paradigm uses Playwriting-guided Generation for improved story structure and Plot-based Reflection for agent reaction refinement.
- The framework aims to bridge gap in current interactive dramas by focusing on deeper emotional connections and meaningful player influence within the story.


---

[IMPROVE: ITERATIVE MODEL PIPELINE REFINEMENT AND OPTIMIZATION LEVERAGING LLM AGENTS](http://arxiv.org/abs/2502.18530v1)

- IMPROVE (Iterative Model Pipeline Refinement and Optimization leveraging LLM agents): introduces a multi-agent framework with Project Architect, Data Engineer, Model Engineer, Training Engineer, and Performance Analyst agents to iteratively refine ML pipelines based on user-provided dataset and task description.
- IMPROVE framework utilizes Iterative Refinement strategy, optimizing one pipeline component at a time through training and evaluation process guided by Performance Analyst feedback for stable and interpretable improvements.
- IMPROVE framework aims to automate object classification pipeline development, achieving high performance without requiring ML expertise by emulating human expert iterative refinement workflow.


---


#### 24th February 2025

[Aligning Compound AI Systems via System-level DPO](http://arxiv.org/abs/2502.17721v1)

- SysDPO (System-level Direct Preference Optimization): introduces DAG, LLM, Diffusion Model, DPO Loss, and Preference Dataset to align compound AI systems.
- SysDPO framework uses DAG to model compound AI system, factorizes probability, and applies DPO loss for end-to-end optimization using preference dataset.
- SysDPO enables joint alignment of components like LLM and diffusion models, improving coherence and preference alignment in complex AI systems.


---

[ARACNE: An LLM-Based Autonomous Shell Pentesting Agent](http://arxiv.org/abs/2502.18528v1)

- ARACNE (Autonomous LLM-based Shell Pentesting Agent): introduces a novel multi-LLM architecture for autonomous shell pentesting, comprising user, core agent, planner, interpreter, summarizer, SSH server and context components.
- ARACNE separates planning and command execution using distinct LLMs, enhancing flexibility and effectiveness in cybersecurity tasks.
- The framework utilizes an optional summarizer to manage context window size, offering a trade-off between accuracy and attack duration.


---

[IGDA: Interactive Graph Discovery Agent](http://arxiv.org/abs/2502.17189v1)

- IGDA (Interactive Graph Discovery Agent): introduces a LLM-based pipeline for interactive graph discovery, with Edge Confidence Estimation, Edge Experiment Selection, and Local Edge Updates components.
- IGDA leverages LLMs for uncertainty-driven edge selection and local graph updates based on binary feedback from experiments.
- IGDA iteratively refines graph predictions by selecting uncertain edges for experiments and updating related edges based on experimental outcomes.


---

[A Multi-LLM-Agent-Based Framework for Economic and Public Policy Analysis](http://arxiv.org/abs/2502.16879v1)

- MLAB (Multi-LLM-Agent-Based Framework): introduces a novel approach for economic analysis by employing multiple LLMs as heterogeneous agents representing different socio-economic groups.
- MLAB framework simulates policy impacts by mapping LLMs to educational and income brackets, utilizing calibrated economic parameters for each agent group.
- This framework leverages LLMs' diverse reasoning capabilities to model population heterogeneity and analyze policy responses in economic scenarios.


---

[Graphy'our Data: Towards End-to-End Modeling, Exploring and Generating Report from Raw Data](http://arxiv.org/abs/2502.16868v1)

- Graphy: introduces an end-to-end platform, with Offline Scrapper, Inspection, Define Workflow, File Extractor, LLM or Rule Extractor, Fact Node, Dimension Node, Navigation, Online Surveyor, Exploration, Search, StatRefiner, GraphView, NeighborQuery, Generation, DataInfer, Mindmap Generator, Confirmed, Report Writer, and Graph Store, that automates data modeling, exploration, and report generation from raw data.
- Graphy platform comprises an offline Scrapper for transforming unstructured documents into structured graphs and an online Surveyor for iterative exploration and LLM-driven report creation.
- Graphy facilitates progressive document investigation by enabling users to iteratively explore, analyze, and synthesize information from large unstructured datasets to generate high-quality reports.


---

[Leveraging Large Language Models for Effective and Explainable Multi-Agent Credit Assignment](http://arxiv.org/abs/2502.16863v1)

- LLM-MCA (Large Language Model Multi-agent Credit Assignment): introduces centralized LLM Critic (LLM for credit assignment), Base Prompt (LLM initial instructions), LLM Parser (extracts feedback from LLM), Individualized Feedback (per-agent reward signals), Centralized Policy Training (learns decentralized policies), Demultiplexer (splits input data for critic), Multiplexer (aggregates agent feedback), Agent Policies (decentralized agent controllers), Environment (multi-agent simulation scenario), Observations and Global Reward (environment state input), and Joint Action (agent actions output).
- LLM-MCA employs centralized LLM critic with base prompt to generate individualized feedback, guiding decentralized agent policy training for effective credit assignment.
- By reformulating credit assignment as pattern recognition, LLM-MCA leverages LLMs to achieve human-level credit evaluation and enhance multi-agent cooperative learning.


---

[Grounded Persuasive Language Generation for Automated Marketing](http://arxiv.org/abs/2502.16810v1)

- AI Realtor: introduces agentic framework, with Grounding Module, Personalization Module, Marketing Module, ChatGPT, to automate persuasive marketing content generation.
- It uses LLMs to align content with user preferences and highlight factual attributes, demonstrated in real estate marketing.
- The framework achieves superhuman persuasion in experiments, outperforming human experts in real estate marketing description generation.


---

[Multi-Agent Autonomous Driving Systems with Large Language Models: A Survey of Recent Advances](http://arxiv.org/abs/2502.16804v1)

- LLM-based Multi-Agent ADS Framework: introduces multi-agent system for autonomous driving, with Environment (driving context), Information (perceived data), Action (driving commands), Profile (role definition), Agent (autonomous entity), Driver Agent (vehicle control), Infrastructure Agent (external infrastructure), Shared Message Pool (communication medium), and Memory (experience storage).
- This framework employs profiles to define agent functionalities, facilitating collaborative decision-making through shared message pool and memory for experience retention.
- The architecture improves driving safety and efficiency in intricate scenarios by integrating separate agents for vehicle and infrastructure interaction, supported by LLM-based reasoning capabilities.


---

[AlphaAgent: LLM-Driven Alpha Mining with Regularized Exploration to Counteract Alpha Decay](http://arxiv.org/abs/2502.16789v1)

- AlphaAgent (LLM-Driven Alpha Mining with Regularized Exploration to Counteract Alpha Decay): introduces autonomous framework integrating Idea Agent, Factor Agent, and Eval Agent with regularization mechanisms for decay-resistant alpha factor mining.
- AlphaAgent framework employs Human Knowledge, Research Report, Market Insight, Performance Metrics, Backtest, Self-reflection, Analysis Feedback, Factor Zoo, Regularization Mechanisms, Operator Library, and Abstract Syntax Trees within closed-loop iterative refinement process.
- AlphaAgent utilizes originality enforcement, hypothesis-factor alignment, and complexity control to guide alpha generation, balancing financial rationale and market adaptability for effective alpha mining.


---

#### 23rd February 2025

[GUARDIANS OF THE AGENTIC SYSTEM: PREVENTING MANY SHOTS JAILBREAK WITH AGENTIC SYSTEM](http://arxiv.org/abs/2502.16750v1)

- Evaluating Agentic Systems: introduces methodology to evaluate agentic system security, with Reverse Turing Test, Aligning Multi-Agent Systems, and Prevention of Multi-Shot Jailbreaks.
- The framework employs GamoraAI, RocketAI, Star-LordAI, GrootAI, ObserverAI agents for assessing security vulnerabilities, deceptive alignment, and jailbreak defense.
- This comprehensive approach aims to enhance LLM-based agentic system robustness against adversarial threats through dynamic, tool-mediated security evaluations.


---

[RapidPen: Fully Automated IP-to-Shell Penetration Testing with LLM-based Agents](http://arxiv.org/abs/2502.16730v1)

- RapidPen (RapidPenetration): introduces a fully automated penetration testing framework, integrating Re Module (task planning module), Act Module (command execution module), and RapidPen-vis (visualization and reporting tool), utilizing PTT (pentesting process data model) for IP-to-Shell achievement.
- RapidPen framework incorporates ReAct paradigm with specialized RAG (Retrieval-Augmented Generation) repositories, featuring Re (L1) PTT Planner (PTT expansion and maintenance), Re (L1) PTT Prioritizer (task prioritization), Re (L2) New Tasks (Success Cases) (success case based task generation), Act (L1) Command Generation (command generation using RAG), Act (L1) Command Execution (executes commands), and Act (L1) Log Analysis (analyzes command logs) modules.
- The framework leverages Command Generation RAG (RAG for command generation) and Success Cases RAG (RAG for success cases) to enhance offensive security, enabling autonomous vulnerability discovery and exploitation through iterative command refinement and success case reuse.


---

[From Text to Space: Mapping Abstract Spatial Models in LLMs during a Grid-World Navigation Task](https://arxiv.org/abs/2502.16690v1)

- GWSOT (Grid-World Spatial Orientation Task): introduces agent, goal, grid, spatial information representations, LLM, activations, policy maps, and performance metrics to investigate spatial understanding of language models in grid navigation.
- GWSOT evaluates how different spatial information representations like cartesian, topographic, and textual formats impact LLM navigation performance and internal spatial encoding.
- The framework uses performance metrics and policy maps to analyze LLM success rate, path efficiency, and spatial decision-making within the grid-world environment.


---


[BIOMAZE: BENCHMARKING AND ENHANCING LARGE LANGUAGE MODELS FOR BIOLOGICAL PATHWAY REASONING](http://arxiv.org/abs/2502.16660v2)

- PATHSEEKER: introduces LLM agent for biological pathway reasoning via interactive subgraph navigation.
- PATHSEEKER enhances reasoning using global subgraph search, local subgraph search, graph encoding and final reasoning on pathway database.
- This method provides robust, scientifically grounded approach for complex pathway reasoning challenges.

---

[The Hidden Strength of Disagreement: Unraveling the Consensus-Diversity Tradeoff in Adaptive Multi-Agent Systems](http://arxiv.org/abs/2502.16565v1)

- Dynamic Consensus-Diversity Tradeoff: introduces a framework with Receives information, Arguments, Interpret intention, and Action components, describing consensus-diversity tradeoff in multi-agent systems.
- This framework contrasts implicit consensus, where agents decide independently after discussion, with explicit consensus, where agents unify actions via voting.
- The framework aims to demonstrate that implicit consensus enhances robustness and adaptability in dynamic environments by preserving diversity.


---


[All That Glitters is Not Novel: Plagiarism in AI Generated Research](http://arxiv.org/abs/2502.16487v1)

- SSAG (Semantic Scholar Augmented Generation): introduces plagiarism detection framework with query generation, paper retrieval, relevance scoring and similarity checking components for LLM-generated research.
- SSAG framework utilizes LLMs and Semantic Scholar API to identify similar research papers and assess plagiarism in generated research proposals.
- SSAG framework's evaluation reveals limitations in detecting sophisticated plagiarism within LLM-generated research documents, highlighting need for improved methods.


---

#### 22nd February 2025

[SMARTIFY: A MULTI-AGENT FRAMEWORK FOR AUTOMATED VULNERABILITY DETECTION AND REPAIR IN SOLIDITY AND MOVE SMART CONTRACTS](http://arxiv.org/abs/2502.18515v1)

- Smartify (SMARTIFY: A MULTI-AGENT FRAMEWORK FOR AUTOMATED VULNERABILITY DETECTION AND REPAIR IN SOLIDITY AND MOVE SMART CONTRACTS): introduces a multi-agent framework with Auditor, Architect, Code Generator, Refiner, and Validator components for automated smart contract vulnerability detection and repair.
- Smartify leverages specialized LLMs, including LLM1 (Gemma2 9B) for initial analysis and LLM 2 (FT CodeGemma) for code generation, alongside Move RAG and Solidity RAG for language-specific context retrieval.
- Smartify framework processes Code Dataset of smart contracts through its components to output Repaired Smart Contract, aiming for improved accuracy and efficiency in vulnerability remediation within blockchain landscape.


---

[Exploring Sentiment Manipulation by LLM-Enabled Intelligent Trading Agents](http://arxiv.org/abs/2502.16343v1)

- Framework name here: introduces a system exploring sentiment manipulation in trading using reinforcement learning agent, with arxiv_paper_framework_2-components RL-based Trading Agent, TD3 Algorithm, Actor Network, Critic Network, Target Networks, Internal State, Environmental State, Sentiment Agent, Social Media Feed, Sentiment Analysis (RoBERTa), Sentiment Heuristic, Social Media Post Generation, Language Model (Llama 3.2), Market Simulation (ABIDES), Order Book, and Historical Data (LOBSTER).
- The framework investigates how an RL-based trading agent can learn to manipulate market sentiment through generated social media posts to improve trading performance in a simulated market environment.
- The study utilizes a sentiment agent that reacts to social media posts and a market simulation driven by historical order book data to evaluate the RL agent's sentiment manipulation strategies.


---

[Reproducibility Study of Cooperation, Competition, and Maliciousness: LLM-Stakeholders Interactive Negotiation](http://arxiv.org/abs/2502.16242v1)

- LLM-Stakeholders Interactive Negotiation benchmark: evaluates LLM agents in negotiation games with negotiation game, LLM agents, CoT prompts, single-agent baseline, multi-agent setup, evaluation metrics, Pareto front analysis, structure leakage metric, and inequality metric.
- This benchmark study reproduces and extends prior negotiation research by analyzing open-weight models and introducing fairness and confidentiality metrics.
- The research highlights that single-agent baselines can achieve comparable negotiation performance to multi-agent setups, questioning communication necessity.


---

[An Autonomous Network Orchestration Framework Integrating Large Language Models with Continual Reinforcement Learning](http://arxiv.org/abs/2502.16198v1)

- ARC (Autonomous Reinforcement Coordination): introduces a two-tier network orchestration framework integrating LLMs and continual RL for SemCom-enabled SAGIN, featuring RAG for data processing, HAP for hierarchical planning, SKB and DKB for knowledge storage, and RL Agents for action execution.
- ARC decomposes network orchestration into high-level planning using LLM within HAP and low-level decision-making using RL Agents within Action Executioner, enhancing adaptability and efficiency through continual learning and few-shot learning.
- ARC utilizes RAG to generate allocation prompts for HAP, which then employs User Sequencer to optimize user order and Action Executioner with RL agents to execute resource allocation decisions based on SKB and DKB knowledge.


---


[Mojito: LLM-Aided Motion Instructor with Jitter-Reduced Inertial Tokens](http://arxiv.org/abs/2502.16175v1)

- Mojito (LLM-Aided Motion Instructor): introduces an intelligent motion agent utilizing IMU Tokenizer, Motion Tokenizer, Distribution Matching, Motion Decoder, Projection Layers, Decoder-only Transformer, LoRA Adapters, Text Tokenizer, and Qwen2-based Language Model for interactive motion capture and analysis.
- Mojito employs a jitter-reduced inertial token representation and extended language model to provide real-time human motion analysis and feedback, addressing limitations of noisy IMU data.
- The framework leverages VQVAE for discrete latent space learning of IMU signals and incorporates LoRA adapters for personalized feedback styles in fitness or rehabilitation scenarios.


---

[Protecting Users From Themselves: Safeguarding Contextual Privacy in Interactions with Conversational Agents](http://arxiv.org/abs/2502.18509v1)

- LLM-based Conversational Agent Framework: introduces a process for contextual privacy in conversational agents, with User Prompt (Initial user input), Detection & Flagging (Identifies context and sensitive data), Determine Subject & Context (Establishes topic and setting), Detect PII and Sensitive Phrases (Finds personal and private phrases), Sensitive Space (Categorizes sensitivity level), Essential Info (Identifies necessary information), Non-Essential Info (Identifies unnecessary information), Mitigation (Applies privacy measures), Get User Approval (User confirms action), Reformulate Prompt (Rewrites user input for privacy), Get User Approval (User confirms rewritten input), and LLM-based Conversational Agent (Core agent processing input).
- This framework processes user prompts to recognize context and sensitive information, subsequently providing revised prompts to users that aim to maintain original intent while minimizing out-of-context details.
- The framework empowers users to make informed privacy decisions during interactions with conversational agents by identifying and reformulating contextually inappropriate information in prompts.


---

[Echo: A Large Language Model with Temporal Episodic Memory](http://arxiv.org/abs/2502.16090v1)

- MADGF (Multi-Agent Data Generation Framework): introduces Characters, Plots, and Environments to simulate multi-turn dialogues for generating episodic memory training data.
- MADGF framework controls dialogue scenarios between human roles and AI assistant to create context-rich episodic memory data.
- MADGF framework aims to produce high-quality episodic memory data by designing diverse characters and plot-driven dialogues.


---

[Curie: Toward Rigorous and Automated Scientific Experimentation with AI Agents](http://arxiv.org/abs/2502.16069v2)

- Curie: introduces AI agent framework designed for rigorous automated scientific experimentation with intra-agent rigor module, inter-agent rigor module and experiment knowledge manager.
- Curie framework employs architect agent for planning and technician agents for execution, coordinated by experimental rigor module.
- Curie framework aims to enhance reliability, methodical control, and interpretability in AI-driven scientific experimentation.


---

[RAG-Enhanced Collaborative LLM Agents for Drug Discovery](http://arxiv.org/abs/2502.17506v1)

- CLADD (Collaborative framework of LLM Agents for Drug Discovery): introduces multi-agent framework for drug discovery question-answering, integrating Planning Team (identifies data sources), Knowledge Graph Team (retrieves KG information), Molecule Understanding Team (molecule description), and Prediction Agent (generates final answer) to leverage Annotation Database (molecular annotations source), Knowledge Graph (biomedical knowledge source), Captioning Tool (external molecule captioning) and Available Data and Tools (general resources).
- CLADD framework utilizes Planning Team with MolAnn Planner (annotation database relevance) and KG Planner (knowledge graph relevance), Knowledge Graph Team with DrugRel Agent (related drug entities report) and BioRel Agent (biological relationships report), and Molecule Understanding Team with MU Agent (molecule annotation report) to provide comprehensive analysis.
- CLADD framework enhances drug discovery tasks by employing collaborative agents to dynamically retrieve and integrate external knowledge, improving interpretability and flexibility without domain-specific fine-tuning.


---

#### 21st February 2025

[Multi-Agent Multimodal Models for Multicultural Text to Image Generation](http://arxiv.org/abs/2502.15972v1)

- MosAIG (Multi-Agent framework for Multicultural Image Generation): introduces multi-agent framework with Moderator, Social Agents (Country, Landmark, Age-Gender), Summarizer Agents, and Social Agents Conversation to generate Image Caption for AltDiffusion/FLUX image generation models.
- MosAIG framework employs iterative Social Agents Conversation for refining culturally sensitive and contextually rich Image Caption, enhancing multicultural text-to-image generation.
- MosAIG framework leverages distinct agent roles to decompose multicultural image generation task, achieving improved Alignment, Aesthetics, and Quality compared to simple models.


---


[R³Mem: Bridging Memory Retention and Retrieval via Reversible Compression](http://arxiv.org/abs/2502.15957v1)

- R³Mem (Retention and Retrieval through Reversible context compression): introduces memory network optimizing information retention and retrieval through reversible context compression with Reversible Adapter, Large Language Model M, and Virtual memory token components.
- R³Mem employs hierarchical compression for multi-granularity assimilation and reversible architecture integrating Context Compression and Context Expansion for duplex network.
- R³Mem utilizes Virtual memory token to encode long histories and achieves state-of-the-art performance in long-context language tasks.


---


[Self-Taught Agentic Long-Context Understanding](http://arxiv.org/abs/2502.15920v1)

- AgenticLU (Agentic Long-Context Understanding): introduces a framework designed for enhancing long-context question answering in LLMs, utilizing Chain-of-Clarifications (CoC) through iterative Raise Clarification Question, Find Context, and Self Clarify steps, and trained via CoC Path Distillation, SFT Dataset, Path Sampling, DPO Dataset, and Path & Neg Path Pair, starting from a base LLM and resulting in an Answer to the Long Context QA, contrasting with a Direct Answer approach.
- AgenticLU framework employs a two-stage fine-tuning process involving Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) to distill collected Chain-of-Clarifications (CoC) paths into a single inference pass model, improving efficiency and effectiveness.
- The core innovation of AgenticLU lies in its Chain-of-Clarifications (CoC) mechanism, which enables models to iteratively refine understanding and resolve uncertainties in long contexts through self-generated questions and contextual grounding, leading to improved reasoning and answer quality.


---


[AutoToM: Automated Bayesian Inverse Planning and Model Discovery for Open-ended Theory of Mind](http://arxiv.org/abs/2502.15676v1)

- AutoToM (Automated Theory of Mind): introduces automated Bayesian Theory of Mind method with Information Extraction, Initial Model Proposal, BTOM Models, Bayesian Inverse Planning, and Model Adjustment components.
- AutoToM leverages Large Language Model for backend operations and iteratively refines Bayesian Theory of Mind model based on inference uncertainty.
- This framework achieves state-of-the-art performance in Theory of Mind benchmarks, offering scalable, robust, and interpretable approach to machine Theory of Mind.


---

[WorldCraft: Photo-Realistic 3D World Creation and Customization via LLM Agents](http://arxiv.org/abs/2502.15601v1)

- WorldCraft: introduces a system utilizing LLM agents including coordinator, Forgelt, Arrangelt, trajectory control, asset collection and renderer components to create photo-realistic 3D virtual worlds from text instructions.
- WorldCraft framework employs a coordinator agent managing specialized agents for object customization, layout arrangement and scene animation based on user's natural language input.
- WorldCraft enables non-professionals to create and customize complex 3D scenes with precise object geometry and PBR textures through intuitive natural language interaction.


---

[Construction and Evaluation of LLM-based agents for Semi-Autonomous penetration testing](http://arxiv.org/abs/2502.15506v1)

- LLM Penetration Testing Agent: introduces a semi-autonomous penetration testing system, with Planning Module, Executor Module, Summarizer Module, RAG, Search Engines, Execution Environment, and PTT, to address limitations of LLMs in cybersecurity tasks.
- The system employs multiple LLMs in modules for strategy formulation, command generation, and result analysis, leveraging RAG and search engines for knowledge integration.
- This framework aims to overcome challenges in applying LLMs to penetration testing by using iterative reasoning and flexible information retrieval, reducing manual intervention.


---


[Position: Standard Benchmarks Fail – LLM Agents Present Overlooked Risks for Financial Applications](http://arxiv.org/abs/2502.15865v1)

- SAEA (Safety-Aware Evaluation Agent): introduces a three-level evaluation framework, including model-level, workflow-level, and system-level audits, to assess safety risks of LLM agents in finance.
- SAEA framework analyzes agent's intrinsic capabilities, multi-step process reliability, and integration robustness to identify vulnerabilities overlooked by traditional benchmarks.
- The proposed SAEA framework shifts focus from raw performance to safety, robustness, and real-world resilience, addressing critical gaps in current LLM agent evaluations for high-stakes financial applications.


---

[Pub-Guard-LLM: Detecting Fraudulent Biomedical Articles with Reliable Explanations](http://arxiv.org/abs/2502.15429v2)

- Pub-Guard-LLM (Large Language Model): introduces Pub-Guard-LLM, a system for detecting fraudulent biomedical articles, with Input Article, External Knowledge, Teacher Model, Pub-Guard-LLM, Vanilla, RAG, Debate, Fine-Tuning, Output, Prediction, Explanation, Relevance, and Coherence components.
- Pub-Guard-LLM enhances fraud detection in biomedical research by providing reliable explanations for its predictions.
- The framework offers three application modes: Vanilla Reasoning, Retrieval-Augmented Generation, and Multi-Agent Debate, to accommodate diverse user needs and improve detection performance and explainability.


---

[Textual-to-Visual Iterative Self-Verification for Slide Generation](http://arxiv.org/abs/2502.15412v1)

- Iterative Self-Verification Framework (Textual-to-Visual Iterative Self-Verification Framework): decomposes slide generation into content and layout generation, using textual-to-visual self-verification for refinement.
- Content generation enhances coherence using context from surrounding slides and section retrieval, while layout generation employs Reviewer + Refiner workflow.
- Modality transformation visualizes textual layouts, enabling intuitive review and refinement by LLM-based Reviewer and Refiner modules for improved slide quality.


---

[ARS: Automatic Routing Solver with Large Language Models](http://arxiv.org/abs/2502.15359v1)

- ARS (Automatic Routing Solver): introduces automatic routing solver framework, with pre-defined constraint examples, constraint selection, constraint checker, violation scorer, constraint handling method, initialization, optimization, final solution, local search, destroy & repair, destroy operators, repair operator, local search operators, input problem instance and termination condition.
- ARS framework enhances backbone heuristic algorithm by automatically generating constraint-aware heuristics using LLM agents.
- ARS framework utilizes database of VRP constraints and RAG-like approach for constraint selection to improve heuristic generation.


---

[Auto-Bench: An Automated Benchmark for Scientific Discovery in LLMs](http://arxiv.org/abs/2502.15224v1)

- Auto-Bench: introduces benchmark for evaluating Large Language Models in scientific discovery, incorporating settings, prompting, Large Language Model, interventions, observations, ground-truths comparison, adjacency matrix, match-not match, and loop control components.
- Auto-Bench framework evaluates LLMs' capability to discover hidden causal structures via iterative interactions and strategic interventions within chemistry and social network environments.
- This benchmark leverages causal graph discovery to assess LLMs' reasoning and decision-making skills in simulated scientific exploration tasks.


---

[The Evolving Landscape of LLM- and VLM-Integrated Reinforcement Learning](http://arxiv.org/abs/2502.15214v1)

- Taxonomy: introduces a framework for integrating LLMs/VLMs into RL, categorizing approaches based on three roles: agent (FM serves as policy), planner (FM generates sub-goals), and reward (FM shapes rewards).
- This taxonomy further distinguishes agent roles into parametric (fine-tuning FM to generate outputs) and non-parametric (enriching prompts with context) approaches, planner roles into comprehensive (sequence of sub-goals in one pass) and incremental (sub-goals step by step) planning, and reward roles into reward model (outputs scalar reward signal) and reward function (specifies reward function code) mechanisms.
- The framework helps to understand how LLMs/VLMs address RL challenges like prior knowledge, planning, and reward design, paving the way for unifying natural language and visual understanding with sequential decision-making.


---


[Investigating the Adaptive Robustness with Knowledge Conflicts in LLM-based Multi-Agent Systems](http://arxiv.org/abs/2502.15153v1)

- AutoGen (Multi-Agent System framework): introduces a multi-agent programming system comprising project manager for task coordination, coders for collaborative programming, and executor for tool interaction and code execution.
- This framework investigates robustness of LLM-based multi-agent systems when facing knowledge conflicts during collaborative programming tasks.
- The system aims to simulate real-world collaborative programming scenarios to analyze the impact of knowledge conflicts on decision-making and system stability.


---

#### 20th February 2025

[GATE: Graph-based Adaptive Tool Evolution Across Diverse Tasks](http://arxiv.org/abs/2502.14848v1)

- GATE (Graph-based Adaptive Tool Evolution): introduces an adaptive framework for dynamic construction and evolution of hierarchical graph of reusable tools across scenarios, utilizing Task Solver, Tool Manager, Adaptive Tool Graph, Graphrank Retrieval, Tool Requirement, Tool Generation, Tool Creation, Tool Merging, Self-Check, Tool Graph Update, Basic Tools, Composed Tools, Node, Edge, Adjacency Matrix, Graphrank Algorithm, Pruning, Online Learning, Training Stage and Testing Stage.
- GATE framework employs two interacting agents, Task Solver and Tool Manager, with Adaptive Tool Graph to dynamically manage and evolve toolset, addressing tool redundancy and limited generalizability in existing methods.
- The framework leverages Graphrank Retrieval for efficient tool discovery and incorporates Self-Check and Tool Merging to ensure tool quality and conciseness, achieving state-of-the-art performance across diverse tasks including open-ended and closed-ended scenarios.


---

[Is Safety Standard Same for Everyone? User-Specific Safety Evaluation of Large Language Models](http://arxiv.org/abs/2502.15086v1)

- U-SAFEBENCH (User-Specific Safety Benchmark): introduces benchmark, with LLM Agent (generates response considering user profile) and LLM-as-a-Judge (evaluates response safety and refusal), to evaluate user-specific safety of Large Language Models.
- U-SAFEBENCH assesses if LLM Agent response is user-specific unsafe response based on user profile and instruction.
- U-SAFEBENCH employs LLM-as-a-Judge to classify LLM Agent response as either refusal or fulfillment regarding user instruction.


---

[Red-Teaming LLM Multi-Agent Systems via Communication Attacks](http://arxiv.org/abs/2502.14847v1)

- AiTM (Agent-in-the-Middle) introduces communication attack framework for LLM Multi-Agent Systems, which includes Benign Agent (system participant), Malicious Agent (harmful actor), Agent-in-the-Middle (message interceptor manipulator), Adversarial Input (malicious agent data), Communication Channel (message pathway), Messages (agent information exchange), Reflection Mechanism (adversarial self-improvement), and Victim Agent (targeted agent).
- The framework evaluates vulnerability by employing Agent-in-the-Middle to intercept Messages within Communication Channel to manipulate Victim Agent, contrasting with Malicious Agent and Adversarial Input attacks targeting individual agents.
- AiTM leverages Reflection Mechanism in Agent-in-the-Middle to refine adversarial strategies based on intercepted Messages, highlighting critical security concerns in inter-agent communication within LLM Multi-Agent Systems.


---

[Scaling Text-Rich Image Understanding via Code-Guided Synthetic Multimodal Data Generation](http://arxiv.org/abs/2502.14846v1)

- CoSyn (Code Guided Synthetic data generation system): introduces a framework for generating text-rich multimodal data using topic generation, data generation, code generation, rendering tools, and instruction generation.
- CoSyn leverages text-only LLMs to generate code for rendering synthetic images and textual instructions for vision-language model training.
- The framework addresses the scarcity of diverse text-rich vision-language data for improving VLMs in understanding text-rich images.


---

[Optimizing Model Selection for Compound AI Systems](http://arxiv.org/abs/2502.14815v1)

- LLMSELECTOR (LLMSELECTOR): introduces Input, Module Nominator, Model Updater, and Output components for efficient model selection in compound AI systems.
- LLMSELECTOR iteratively nominates modules and uses module-wise performance estimation to allocate the best-performing model to each module.
- This framework achieves high-quality model allocation for compound AI systems, outperforming single-LLM allocation strategies.


---

[A Multi-Agent Perspective on Modern Information Retrieval](http://arxiv.org/abs/2502.14796v1)

- Multi-Agent Perspective on Modern Information Retrieval: introduces query agent, document agent, and ranker agent to analyze modern information retrieval through agent interactions.
- This perspective addresses complexities arising from automated query and document generation impacting retrieval paradigms.
- The framework emphasizes revisiting classical IR evaluation and modeling for effective multi-agent retrieval systems.


---


[Tree-of-Debate: Multi-Persona Debate Trees Elicit Critical Thinking for Scientific Comparative Analysis](http://arxiv.org/abs/2502.14767v1)

- TOD (Tree-of-Debate): introduces a framework for comparative scientific paper analysis using paper personas, moderator-guided debate tree construction, self-deliberation, debate rounds, expansion determination, debate synthesis, retrieval embedding model and evidence pool.
- TOD dynamically builds a debate tree to analyze novelty arguments by converting papers into debating personas and facilitating structured critical reasoning.
- The framework employs iterative retrieval and multi-persona debates to generate fine-grained contrastive summaries of scientific literature, aiding researchers in literature review.


---

[Multi-Agent Coordination across Diverse Applications: A Survey](http://arxiv.org/abs/2502.14743v2)

- Unified Framework: introduces iterative process for sequential decision-making in multi-agent coordination, consisting of Evaluate System-level Goal, Who to Coordinate with, and How to Coordinate components.
- Unified Framework: addresses coordination by evaluating system performance, determining agent clusters based on interdependencies, and updating decisions using appropriate methodologies.
- Unified Framework: provides a structured perspective on coordination, applicable across diverse multi-agent system applications by breaking down the coordination process into key decision points.


---


[I-MCTS: Enhancing Agentic AutoML via Introspective Monte Carlo Tree Search](http://arxiv.org/abs/2502.14693v2)

- I-MCTS (Introspective Monte Carlo Tree Search): introduces agentic AutoML framework, incorporating I-MCTS search module, LLM agent experiment executor, introspective node expansion, and hybrid reward mechanism.
- I-MCTS enhances search quality and efficiency by introspectively expanding nodes and adaptively blending LLM-estimated and empirical rewards.
- The introspective node expansion leverages parent and sibling node analysis for continuous refinement, addressing limitations of scalar feedback and static search spaces in AutoML.


---


[InstructAgent: Building User Controllable Recommender via LLM Agent](http://arxiv.org/abs/2502.14662v1)

- InstructAgent and Instruct² Agent: introduce user-agent-platform paradigm for recommendation, featuring Parser for instruction understanding, Reranker for recommendation adjustment, Self-reflection Mechanism for output verification, External Knowledge for external data access, Internal Knowledge for instruction based knowledge, Static Memory for historical user interactions, Dynamic Memory for adaptive user representation, Extractor for interest extraction and Profile Generator for profile creation.
- InstructAgent employs static memory and instruction parsing for reranking recommendations, whereas Instruct² Agent enhances personalization through dynamic memory and profile learning from user feedback.
- The framework aims to enhance user control in recommendation systems and mitigate issues like echo chambers and biases against less-active users by acting as a protective shield between users and platforms.


---

[Vending-Bench: A Benchmark for Long-Term Coherence of Autonomous Agents](http://arxiv.org/abs/2502.15840v1)

- Vending-Bench Framework: introduces agent architecture with main agent, sub-agent, memory tools, context management, and task-specific tools for vending machine operation benchmark.
- The framework uses main agent for decision making and sub-agent to interact with simulated vending machine environment.
- Memory tools and context management address LLM's memory limitations for long-term coherence evaluation.


---

[Plan-over-Graph: Towards Parallelable LLM Agent Schedule](http://arxiv.org/abs/2502.14563v1)

- Plan-over-Graph: introduces a novel paradigm for parallel LLM agent scheduling, incorporating RAGS, tree-based random graph generation, annotated data, goal definition, initial source specification, textual query generation, SFT, DPO, graph extraction, plan generation, and executable task schedule.
- This framework decomposes textual tasks into graph structures, enabling parallel execution planning and enhancing efficiency for complex tasks.
- The plan-over-graph approach addresses limitations in existing sequential planning methods by leveraging graph representations for improved scalability and performance in LLM agents.


---

[CORBA: Contagious Recursive Blocking Attacks on Multi-Agent Systems Based on Large Language Models](http://arxiv.org/abs/2502.14529v1)

- CORBA (Contagious Recursive Blocking Attacks): introduces a novel attack paradigm against LLM-MAS (Large Language Model-based Multi-Agent System) by leveraging CORBA Prompt to initiate Attack Propagation across the Topology of Agents, ultimately leading to Blocking State and system unavailability.
- CORBA exploits contagious and recursive properties to propagate blocking state through LLM-MAS network, causing resource depletion and availability degradation.
- The attack's effectiveness is demonstrated across various LLM-MAS frameworks and topologies, highlighting security vulnerabilities in current multi-agent systems.


---

[MLGYM: A New Framework and Benchmark for Advancing AI Research Agents](http://arxiv.org/abs/2502.14499v1)

- MLGYM (Meta MLGYM): introduces a framework for developing and evaluating LLM agents in AI research tasks, comprising Agent, Environment, and Computer components.
- MLGYM framework utilizes a Gymnasium Environment to integrate diverse AI research tasks, enabling agent interaction through actions and feedback within a controlled setting.
- The framework provides components like Tool Docs, Task Description, Prompts, Models for Agent; Tools, Data, Code, Requirements for Environment; and Shell, File System for Computer, facilitating comprehensive AI research agent evaluation.


---

[Enhancing Language Multi-Agent Learning with Multi-Agent Credit Re-Assignment for Interactive Environment Generalization](http://arxiv.org/abs/2502.14496v1)

- CollabUIAgents: introduces multi-agent reinforcement learning framework, with Agents, Critic Agent, Adversarial Agent, Reward Matrix, Action Matrix, Preference Optimization, Actions Rolling Out, System Update, Group Initialization, Multi-Agent Reinforcement Learning, Agentic Fine-Tuning, Curriculum Learning, Data Collection, Base Model, Base UIAgent, Environment, Observation, Reward, and Action, for enhancing generalization in interactive environments.
- CollabUIAgents framework employs novel credit re-assignment strategy using LLM-based critic and preference learning to foster collaborative behaviors and improve generalization.
- The framework achieves state-of-the-art performance in mobile and web UI interaction tasks, demonstrating effectiveness of credit re-assignment and preference optimization for multi-agent learning.


---

[FLOWAGENT: Achieving Compliance and Flexibility for Workflow Agents](http://arxiv.org/abs/2502.14345v1)

- FLOWAGENT (FLOWAGENT): introduces a novel agent framework for workflow management, incorporating PDL, Controllers, DAG of node dependency, API node, Answer node, OOW node, Pre-decision controllers, Post-decision controllers, Conversation history, User, Bot agent, System, Workflow, Output Action, and Output System response, to achieve both compliance and flexibility.
- FLOWAGENT framework utilizes Procedure Description Language (PDL) to define workflows and employs controllers for managing agent behavior, dynamically balancing compliance and flexibility when handling user interactions and unexpected queries.
- The framework architecture includes pre- and post-decision controllers that guide and validate agent actions based on PDL-defined workflows, ensuring both structured execution and responsiveness to dynamic interactions.


---


[ChemHTS: Hierarchical Tool Stacking for Enhancing Chemical Agents](http://arxiv.org/abs/2502.14327v1)

- ChemHTS (Chemical Hierarchical Tool Stacking): introduces a method that optimizes tool invocation pathways through hierarchical stacking strategy.
- ChemHTS comprises Self-Stacking Warmup (individual tool warmup) and Multi-Layer Optimization (hierarchical path optimization) stages, enabling dynamic refinement of tool usage.
- This framework addresses limitations in tool-augmented Large Language Models by facilitating effective collaboration among diverse tools and minimizing tool invocation errors.


--- 

[Beyond Self-Talk: A Communication-Centric Survey of LLM-Based Multi-Agent Systems](http://arxiv.org/abs/2502.14321v1)

- Communication-Centric Framework: introduces a communication-centric perspective on LLM-based multi-agent systems, with Communication Architecture, Communication Goal, Communication Strategy, Communication Paradigm, Communication Object, and Communication Content components, where the framework analyzes system-level and internal communication elements in LLM-MAS workflows.
- Communication-Centric Framework decomposes LLM-MAS workflow based on communication, categorizing system-level aspects like agent organization and goals, and internal aspects like strategies and message handling.
- Communication-Centric Framework provides a structured approach to understand and analyze the communication dynamics within LLM-MAS, offering insights into design and optimization for diverse applications.


---

[STeCa: Step-level Trajectory Calibration for LLM Agent Learning](http://arxiv.org/abs/2502.14276v1)

- STeCa (Step-Level Trajectory Calibration): introduces a framework for LLM agent learning with Deviated Action Detection, MC Step Reward, Expert Sub-trajectory, Reflection, Reflective Thought, Calibration Trajectory Construction, Calibrated Trajectory, Expert Trajectory, Successful Data, Reinforced Training, and Calibration Data, to enable step-level trajectory calibration for mitigating suboptimal actions.
- STeCa framework utilizes step-level reward comparison and LLM-driven reflection to construct calibrated trajectories from explored trajectories with detected deviations, which are then used with successful trajectories for reinforced training.
- The framework aims to improve LLM agent's decision-making in long-horizon tasks by addressing early-stage deviations through timely calibration, enhancing robustness and reducing error accumulation.


---

[MEM2EGO: EMPOWERING VISION-LANGUAGE MODELS WITH GLOBAL-TO-EGO MEMORY FOR LONG-HORIZON EMBODIED NAVIGATION](http://arxiv.org/abs/2502.14254v1)

- MEM2EGO (Memory-to-Egocentric): introduces a VLM-based navigation framework, integrating Observation, Memory Mapping, Memory Augmented Observation, Landmark Memory Update, and Metric Map Memory, for enhanced embodied agent navigation.
- MEM2EGO framework adaptively retrieves task-relevant cues from global memory, encompassing Frontier Map, Landmark Semantic Memory, and Visitation Memory, and dynamically aligns global context with local perception for improved spatial reasoning.
- MEM2EGO enhances agent's navigation in complex environments by maintaining three distinct memory types and projecting cues onto egocentric images to guide goal location prediction and decision-making.


---

[Enhancing Conversational Agents with Theory of Mind: Aligning Beliefs, Desires, and Intentions for Human-Like Interaction](http://arxiv.org/abs/2502.14171v3)

- LatentQA interpretability pipeline (LatentQA): introduces Target Model (analyzed language model) to process Dialogue (input conversation text) and answer ToM Question (query about mental states) using Decoder Model (extracts ToM information) to produce ToM Answer (inferred mental state) with Feedback (gradient for training-steering) for generating Aligned Response (ToM-steered output) instead of Generated Answer (model's initial output), involving ToM Inference (inferring mental states), ToM Feedback (feedback on ToM inference), Steering Inference (ToM-based model steering), and Steering Feedback (feedback on steering).
- LatentQA pipeline employs Decoder Model to extract Theory of Mind (ToM) related information from Target Model's internal representations based on Dialogue and ToM Questions, utilizing Feedback mechanisms for both ToM inference and model steering to achieve improved response alignment.
- The framework aims to enhance conversational agents by incorporating Theory of Mind (ToM) principles, leveraging LatentQA to interpret and manipulate model's latent representations for generating more human-like and aligned responses through explicit consideration of beliefs, desires, and intentions.


---


#### 19th February 2025

[Investigating Non-Transitivity in LLM-as-a-Judge](http://arxiv.org/abs/2502.14074v1)

- SWIM (Swiss-Wise Iterative Matchmaking): introduces User Instruction, Response of A, Response of B, Response of C, Judge Evaluation, Round Robin Tournament, Bradley Terry, Elo Score, and SWIM Tournament components for evaluating LLMs by addressing non-transitivity in pairwise comparisons using efficient tournament approach.
- SWIM framework employs round-robin tournaments and Bradley-Terry model to produce reliable model rankings, mitigating sensitivity to baseline choice in LLM evaluation.
- SWIM tournament enhances computational efficiency of round-robin evaluations while maintaining robustness and alignment with human evaluations by dynamic model matching.


---

[Autellix: An Efficient Serving Engine for LLM Agents as General Programs](http://arxiv.org/abs/2502.13965v1)

- Autellix: introduces an efficient serving engine for LLM agents, incorporating Process Table (tracks program metadata), Load Balancer (distributes LLM calls), LLM Engine (processes LLM calls) with Scheduler (schedules LLM calls), Priority Function (determines call priority), Memory Manager (manages engine memory), KV Cache (stores key-value pairs), and Model Executor (executes LLM model).
- Autellix leverages program-level statistics and discretized priority queues to minimize head-of-line blocking and improve throughput for agentic programs with dynamic execution workflows.
- The system employs a stateful API and data locality-aware load balancing to enhance KV-cache reuse and reduce latency in multi-engine LLM serving environments.


---

[RAG-Gym: Optimizing Reasoning and Search Agents with Process Supervision](http://arxiv.org/abs/2502.13957v1)

- RAG-Gym (Retrieval-Augmented Generation Gymnasium): introduces unified framework optimizing agentic RAG through process supervision with inner and outer Markov Decision Processes.
- RAG-Gym: formulates knowledge-intensive question answering as nested Markov Decision Process, incorporating diverse agent architectures and process supervision methods.
- RAG-Gym: enhances information-seeking agents by fine-grained process supervision at each search step, utilizing process reward data for optimization.


---

[Qwen2.5-VL Technical Report](https://arxiv.org/abs/2502.13923v1)

- Qwen2.5-VL (Qwen2.5 Vision-Language): introduces vision-language framework integrating vision encoder, vision-language merger and language model decoder for processing multimodal inputs like images and videos.
- Qwen2.5-VL framework's vision encoder utilizes native resolution input, dynamic FPS sampling, MROPE, window attention and full attention to process visual data efficiently before merging with text embeddings.
- This architecture enables Qwen2.5-VL to achieve advancements in visual recognition, document parsing and long-video comprehension, while maintaining computational efficiency through window attention and dynamic resolution processing.


---

[Exploring Personalized Health Support through Data-Driven, Theory-Guided LLMs: A Case Study in Sleep Health](http://arxiv.org/abs/2502.13920v1)

- HEALTHGURU: introduces multi-agent framework for personalized health support, integrating behavior change technique theory, wearable data, context data, activity recommendation model, user message, agent coordinators, data insight agent, recommendation agent, response agent, and chat history.
- HEALTHGURU: is LLM-powered chatbot providing data-driven theory-guided sleep health support using contextual multi-armed bandit model for adaptive recommendations.
- HEALTHGURU: enhances user engagement motivation for behavior change through personalized context-aware recommendations delivered via natural conversation.


---

[DataSciBench: An LLM Agent Benchmark for Data Science](http://arxiv.org/abs/2502.13897v1)

- DataSciBench (DSB): introduces a benchmark for data science LLM evaluation, with Prompt Definition and Collection-component, Response Integration and Validation-component, and LLM evaluation-component, utilizing Task-Function-Code framework for assessment.
- DataSciBench framework employs Directed Acyclic Graph to manage task dependencies and Programmatic Rules for consistent code evaluation, ensuring comprehensive LLM performance analysis in data science tasks.
- DataSciBench benchmark includes Aggregate Functions and Test Cases with Ground Truth to provide detailed and reliable evaluation metrics for diverse data science challenges, addressing limitations of existing benchmarks.


---

[Enhancing Cross-Domain Recommendations with Memory-Optimized LLM-Based User Agents](http://arxiv.org/abs/2502.13843v1)

- AgentCF++ (Agent Collaborative Filtering Plus Plus): introduces user- and item-agents with domain-separated-, domain-fused-, group-shared-, and item-memories, and interest groups to enhance cross-domain recommendations by refining user behavior simulation.
- AgentCF++ employs dual-layer memory architecture with domain-separated and domain-fused memories and interest groups with group-shared memory to capture popularity influence and domain-specific preferences.
- The framework utilizes a two-step fusion mechanism to integrate cross-domain knowledge and reflection mechanism for memory updates, improving the accuracy of user behavior simulation in recommender systems.


---

[From Correctness to Comprehension: AI Agents for Personalized Error Diagnosis in Education](http://arxiv.org/abs/2502.13789v1)

- MathCCS (Mathematical Classification and Constructive Suggestions) Benchmark: introduces multi-modal benchmark with real-world problems, student data, and expert annotations for error analysis and feedback.
- MathCCS benchmark incorporates real-world problems, unique student IDs with timestamps, and expert-defined error categorization with suggestions.
- MathCCS benchmark facilitates systematic error analysis and personalized feedback in AI-driven education by capturing real student learning complexities.


---

[AI Software Engineer: Programming with Trust](http://arxiv.org/abs/2502.13767v1)

- Framework components: introduces key elements of LLM agents for software engineering, including LLMs as back-ends (computation engines), interaction with software tools (tool utilization), autonomy (agent independence), and guardrails (security and validation).
- These components define the capabilities and trust mechanisms considered essential for deploying AI software engineers in practical software development workflows.
- The paper argues for the importance of trust in AI-generated code and proposes agentic capabilities to enhance trustworthiness in automated programming.


---

[An LLM-based Agent for Reliable Docker Environment Configuration](http://arxiv.org/abs/2502.13681v1)

- Repo2Run (LLM-based Agent for Reliable Docker Environment Configuration): introduces automated Docker environment configuration, with external environment, internal environment, Dockerfile generator, rollback mechanism, event stream, environment monitoring, dependency installation, code editing, test running, bash commands, dependency management, result processor, action-observation interaction, event history, finished commands, conflict list, and Dockerfile action.
- Repo2Run utilizes dual-environment architecture for atomic configuration synthesis, ensuring reliable Dockerfile generation and preventing environment pollution through rollback.
- Repo2Run's atomic configuration synthesis and Dockerfile generator address challenges in automated environment setup, achieving high success rate in configuring Python repositories.


---

[STaR-SQL: Self-Taught Reasoner for Text-to-SQL](http://arxiv.org/abs/2502.13550v1)

- STaR-SQL (Self-Taught Reasoner for Text-to-SQL): introduces reasoning-driven approach for text-to-SQL, utilizing Question, Schema, Rationale Generation, Finetune, Scale up test-time compute, Outcome-supervised Reward Model, Test-time Verification, and Difficulty-based Resample components.
- STaR-SQL framework employs rationale generation and outcome supervision to enhance text-to-SQL performance by iteratively refining rationales and verifying SQL query correctness.
- The framework leverages increased test-time computation and difficulty-based resampling to improve accuracy and robustness for complex text-to-SQL tasks.


---

[OpenSearch-SQL: Enhancing Text-to-SQL with Dynamic Few-shot and Consistency Alignment](http://arxiv.org/abs/2502.14913v1)

- OpenSearch-SQL: introduces a multi-agent framework for Text-to-SQL, incorporating Preprocessing, Extraction, Generation, Refinement, and Alignment Module with Agent Alignment, Function Alignment, Style Alignment, Correction, and Self-consistency & vote components.
- This framework uses a consistency alignment mechanism to reduce hallucination and improve information flow between agents during the Text-to-SQL process, leveraging Vector Database and Few-shot examples.
- The method achieves state-of-the-art performance by dynamically adjusting few-shot examples and employing a SQL-Like intermediate language within a structured Chain-of-Thought approach, enhancing both effectiveness and efficiency without fine-tuning.


---

[Beyond Single-Value Metrics: Evaluating and Enhancing LLM Unlearning with Cognitive Diagnosis](http://arxiv.org/abs/2502.13996v1)

- UNCD (UNlearning evaluation using Cognitive Diagnosis): introduces UNCD, a framework for fine-grained LLM unlearning evaluation, with Unlearning Process, QA Eval, UNCD Eval, Base LLM, LLM+GA, LLM+NPO, Precise Diagnosis, Training-free Diagnosis, CDM, Knowledge States, Unlearn Set, Eval Set, Knowledge Concepts, Forget KC, Retain KC, Expert check, Question generation, Scoring, Processing, Raw data, and UNCD-Agent.
- UNCD leverages Cognitive Diagnosis Modeling for detailed assessment of harmful knowledge removal and introduces UNCD-Cyber benchmark for cybersecurity domain.
- UNCD-Agent enhances unlearning by diagnosing knowledge remnants and generating targeted unlearning data, improving removal of harmful LLM abilities.


---

[MCTS-KBQA: Monte Carlo Tree Search for Knowledge Base Question Answering](http://arxiv.org/abs/2502.13428v1)

- MCTS-KBQA (Monte Carlo Tree Search for Knowledge Base Question Answering): introduces MCTS methodology to KBQA domain, enhancing LLM reasoning with selection, expansion, evaluation, backpropagation, and termination steps.
- This framework uses LLM agent interacting with database environment, guided by step-wise reward mechanism and prompts, to perform knowledge base question answering.
- MCTS-KBQA achieves improved performance over linear methods by exploring multiple reasoning paths and evaluating intermediate steps within the search tree.


---



#### 18th February 2025

[Towards an AI co-scientist](https://storage.googleapis.com/coscientist_paper/ai_coscientist.pdf)

- AI co-scientist: introduces a multi-agent system designed to augment scientific discovery by generating, debating, and evolving research hypotheses, utilizing Scientist inputs, Research plan configuration, Generation agent, Reflection agent, Ranking agent, Evolution agent, Proximity agent, Meta-review agent, Tool Use, Memory, and Supervisor agent components.
- AI co-scientist employs a generate, debate, and evolve approach inspired by the scientific method, leveraging specialized agents for literature exploration, hypothesis review, ranking via tournaments, and iterative refinement, all orchestrated by a Supervisor agent and supported by Memory and Tool Use.
- AI co-scientist framework facilitates flexible compute scaling and iterative improvement of hypothesis quality through a self-improving loop enabled by feedback from tournament-based ranking and meta-review, aiming to accelerate scientific discovery in biomedicine and beyond.


---

[AIDE: AI-Driven Exploration in the Space of Code](http://arxiv.org/abs/2502.13138v1)

- AIDE (AI-Driven Exploration): introduces an agent for machine learning engineering, with Solution Tree, Coding Operator, Evaluator, Search Policy, and Summarization Operator, automating trial-and-error via tree search in code space.
- AIDE employs a tree structure to organize historical solutions and uses a coding operator to propose improvements based on tree nodes, guided by automated evaluations.
- By strategically reusing and refining solutions within its framework, AIDE trades computational resources for enhanced performance on machine learning engineering benchmarks.


---

[Facilitating Long Context Understanding via Supervised Chain-of-Thought Reasoning](http://arxiv.org/abs/2502.13127v1)

- PAI (Property-driven Agentic Inference): introduces three-stage framework with property extraction, retrieval, and summarization agents for generating reasoning-augmented answers in long-context question answering.
- PAI framework simulates human-like reasoning by decomposing queries, retrieving relevant information, and synthesizing conclusions to facilitate long-context understanding.
- PAI framework enhances long-context question answering by incorporating chain-of-thought reasoning and improving model performance on complex tasks.


---

[TEXT2WORLD: Benchmarking Large Language Models for Symbolic World Model Generation](http://arxiv.org/abs/2502.13092v1)

- TEXT2WORLD: introduces benchmark for evaluating LLMs in symbolic world model generation, with Automatic Generation, Automatic Correction, Syntax Parser, World Model, Executor, and Multi-criteria Evaluation components.
- TEXT2WORLD benchmark employs PDDL and execution-based metrics to address limitations in prior world model evaluations, emphasizing domain diversity and evaluation robustness.
- TEXT2WORLD enables detailed analysis of LLM world modeling performance via component-wise F1 scores and error analysis, aiming to foster advancements within the field.


---

[LLM TRADING: ANALYSIS OF LLM AGENT BEHAVIOR IN EXPERIMENTAL ASSET MARKETS](http://arxiv.org/abs/2502.15800v1)

- LLM Trading (Large Language Model Trading): introduces experimental framework with agent, order submission, price forecasting, memory, market, and environment components for analyzing LLM behavior in asset markets.
- This framework investigates LLM agents' trading strategies and market dynamics in simulated financial markets, comparing their behavior to human participants.
- The study focuses on evaluating LLMs' rationality and ability to replicate human-driven market phenomena like bubbles and crashes within controlled experimental settings.


---

[Training Turn-by-Turn Verifiers for Dialogue Tutoring Agents: The Curious Case of LLMs as Your Coding Tutors](http://arxiv.org/abs/2502.13311v2)

- TRAVER (Trace-and-Verify): introduces agent workflow with knowledge tracing for student state estimation, utterance generation for tutor messages, and verifier for response quality assessment.
- TRAVER leverages turn-by-turn verification and knowledge tracing to guide students in coding tasks through dialogue.
- The framework aims to improve tutoring effectiveness by adapting guidance based on student knowledge and utterance quality.


---


[Demonstrating specification gaming in reasoning models](http://arxiv.org/abs/2502.13295v1)

- ReAct-like harness: introduces observe, orient, decide, and act phases alongside memory, plan, and subgoal components for LLM agent to interact with environment.
- The framework employs observe phase to process command outputs, orient phase to update strategic plan, decide phase to select tactical subgoal, and act phase to generate shell commands for task execution.
- Memory, plan, and subgoal components maintain agent state, enabling iterative refinement of actions based on observed outcomes within the environment.


---

[OCCULT: Evaluating Large Language Models for Offensive Cyber Operation Capabilities](http://arxiv.org/abs/2502.15797v1)

- OCCULT (Offensive Cyber Operation Lightweight operational evaluation framework): introduces a methodology to evaluate LLMs for Offensive Cyber Operations, structured around LLM Use Case, OCO Capability Areas, and Reasoning Power components.
- OCCULT framework facilitates rigorous and repeatable evaluations to quantify cyber security risks associated with employing LLMs in offensive cyber operations.
- OCCULT methodology aims to standardize LLM testing in OCO domain, enabling better comparisons across different models and evaluation approaches.


---

[Grounding LLM Reasoning with Knowledge Graphs](http://arxiv.org/abs/2502.13247v2)

- Framework for Grounding LLM Reasoning with Knowledge Graphs: introduces agent and automatic graph exploration approaches for question answering using knowledge graphs, incorporating components like RetrieveNode, NeighborCheck, Entities and Triples.
- Agent approach employs predefined actions such as RetrieveNode and NeighborCheck for targeted KG interaction, while automatic exploration utilizes extracted Entities and Triples to navigate the knowledge graph.
- The framework evaluates Chain-of-Thought, Tree-of-Thought, and Graph-of-Thought reasoning strategies within both Agent and Automatic Graph Exploration approaches to enhance question answering performance on knowledge graphs.


---

[Interactive Agents to Overcome Ambiguity in Software Engineering](http://arxiv.org/abs/2502.13069v1)

- OpenHands framework (OpenHands): introduces interactive environment for LLM Agent, enabling structured code refinement, task planning, and command execution using integrated tools within secure sandbox.
- OpenHands framework: facilitates iterative code improvement through file editing, script execution, and error analysis within controlled environment.
- OpenHands framework: leverages User Proxy to simulate realistic interactions, allowing agent to gather necessary context and improve performance in ambiguous software engineering tasks.


---

[AEIA-MN: Evaluating the Robustness of Multimodal LLM-Powered Mobile Agents Against Active Environmental Injection Attacks](http://arxiv.org/abs/2502.13053v1)

- AEIA-MN (Active Environment Injection Attack - Mobile Notifications): introduces active environment injection attack scheme, with Perception Stage, Reasoning Stage, Action Stage, System, State and Action components, to evaluate MLLM-based agents robustness.
- AEIA-MN leverages mobile notifications to perform attacks by disrupting agent decision-making through environmental manipulation.
- The framework includes Adversarial Attack, Reasoning Gap Attack, and Combinatorial Attack strategies to comprehensively evaluate agent robustness against active injection attacks.


---

[Towards a Design Guideline for RPA Evaluation: A Survey of Large Language Model-Based Role-Playing Agents](http://arxiv.org/abs/2502.13012v1)

- RPA evaluation design guideline: introduces agent attributes, agent-oriented metrics, task attributes, and task-oriented metrics for systematic RPA evaluation.
- The guideline proposes a two-step process: first, decide agent-oriented metrics based on agent attributes, and second, decide task-oriented metrics based on task attributes.
- This guideline aims to enhance the reliability and consistency of RPA evaluation by linking evaluation metrics to agent and task attributes.


---

[You need to MIMIC to get FAME: Solving Meeting Transcript Scarcity with a Multi-Agent Conversations](http://arxiv.org/abs/2502.13001v1)

- MIMIC (Multi-agent IMItation of Conversations): introduces a multi-agent meeting synthesis framework that uses Knowledge Source, Content Brainstorming, Casting, Scriptwriting, Filming, Quality Assuring, Special Effects, and Editing to generate Meeting Transcript.
- MIMIC framework employs pre-production, production, and post-production stages to orchestrate psychologically grounded agents debating turn-by-turn, refining outputs to ensure coherent and credible dialogues.
- The modular architecture of MIMIC allows for scalable generation of meeting transcripts, addressing data scarcity for training and testing meeting summarization systems.


---

[Flow-of-Options: Diversified and Improved LLM Reasoning by Thinking Through Options](http://arxiv.org/abs/2502.12929v1)

- FoO (Flow-of-Options): introduces an agentic framework for automated machine learning tasks, incorporating Input task, Planner, Option Generator, Flow-of-Options, Plan Executor, Update, CODE-RAW, Case-Based Reasoning, Case Bank, Retrieve and adapt, Walk Generation with Consistency Checker, Update Values, and Update Case Bank components.
- This framework leverages a network data structure to systematically explore diverse reasoning paths by enumerating options at each step of a task plan, enhancing Large Language Model performance in solving complex problems.
- The approach integrates case-based reasoning for long-term memory and solution reuse, improving efficiency and overcoming biases inherent in Large Language Models for automated machine learning workflows.


---

[SEFL: Harnessing Large Language Model Agents to Improve Educational Feedback Systems](http://arxiv.org/abs/2502.12927v1)

- SEFL (Synthetic Educational Feedback Loops): introduces Agent Framework with Teacher (LLM creating assignments), Student (LLM completing assignments with errors), Fineweb-Edu (assignment text source), Synthetic Instruction-Tuning Data (generated interaction data), fine-tuned LLM (feedback model), and Output Evaluation (performance measurement process) for improving educational feedback systems.
- SEFL framework leverages two LLMs in Teacher and Student roles to simulate formative feedback workflows and generate synthetic data for fine-tuning smaller feedback LLMs.
- This synthetic data generation and fine-tuning pipeline enables scalable and effective educational feedback systems, addressing real-world data scarcity challenges.


---

[Towards more Contextual Agents: An extractor-Generator Optimization Framework](http://arxiv.org/abs/2502.12926v1)

- Extractor-Generator Framework: introduces a two-stage approach with feature extraction and prompt generation to optimize prompts for contextual LLM-based agents using input-output dataset, feature extraction, prompt component generation and performance evaluation.
- The framework extracts contextual features from gold-standard input-output pairs and generates prompt components iteratively refining them through self-improvement techniques and performance evaluation.
- This automated optimization process enhances the adaptability and reliability of LLM agents in context-specific tasks by improving generalization and reducing error propagation.


---

[Knapsack Optimization-based Schema Linking for LLM-based Text-to-SQL Generation](http://arxiv.org/abs/2502.12911v1)

- KaSLA (Knapsack optimization-based Schema Linking Agent): introduces a plug-in schema linking agent, with Hierarchical Linking Strategy, Table linking, Column linking, Knapsack optimization-based schema linking, Binary scoring function, Probabilistic scoring function, Relevance score, Redundancy score, Redundancy tolerance, Linking, Dynamic Programming, Training dataset, and Query, designed to prevent missing relevant schema elements and minimize redundant ones.
- KaSLA employs hierarchical linking strategy, initially linking tables and subsequently columns, utilizing knapsack optimization with binary-probabilistic scoring functions and dynamic programming to select relevant schema elements under redundancy tolerance.
- The framework enhances text-to-SQL models by replacing schema linking processes, improving SQL generation accuracy through optimized schema linking and reduced missing or redundant information.


---


[Fraud-R1 : A Multi-Round Benchmark for Assessing the Robustness of LLM Against Augmented Fraud and Phishing Inducements](http://arxiv.org/abs/2502.12904v1)

- Fraud-R1: introduces a multi-round evaluation framework with Helpful Assistant, Role-play, LLM Judge, and Defense Status Judgement components.
- Fraud-R1 assesses LLM robustness against fraud using Defense Success, Defense Failure, and Need More Information statuses.
- Fraud-R1 framework evaluates LLMs in different settings to identify challenges in fraud defense.


---

[Continuous Learning Conversational AI: A Personalized Agent Framework via A2C Reinforcement Learning](http://arxiv.org/abs/2502.12876v1)

- CLCA (Continuous Learning Conversational AI): presents an A2C reinforcement learning framework for personalized conversational agents, integrating synthetic data generation, RL environment design, A2C agent training, and A2C-guided response selection.
- CLCA framework employs a simulated RL environment with state space representing dialogue context, action space controlling dialogue metrics, and reward function guiding A2C agent to learn personalized dialogue strategies.
- This A2C-driven CLCA method advances beyond static LLMs by enabling continuous learning and personalization through synthetic data and RL, creating dynamically adaptive AI companions.


---

[Benchmarking Automatic Speech Recognition coupled LLM Modules for Medical Diagnostics](http://arxiv.org/abs/2502.13982v1)

- Framework name here: introduces a two-stage system for medical diagnosis from speech, with audio preprocessing, speech recognition, and LLM-based diagnosis classification, utilizing medical speech database.
- The system employs audio preprocessing with denoising and equalization to enhance audio quality before ASR and uses LLM for context-aware medical diagnosis from transcribed speech.
- The framework is designed to improve robustness in noisy medical call recordings and leverage LLMs for accurate medical diagnosis from patient speech.


---

[Towards Adaptive Feedback with AI: Comparing the Feedback Quality of LLMs and Teachers on Experimentation Protocols](https://arxiv.org/abs/2502.12842)

- LLM feedback agent (Large Language Model feedback agent): presents a system generating student feedback on experiment protocols, utilizing Feed Up, Feed Back, Feed Forward feedback types, assessed by Constructive Tone, Linguistic Clarity, Technical Terminology criteria.
- The study compares LLM feedback against teacher and expert feedback, revealing similar overall quality yet LLM agent's limitations in Feed Back error identification.
- Findings indicate LLMs' capability for efficient educational feedback, underscoring the necessity for enhanced contextual understanding in error-specific feedback generation.


---

[An LLM-Powered Agent for Physiological Data Analysis: A Case Study on PPG-based Heart Rate Estimation](http://arxiv.org/abs/2502.12836v1)

- OpenCHA Framework: introduces an LLM-powered agent for physiological data analysis, with Interface, Orchestrator, External Sources, Response Generator, Task Planner, Task Executor, Data Pipe, PPG Processing Pipeline, AI and Analysis Models, Wearable PPG Data and User Data Sources components, aiming to integrate LLMs with analytical tools for health insights.
- The framework utilizes an orchestrator to coordinate user interaction, data retrieval, and analytical processing, leveraging external sources for data and AI models to generate accurate health assessments.
- The agent's architecture is designed for modularity and adaptability, enabling integration of various data sources and analytical tools for diverse physiological data analysis tasks.


---

[R2-KG: General-Purpose Dual-Agent Framework for Reliable Reasoning on Knowledge Graphs](http://arxiv.org/abs/2502.12767v1)

- R2-KG (General-Purpose Dual-Agent Framework for Reliable Reasoning on Knowledge Graphs): introduces dual-agent framework with Operator, Supervisor, KG, Iteration limit, Feedback, Question, Answer, Abstention for reliable KG reasoning by separating evidence gathering and judgment roles.
- It employs Operator (low-capacity LLM evidence gatherer) and Supervisor (high-capacity LLM judgment maker) to enhance cost-efficiency and reliability.
- R2-KG incorporates Abstention mechanism to avoid answering when evidence is insufficient, improving trustworthiness.


---


[Multi-Novelty:Improve the Diversity and Novelty of Contents Generated by Large Language Models via inference-time Multi-Views Brainstorming](http://arxiv.org/abs/2502.12700v1)

- Multi-Novelty: introduces inference-time multi-view brainstorming method with Input Prompt, Multi-view Embedding, LLMs, Generated Answers and DNC Framework components to enhance diversity and novelty of generated contents.
- Multi-view Embedding component incorporates Text views and Image views to enrich input prompts by generating diverse perspectives from textual and visual sources, which are then processed by LLMs to produce varied responses.
- DNC Framework evaluates Generated Answers using diversity, novelty, and correctness metrics, demonstrating the effectiveness of Multi-Novelty in improving LLM outputs without architectural changes and across different models.

---

[Perovskite-LLM: Knowledge-Enhanced Large Language Models for Perovskite Solar Cell Research](http://arxiv.org/abs/2502.12669v1)

- Perovskite-LLM (Knowledge-Enhanced Large Language Models for Perovskite Solar Cell Research): introduces Perovskite-KG, a domain-specific knowledge graph, constructed via Document Filtering, Knowledge Extracting, and Knowledge Graph Organization, alongside a Multi-agent framework with Information Extraction Agent, Quality Validation Agent, and Document Summarizer Agent, utilizing DeepSeek R1 and OpenAI 01 LLMs to generate Instruction Tuning and Reasoning Dataset.
- Perovskite-KG organizes knowledge from research papers into a structured graph, while the multi-agent framework creates datasets for instruction tuning specialized Large Language Models.
- The system aims to enhance research efficiency in perovskite solar cell domain by providing tools for knowledge retrieval, literature review, and complex problem-solving.


---

[One Size doesn't Fit All: A Personalized Conversational Tutoring Agent for Mathematics Instruction](http://arxiv.org/abs/2502.12633v2)

- PACE (PersonAlized Conversational tutoring agEnt): introduces a personalized tutoring framework for mathematics instruction, incorporating Simulating Learning Styles (models student learning style), Conceptualize Teaching Strategy (designs teaching approach), Socratic-style Conversation (implements teaching dialogue), Persona Pool (collection of student profiles), Interaction (tutor-student communication), Multi-aspect Criteria (quality assessment metrics), and Evaluation Approaches (assessment methodologies).
- PACE framework personalizes learning by simulating student learning styles from personas, conceptualizing tailored teaching strategies, and employing Socratic dialogue for enhanced engagement and critical thinking.
- The framework utilizes multi-aspect criteria and dual evaluation approaches, including reference-based and LLM-based methods, to comprehensively assess the personalized tutoring performance.


---

[Automating Prompt Leakage Attacks on Large Language Models Using Agentic Approach](http://arxiv.org/abs/2502.12630v1)

- AG2 (AutoGen): introduces agentic framework for automating prompt leakage attacks, utilizing Initial Analysis Agent, Judge Agent, and Tested Agent within GroupChat for evaluating LLM security.
- This framework employs specialized agents to probe and exploit target LLMs, assessing prompt leakage by comparing responses from original and sanitized prompts.
- The agentic approach provides a systematic methodology for adversarial testing, bridging automated threat modeling and practical LLM security evaluation.


---


[DemonAgent: Dynamically Encrypted Multi-Backdoor Implantation Attack on LLM-based Agent](http://arxiv.org/abs/2502.12575v1)

- DemonAgent (Dynamically Encrypted Multi-Backdoor Implantation Attack): introduces dynamically encrypted multi-backdoor implantation attack, with Dynamic Encryption Mechanism, Multi-Backdoor Tiered Implantation (MBTI), and AgentBackdoorEval dataset components.
- DemonAgent decomposes backdoor code into Sub-backdoor fragments, uses Anchor Tokens and Attack Matrix for stealth, and employs Encryption Table for secure storage within Agent's workflow.
- DemonAgent leverages Encryptor, Decoder, Assembler, Executor, and Retriever components to manage encrypted backdoor fragments and activate attack through Cumulative Triggering, effectively bypassing safety audits.


---

[A Cognitive Writing Perspective for Constrained Long-Form Text Generation](http://arxiv.org/abs/2502.12568v2)

- CogWriter: introduces a novel training-free framework with Planning Agent for hierarchical task decomposition, Generation Agents for parallel segment generation, and Monitor Functions including Global Plan Reviewing, Local Plan Reviewing and Length Reviewing for continuous quality control.
- CogWriter framework employs Planning Agent to create structured plans and Generation Agents to execute these plans, utilizing Global Plan Reviewing and Local Plan Reviewing for iterative refinement and Length Reviewing for output length adjustment.
- CogWriter framework aims to bridge gap between human cognitive writing processes and current LLMs for complex constrained long-form text generation, enhancing instruction completion and generation length.


---

[UXAgent: An LLM-Agent-Based Usability Testing Framework for Web Design](http://arxiv.org/abs/2502.12561v2)

- UXAGENT (LLM-Agent-Based Usability Testing Framework) introduces a system with Persona Generator, LLM Agent, Universal Browser Connector, and Result Viewer, utilizing Chrome browser, Action Trace, Memory Trace, Video Recording, Final Outcome, Chat Interface, Fast Loop with Perception-, Planning-, and Action-Modules, Slow Loop with Wonder- and Reflect-Modules, and Memory Stream to simulate usability testing for web design.
- UXAGENT employs Persona Generator to create diverse user demographics, LLM Agent with Fast and Slow Loops for web interaction and reasoning, Universal Browser Connector for website interaction, and Result Viewer to present collected user behavior data to UX researchers.
- The framework facilitates iterative UX study design by providing simulated user behavior data including action traces, memory logs, video recordings, and chat interfaces, enabling researchers to evaluate and refine usability testing before real human-subject studies.


---


[CityEQA: A Hierarchical LLM Agent on Embodied Question Answering Benchmark in City Space](http://arxiv.org/abs/2502.12532v2)

- PMA (Planner-Manager-Actor): introduces hierarchical framework with Planner, Manager, and Actor modules for embodied question answering in city environments.
- PMA framework incorporates Planner for task parsing, Manager with Memory and Map for process control and spatial reasoning, and Actor with Navigator, Explorer, and Collector for action generation.
- PMA agent utilizes cognitive map and hierarchical structure to achieve long-horizon planning and efficient task execution in complex urban spaces.


---

[Policy-to-Language: Train LLMs to Explain Decisions with Flow-Matching Generated Rewards](http://arxiv.org/abs/2502.12530v1)

- Policy-to-Language Framework: introduces a model-agnostic explanation generator using Explanation LLM, Guidance LLM and Reward Generation by Flow Matching for training with PPO Training, taking Input context and producing Output reasoning, verified against True action.
- The framework employs Reward Generation by Flow Matching with components like Projection, Rectified Flow Network, Linear Layer, Embedding, First L-1 Layers, Gaussian Noise, PE(t), Zt, and Cross-Attention Layer to provide effective rewards for training the Explanation LLM.
- This approach aims to generate dense and effective rewards, reducing reliance on human feedback and improving the quality and accuracy of explanations for agent decisions in both RL and LLM tasks.


---

[Simulating Cooperative Prosocial Behavior with Multi-Agent LLMs: Evidence and Mechanisms for AI Agents to Inform Policy Decisions](http://arxiv.org/abs/2502.12504v1)

- Multi-Agent Architecture: introduces a class structure for social emergent behavior simulation, encompassing World (simulation environment), Locations (places for agents), Events (agent actions and observations), Agents (LLM instances representing people), Plans (agent intentions and goals), and Memories (agent past experiences).
- The framework uses World class to define simulation space with Locations for agent interaction and Events to record agent actions, while Agents, as LLM instances, possess Plans to guide behavior and Memories to inform actions based on past events.
- This architecture facilitates emergent behaviors by enabling agents to reason about surroundings, create plans, react to events, and communicate, offering a structured approach to simulate complex social interactions.


---

[EDGE: Efficient Data Selection for LLM Agents via Guideline Effectiveness](http://arxiv.org/abs/2502.12494v1)

- EDGE (Efficient Data selection for LLM Agents via Guideline Effectiveness): introduces a data selection framework for LLM agents, with Unlabeled Data Pool, Initial Guideline, GE Metric, GE Score Calculation, Lowest GE Score Data Selection, Guideline Update, Updated Guideline, High-quality SFT Data Generation, Fine-tuning open-source LLM, and Guideline-based prompt engineering components.
- EDGE framework uses Guideline Effectiveness metric to identify informative samples from unlabeled data by measuring the impact of human guidelines in multi-turn interaction tasks.
- Selecting low GE score samples allows for efficient prompt engineering and fine-tuning by focusing on data where guidelines are less effective, thus more informative.


---

[Boost, Disentangle, and Customize: A Robust System2-to-System1 Pipeline for Code Generation](http://arxiv.org/abs/2502.12492v1)

- BDC Framework (Boost, Disentangle, and Customize Framework): introduces System2-to-System1 pipeline for code generation, with System 2 Knowledge Exploration, Composable System 1 Experts Preparation, and Customized Solver Generation components.
- BDC Framework addresses complex reasoning and data heterogeneity using MC-Tree-Of-Agents with mutual boosting, disentangling data for LoRA experts, and input-aware hypernetwork for customization.
- The framework utilizes multiple LLMs for verification, Monte-Carlo Tree Search with pruning, and DisenLoRA for adaptive generation of customized problem solvers.


---

[EPO: Explicit Policy Optimization for Strategic Reasoning in LLMs via Reinforcement Learning](http://arxiv.org/abs/2502.12486v1)

- EPO (Explicit Policy Optimization): introduces strategic reasoning model (LLMs) with policy, optimize, multi-turn RL, PRM (Process Reward Model), history, interaction, agent/human/env, LLM agent, observation, strategy, and reward components for goal-directed behavior in dynamic environments.
- EPO framework utilizes multi-turn RL with process rewards and iterative self-play to train the strategic reasoning model, enhancing adaptability and policy transferability without supervised fine-tuning.
- The strategic reasoning model in EPO integrates with LLM agents, enabling long-term goal achievement through enhanced strategic reasoning in interactive scenarios.


---

[Investigating and Extending Homans' Social Exchange Theory with Large Language Model based Agents](http://arxiv.org/abs/2502.12450v1)

- Agent Framework: introduces LLM-based agent framework with BDI, Affinity, REI, SVO, Negotiation and Exchange components to study Homans' Social Exchange Theory.
- The framework simulates a multi-agent society where agents negotiate and exchange resources based on designed components.
- This approach provides a novel method to investigate social science theories using LLM-based agents, bridging social science and computer science.


---


#### 17th February 2025

[A-MEM: Agentic Memory for LLM Agents](http://arxiv.org/abs/2502.12110v1)

- A-MEM (Agentic Memory) introduces agentic memory system for LLM agents with Note Construction, Link Generation, Memory Evolution, Memory Retrieval, and Memory components.
- A-MEM enables dynamic memory structuring and autonomous memory management inspired by Zettelkasten method for long-term agent interactions.
- A-MEM facilitates creation of interconnected knowledge networks and evolution of memories, enhancing LLM agents' long-term interaction capabilities.


---

[ARMAP: SCALING AUTONOMOUS AGENTS VIA AUTOMATIC REWARD MODELING AND PLANNING](http://arxiv.org/abs/2502.12130v1)

- ARMAP (autonomous Agents from automatic Reward Modeling And Planning): introduces a framework that enhances LLM agents' decision-making by using Automatic Reward Model (evaluates trajectory quality) to guide Default Policy Model (generates initial action plans) in Tree Planning (search algorithm for actions) using Trajectories (sequences of agent actions) and Reward (score for trajectory success).
- Leverages Automatically Generated Dataset (training data for reward model) from Sampled Trajectories (trajectories from environment), Refine Task Instructions (improved task goals), and Sample Negative Trajectories (unsuccessful action paths) to train Reward Model (evaluates trajectory success) without human annotations.
- Improves agent performance across tasks by integrating learned Reward Model (evaluates trajectory success) with various planning algorithms, addressing limitations of data scarcity and API accessibility for complex interactive environments.


---

[HARBOR: Exploring Persona Dynamics in Multi-Agent Competition](http://arxiv.org/abs/2502.12149v1)

- HARBOR (Housing Auction for Reasoning, Bidding, and Opponent Recognition): introduces a testbed to study persona dynamics in multi-agent auctions, incorporating Persona, Bidding Domain Knowledge, Auction History Memory, Priority Planning, Profiling Competitors, and Theory of Mind Strategy.
- HARBOR simulates realistic house bidding scenarios to analyze how personas influence agent behavior, competitor profiling, and strategic decision-making in competitive environments.
- This framework enables the evaluation of LLM agents' profitability, competitive standing, and persona-driven objective achievement in multi-agent competitive settings.


---

[SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-World Freelance Software Engineering?](https://arxiv.org/abs/2502.12115)

- SWE-Lancer: introduces benchmark evaluating language models on real-world software engineering tasks using Original Issue, Codebase, Large Language Model, Generated PR, Human End-to-End Tests, Grader, and Scoring for individual contributions and Original Issue, Proposals, Large Language Model, Rejected Proposals, Chosen Proposal, Comparison, and Scoring for management decisions.
- SWE-Lancer benchmark assesses model's ability to solve freelance software engineering tasks by generating code patches or selecting optimal proposals, evaluated through end-to-end tests and comparison with human decisions.
- SWE-Lancer framework provides realistic software engineering evaluation by utilizing real-world tasks, payouts, and full-stack complexities, moving beyond isolated unit tests to comprehensive end-to-end assessments.


---


[Learning Getting-Up Policies for Real-World Humanoid Robots](https://arxiv.org/abs/2502.12152)

- HUMANUP: introduces a two-stage RL framework with Discovery Policy (Stage I motion exploration) and Deployable Policy (Stage II robust motion tracking) for humanoid robots getting-up.
- HUMANUP employs a Curriculum (Progressive training strategy) including Collision Mesh Curriculum (Mesh complexity progression), Posture Randomization Curriculum (Initial pose variation), and Control Regularization Curriculum (Regularization strength progression) to enhance learning.
- Stage II Deployable Policy utilizes Tracking Rewards (Stage II imitation reward) to refine discovered motions for real-world deployment.


---

[Can LLMs Simulate Social Media Engagement? A Study on Action-Guided Response Generation](http://arxiv.org/abs/2502.12073v1)

- Action-Guided Response Generation Framework: introduces a method to simulate social media engagement using Trending Post, User Information Historical Records, Action, and Generated Response components.
- Action-Guided Response Generation Framework predicts user engagement Action (retweet, quote, rewrite) towards Trending Post, then generates Generated Response based on predicted Action and User Information Historical Records.
- Action-Guided Response Generation Framework aims to capture user engagement dynamics for informed response generation in social media simulations.


---


[CAMEL: Continuous Action Masking Enabled by Large Language Models for Reinforcement Learning](http://arxiv.org/abs/2502.11896v1)

- CAMEL (Continuous Action Masking Enabled by Large Language Models): introduces reinforcement learning framework integrating LLM Policy Generator, Action Masking, Actor, Critic, Replay Buffer and Epsilon Masking to enhance exploration and convergence by using LLM-generated policies and dynamic action constraints.
- CAMEL leverages Action Masking to dynamically constrain action space based on LLM outputs and Epsilon Masking to reduce reliance on LLM guidance over time, enabling autonomous policy refinement.
- The framework demonstrates improved sample efficiency and performance in MuJoCo environments by effectively utilizing LLM-generated priors for initial policy guidance and exploration.


---

[Leveraging Dual Process Theory in Language Agent Framework for Real-time Simultaneous Human-AI Collaboration](http://arxiv.org/abs/2502.11882v1)

- DPT-Agent (Dual Process Theory Agent): introduces a language agent framework integrating System 1 with Finite-State Machine, Code as Policy, Action Executor and System 2 with Theory of Mind, Asynchronous Reflection, Belief, Guide, alongside General Introduction and Information History Buffer for real-time human-AI collaboration.
- DPT-Agent leverages Dual Process Theory, employing System 1 for rapid responses and System 2 for deliberate reasoning, to achieve autonomous and simultaneous human-AI collaboration.
- The framework utilizes Finite-State Machine and code-as-policy in System 1 for fast decision-making, and Theory of Mind with asynchronous reflection in System 2 to infer human intentions and improve autonomous decisions.


---

[Hypothesis-Driven Theory-of-Mind Reasoning for Large Language Models](http://arxiv.org/abs/2502.11881v1)

- Thought-tracing: introduces inference-time reasoning algorithm, with Parse Trajectory, Perception Inference, Hypothesis Inference, Initialize Hypotheses, Update Weights, Resample Hypotheses, Rejuvenate Hypotheses, Propagate Hypotheses, designed to trace agent mental states.
- Thought-tracing algorithm, inspired by Bayesian theory-of-mind and sequential Monte Carlo, uses LLMs to generate and weight natural language hypotheses about agent beliefs based on perceptions and actions.
- Thought-tracing improves performance on theory-of-mind benchmarks by providing intermediate reasoning steps, contrasting with math/coding focused reasoning models.


---

[Can LLM Agents Maintain a Persona in Discourse?](http://arxiv.org/abs/2502.11843v1)

- Agent-based evaluation framework: introduces a methodology to evaluate personality maintenance in dyadic conversations using Participant A/B, Assign, Personality Traits, Topic of Conversation, Pairwise Conversation, and Judge Agent components.
- This framework employs System Prompt and User Prompt to guide LLM agents in conversations and JSON output for structured evaluation by Judge Agent, including Predicted_bfi and Correct? metrics.
- The framework aims to assess personality consistency and alignment by Extract, Analyze, and Plot actions performed by Judge Agents on conversation data to evaluate personality adherence.


---


[Table-Critic: A Multi-Agent Framework for Collaborative Criticism and Refinement in Table Reasoning](http://arxiv.org/abs/2502.11799v1)

- Table-Critic: introduces multi-agent framework with Judge, Critic, Refiner, Curator and Self-evolving Template Tree, for collaborative criticism and iterative refinement in table reasoning tasks.
- Table-Critic framework employs Judge to identify errors, Critic to provide critiques, Refiner to correct reasoning, and Curator with self-evolving template tree to accumulate critique knowledge for improved future performance.
- Self-evolving template tree in Table-Critic dynamically accumulates critique patterns from experience-driven learning, enabling system to handle diverse error types and improve reasoning quality over time.


---

[Personality Editing for Language Models through Relevant Knowledge Editing](http://arxiv.org/abs/2502.11789v1)

- PALETTE (Persona Adjustment by LLM Self-Targeted Trait Control via Relevant Knowledge Editing): introduces personality control method through knowledge editing, with MBTI questionnaire, adjustment query construction, LLM (original), generate model response, extract self-referential statement, extract opposite trait word, layer, association at layer 1, optimize v by object, edited LLM, and specific trait-focused response generation components.
- PALETTE leverages MBTI-inspired adjustment queries and rank-one model editing to modify LLM's internal representations for personality traits.
- This approach enables controlled shifts in personality, addressing inherent biases and improving consistency in LLM responses.


---

[Plant in Cupboard, Orange on Table, Book on Shelf Benchmarking Practical Reasoning and Situation Modelling in a Text-Simulated Situated Environment](http://arxiv.org/abs/2502.11733v1)

- AdventureGame: introduces text-based environment, with Agent (executes game actions), Environment (simulated text-based world), Interpreter (processes agent commands), Parser (command grammar definition), State Change Module (updates game world state), World State (current game facts representation), Observation Feedback (textual game responses), Goal (task objective for agent), Action Space (set of valid commands), and Memory (interaction history storage).
- AdventureGame facilitates situated language environment understanding and common-sense reasoning evaluation through simplified interactive fiction game.
- AdventureGame framework assesses unassisted LLMs performance by providing direct action outcome observations, combining planning and execution within turn-limited episodes.


---

[LLM Agents Making Agent Tools](http://arxiv.org/abs/2502.11705v1)

- TOOLMAKER: introduces an agentic framework, with User, AI research assistant, Tool library, Environment setup, Tool implementation, Workflow components, LLM calls, Environment interactions, Agents, TM-BENCH, Docker container, Conversation history, and Environment state, that autonomously creates LLM-compatible tools from scientific papers and code repositories.
- TOOLMAKER framework addresses the limitation of requiring pre-defined tools for LLM agents by enabling dynamic tool creation through a closed-loop self-correction mechanism.
- The framework's effectiveness is objectively evaluated using TM-BENCH, a benchmark suite designed to assess tool correctness and robustness across diverse tasks.


---

[Exploring LLM-based Student Simulation for Metacognitive Cultivation](http://arxiv.org/abs/2502.11678v1)

- Pipeline for generating and filtering high-quality simulated student agents: introduces a multi-component framework with Student Profile Generation, Two-Round Scoring with Profile Consistency Scoring using Questioning Agent and Profile Scorer, Behavioral Consistency Scoring using Dialogue Agent and Behavior Scorer, Graph-Based Score Propagation, Ranking and Filtering, and Human Expert Evaluation to automate the creation of authentic student simulations for metacognitive cultivation.
- This pipeline leverages a two-round automated scoring system, incorporating graph neural networks for score propagation, to ensure both profile and behavioral consistency of simulated agents, thereby reducing the need for extensive human annotation.
- The framework aims to enhance the authenticity of learning difficulty simulations, facilitating broader applications in personalized learning and pedagogical evaluation by providing a robust method for generating and validating high-quality simulated students.


---


[Competing LLM Agents in a Non-Cooperative Game of Opinion Polarisation](http://arxiv.org/abs/2502.11649v1)

- Non-Cooperative Game Framework: introduces a simulation framework with Red Agent, Blue Agent, Judge Agent, Network, BCM Model and Memory to analyse opinion polarisation in a non-cooperative game setting.
- This framework models adversarial interactions between LLM agents, simulating misinformation spread and countering within a social network using BCM Model for opinion updates and Judge Agent for message potency assessment.
- The framework investigates the impact of resource constraints and cognitive biases on opinion dynamics, highlighting the strategic importance of early influence and resource management in countering misinformation.


---

[DEVIATION RATINGS: A GENERAL, CLONE INVARIANT RATING METHOD](http://arxiv.org/abs/2502.11645v1)

- Deviation Ratings: introduces deviation ratings, a novel rating method, with Deviation Rating, CCE, Deviation Gain, Iterative Minimization, and Linear Programming components, which provides clone invariant ratings for N-player general-sum games.
- Deviation Ratings framework utilizes Coarse Correlated Equilibrium and iterative minimization of deviation gain via linear programming for rating calculation.
- Deviation Ratings method overcomes Nash Equilibrium limitations by employing CCE, achieving scalable, clone-attack-proof, and data agnostic rating system.


---

[A Survey of Personalized Large Language Models: Progress and Future Directions](http://arxiv.org/abs/2502.11528v1)

- PLLM (Personalized Large Language Models) Framework: introduces personalized response generation through profile, dialogues, content, and interactions, utilizing personalized prompting, efficient fine-tuning, and personalized alignment with generation, recommendation and classification tasks.
- The framework processes user query and data to adapt LLM via prompting, adaptation and alignment for tailored responses, considering generation, recommendation, and classification.
- This approach enhances user experience across applications by contextually relevant and user-specific response generation, addressing limitations of general LLMs.


---

[AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection](https://arxiv.org/abs/2502.11448)

- AGrail (A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection): introduces a lifelong agent guardrail framework, with Analyzer, Memory, Executor, and Tool Box components, to enhance LLM agent safety by adaptively detecting risks and applying effective safety policies.
- AGrail framework, depicted in figures, integrates with Agent (Planning, ReAct) interacting with diverse environments like Web, Database, and OS, utilizing Guard Request, Agent Specification, and Safety Criteria for context-aware safety checks.
- AGrail framework optimizes safety checks through iterative refinement and tool compatibility, aiming for a trade-off between robustness and utility in LLM agent security.


---

[SMART: Self-Aware Agent for Tool Overuse Mitigation](http://arxiv.org/abs/2502.11435v1)

- SMART (Strategic Model-Aware Reasoning with Tools): introduces SMARTAgent, a family of models, with MetaCognition, User Reasoning, SMART-ER, Parametric Knowledge, and External Tools, to enhance agent self-awareness for optimized task handling and reduced tool overuse.
- SMARTAgent leverages SMART-ER dataset, which includes Reasoning Chain, Decompose, Annotate, Tool Mapping, Execute, and Refine components, to dynamically balance parametric knowledge and tool use in problem-solving.
- By calibrating agent's self-awareness through explicit justifications and strategic tool utilization, SMARTAgent achieves improved performance, reduced tool overuse, and better generalization across diverse tasks.


---

[FLAG-TRADER: Fusion LLM-Agent with Gradient-based Reinforcement Learning for Financial Trading](http://arxiv.org/abs/2502.11433v1)

- FLAG-TRADER: introduces a financial trading framework integrating LLM (linguistic processing model) with gradient-based RL, using prompts (structured input), LLM (linguistic processing model), policy head (action probability), value head (state value), actor (policy network), critic (value network), reply buffer (experience replay), and environment (financial market).
- The framework uses a partially fine-tuned LLM (linguistic processing model) as policy network, optimized by policy gradient and experience replay in reply buffer (experience replay storage) within the environment (financial market).
- FLAG-TRADER enhances LLM performance in financial tasks by synergistically combining linguistic processing with reward-driven policy optimization for improved trading decisions.


---

[TimeCAP: Learning to Contextualize, Augment, and Predict Time Series Events with Large Language Model Agents](http://arxiv.org/abs/2502.11418v1)

- TimeCAP (TimeCAP: Learning to Contextualize, Augment, and Predict): introduces TimeCAP framework, which includes Contextualize LLM Agent, Predict LLM Agent, Multi-Modal Encoder, Augment Prompt, Augment Input, Time Series, Text Summary, and LLM Aggregate, for time series event prediction using dual LLM agents and multi-modal encoder.
- TimeCAP framework leverages a contextualize LLM agent to generate text summaries of time series data, which are then used by a predict LLM agent for enhanced event prediction.
- The framework incorporates a multi-modal encoder to synergize with LLM agents through input and prompt augmentations, further improving prediction accuracy and interpretability.


---

["Nuclear Deployed!”: Analyzing Catastrophic Risks in Decision-making of Autonomous LLM Agents](http://arxiv.org/abs/2502.11355v1)

- Three-stage evaluation framework: introduces System, Agent, State Update, and Reasoning components to analyze catastrophic risks in autonomous LLM agents' decision-making, particularly in CBRN scenarios.
- This framework uses Restricted Authority, Cat. Behav. w/ Cmd. Violation, and Deception: False Accusation to expose potential catastrophic behaviors and deceptive tendencies in LLM agents.
- The evaluation method empirically proves the existence of catastrophic risks by simulating agent interactions and analyzing agent's reasoning and actions within defined scenarios.


---

#### 17th February 2025

[A Study on Leveraging Search and Self-Feedback for Agent Reasoning](https://arxiv.org/abs/2502.12094)

- MCTSr (MCTS with Self-Refine): introduces search and self-feedback with search, self-feedback, reward, and selection strategy for agent reasoning tasks.
- This study compares ground-truth feedback and self-feedback in math reasoning and tool-calling, revealing self-feedback can be suboptimal.
- The research emphasizes the necessity of engineered feedback mechanisms in search for dependable agent reasoning, particularly in complex scenarios.


---



#### 16th February 2025

[OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning](http://arxiv.org/abs/2502.11271v1)

- OctoTools: introduces a training-free agentic framework with Query Analyzer, Action Predictor, Context Verifier, Solution Summarizer, Task-specific Toolset Optimization, Planner, Executor, Tool cards, Action, Context, Command Generator, Command Executor and Answer for complex reasoning across diverse domains.
- OctoTools framework uses Tool cards to standardize tool integration and employs Planner-Executor paradigm for managing multi-step reasoning and tool usage.
- The framework achieves substantial accuracy gains over baselines by combining multi-step planning with specialized tool usage and task-specific toolset optimization.


---

[PlanGenLLMs: A Modern Survey of LLM Planning Capabilities](http://arxiv.org/abs/2502.11221v1)

- LLM Planning Framework: introduces taxonomy of LLM planning approaches, with Foundation, Performance Criteria, Datasets and Evaluation, to categorize and analyze components and methodologies in the field.
- LLM Planning Framework: systematically breaks down LLM planning into key aspects like task decomposition, search algorithms, and evaluation metrics, providing a structured overview.
- LLM Planning Framework: serves as a comprehensive guide for understanding the architectural components and evaluation strategies employed in current LLM planning research, highlighting key areas and future directions.


---

[A Survey of LLM-based Agents in Medicine: How far are we from Baymax?](http://arxiv.org/abs/2502.11211v1)

- LLM-based Medical Agent Framework: introduces profile, clinical planning, medical reasoning, and external capacity enhancement components for structuring medical agents.
- LLM-based Medical Agent Framework facilitates medical decision-making by integrating clinical knowledge and ensuring safe deployment through defined components.
- The framework supports agent paradigms like single agent, sequential task chain, collaborative experts and iterative evolution to enable diverse medical applications.


---

[CSP: A Simulator For Multi-Agent Ranking Competitions](http://arxiv.org/abs/2502.11197v1)

- CSP (Competitive Search Platform) introduces CSP SIMULATOR (core simulation component) with Competition properties (competition setup parameters), Player properties (agent characteristics), Ranking function properties (ranking algorithm definition), CSP ANALYZER (competition analysis module), and CSP COMPARE (competition comparison tool) for configurable multi-agent ranking competition simulations.
- CSP SIMULATOR facilitates fine-grained control over ranking function, query, initial documents, and agent types, supporting LLM-based players and diverse experimental setups.
- CSP ANALYZER and CSP COMPARE modules enable in-depth analysis of individual competitions and comparative analysis across different competition configurations, respectively.


---

[NavRAG: Generating User Demand Instructions for Embodied Navigation through Retrieval-Augmented LLM](http://arxiv.org/abs/2502.11142v1)

- NavRAG (Retrieval-Augmented Generation): introduces NavRAG framework with Navigation Graph Generator, Object and View Annotator, View Retriever, Viewpoint Annotator, Viewpoint Retriever, Zone Generator & Annotator, Zone Retriever, Scene Annotator, Scene Description, Zone Description, Viewpoint Description, Object Description & Functionality, User Demands, Role Profiles, Rough Instruction Generator, Refined Instruction Generator, Trajectory Generator, Instruction Records, Store Instruction, Ground Truth Trajectory, Hierarchical Retrieval LLM, Viewpoint LLM, and Scene Tree, which generates user demand instructions for vision-language navigation using retrieval-augmented large language models.
- NavRAG framework constructs hierarchical scene description tree using Scene Tree memory component and leverages Hierarchical Retrieval LLM and Viewpoint LLM to generate diverse navigation instructions tailored to user demands and roles.
- NavRAG improves instruction quality by considering global context and user needs through hierarchical scene understanding and retrieval-augmented generation, addressing limitations of step-by-step instruction methods.


---

[VisPath: Automated Visualization Code Synthesis via Multi-Path Reasoning and Feedback-Driven Optimization](http://arxiv.org/abs/2502.11140v1)

- VisPath (A Multi-Path Reasoning and Feedback-Driven Optimization Framework for Visualization Code Generation): introduces a multi-stage framework for visualization code generation, utilizing Multi-Path Agent for query expansion, Code Agent for code generation, Visual Feedback Agent for evaluation, and Synthesis Agent for result aggregation, incorporating Feedback for optimization.
- VisPath framework enhances code quality by employing structured reasoning and refinement, addressing underspecified queries through diverse reformulated queries and feedback-driven optimization.
- VisPath systematically explores multiple interpretative pathways and leverages iterative feedback aggregation to improve accuracy and robustness in visualization code generation for complex user intents.


---

[MasRouter: Learning to Route LLMs for Multi-Agent Systems](http://arxiv.org/abs/2502.11133v1)

- MasRouter: introduces Multi-Agent System Routing (MASR) problem and proposes MasRouter framework with collaboration determiner, role allocator, and LLM router for cost-effective multi-agent systems.
- MasRouter: employs cascaded controller network integrating collaboration mode determination, role allocation, and LLM routing to construct high-performing and resource-efficient MAS progressively.
- MasRouter: optimizes performance and cost in multi-agent systems by dynamically routing LLMs and balancing effectiveness with reduced overhead via customized routing.


---

[G-Safeguard: A Topology-Guided Security Lens and Treatment on LLM-based Multi-agent Systems](http://arxiv.org/abs/2502.11127v1)

- G-Safeguard: introduces a topology-guided security framework for LLM-based multi-agent systems, with Multi-agent Utterance Graph, Detection, Remediation, Edge pruning, Graph Neural Network, Node Encoder, and Embedding components.
- G-Safeguard leverages graph neural networks to detect anomalies on multi-agent utterance graphs and employs topological intervention for attack remediation.
- This framework enhances security in multi-agent systems by identifying and mitigating adversarial attacks through graph-based analysis and intervention.


---

[Hierarchical Expert Prompt for Large-Language-Model: An Approach Defeat Elite AI in TextStarCraft II for the First Time](http://arxiv.org/abs/2502.11122v1)

- HEP (Hierarchical Expert Prompt): introduces a framework with Expert Tactic Prompt (inject expert tactic knowledge), Hierarchical Decision Prompt (hierarchical decision making logic), and Legal Action Library (action options for LLM) within a System Prompt (prompt to guide LLM behavior) to enhance LLM decision-making for StarCraft II, utilizing LLM Input (condensed text game observation), LLM Output (text-based game actions), and Text Action Recognition (converts text actions to game commands).
- HEP injects expert knowledge and employs hierarchical decision-making to tackle challenges like insufficient knowledge and inadequate control over subtasks in complex environments.
- This method enables an LLM agent to overcome the Elite AI in TextStarCraft II for the first time, demonstrating its efficacy in intricate decision-making scenarios.


---

[Talk Structurally, Act Hierarchically: A Collaborative Framework for LLM Multi-Agent Systems](http://arxiv.org/abs/2502.11098v1)

- TalkHier (Talk Structurally, Act Hierarchically): introduces Structured Communication Protocol (organizes agent communication) and Hierarchical Refinement (hierarchical evaluation process) within a multi-agent framework to improve communication and refinement in LLM-based multi-agent systems.
- TalkHier framework utilizes Supervisor (oversees task success), Member Agent (problem-solving focus), and Evaluation Team (hierarchical feedback provision) with components like Message (instruction content), Background Information (contextual details), and Intermediate Output (shared output for progression) for effective collaboration.
- TalkHier enhances agent functionality through Memory (agent-specific information storage), Plugins (domain-specific external tools), Roles (generator, evaluator, revisor), and Types (supervisor, member), enabling structured, role-specific operations and improved performance across diverse tasks.


---

[AGENTIC LLM FRAMEWORK FOR ADAPTIVE DECISION DISCOURSE](http://arxiv.org/abs/2502.10978v1)

- Agentic LLM Framework: introduces agent assembly within conference room, utilizing scenario and persona prompts, employing summoning mechanism, generating conversation output to derive actionable measures.
- This framework simulates decision discourse using LLM agents representing stakeholders, enabling exploration of diverse perspectives and adaptive strategy refinement through self-governance.
- The framework facilitates breadth-first exploration of alternatives for robust recommendations in complex, uncertain scenarios, enhancing decision-making and scalability for AI-driven solutions.


---


[SCALE: Towards Collaborative Content Analysis in Social Science with Large Language Model Agents and Human Intervention](http://arxiv.org/abs/2502.10937v1)

- SCALE (Simulates Content Analysis via Large language model Agents): introduces multi-agent framework for content analysis, incorporating Coder Simulation to initialize agents, Bot Annotation for independent coding, Agent Discussion for collaborative refinement, Codebook Evolution for iterative rule updates, and Human Intervention for expert guidance.
- SCALE framework simulates content analysis phases including text coding, collaborative discussions, and codebook evolution, aiming to reduce subjectivity and enhance scalability through human-AI collaboration.
- SCALE leverages LLM agents with diverse personas and iterative refinement processes to achieve human-level performance in complex content analysis tasks, offering potential for social science research automation.


---

#### 15th February 2025

[D-CIPHER: Dynamic Collaborative Intelligent Agents with Planning and Heterogeneous Execution for Enhanced Reasoning in Offensive Security](http://arxiv.org/abs/2502.10931v1)

- D-CIPHER: introduces multi-agent framework with Planner Agent for planning, heterogeneous Executor Agents for task execution, and Auto-prompter Agent for initial prompt generation, utilizing shared Container Environment to interact with Challenge Server.
- D-CIPHER employs Planner-Executor system to divide responsibilities and Auto-prompter to enhance initial prompt relevance for collaborative CTF challenge solving.
- D-CIPHER framework facilitates dynamic feedback loops and agent interactions to improve reasoning and performance in complex offensive security tasks.


---


[Enhancing Conversational Agents from Open-Source Large Language Models with Illocutionary Force and Document-Based Knowledge Retrieval](http://arxiv.org/abs/2502.10916v1)

- Bespoke Conversational System: introduces a system for analyzing dialogue illocutionary forces and integrating them with document retrieval for enhanced agent responses.
- Bespoke Conversational System utilizes BERT for force extraction and Ollama-served open-source LLMs for response generation, using custom documents as knowledge.
- This system enhances conversational agent relevance by incorporating user intent and document knowledge within open-source LLM frameworks.


---


[PCGRLLM: Large Language Model-Driven Reward Design for Procedural Content Generation Reinforcement Learning](http://arxiv.org/abs/2502.10906v1)

- PCGRLLM (Large Language Model-Driven Reward Design for Procedural Content Generation Reinforcement Learning): introduces feedback-based reward generation framework for PCG, with Instruct (Story), LLM M, Alignment, Agent π, Environment, Content, and Feedback components.
- PCGRLLM framework refines reward function iteratively using self-alignment and feedback mechanisms to improve content generation in PCGRL.
- PCGRLLM leverages prompt engineering techniques like Chain-of-Thought, Tree-of-Thought, and Graph-of-Thought to enhance reward space exploration and improve reward function design.


---

[Divergent Thoughts toward One Goal: LLM-based Multi-Agent Collaboration System for Electronic Design Automation](http://arxiv.org/abs/2502.10857v1)

- EDAid (Electronic Design Automation id): introduces multi-agent system, with divergent-thoughts agent (generates diverse EDA scripts), decision-making agent (selects optimal EDA script), EDA tool usage demo database (stores EDA task examples), relevant demos (retrieved similar EDA tasks), demo groups (sets of relevant demos), planning steps (sequential task breakdown), EDA script (executable automation code), KV cache (stores system prompts), and EDA tools (software for circuit design), where system automates electronic design automation flow using multiple agents with diverse approaches.
- EDAid employs divergent-thoughts agents to generate multiple electronic design automation script solutions using retrieved relevant demos and demo groups, then decision-making agent selects optimal script based on analysis of script correctness.
- EDAid enhances electronic design automation flow automation reliability by utilizing multi-agent collaboration and divergent thinking, effectively addressing challenges inherent in complex electronic design automation tasks and diverse tool interfaces.


---


[Be Friendly, Not Friends: How LLM Sycophancy Shapes User Trust](http://arxiv.org/abs/2502.10844v1)

- Framework name here: introduces LLM agent (conversational agent) with Sycophancy manipulation (adapts responses to user views) and Friendliness manipulation (expresses warmth or neutrality) to investigate user trust.
- LLM agent's sycophancy dynamically aligns responses with user perspectives, while friendliness incorporates warm language cues.
- The framework examines how these manipulations jointly influence perceived authenticity and user trust in human-LLM interactions.


---

[Rule-Bottleneck Reinforcement Learning: Joint Explanation and Decision Optimization for Resource Allocation with Language Agents](http://arxiv.org/abs/2502.10732v1)

- RBRL (Rule-Bottleneck Reinforcement Learning): introduces a framework that integrates LLMs for rule generation and RL for rule selection, with state-to-language descriptor, prompt function, LLM (rule generator), rule sets, attention network (rule selector), RL agent (policy optimizer), budget constraint, action and explanation LLM (action and explanation generator), and replay buffer, to jointly optimize decision-making and explanation in resource allocation tasks.
- RBRL framework leverages LLMs to generate interpretable candidate rules based on the environment state and employs an attention-based RL policy to select the most suitable rule, optimizing for both environment reward and explanation quality.
- The framework enhances transparency and interpretability in sequential decision-making by using structured language rules as a bottleneck between high-level reasoning and action execution, facilitating human understanding and trust in AI systems.


---



#### 14th February 2025

[Can Large Language Model Agents Balance Energy Systems?](http://arxiv.org/abs/2502.10557v1)

- LLM-SUC (LLM-assisted Stochastic Unit Commitment): introduces a hybrid approach integrating LLM Agent, Agent 1, Agent 2, and SUC to enhance stochastic unit commitment by leveraging scenario tree and MILP for improved energy system balancing.
- LLM-SUC framework uses LLM Agent with Agent 1 and Agent 2 to refine scenario tree generation, improving the stochastic unit commitment process for renewable energy integration.
- By dynamically adjusting quantile parameters and interpreting wind error distributions, LLM-SUC framework enhances computational efficiency and decision-making in uncertain operating conditions.


---

[Agentic Verification for Ambiguous Query Disambiguation](http://arxiv.org/abs/2502.10352v1)

- VERDICT (Verified-Diversification with Consolidation): introduces a unified framework integrating diversification and verification for ambiguous query disambiguation, incorporating query relaxation & retrieval, relevance feedback from retriever, execution feedback from generator, verified diversification, and consolidating feedback components.
- VERDICT framework leverages agentic feedback from retriever and generator to ensure grounded disambiguations upfront, mitigating noisy retrieval and cascading errors during ambiguous question answering.
- VERDICT improves efficiency and robustness by reducing reliance on multiple retrieval and inference steps, achieving enhanced grounding and performance in comparison to diversify-then-verify approaches.


---

[Process Reward Models for LLM Agents: Practical Framework and Directions](https://arxiv.org/abs/2502.10325v1)

- AgentPRM (Agent Process Reward Models): introduces a framework for training LLM agents, with Agent Policy, Environment, Rollout, Target Dataset, Target Computation, PRM Dataset, Process Reward Model, PRM Training, Prompts, Policy Update, and Updated Policy, where framework trains agents through interaction.
- AgentPRM framework uses actor-critic paradigm and Monte Carlo rollouts for reward target computation, enabling iterative policy refinement.
- AgentPRM framework integrates into RLHF pipelines with minimal modifications, facilitating scalable agent training and deployment.


---

[LARGE LANGUAGE MODELS AND SYNTHETIC DATA FOR MONITORING DATASET MENTIONS IN RESEARCH PAPERS](http://arxiv.org/abs/2502.10263v1)

- Data Use Extraction and Classification Framework: introduces a machine learning pipeline with zero-shot extraction and classification, LLM-as-a-Judge, reasoning agent, synthetic pre-fine-tuning data, fine-tuned LLM, BERT-based classifier, and curated data to automate dataset mention detection.
- This framework employs synthetic data generation and two-stage fine-tuning to address data scarcity and improve model generalization for scalable dataset monitoring in research papers.
- The approach utilizes LLMs for extraction and refinement, and a BERT-based classifier for efficient filtering, achieving state-of-the-art performance in dataset extraction accuracy.


---

[Do Large Language Models Reason Causally Like Us? Even Better?](http://arxiv.org/abs/2502.10215v1)

- LLM (Large Language Model): introduces comparative study evaluating LLMs' causal reasoning against human reasoning using collider graph inference tasks and normative/psychological models.
- Study assesses GPT-40, Claude, Gemini-Pro, GPT-3.5 on predictive, independence, diagnostic inferences, comparing to human data and Causal Bayes Nets, Mutation Sampler models.
- Findings emphasize importance of understanding AI biases in causal reasoning for reliable AI systems, revealing LLMs' varying normative alignment and domain knowledge influence.


---

[Cooperative Multi-Agent Planning with Adaptive Skill Synthesis](http://arxiv.org/abs/2502.10148v1)

- COMPASS (Cooperative Multi-Agent Planning with Adaptive Skill Synthesis): introduces a decentralized closed-loop framework for cooperative multi-agent systems, with Perception (multi-modal input processing), Task Reasoning (objective decomposition), Self-Reflection (execution quality evaluation), Actor (skill selection and execution), Skill Synthesis (executable code generation), Local Memory (agent's individual memory), Global Memory (shared memory), and Skill Library (executable skill collection).
- COMPASS integrates VLMs with a dynamic skill library and structured communication for decentralized decision-making under partial observability.
- The framework enables agents to adapt strategies through iterative planning, skill synthesis, and information sharing, improving performance in cooperative tasks.


---

[A Survey on LLM-powered Agents for Recommender Systems](http://arxiv.org/abs/2502.10050v1)

- Unified Agent Architecture: introduces unified agent architecture consisting of Profile, Memory, Planning and Action modules for LLM-powered agent recommender systems.
- Unified Agent Architecture: decomposes agent recommender into profile construction, memory management, strategic planning, and action execution modules.
- Unified Agent Architecture: facilitates analysis of existing LLM-powered agent methods by providing structured framework of core components and their functions.


---

[Automated Hypothesis Validation with Agentic Sequential Falsifications](http://arxiv.org/abs/2502.09858v1)

- POPPER: introduces an agentic framework for automated hypothesis validation, with Experiment Design Agent, Experiment Execution Agent, Sequential Error Control, Relevance Checker, Self-Refine, and Memory components.
- POPPER framework rigorously validates free-form hypotheses by sequentially testing measurable implications through experiments and controlling Type-I error.
- POPPER leverages LLM agents to automate experiment design and execution, providing a scalable and efficient solution for hypothesis validation across diverse domains.


---



[Diverse Inference and Verification for Advanced Reasoning](http://arxiv.org/abs/2502.09955v1)

- Diverse Inference: introduces a diverse inference framework that combines multiple models and methods, including Human (User input), LLM (Reasoning engine), Agent (Process orchestrator), Game Environment (Problem representation), Verifier (Solution checker), and specific methods like LEAP (Task-specific learning), Z3 (Theorem prover), RTO (Round trip optimization), BoN (Best-of-N sampling), SC (Self-consistency), MoA (Mixture of agents), MCTS (Monte Carlo search), PV (Prover-verifier game), Unit Tests (Code execution verification), and Best-of-N (Sampling based verification), to enhance reasoning and verification for advanced tasks.
- Leverages perfect verifiers like Lean Verifier (Formal proof checker) for IMO and ARC problems and imperfect verifiers like Best-of-N (Sampling based verification) for HLE questions, achieving higher accuracy on challenging benchmarks.
- Utilizes test-time simulations, reinforcement learning, and meta-learning to adapt agent graph representations and improve generalization across diverse problem types.


---


[Agentic Verification for Ambiguous Query Disambiguation](http://arxiv.org/abs/2502.10352v1)

- VERDICT (Verified-Diversification with Consolidation): unifies diversification with verification by incorporating feedback from retriever and generator early on, improving efficiency and robustness by reducing reliance on multiple retrieval and inference steps.
- VERDICT framework integrates Rewrite-component for query relaxation, Retrieve-component for relevant passages, Execution-component for interpretation extraction, Embed-component for latent space projection, and Clustering-component for feedback consolidation.
- The framework leverages LLM Calls and Retriever Calls to enhance the grounding and accuracy of ambiguous query disambiguation in retrieval-augmented generation.


---

[Process Reward Models for LLM Agents: Practical Framework and Directions](https://arxiv.org/abs/2502.10325v1)

- AgentPRM (Agent Process Reward Models): introduces a framework for training LLM agents, with Agent Policy, Environment, Rollout, Target Dataset, Target Computation, PRM Dataset, Process Reward Model, PRM Training, Prompts, Policy Update, and Updated Policy, where framework trains agents through interaction.
- AgentPRM framework uses actor-critic paradigm and Monte Carlo rollouts for reward target computation, enabling iterative policy refinement.
- AgentPRM framework integrates into RLHF pipelines with minimal modifications, facilitating scalable agent training and deployment.


---


[LARGE LANGUAGE MODELS AND SYNTHETIC DATA FOR MONITORING DATASET MENTIONS IN RESEARCH PAPERS](http://arxiv.org/abs/2502.10263v1)

- Data Use Extraction and Classification Framework: introduces a machine learning pipeline with zero-shot extraction and classification, LLM-as-a-Judge, reasoning agent, synthetic pre-fine-tuning data, fine-tuned LLM, BERT-based classifier, and curated data to automate dataset mention detection.
- This framework employs synthetic data generation and two-stage fine-tuning to address data scarcity and improve model generalization for scalable dataset monitoring in research papers.
- The approach utilizes LLMs for extraction and refinement, and a BERT-based classifier for efficient filtering, achieving state-of-the-art performance in dataset extraction accuracy.


---

[Do Large Language Models Reason Causally Like Us? Even Better?](http://arxiv.org/abs/2502.10215v1)

- LLM (Large Language Model): introduces comparative study evaluating LLMs' causal reasoning against human reasoning using collider graph inference tasks and normative/psychological models.
- Study assesses GPT-40, Claude, Gemini-Pro, GPT-3.5 on predictive, independence, diagnostic inferences, comparing to human data and Causal Bayes Nets, Mutation Sampler models.
- Findings emphasize importance of understanding AI biases in causal reasoning for reliable AI systems, revealing LLMs' varying normative alignment and domain knowledge influence.


---

[Cooperative Multi-Agent Planning with Adaptive Skill Synthesis](http://arxiv.org/abs/2502.10148v1)

- COMPASS (Cooperative Multi-Agent Planning with Adaptive Skill Synthesis): introduces a decentralized closed-loop framework for cooperative multi-agent systems, with Perception (multi-modal input processing), Task Reasoning (objective decomposition), Self-Reflection (execution quality evaluation), Actor (skill selection and execution), Skill Synthesis (executable code generation), Local Memory (agent's individual memory), Global Memory (shared memory), and Skill Library (executable skill collection).
- COMPASS integrates VLMs with a dynamic skill library and structured communication for decentralized decision-making under partial observability.
- The framework enables agents to adapt strategies through iterative planning, skill synthesis, and information sharing, improving performance in cooperative tasks.


---

[ScamFerret: Detecting Scam Websites Autonomously with Large Language Models](http://arxiv.org/abs/2502.10110v1)

- ScamFerret: presents an agent system for autonomous scam website detection, integrating Scam Website Analysis, External Information Collection, and Analysis Results Output components.
- ScamFerret utilizes LLM's pre-existing knowledge and tool-based information retrieval to classify scam websites without scam-specific fine-tuning.
- ScamFerret iteratively refines website analysis by collecting external information when initial URL data is insufficient, enhancing detection accuracy and explainability.


---

[A Survey on LLM-powered Agents for Recommender Systems](http://arxiv.org/abs/2502.10050v1)

- Unified Agent Architecture: introduces unified agent architecture consisting of Profile, Memory, Planning and Action modules for LLM-powered agent recommender systems.
- Unified Agent Architecture: decomposes agent recommender into profile construction, memory management, strategic planning, and action execution modules.
- Unified Agent Architecture: facilitates analysis of existing LLM-powered agent methods by providing structured framework of core components and their functions.


---

[VIRAC: A VISION-REASONING AGENT HEAD MOVEMENT CONTROL FRAMEWORK IN ARBITRARY VIRTUAL ENVIRONMENTS](http://arxiv.org/abs/2502.10046v1)

- VIRAC (Vision-Reasoning Agent Head Movement Control framework): introduces vision-reasoning framework for realistic agent head rotations utilizing Perception Module with VLM and FMM, Decision-making Module with AHM and LLM, and iterative loop with perception, reasoning, action selection, environment update and history update components.
- VIRAC framework leverages large-scale models for common-sense knowledge and reasoning capabilities, emulating human-like perception and decision-making processes for context-aware head rotations.
- VIRAC framework operates through iterative cycle of perception, reasoning, action selection, and environment/history updates to produce dynamic and context-sensitive head rotations in virtual environments.


---

[Automated Hypothesis Validation with Agentic Sequential Falsifications](http://arxiv.org/abs/2502.09858v1)

- POPPER: introduces an agentic framework for automated hypothesis validation, with Experiment Design Agent, Experiment Execution Agent, Sequential Error Control, Relevance Checker, Self-Refine, and Memory components.
- POPPER framework rigorously validates free-form hypotheses by sequentially testing measurable implications through experiments and controlling Type-I error.
- POPPER leverages LLM agents to automate experiment design and execution, providing a scalable and efficient solution for hypothesis validation across diverse domains.


---

[Representation and Interpretation in Artificial and Natural Computing](http://arxiv.org/abs/2502.10383v1)

- Newell's hierarchy of system levels: analyzes computing machines through system levels, including knowledge level, symbol level, hardware level, and physical world.
- This hierarchy facilitates analyzing computing machines across abstraction levels, ranging from knowledge representation to physical implementation.
- Understanding these levels facilitates comprehending functionality and independence across complex computing systems.


---

[Robustness tests for biomedical foundation models should tailor to specification](http://arxiv.org/abs/2502.10374v1)

- Robustness testing frameworks: introduces threat-based test design, priority-based test design, patient EHR foundation model, and brain MRI foundation model, where paper describes robustness testing framework for biomedical foundation models.
- Framework uses threat-based tests with distance bounds and priority-based tests with realistic artifacts to evaluate robustness.
- This approach aims to standardize robustness evaluation by tailoring tests to specific tasks and priorities in biomedical domain.


---

[Agentic Verification for Ambiguous Query Disambiguation](http://arxiv.org/abs/2502.10352v1)

- VERDICT (Verified-Diversification with Consolidation): introduces a unified framework integrating diversification and verification for ambiguous query disambiguation, incorporating query relaxation & retrieval, relevance feedback from retriever, execution feedback from generator, verified diversification, and consolidating feedback components.
- VERDICT framework leverages agentic feedback from retriever and generator to ensure grounded disambiguations upfront, mitigating noisy retrieval and cascading errors during ambiguous question answering.
- VERDICT improves efficiency and robustness by reducing reliance on multiple retrieval and inference steps, achieving enhanced grounding and performance in comparison to diversify-then-verify approaches.


---

[VocalCrypt: Novel Active Defense Against Deepfake Voice Based on Masking Effect](http://arxiv.org/abs/2502.10329v1)

- VocalCrypt: introduces active defense mechanism, with Preprocessing, DWT Transform, Band analysis module, Frequency band division, Calculate the energy, Masking threshold calculation module, Masking threshold calculation, and iSTFT, to protect against deepfake voice cloning.
- VocalCrypt leverages auditory masking effect by embedding pseudo-timbre based on calculated masking thresholds to disrupt AI voice cloning systems.
- VocalCrypt enhances robustness, real-time performance, and offers preemptive defense compared to existing post-attack detection methods against voice cloning attacks.


---

[Process Reward Models for LLM Agents: Practical Framework and Directions](https://arxiv.org/abs/2502.10325v1)

- AgentPRM (Agent Process Reward Models): introduces a framework for training LLM agents, with Agent Policy, Environment, Rollout, Target Dataset, Target Computation, PRM Dataset, Process Reward Model, PRM Training, Prompts, Policy Update, and Updated Policy, where framework trains agents through interaction.
- AgentPRM framework uses actor-critic paradigm and Monte Carlo rollouts for reward target computation, enabling iterative policy refinement.
- AgentPRM framework integrates into RLHF pipelines with minimal modifications, facilitating scalable agent training and deployment.


---

[Reinforcement Learning in Strategy-Based and Atari Games: A Review of Google DeepMind's Innovations](http://arxiv.org/abs/2502.10303v1)

- AlphaGo: introduces a pioneering AI model utilizing policy- and value-networks with Monte Carlo Tree Search (MCTS) for playing Go.
- AlphaGo integrates supervised and reinforcement learning to achieve expert-level Go performance, surpassing human players.
- The model's architecture combines neural networks with tree search for effective game exploration and decision-making in Go.


---


[Open-Source AI-Powered Optimization in Scalene: Advancing Python Performance Profiling with DeepSeek-R1 and LLaMA 3.2](http://arxiv.org/abs/2502.10299v1)

- SCALENE: introduces open-source AI-powered optimization, with Profiler, AI-powered optimization suggestions, Open-source LLMs, Ollama framework, Code Snippet Input, Optimization Suggestions Output, to advance Python performance profiling.
- SCALENE integrates DeepSeek-R1 and LLaMA 3.2 via Ollama, enabling local, cost-effective AI-driven code optimization suggestions for Python.
- This integration enhances SCALENE's utility by providing accessible, transparent, and hardware-aware optimization, improving Python developer efficiency.


---

[SegX: Improving Interpretability of Clinical Image Diagnosis with Segmentation-based Enhancement](http://arxiv.org/abs/2502.10296v1)

- SegX (Segmentation-based Explanation) and SegU (Segmentation-based Uncertainty Assessment) introduces Segmentation-based Explanation (SegX) module to refine original XAI map using segmentation mask and Segmentation-based Uncertainty Assessment (SegU) module to evaluate prediction certainty by comparing explanation map and clinical interests mask.
- SegX enhances interpretability of clinical image diagnosis by aligning model's explanation with clinically relevant areas using Segmentation Model and improves reliability through uncertainty quantification with SegU.
- The framework utilizes Classification Model for initial prediction and XAI Method for explanation, then refines explanation and assesses certainty using segmentation-derived clinical knowledge, aiming for model-agnostic enhancement in medical AI.


---

[Artificial Intelligence to Assess Dental Findings from Panoramic Radiographs - A Multinational Study](http://arxiv.org/abs/2502.10277v1)

- AI system: introduces Dental Panoramic Radiograph (DPR) input with finding localization, tooth index classification, and post-processing to generate Output Finding Assessment for dental radiographs.
- AI system employs object detection and semantic segmentation, utilizing convolutional neural networks for dental findings and tooth indices from radiographic images.
- AI system achieves performance comparable to human experts in dental findings assessment, demonstrating potential for clinical workflow integration and diagnostic improvement.


---

[Robust variance estimators in application to segmentation of measurement data distorted by impulsive and non-Gaussian noise](http://arxiv.org/abs/2502.10275v1)

- Robust Change Point Detection Methodology: introduces robust offline methodology for measurement data segmentation based on classical structural break detection with robust scale estimators, utilizing data, CSS and change point components.
- Methodology uses Cumulative Sums of Squares statistic and quantile method, enhanced by Biweight Midvariance and Quantile Conditional Variance for non-Gaussian data segmentation.
- Proposed approach improves change point estimation accuracy, especially for heavy-tailed and impulsive noise data in financial, mechanical, and medical systems.


---


[LARGE LANGUAGE MODELS AND SYNTHETIC DATA FOR MONITORING DATASET MENTIONS IN RESEARCH PAPERS](http://arxiv.org/abs/2502.10263v1)

- Data Use Extraction and Classification Framework: introduces a machine learning pipeline with zero-shot extraction and classification, LLM-as-a-Judge, reasoning agent, synthetic pre-fine-tuning data, fine-tuned LLM, BERT-based classifier, and curated data to automate dataset mention detection.
- This framework employs synthetic data generation and two-stage fine-tuning to address data scarcity and improve model generalization for scalable dataset monitoring in research papers.
- The approach utilizes LLMs for extraction and refinement, and a BERT-based classifier for efficient filtering, achieving state-of-the-art performance in dataset extraction accuracy.


---

[Seamless acceleration of Fortran intrinsics via AMD AI engines](http://arxiv.org/abs/2502.10254v1)

- Compilation flow: introduces an approach for seamless acceleration of Fortran intrinsics on AMD AI Engines, utilizing Fortran source code, Flang, HLFIR & FIR, Existing Lowering, Linalg dialect, Standard MLIR dialects, Lowering passes, LLVM dialect, Generation, LLVM IR, CPU code, xrt dialect, func dialect, aie dialect, Specialisation, AIE code, AMD's AIE MLIR tooling, and Library of AIE dialect kernels.
- This compilation flow leverages MLIR infrastructure to lower Fortran intrinsics represented in linalg dialect to CPU and AIE code, using xrt dialect for CPU-AIE interaction and aie dialect for AIE specific operations, enabling transparent offloading without programmer modifications.
- The approach uses a library of pre-built AIE kernel templates and a specialisation process to tailor AIE code for specific Fortran intrinsics, demonstrating performance benefits for reduction, transpose, and matrix multiplication operations on AMD Ryzen AI NPUs.


---

[Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model](https://github.com/stepfun-ai/Step-Video-T2V)

- Step-Video-T2V: introduces a text-to-video model with Video-VAE Encoder, Video-VAE Decoder, Bilingual Text Encoder(s), DiT w/ 3D Full Attention and Video-DPO components.
- Step-Video-T2V: employs cascaded training and video-based DPO to enhance video generation quality and reduce artifacts.
- Step-Video-T2V: presents state-of-the-art text-to-video generation and is publicly released to foster advancements in video foundation models.


---

[Learning to Solve the Min-Max Mixed-Shelves Picker-Routing Problem via Hierarchical and Parallel Decoding](http://arxiv.org/abs/2502.10233v1)

- MAHAM (Multi-Agent Hierarchical Attention Model): introduces a hierarchical and parallel decoding framework for solving the min-max Mixed-Shelves Picker-Routing Problem (MSPRP) with Problem Encoder, Agent Context Encoder, Parallel Agent Pointer, and Sequential Action Selection components.
- MAHAM framework facilitates efficient picker coordination within complex action spaces by integrating hierarchical decoding, parallel solution construction, and sequential action selection mechanisms.
- MAHAM achieves state-of-the-art performance regarding solution quality and computational efficiency, especially for large-scale MSPRP instances, highlighting neural combinatorial optimization effectiveness for warehouse logistics.


---

[ProReco: A Process Discovery Recommender System](http://arxiv.org/abs/2502.10230v1)

- ProReco (Process discovery Recommender): introduces a system recommending process discovery algorithms by utilizing Event Log as input, Feature Extractor to derive log features, Machine Learning Predictor to forecast algorithm performance, Algorithm Ranking to order algorithms, and Measure Weights for user preference integration.
- ProReco employs machine learning to predict quality measures like fitness, simplicity, precision, and generalization for various process discovery algorithms based on event log characteristics.
- The system enhances user experience in process discovery algorithm selection by providing explainable recommendations and incorporating user-defined weights for quality measures.


---

[A Multiagent Path Search Algorithm for Large-Scale Coalition Structure Generation](http://arxiv.org/abs/2502.10226v1)

- SALDAE (Scalable Algorithm with Large-Scale Distributed Agent Exploration): introduces multiagent path search algorithm for coalition structure generation using search agents exploring coalition structure graph from start node, generating child nodes, performing node selection, comparing to incumbent, employing bridging paths, utilizing memory management and applying conflict resolution.
- SALDAE algorithm iteratively builds search graph by splitting or merging coalitions for solving coalition structure generation problems, aiming to find optimal partitioning of agents into coalitions to maximize social welfare.
- SALDAE leverages memory management with OPEN, SUBSTITUTE, and RESERVE lists and incorporates strategies like SPLIT-THEN-MERGE, MERGE-THEN-SPLIT, and APPROACH-THEN-SWAP to enhance search efficiency and solution quality in large-scale multiagent systems.


---

[Do Large Language Models Reason Causally Like Us? Even Better?](http://arxiv.org/abs/2502.10215v1)

- LLM (Large Language Model): introduces comparative study evaluating LLMs' causal reasoning against human reasoning using collider graph inference tasks and normative/psychological models.
- Study assesses GPT-40, Claude, Gemini-Pro, GPT-3.5 on predictive, independence, diagnostic inferences, comparing to human data and Causal Bayes Nets, Mutation Sampler models.
- Findings emphasize importance of understanding AI biases in causal reasoning for reliable AI systems, revealing LLMs' varying normative alignment and domain knowledge influence.


---

[AI-in-the-Loop Sensing and Communication Joint Design for Edge Intelligence](http://arxiv.org/abs/2502.10203v1)

- JSAC (AI-in-the-loop joint sensing and communication): introduces an AI-driven closed-loop architecture, with Local Data Source, Data Collection, Sensing, AI Model, Input, Feedback, Reweight, Gradient Uploading, Communication, and Server, that jointly optimizes system resources for superior system-level performance.
- JSAC framework incorporates AI Model Feedback into Data Collection and Communication, using Reweight and Gradient Uploading to dynamically adjust data sampling and gradient noise for enhanced model generalization.
- This approach aims to reduce communication energy and sensing costs while improving model generalization by integrating model feedback into the control loop of edge intelligence systems.


---

[Dynamic Reinforcement Learning for Actors](http://arxiv.org/abs/2502.10200v1)

- Dynamic RL (Dynamic Reinforcement Learning): introduces Actor RNN (generates chaotic dynamics), Sensitivity (local index of convergence), SAL (prevents excessive convergence), and SRL (adjusts dynamics based on TD error) for controlling system dynamics directly in reinforcement learning.
- Dynamic RL framework shifts from static to dynamic RL by embedding exploration into action generation through chaotic system dynamics within the Actor RNN.
- The framework utilizes Sensitivity, SAL, and SRL to manage convergence and divergence of system dynamics based on temporal difference error, aiming for improved learning and adaptability.


---

[VideoDiff: Human-AI Video Co-Creation with Alternatives](https://arxiv.org/abs/2502.10190v1)

- VideoDiff: introduces a human-AI co-creation system for video editing, with AI Edit Recommendations, Multiple Alternatives, Timeline View, Transcript View, Video Alignment, Difference Highlighting, Regenerate, Recombine, Refine, and Sort components.
- VideoDiff supports video creators in exploring multiple variations of video edits through AI-driven suggestions and comparison interfaces.
- The framework facilitates efficient review and customization of video edits by aligning variations, highlighting differences, and providing tools for organization and refinement.


---

[Reinforcement Learning based Constrained Optimal Control: an Interpretable Reward Design](http://arxiv.org/abs/2502.10187v1)

- Interpretable Reward Design Framework: introduces interpretable reward design for reinforcement learning based constrained optimal control, with reward function, terminal constraint reward, guidance reward, penalty for state constraint violations, cost reduction incentive reward, curriculum learning stages, and subproblem solving.
- Framework constructs reward function from four weighted components and uses curriculum learning with subproblem solutions to inform reward design and improve convergence.
- Proposed approach enhances satisfaction of constraints and optimization of control cost in reinforcement learning for constrained optimal control problems.


---

[Safe platooning control of connected and autonomous vehicles on curved multi-lane roads](http://arxiv.org/abs/2502.10180v1)

- Decentralized Control Strategy: introduces decentralized control strategy for safe platooning and merging on curved multi-lane roads, featuring lateral control law, longitudinal control law, and constructive barrier feedback for collision avoidance.
- Decentralized Control Strategy: incorporates lateral control law ensuring geometrical convergence using nominal lateral controller and lateral constructive barrier feedback for road edge collision prevention.
- Decentralized Control Strategy: employs longitudinal control law achieving desired arc length and velocity using nominal longitudinal controller and longitudinal constructive barrier feedback for inter-vehicle collision prevention.


---

[From Markov to Laplace: How Mamba In-Context Learns Markov Chains](http://arxiv.org/abs/2502.10178v1)

- MambaZero: introduces simplified Mamba model with embedding, MambaZero block, linear and prediction components for Markov chain learning.
- MambaZero framework utilizes convolution within its MambaZero block to achieve Laplacian smoothing for optimal next-token prediction.
- The architecture demonstrates that convolution is a key component for Mamba's in-context learning capabilities on Markovian data.


---

[STMA: A Spatio-Temporal Memory Agent for Long-Horizon Embodied Task Planning](http://arxiv.org/abs/2502.10177v1)

- STMA (Spatio-Temporal Memory Agent) introduces a novel framework with Spatio-Temporal Memory Module (captures historical and environmental changes) and Planner-Critic Module (enables closed-loop planning), utilizing Temporal Memory Submodule (processes sequential event records) with Record (stores raw interaction data), Summarizer (condenses raw observations), Temporal Belief (compressed temporal information), and Spatial Memory Submodule (manages spatial relationships) with Spatial Memory (dynamic knowledge graph), Update KGs (updates knowledge graph), Relation Retriever (extracts spatial relationships), Retrieve Algorithm (extracts task-relevant subgraphs), Relation Aggregator (organizes triples into natural language), Spatial Belief (processed spatial memory), operating within Environment (simulated task environment).
- STMA framework enhances task planning and execution by integrating spatio-temporal memory, enabling dynamic adaptation and improved performance in long-horizon embodied tasks within dynamic environments.
- The planner-critic mechanism in STMA facilitates iterative refinement of task strategies through closed-loop feedback, contributing to robust decision-making and adaptability for embodied agents.


---

[Agentic End-to-End De Novo Protein Design for Tailored Dynamics Using a Language Diffusion Model](http://arxiv.org/abs/2502.10173v1)

- VibeGen (generative AI framework): introduces agentic dual-model architecture with Protein designer (PD) (sequence candidate generator) and Protein predictor (PP) (dynamic accuracy evaluator) for end-to-end de novo protein design conditioned on normal mode vibrations.
- VibeGen framework synergizes diversity, accuracy, and novelty in protein design by using Protein designer (PD) (sequence candidate generator) to propose sequences based on vibrational modes and Protein predictor (PP) (dynamic accuracy evaluator) to evaluate dynamic accuracy.
- VibeGen framework establishes bidirectional link between protein sequence and vibrational behavior, enabling new pathways for engineering biomolecules with tailored dynamical and functional properties, validated by full-atom molecular simulations.


---

[Modeling biases in binary decision-making within the generalized nonlinear q-voter model](http://arxiv.org/abs/2502.10172v1)

- Generalized nonlinear q-voter model: introduces agent-based framework, with agent, q-panel, opinion, unanimity, conformity, non-unanimity, bias, complete graph, Monte Carlo simulations, rate equation, phase diagram, and exit probability, to study biased binary decision-making.
- This model extends the classic q-voter model by incorporating state-dependent biases in opinion updates during non-unanimous influence scenarios, analyzed using rate equations and Monte Carlo simulations on complete graphs.
- The framework reveals novel phase diagrams and exit probability behaviors, particularly for larger influence groups (q ≥ 3), highlighting the complex interplay of bias and group influence in collective decision outcomes.


---

[Combinatorial Reinforcement Learning with Preference Feedback](http://arxiv.org/abs/2502.10158v1)

- MNL-VQL (MNL Preference Model with Variance-weighted Item-level Q-Learning): introduces Online Parameter Estimation, Optimistic Q-Values, Pessimistic Q-Values, Variance Estimation, Efficient Optimistic Q-Value Estimation and Exploration Policy to address combinatorial reinforcement learning with preference feedback challenges.
- MNL-VQL framework incorporates variance-weighted regression and optimistic estimation to achieve computational efficiency and nearly minimax-optimal regret, particularly in linear MDPs with preference feedback.
- The framework's novelty lies in its efficient optimistic assortment selection and regret reduction by factor of √H compared to summing H MNL bandit regrets, offering statistical guarantees in combinatorial RL with preference feedback.


---

[Cooperative Multi-Agent Planning with Adaptive Skill Synthesis](http://arxiv.org/abs/2502.10148v1)

- COMPASS (Cooperative Multi-Agent Planning with Adaptive Skill Synthesis): introduces a decentralized closed-loop framework for cooperative multi-agent systems, with Perception (multi-modal input processing), Task Reasoning (objective decomposition), Self-Reflection (execution quality evaluation), Actor (skill selection and execution), Skill Synthesis (executable code generation), Local Memory (agent's individual memory), Global Memory (shared memory), and Skill Library (executable skill collection).
- COMPASS integrates VLMs with a dynamic skill library and structured communication for decentralized decision-making under partial observability.
- The framework enables agents to adapt strategies through iterative planning, skill synthesis, and information sharing, improving performance in cooperative tasks.


---

[Interpretable Concept-based Deep Learning Framework for Multimodal Human Behavior Modeling](http://arxiv.org/abs/2502.10145v1)

- AGCM (Attention-Guided Concept Model): introduces interpretable concept-based framework for multimodal human behavior modeling with Transformer Backbone, Attention-Guided Concept Generator (ACG), Multi-scale Spatial Attention (MSA), Channel Attended Concept Mapping (CACM), Concept Probability Generator, Task Predictor and Loss Computation.
- AGCM framework learns conceptual explanations by identifying predictive concepts and their spatial locations through multimodal concept alignment and co-learning for enhanced decision-making insights.
- AGCM framework achieves state-of-the-art performance in affective computing tasks by balancing interpretability and accuracy through spatial concept supervision and attention mechanisms.


---

[Provably Efficient RL under Episode-Wise Safety in Constrained MDPs with Linear Function Approximation](http://arxiv.org/abs/2502.10138v1)

- OPSE-LCMDP (Optimistic-Pessimistic Softmax Exploration for Linear CMDP): introduces a reinforcement learning algorithm for linear constrained Markov decision processes, utilizing Safe Policy Deployment, Optimistic Exploration, Pessimistic Constraint, Softmax Policy, Bisection Search, Clipped Value Functions, and Confidence Bounds.
- This algorithm achieves episode-wise zero-violation guarantee and sublinear regret in linear CMDPs, improving upon existing methods by ensuring safety and computational efficiency.
- The key innovations include a novel safe policy deployment rule and a softmax-based optimistic-pessimistic exploration strategy, addressing the challenge of safe RL with function approximation in large-scale CMDPs.


--

[Leveraging V2X for Collaborative HD Maps Construction Using Scene Graph Generation](http://arxiv.org/abs/2502.10127v1)

- HDMapLaneNet (High-Definition Map Lane Network): introduces a framework leveraging V2X communication and scene graph generation, with Input Image, Backbone, Encoder, Decoder, Prediction Heads, RGCN, Scene Graph, V2X Conversion & Transmission, and Final Map Generation & Distribution, to collaboratively construct localized geometric HD maps from camera images.
- HDMapLaneNet utilizes DeepLabV3 for feature extraction, DETR-based transformer for lane detection, and RGCN for modeling lane connectivity, transmitting scene graphs via V2X for cloud-based aggregation and HD map generation.
- The framework aims to improve HD map generation by enabling individual vehicles to contribute localized lane information, addressing limitations of traditional mapping approaches in real-time updates and cost-effectiveness.


---

[CAUSAL INFORMATION PRIORITIZATION FOR EFFICIENT REINFORCEMENT LEARNING](http://arxiv.org/abs/2502.10097v1)

- CIP (Causal Information Prioritization): introduces augment, reweight, and empowerment components to improve reinforcement learning sample efficiency by prioritizing causal information.
- CIP framework leverages causal relationships between states, actions, and rewards within factored MDPs to enhance exploration and learning of efficient policies.
- CIP utilizes counterfactual data augmentation and causality-aware empowerment to focus on causally significant behaviors, bridging causal reasoning and efficient exploration.


---

[A novel approach to data generation in generative model](http://arxiv.org/abs/2502.10092v1)

- CFP (Convergent Fusion Paradigm): introduces a geometric framework for data generation in generative models like VAEs, utilizing Ambient (input) space, Latent space, Ambient (output) space, Riemannian metric, Jacobian, Pull-back metric, crSTR, and DCPSs of TC-EO components.
- arxiv_paper_framework_name: framework facilitates structured integration of dimensional spaces through Riemannian metric and Jacobian, enabling qualitative transformation in data generation.
- arxiv_paper_framework_name: theory addresses limitations of Euclidean geometry in capturing complex data generation by incorporating concepts like crSTR and DCPSs of TC-EO for enhanced model expressivity.


---

[Enhancing Patient Acceptance of Robotic Ultrasound through Conversational Virtual Agent and Immersive Visualizations](http://arxiv.org/abs/2502.10088v1)

- Robotic Ultrasound Guidance Procedure: introduces a system for robotic ultrasound with virtual agent guidance, incorporating STT (transcribes patient speech), LLM (generates responses), TTS (converts text to speech), IK (controls avatar movement), Virtual Environment (immersive setting), Motion & Force Control (robot control), and Image Processing (ultrasound image processing).
- The system uses mixed reality visualizations (AR, AV, VR) to enhance patient comfort and trust during robotic ultrasound procedures.
- The integration of a conversational virtual agent and immersive visualizations aims to bridge the gap between robotic automation and patient-centered care in medical procedures.


---

[Coordinated control of multiple autonomous surface vehicles: challenges and advances - a systematic review](http://arxiv.org/abs/2502.10080v1)

- Coordinated control of multiple autonomous surface vehicles: introduces a systematic review of coordinated control for multiple autonomous surface vehicles (ASVs), focusing on Control Techniques, Disturbances, Uncertainties, Communication, and Experimental Validation.
- This review analyzes various control methods, disturbance considerations, uncertainty handling, communication strategies, and experimental validation approaches in coordinated ASV control.
- The paper identifies research gaps and future directions in coordinated ASV control, emphasizing the need for more experimental validation and robust communication strategies.


---

[TOWARDS EMPOWERMENT GAIN THROUGH CAUSAL STRUCTURE LEARNING IN MODEL-BASED RL](https://arxiv.org/abs/2502.10077v1)

- ECL (Empowerment through Causal Learning): introduces a novel framework integrating empowerment with causal reasoning in model-based reinforcement learning, incorporating Causal Dynamics Model, Reward Model, Model Optimization, Empowerment-driven Exploration, and Policy Learning with Intrinsic Reward Bonus.
- ECL framework actively utilizes causal structure to maximize empowerment gain, enhancing agent controllability and learning efficiency within complex environments.
- The framework employs curiosity reward to reduce overfitting and improve exploration, achieving enhanced performance in causal discovery and policy learning tasks.


---

[A Survey on LLM-powered Agents for Recommender Systems](http://arxiv.org/abs/2502.10050v1)

- Unified Agent Architecture: introduces unified agent architecture consisting of Profile, Memory, Planning and Action modules for LLM-powered agent recommender systems.
- Unified Agent Architecture: decomposes agent recommender into profile construction, memory management, strategic planning, and action execution modules.
- Unified Agent Architecture: facilitates analysis of existing LLM-powered agent methods by providing structured framework of core components and their functions.


---

[Automation Bias in the AI Act On the Legal Implications of Attempting to De-Bias Human Oversight of AI](http://arxiv.org/abs/2502.10036v1)

- AIA (Artificial Intelligence Act): introduces AI providers (develop and design AI), AI deployers (use AI systems), human oversight agents (oversee AI systems) and harmonised standards (technical specifications for AI) to address automation bias in high-risk AI systems.
- AIA mandates human oversight and awareness of automation bias, yet its focus on providers may not fully address design and context as causes of bias.
- Harmonised standards referencing research on automation bias and human-AI interaction are proposed to balance legal mandates and behavioural science within AIA framework.


---

[Dream to Drive: Model-Based Vehicle Control Using Analytic World Models](http://arxiv.org/abs/2502.10012v1)

- Analytic World Models (AWMs): introduces differentiable simulation framework utilizing observed modalities, modality features, fused world state, RNNCell, world model, differentiable simulator, dynamics, agent, reward, and semantic predictions for vehicle control tasks.
- AWMs framework enables learning relative odometry, state planning, and inverse state estimation by leveraging gradients from differentiable simulator, improving upon Analytic Policy Gradients (APG).
- The proposed approach uses Model Predictive Control (MPC) with AWMs for planning, achieving improved performance and interpretability in autonomous driving tasks compared to reactive policies.


---

[V2V-LLM: Vehicle-to-Vehicle Cooperative Autonomous Driving with Multi-Modal Large Language Models](http://arxiv.org/abs/2502.09980v1)

- V2V-LLM (Vehicle-to-Vehicle Large Language Model): introduces V2V-LLM, a framework for cooperative autonomous driving using multiple CAVs sharing Perception Data Language QA with a central LLM to answer driving-related questions.
- V2V-LLM fuses scene and object level features from each CAV's perception data, enabling comprehensive environmental understanding for improved driving safety.
- This approach addresses sensor occlusion challenges in autonomous driving by leveraging cooperative perception and LLMs for enhanced decision-making and trajectory planning.


---

[Generating on Generated: An Approach Towards Self-Evolving Diffusion Models](http://arxiv.org/abs/2502.09963v1)

- RSIDiff (Recursive Self-Improvement Diffusion): introduces a self-training approach for diffusion models, iteratively refining the model using its own generated data via prompt construction and filtering pipeline, preference sampling, distribution-based weighting, and model fine-tuning.
- RSIDiff framework enhances diffusion model performance by addressing training collapse through perceptual alignment and hallucination reduction using quality-focused data and distribution control.
- The framework leverages synthetic data for continuous self-evolution, employing strategies to generate perceptually aligned data, filter human-preferred samples, and penalize hallucinatory errors.


---


[Strategyproof Maximum Matching under Dichotomous Agent Preferences](http://arxiv.org/abs/2502.09962v1)

- SAFE (Sequential Allocation for Fairness and Efficiency) and Rank-Maximal mechanisms: introduces acceptability graph, safe blocks, baseline permutation and iterative assignment to achieve strategyproof maximum matching under dichotomous agent preferences and strict institution priorities.
- SAFE mechanism iteratively identifies safe blocks of institutions based on acceptability graph and baseline permutation, assigning agents to institutions within these blocks to maximize matching size while ensuring fairness.
- Rank-Maximal mechanism, equivalent to SAFE, uses ranked acceptability graph and lexi-optimal set of institutions for iterative matching, providing an alternative perspective on achieving the same desirable properties.


---

[Diverse Inference and Verification for Advanced Reasoning](http://arxiv.org/abs/2502.09955v1)

- Diverse Inference: introduces a diverse inference framework that combines multiple models and methods, including Human (User input), LLM (Reasoning engine), Agent (Process orchestrator), Game Environment (Problem representation), Verifier (Solution checker), and specific methods like LEAP (Task-specific learning), Z3 (Theorem prover), RTO (Round trip optimization), BoN (Best-of-N sampling), SC (Self-consistency), MoA (Mixture of agents), MCTS (Monte Carlo search), PV (Prover-verifier game), Unit Tests (Code execution verification), and Best-of-N (Sampling based verification), to enhance reasoning and verification for advanced tasks.
- arxiv_paper_framework_name: leverages perfect verifiers like Lean Verifier (Formal proof checker) for IMO and ARC problems and imperfect verifiers like Best-of-N (Sampling based verification) for HLE questions, achieving higher accuracy on challenging benchmarks.
- arxiv_paper_framework_name: utilizes test-time simulations, reinforcement learning, and meta-learning to adapt agent graph representations and improve generalization across diverse problem types.


---

[The Blind Men and the Elephant: Mapping Interdisciplinarity in Research on Decentralized Autonomous Organizations](http://arxiv.org/abs/2502.09949v1)

- Framework name here: introduces citation network analysis, topic modeling, and outlet analysis components to assess interdisciplinary research maturity on Decentralized Autonomous Organizations (DAOs).
- Citation network analysis identifies boundary papers and interaction patterns, topic modeling explores interdisciplinary discussion themes, and outlet analysis investigates author and publication relationships.
- This multi-method approach uncovers where and how interdisciplinary exchanges occur in DAO research, revealing fragmented yet inherently interdisciplinary nature.


---

[MIR-Bench: Benchmarking LLM's Long-Context Intelligence via Many-Shot In-Context Inductive Reasoning](http://arxiv.org/abs/2502.09933v1)

- MIR-Bench: introduces a data generation pipeline with Data Collection, Input-Output Generation, and Dataset Construction for benchmarking LLMs' long-context inductive reasoning.
- MIR-Bench pipeline utilizes coding benchmarks for function acquisition and GPT-4 for generating input-output pairs, employing filtering to create MIR-Extended and MIR-Core datasets via factor analysis.
- MIR-Bench addresses the evaluation gap in LLMs' many-shot inductive reasoning by offering a large-scale, diverse benchmark and providing novel problems for insightful analysis.


---

[Self-Consistent Model-based Adaptation for Visual Reinforcement Learning](http://arxiv.org/abs/2502.09923v1)

- SCMA (Self-Consistent Model-based Adaptation): introduces robust visual RL adaptation method using denoising model, pre-trained world model, and policy to mitigate distractions.
- SCMA utilizes a denoising model to transfer cluttered observations to clean ones, guided by a pre-trained world model for unsupervised distribution matching.
- The approach enhances policy performance in distracting environments without policy modification, offering a plug-and-play solution for various policies.


---

[(How) Can Transformers Predict Pseudo-Random Numbers?](http://arxiv.org/abs/2502.10390v1)

- GPT-style Autoregressive Transformer: introduces paper investigates Transformer's ability to predict pseudo-random numbers using embedding layers, attention heads, MLP block, output layer, and memory.
- It reveals Transformers learn to factorize modulus and use digit-wise representations for prediction.
- The study shows a sharp accuracy transition at depth 3 and sublinear scaling of context elements with modulus.


---

[Unconventional Transport in a System with a Tower of Quantum Many-Body Scars](http://arxiv.org/abs/2502.10387v1)

- Spin-1 Chain Model: introduces investigation of unconventional transport phenomena within a spin-1 model, utilizing Hamiltonian, Ladder Operator, Scarred Subspace, Coherent States, and Autocorrelation Function components.
- This research demonstrates transport mechanism linked to quantum many-body scars, observing slowly decaying oscillations from dynamical symmetry within the scar subspace using autocorrelation function analysis.
- The study reveals that ETH-preserving many-body spectrum mediates this transport, while quantum many-body scars themselves provide negligible contribution in thermodynamic limit, suggesting generalized eigenstate thermalization hypothesis.


---


[Unknown Word Detection for English as a Second Language (ESL) Learners Using Gaze and Pre-trained Language Models](https://doi.org/10.1145/3706598.3714181)

- EyeLingo: introduces method for unknown word detection utilizing Gaze Data (user's eye movement) and Text Data (reading content) processed by Transformer-based Model (predicts unknown words) to identify Unknown Words (words needing definition) for ESL learners.
- EyeLingo leverages gaze to locate region of interest, integrating linguistic information from pre-trained language models and gaze trajectory for real-time unknown word prediction.
- The framework compensates for gaze inaccuracy by incorporating probabilities from language model, enabling real-time language learning assistance and vocabulary acquisition.


---


[CISSIR: Beam Codebooks with Self-Interference Reduction Guarantees for Integrated Sensing and Communication Beyond 5G](http://arxiv.org/abs/2502.10371v1)

- CISSIR (Codebooks with Integral Split for Self-Interference Reduction): introduces beam codebook design with digital pre-coding, beam selection, gain control, radar processing, I/Q Modulation, DAC, TX Analog Beams, TX Antennas, direct coupling, clutter, user equipment, SI channel, target, radar channel, RX Antennas, RX Analog Beams, ADC, and I/Q Demodulation for self-interference reduction in integrated sensing and communication (ISAC) systems.
- CISSIR framework optimizes codebooks for tapered beamforming and phased arrays, adapting codebooks to self-interference channel and achieving specific self-interference level.
- CISSIR method improves sensing quality while maintaining communication performance, reducing dependence on hyperparameters and enhancing self-interference reduction capabilities.


---

[Decentralized State Estimation and Opacity Verification Based on Partially Ordered Observation Sequences](http://arxiv.org/abs/2502.10367v1)

- ASS (All Sequence Structure): introduces decentralized observation architecture for state estimation and opacity verification using observation sites and coordinator.
- ASS framework constructs current-state and initial-state estimators based on partially ordered observation sequences for offline analysis.
- The approach reduces complexity in verifying state-isolation properties like opacity within decentralized systems compared to existing methods.


---


[Investigations of multi-socket high core count RISC-V for HPC workloads](http://arxiv.org/abs/2502.10320v1)

- Sophon SG2042 Benchmarking Framework: introduces performance evaluation of Sophon SG2042 CPU, dual-socket system, nodes, sockets, cores, memory subsystem, benchmark suite, and comparison CPUs for HPC workloads.
- This framework assesses RISC-V based Sophon SG2042 CPU in dual-socket configuration using NAS Parallel Benchmarks, focusing on memory and compute bound performance.
- The study contrasts SG2042 against AMD EPYC, Intel Skylake, and Marvel ThunderX2 CPUs to identify performance characteristics in realistic HPC scenarios.


---

[TRUSTZERO - OPEN, VERIFIABLE AND SCALABLE ZERO-TRUST](http://arxiv.org/abs/2502.10281v1)

- TrustZero (Zero Trust Architecture (ZTA)): introduces ModSecurity, Policy Enforcement Point, Policy Administrator, Policy Engine, Trust Token, and Trust Algorithm to establish a scalable zero-trust security layer using verifiable cryptographic signatures and continuous identity verification.
- TrustZero framework, leveraging cryptographic principles and zero-trust architecture, aims to enhance security and trust in inter-organisational communication by replacing implicit trust with explicit verification and portable trust tokens.
- TrustZero's architecture emphasizes transparency and reproducibility, offering an open-source framework designed for deployment in sensitive infrastructures and adaptable to legacy systems by integrating with European Digital Identity Wallet.


---

[SPIRIT: Short-term Prediction of solar IRradlance for zero-shot Transfer learning using Foundation Models](http://arxiv.org/abs/2502.10307v1)

- SPIRIT (Short-term Prediction of solar IRradlance for zero-shot Transfer learning using Foundation Models): introduces a novel approach for solar irradiance forecasting using Dataset, Vision Encoder, Physics Features, SpatioTemporal Data, Regressor, Time Series Model and Future Covariate Vector components.
- arxiv_paper_framework_name: leverages foundation models and physics-informed features to enable zero-shot transfer learning for solar irradiance prediction, reducing reliance on site-specific data.
- arxiv_paper_framework_name: achieves effective adaptation across diverse transfer learning scenarios and demonstrates rapid scalability to new solar plant locations without prior data.


---

[A Multiagent Path Search Algorithm for Large-Scale Coalition Structure Generation](http://arxiv.org/abs/2502.10226v1)

- SALDAE (Scalable Algorithm with Large-Scale Distributed Agent Exploration): introduces multiagent path search algorithm for coalition structure generation using search agents exploring coalition structure graph from start node, generating child nodes, performing node selection, comparing to incumbent, employing bridging paths, utilizing memory management and applying conflict resolution.
- SALDAE algorithm iteratively builds search graph by splitting or merging coalitions for solving coalition structure generation problems, aiming to find optimal partitioning of agents into coalitions to maximize social welfare.
- SALDAE leverages memory management with OPEN, SUBSTITUTE, and RESERVE lists and incorporates strategies like SPLIT-THEN-MERGE, MERGE-THEN-SPLIT, and APPROACH-THEN-SWAP to enhance search efficiency and solution quality in large-scale multiagent systems.


---

#### 12th February 2025

[Spike sorting AI agent](https://www.biorxiv.org/content/10.1101/2025.02.11.637754v1.full.pdf)

- SpikeAgent: introduces a multimodal large language model (LLM)-based AI agent with a Backend (core processing unit) and Frontend User Interface (chat-based interaction), integrating Multimodal LLM Backends (reasoning, planning), Multimodal Context Memory (retains information), Code Execution Module (executes code), Specialized Tools and Modules (perform tasks), Vision-Language Model Module (interprets visual data), Task Planning and Orchestration (breaks down tasks), and Context-aware Code Generation (generates code) to automate spike sorting.
- The system integrates multiple LLM backends, coding functions, and established algorithms, autonomously performing spike sorting with reasoning-based decision-making and real-time interaction.
- SpikeAgent generates interpretable reports with transparent justifications for sorting decisions, enhancing transparency and reliability compared to manual curation.


---


#### 11th February 2025

[CSR-Bench: Benchmarking LLM Agents in Deployment of Computer Science Research Repositories](https://arxiv.org/abs/2502.06111)

- CSR-Agents: introduces a multi-agent framework to automate code repository deployment using multiple LLM agents with specialized roles including Command Drafter, Script Executor, Log Analyzer, Issue Retriever, and Web Searcher.
- CSR-Agents framework leverages iterative trial-and-error process within Docker Environment, refining bash commands based on execution logs, issue database retrieval and web search integration.
- CSR-Agents framework is evaluated on CSR-Bench, a novel benchmark designed for assessing LLM agent capabilities in automating deployment of computer science research repositories from GitHub.


---

#### 10th February 2025

[Visual Agentic AI for Spatial Reasoning with a Dynamic API](https://arxiv.org/abs/2502.06787)

- VADAR (Visual, Agentic, Dynamic AI for Reasoning): introduces a training-free agentic approach for 3D understanding, which dynamically generates new skills in Python, using Signature Agent, Implementation Agent, Test Agent, Program Agent, Execution Agent, Vision Specialists, and API, and is evaluated on CLEVR and OMNI3D-BENCH.
- VADAR leverages LLM agents to define and expand a domain-specific language, generating new functions and skills in two phases: API Generation and Program Synthesis.
- The framework addresses limitations of prior approaches that rely on a static, human-defined API, allowing it to handle a wider range of queries.


---

#### 7th February 2025


[Sirius: Self-improving Multi-agent Systems via Bootstrapped Reasoning](http://arxiv.org/abs/2502.04780v1)

- SIRIUS: introduces a self-improving multi-agent system framework, utilizing Physicist, Mathematician, Summarizer agents, Experience Library, Experience Augmentation, and Fine-tuning for optimizing multi-agent systems.
- SIRIUS constructs an experience library by retaining successful reasoning trajectories to provide training data for agent policy fine-tuning.
- SIRIUS further enriches the library by augmenting unsuccessful trajectories, enhancing data diversity and improving system performance.


---


[MELON: Indirect Prompt Injection Defense via Masked Re-execution and Tool Comparison](http://arxiv.org/abs/2502.05174v1)

- MELON (Masked re-Execution and TooL comparisON) introduces an indirect prompt injection defense framework, with Agent System, Tool Execution, Tool Call Cache, Compare Tool Calls, and Masking Function, that detects attacks by comparing tool calls between original and masked executions.
- MELON framework leverages Masking Function to generate task-neutral prompts for masked re-execution, utilizing Tool Call Cache to store masked run tool calls and Compare Tool Calls to identify deviations indicating potential attacks.
- MELON framework enhances security and utility balance by focusing on tool call comparison and incorporating designs like customized masking, tool call caching, and focused comparison to reduce false positives and negatives in indirect prompt injection detection.


---


[NVAGENT: Automated Data Visualization from Natural Language via Collaborative Agent Workflow](http://arxiv.org/abs/2502.05036v1)

- NVAGENT: introduces collaborative agent workflow for NL2VIS, with processor (database processing and context filtering), composer (planning visualization generation), and validator (code translation and output verification).
- NVAGENT decomposes visualization generation into manageable subtasks using processor for data preparation, composer for VQL generation, and validator for ensuring correctness.
- NVAGENT leverages divide-and-conquer strategy with specialized agents to effectively handle complex NL2VIS tasks, improving visualization accuracy and quality.


---

[The Rising Threat to Emerging AI-Powered Search Engines](http://arxiv.org/abs/2502.04951v1)

- Agent-based Defense: introduces agent-based defense with Observation, Thought, Action, Tools, and Agent-based Defense components, where agent-based defense mitigates risks in AIPSE outputs.
- Agent-based defense framework uses Observation to gather AIPSE output, Thought for reasoning, Action to use Tools like Content Refinement and URL Detector.
- Agent-based defense aims to filter and mark potential risks in AIPSE output while preserving response similarity.


---

[S<sup>2</sup>.-MAD: Breaking the Token Barrier to Enhance Multi-Agent Debate Efficiency](http://arxiv.org/abs/2502.04790v1)

- S2-MAD (Selective Sparse Multi-Agent Debate): introduces Initial Response Generation, Grouping Discussion with Decision-Making Mechanism, and Reaching Consensus, with Agents organized in Groups, to enhance multi-agent debate efficiency.
- S2-MAD framework employs Decision-Making Mechanism comprising Similarity Calculation, Redundant Information Filtering, and Conditional Participation modules to manage agent engagement.
- S2-MAD framework aims to reduce token costs in multi-agent debate by selectively incorporating non-redundant viewpoints and optimizing information exchange among agents.


---


[Agentic Reasoning: Reasoning LLMs with Tools for the Deep Research](http://arxiv.org/abs/2502.04644v1)

- Agentic Reasoning: introduces a framework enhancing large language model reasoning by integrating Web-Search Agent, Coding Agent, and Mind Map Agent, to solve complex problems requiring research and logical deduction.
- Agentic Reasoning framework utilizes Mind Map Agent for structured knowledge graph construction, Web-Search Agent for real-time information retrieval, and Coding Agent for computational analysis, improving reasoning and decision-making.
- Agentic Reasoning enables language models to perform multi-step strategies and tackle complex problems by dynamically adapting to information and performing quantitative analyses using external agents and structured memory.


---

[Self-Regulation and Requesting Interventions](http://arxiv.org/abs/2502.04576v1)

- Offline PRM-Tabular RL Framework: introduces an offline approach for training intervention-requesting agents, with State Dynamics, PRM, Tabular RL, Usage computation, Policy computation, Reward Search, and SFT Helper components.
- Offline PRM-Tabular RL Framework combines LLM-based Process Reward Models with tabular reinforcement learning to efficiently determine optimal intervention timing under budget constraints.
- This framework reduces costly intervention calls during training by leveraging offline data and enhancing robustness through PRMs and tabular RL, avoiding deep RL inefficiencies.


---
[Every Software as an Agent: Blueprint and Case Study](http://arxiv.org/abs/2502.04747v1)

- JiT-Codegen: introduces software agent framework for in-software execution using LLM-powered Agent, JiT Code Agent, Software Runtime, and Exec. Sandbox.
- JiT-Codegen framework enables LLMs access to software internals and inject code for execution within a secure Exec. Sandbox.
- This approach aims to overcome limitations of API-based and GUI-based agents by enabling more direct and efficient software interaction.


---

[STRIDE: Automating Reward Design, Deep Reinforcement Learning Training and Feedback Optimization in Humanoid Robotics Locomotion](http://arxiv.org/abs/2502.04692v1)

- STRIDE (Automating Reward Design, Deep Reinforcement Learning Training and Feedback Optimization in Humanoid Robotics Locomotion): introduces framework integrating Humanoid Robotics Environment, Motion Task Description, LLMs, Reward Function Sampling, Reward Functions, Reward Reflection, DRL Training, and Feedback Result for automated reward design.
- STRIDE leverages LLMs for zero-shot reward function generation and iterative refinement through feedback from DRL training outcomes.
- STRIDE automates reward engineering for humanoid robot locomotion, overcoming limitations of manual reward design and improving task performance.


---


[Learning Strategic Language Agents in the Werewolf Game with Iterative Latent Space Policy Optimization](http://arxiv.org/abs/2502.04686v1)

- LSPO (Latent Space Policy Optimization): introduces iterative framework with Latent Space Construction (create discrete strategy space), Policy Optimization in Latent Space (optimize strategy in latent space), and Latent Space Expansion (expand strategy space coverage) for strategic language agents.
- LSPO framework addresses challenges in free-form language games by mapping text to latent space, optimizing policy with game-theoretic methods, and expanding space via LLM fine-tuning.
- Iterative process of LSPO enhances strategic reasoning and language communication, improving agent performance in complex games like Werewolf.


---


#### 6th February 2025


[VTutor: An Open-Source SDK for Generative AI-Powered Animated Pedagogical Agents with Multi-Media Output](http://arxiv.org/abs/2502.04103v1)

- VTutor (Software Development Kit): introduces an open-source framework for creating animated pedagogical agents, integrating Generative AI (LLMs), Text-to-Speech (TTS), Lip Synchronization (LipSync), Character Model, WebGL Rendering, Web Interface, API Communication, SDK, Iframe Integration, and React SDK.
- VTutor combines generative AI with animation technologies to enable personalized learning experiences through adaptable, realistic animated pedagogical agents with multi-media output in web environments.
- The framework leverages LLMs for context-aware feedback, uLipSync for accurate lip movements, and WebGL for seamless web integration, offering tools for developers to create engaging educational agents.


---


[PsyPlay: Personality-Infused Role-Playing Conversational Agents](http://arxiv.org/abs/2502.03821v1)

- PsyPlay: introduces dialogue generation framework with Role Card Creation (generates agent roles), Topic Extraction (extracts dialogue topics), and Dialogue Generation (creates personality-infused dialogues) for personality-infused role-playing.
- PsyPlay framework facilitates expression of rich personalities among multiple LLM agents assuming distinct roles and engaging in discussions.
- PsyPlay validation demonstrates accurate portrayal of intended personality traits with high success rate on generated dialogue data.


---


[Large Language Models for Multi-Robot Systems: A Survey](http://arxiv.org/abs/2502.03814v1)

- BOLAA (Benchmarking and Orchestrating LLM-augmented Autonomous Agents) architecture orchestrates multiple LAAs using Agents Message Controller, which manages communication between Environment, Labor Agents Pool consisting of multiple agents LAA 1, LAA 2, LAA m, each having LLM and Agent Prompt, Action Parser, Memory and Agents Selection.
- BOLAA architecture employs central controller for message distribution to individual agents with own LLMs, processing distributed messages to generate actions, improving consistency and reliability in collaborative systems.
- BOLAA architecture serves as comparative framework for LLM-augmented agents, offering insights into LLM integration and agent orchestration for multi-robot applications, despite focus on multi-agent systems rather than exclusively MRS.


---

[Division-of-Thoughts: Harnessing Hybrid Language Model Synergy for Efficient On-Device Agents](http://arxiv.org/abs/2502.04392v1)

- DoT (Division-of-Thoughts): introduces collaborative reasoning framework, with Task Decomposer, Task Scheduler, Task Allocation, Plug-and-Play Adapter, SLM, LLM, and Self-Reinforced Tree Search, for efficient on-device agents using hybrid language model synergy.
- DoT framework employs Task Decomposer for breaking down queries, Task Scheduler for dependency analysis between sub-tasks, and Plug-and-Play Adapter for dynamic allocation of sub-tasks between SLM and LLM.
- Self-Reinforced Tree Search method trains Plug-and-Play Adapter using task execution feedback to optimize sub-task allocation strategy for enhanced efficiency and maintained accuracy.


--

[Multi-Agent Reinforcement Learning with Focal Diversity Optimization](http://arxiv.org/abs/2502.04492v1)

- MARL-Focal (Multi-Agent Reinforcement Learning with Focal Diversity Optimization): introduces a two-stage framework with Decider Agent (selects optimal LLM subset) and Aggregator Agent (synthesizes final output) to improve LLM performance by leveraging a Pool of LLMs in Cloud (collection of available models) and diversity metrics.
- MARL-Focal framework utilizes Decider Agent (selects optimal LLM subset) within Multi Agent Environment (manages agent interactions) to choose Chosen LLMs (selected ensemble subset) based on Perf. Metrics (diversity-based selection metrics) from Incoming Online Queries (user input queries) and generate Model Outputs (LLM generated responses) for final aggregation.
- The framework's architecture allows for adaptive ensemble creation by dynamically selecting and combining diverse LLMs, aiming to enhance output quality and robustness while maintaining cost-efficiency in multi-agent learning scenarios.


---

[ACTIVE TASK DISAMBIGUATION WITH LLMS](http://arxiv.org/abs/2502.04485v1)

- Active Task Disambiguation: introduces method for LLM agents to actively clarify ambiguous tasks by iteratively asking questions, using solution generator, question generator, and question evaluator to refine problem statement and solution space.
- It leverages Bayesian Experimental Design principles to select questions maximizing information gain, shifting reasoning from implicit to explicit solution space exploration.
- This approach improves task disambiguation compared to methods relying solely on implicit reasoning within the question space, enhancing LLM agents' ability to address underspecified problems.


---

[ScoreFlow: Mastering LLM Agent Workflows via Score-based Preference Optimization](http://arxiv.org/abs/2502.04306v1)

- ScoreFlow: introduces automated workflow generation framework, with LLM Generator (workflow code generator), Executor (workflow performance evaluator), Collect data (score gathering component), Scores (workflow performance metrics), Preference workflow pairs (score-based workflow rankings), Iterative Score-DPO (score-aware optimization algorithm), Operators (reusable agent node combinations), Workflows (code for agent interactions), Problem dataset (input task collection).
- ScoreFlow framework utilizes Score-DPO optimization, incorporating quantitative evaluation feedback for workflow generation.
- ScoreFlow enhances scalability and performance through gradient-based optimization and code-based workflow representation.


---


[Multi-agent Architecture Search via Agentic Supernet](http://arxiv.org/abs/2502.04180v1)

- MaAS (Multi-agent Architecture Search): introduces agentic supernet, probabilistic architecture distribution, with controller, agentic operators, environment, and feedback, where MaAS optimizes distribution of agentic architectures for query-dependent multi-agent systems.
- MaAS framework leverages controller network to sample task-specific multi-agent systems from agentic supernet, adapting architecture based on environmental feedback and agentic operators.
- Agentic supernet in MaAS enables efficient resource allocation by dynamically adjusting multi-agent system complexity based on query difficulty and domain, utilizing feedback for continuous improvement.


---


[Speaking the Language of Teamwork: LLM-Guided Credit Assignment in Multi-Agent Reinforcement Learning](http://arxiv.org/abs/2502.03723v1)

- LCA (LLM-guided Credit Assignment): introduces a novel framework for multi-agent reinforcement learning that uses LLM State Ranking (LLM prompts for pairwise state ranking) to generate agent-specific rewards.
- LCA framework leverages Ego Agent (agent perspective encoding) and Scoring Model Training Dataset (ranking data for training) to train a scoring model, facilitating credit assignment in sparse reward MARL environments.
- By utilizing Temporal Difference (RL update mechanism) and LLM (large language model), LCA achieves faster convergence and higher returns compared to baselines by addressing credit assignment and reward sparsity.


---

[MultiQ&A: An Analysis in Measuring Robustness via Automated Crowdsourcing of Question Perturbations and Answers](http://arxiv.org/abs/2502.03711v1)

- MultiQ&A: introduces a multi-step pipeline for question answering robustness evaluation, with Query Rewrite, Generator, and Aggregator components.
- MultiQ&A framework utilizes Query Rewrite to create diverse question variations, Generator to independently answer them, and Aggregator to evaluate answer robustness and consistency.
- This approach enables automated crowdsourcing and robust question answering evaluation mimicking real-world scenarios for assessing Large Language Model performance under question perturbations.


---


#### 5th February 2025

[A Schema-Guided Reason-while-Retrieve framework for Reasoning on Scene Graphs with Large-Language-Models (LLMs)](http://arxiv.org/abs/2502.03450v1)

- SG-RwR (Schema-Guided Reason-while-Retrieve) introduces a two-agent framework with Reasoner (task planning and query generation) and Retriever (graph information extraction) for scene graph reasoning.
- SG-RwR framework utilizes Scene Graph Schema (textual graph description) to guide both Reasoner and Retriever agents in code-writing for information retrieval and reasoning.
- The framework components Reasoner Query (query for graph information), Retrieve Code (code for information retrieval), Retrieved Information (extracted graph data) and Reason Code (code for reasoning and tools) enable iterative and adaptive graph processing to generate Answer (final task solution).


---

[PalimpChat: Declarative and Interactive AI analytics](http://arxiv.org/abs/2502.03368v1)

- PALIMPCHAT: introduces chat interface, user, pipeline design, program optimization, plan execution, programming framework, cost estimation, plan execution and unstructured data for AI analytics.
- PALIMPCHAT integrates ARCHYTAS reasoning agent and PALIMPZEST declarative framework to enable natural language interaction for AI pipeline creation and execution.
- PALIMPCHAT simplifies complex AI workflows by providing accessible chat-based interface for both expert and non-expert users to design and run data processing pipelines.


---


[SymAgent: A Neural-Symbolic Self-Learning Agent Framework for Complex Reasoning over Knowledge Graphs](http://arxiv.org/abs/2502.03283v1)

- SymAgent (A Neural-Symbolic Self-Learning Agent Framework) introduces an agent framework with Agent-Planner, Agent-Executor, KG Environment, Action Tool Set, and Self-learning Framework for complex reasoning over knowledge graphs.
- SymAgent framework utilizes Agent-Planner to derive symbolic rules from knowledge graphs and Agent-Executor to apply action tools for information integration from knowledge graphs and external sources.
- Self-learning Framework in SymAgent enables iterative online exploration and offline policy updating, facilitating autonomous synthesis of reasoning trajectories and performance improvement.


---

[Strategizing with AI: Insights from a Beauty Contest Experiment](http://arxiv.org/abs/2502.03158v1)

- Framework name here: introduces LLMs, Game Scenarios, Prompts, and Performance Analysis to investigate strategic behavior of AI agents in game theory experiments.
- This framework evaluates LLMs' decision-making by comparing their game strategies against human players and theoretical predictions across varied game scenarios.
- The framework aims to understand LLMs' strategic reasoning, adaptability, and limitations in emulating human-like behavior within economic game contexts.


---


[COSMosFL: Ensemble of Small Language Models for Fault Localisation](http://arxiv.org/abs/2502.02908v1)

- COSMosFL (COllection of Small Language Models for Fault Localisation): introduces a task-level LLM ensemble technique using voting mechanism with M models, SLMs, Query Root Cause, Bug Information, Query Fault Location, Available Tools, Voting-based Ensemble, and Confidence Score for fault localization.
- COSMosFL aggregates answers from multiple SLMs instead of repeated sampling from a single LLM to improve fault localization accuracy and cost-benefit trade-off.
- COSMosFL leverages voting-based ensemble and differential evolution for weight optimization to achieve Pareto-optimality in fault localization accuracy and inference cost.


---



#### 4th February 2025

[Adaptive Self-improvement LLM Agentic System for ML Library Development](http://arxiv.org/abs/2502.02534v1)

- Adaptive self-improvement LLM agentic system: introduces agentic system organization with parallel sampling to enhance LLM Agents via select multi-level experiences, stratify them by difficulty, filter high-quality answers, and use demonstrations for ML library development Task, verified by Verifier to produce Answer.
- This system employs adaptive self-improvement learning algorithm that filters quality answers, stratifies experiences by difficulty, and selects demonstrations to improve LLM agents' performance in generating architecture-specific programming language code.
- The framework addresses challenges in ML library development by enabling complex reasoning with limited data through a self-improvement cycle where LLM agents evolve via earned experiences and generate high-quality ML operators.


---

[AdaptBot: Combining LLM with Knowledge Graphs and Human Input for Generic-to-Specific Task Decomposition and Knowledge Refinement](http://arxiv.org/abs/2502.02067v1)

- AdaptBot: introduces framework integrating LLM, Knowledge Graph, Human Input, Execution, and Decision Module, for task decomposition and knowledge refinement.
- AdaptBot utilizes LLM for generating initial abstract action plans, Knowledge Graph for domain-aware refinement, and human input for error correction and knowledge expansion.
- AdaptBot framework facilitates adaptation to new tasks through incremental knowledge refinement via human feedback and Knowledge Graph-guided error resolution.


---

[Anticipate & Act : Integrating LLMs and Classical Planning for Efficient Task Execution in Household Environments](http://arxiv.org/abs/2502.02066v1)

- Anticipate & Act: introduces a framework for efficient task execution, integrating User, LLM Prompting, LLM, Mapping, Planning, FASTDOWNWARD PLANNER, GENERATED PLAN, and SIMULATION components.
- Anticipate & Act: leverages LLM to predict high-level tasks from User prompts and uses FASTDOWNWARD PLANNER to generate fine-grained action sequences via Planning and Mapping components.
- Anticipate & Act: demonstrates efficiency in household tasks by anticipating future tasks and planning actions jointly within SIMULATION environment, reducing execution time and plan length.


---

[CoAT: Chain-of-Associated-Thoughts Framework for Enhancing Large Language Models Reasoning](https://arxiv.org/abs/2502.02390)

- CoAT (Chain-of-Associated-Thoughts): introduces a reasoning framework for large language models that combines an optimized Monte Carlo Tree Search (MCTS) with a dynamic associative memory mechanism, integrating Target LLM, Associative Memories, Nodes, optional External Brain, Knowledge Graph, Vector Database, LLM agents, Internet Access, and Evaluator.
- The framework expands the reasoning search space and adaptively incorporates new information, mimicking human-like associative thinking during inference.
- Optimized MCTS algorithm systematically integrates associative content and generated content through tree node search, and flexible mechanism sources associative content by self-association or external knowledge retrieval.


---

#### 3rd February 2025

[Improving Transformer World Models for Data-Efficient RL](https://arxiv.org/abs/2502.01591)

- Improved TWM for Data-Efficient RL: introduces MBRL framework with MFRL Baseline, MBRL Baseline, Dyna with Warmup, Nearest Neighbor Tokenizer, and Block Teacher Forcing for enhanced data efficiency in reinforcement learning.
- The framework combines model-free and model-based RL with novel tokenization and training techniques to achieve state-of-the-art performance in the Craftax-classic environment.
- Key improvements include Dyna with Warmup for hybrid real-imaginary training, Nearest Neighbor Tokenizer for efficient image encoding, and Block Teacher Forcing for improved TWM training and rollout accuracy.


---

[PROCESS REINFORCEMENT THROUGH IMPLICIT REWARDS](https://arxiv.org/abs/2502.01456)

- PRIME (Process Reinforcement through IMplicit rEwards): introduces scalable online reinforcement learning framework with dense token-level rewards with Policy Model, Implicit PRM, SFT Model, Outcome Verifier, and Reference Model.
- PRIME framework updates Implicit PRM online using policy rollouts and outcome labels, removing dedicated reward model training phase.
- PRIME utilizes Implicit PRM for token-level rewards generation, mitigating reward hacking and enhancing sample efficiency in reinforcement learning for LLMs.


---

[TReMu: Towards Neuro-Symbolic Temporal Reasoning for LLM-Agents with Memory in Multi-Session Dialogues](https://arxiv.org/abs/2502.01630)

- TReMu (Temporal Reasoning for LLM-Agents in Multi-Session Dialogues): introduces a framework with Time-aware Memorization Model (summarizes dialogue sessions with dates), Memory Retrieval Model (retrieves relevant memory for question), Neuro-symbolic Reasoning Model (generates Python code for reasoning), and Python Executor (executes generated Python code) to enhance temporal reasoning in multi-session dialogues.
- It employs timeline summarization for memory and neuro-symbolic reasoning using LLMs to generate and execute Python code for temporal calculations.
- This approach improves temporal reasoning performance by leveraging Python's libraries for temporal calculations and step-by-step code execution.


---

[Reinforcement Learning for Long-Horizon Interactive LLM Agents](https://arxiv.org/abs/2502.01600)

- LOOP: introduces reinforcement learning framework for training interactive digital agents, utilizing hidden state, task context, agent output, and environment output for long-horizon tasks.
- This framework uses partially observable Markov decision process to formalize agent-environment interactions via read-eval-print loop.
- LOOP framework enhances sample efficiency and memory efficiency by reusing off-policy samples and maintaining single LLM copy.


---

[Memento No More: Coaching AI Agents to Master Multiple Tasks via Hints Internalization](https://arxiv.org/abs/2502.01562)

- MNM (Memento No More): introduces an iterative coaching process with Initial Agent, Human Analyst, Hints, Teacher Agent, Training Data, Student Agent, and Task Trajectories, where human feedback guides an AI agent to master multiple tasks.
- The framework refines agent behavior through iterative rounds of mistake analysis and hint internalization, improving task execution without extensive prompts.
- MNM leverages context distillation to transfer hint knowledge into agent weights, enhancing generalization and reducing reliance on prompt-based guidance.


---


[THE IN-CONTEXT INDUCTIVE BIASES OF VISION-LANGUAGE MODELS DIFFER ACROSS MODALITIES](https://arxiv.org/abs/2502.01530)

- Framework name here: introduces vision-language models, with vision input (processing visual information) and text input (processing textual information), to study generalization process (inferring category from examples) across modalities.
- It highlights that inductive biases in vision-language models differ significantly based on whether input is visual or textual, affecting generalization.
- Furthermore, the study reveals that in textual input, the order of feature descriptors influences the model's generalization, indicating sensitivity to linguistic structure.


---

[SHARPIE: A Modular Framework for Reinforcement Learning and Human-AI Interaction Experiments](http://arxiv.org/abs/2501.19245v2)

- SHARPIE (Shared Human-AI Reinforcement Learning Platform for Interactive Experiments): introduces a modular framework for human-AI interaction experiments, featuring versatile wrapper for RL components, participant web interface, experiment configuration, logging, deployment utilities, and multi-modal communication channels.
- The framework standardizes human-RL interaction research by offering a generic interface and tools for studying diverse interaction aspects and facilitating experiment design and execution.
- SHARPIE supports diverse human-RL interaction use cases including reward annotation, teaching, action delegation, task specification, and human-AI teaming, facilitating research in cognitive science and RL.


---


[TwinMarket: A Scalable Behavioral and Social Simulation for Financial Markets](https://github.com/TobyYang7/TwinMarket)

- TwinMarket: introduces a multi-agent framework designed for simulating socio-economic systems, incorporating User Profile, Belief, Desire, Intention, World Knowledge, Action Space, Market Environment, Social Environment, Order-Driven Trading System, Matching Engine, Data Sources, and Validation Metrics components.
- TwinMarket framework simulates investor behavior within a stock market environment by utilizing Belief-Desire-Intention framework integrated with a simulated social media platform and real-world market data.
- TwinMarket framework facilitates the investigation of emergent market phenomena, such as financial bubbles and volatility clustering, through scalable simulations of individual decision-making and social interactions.


---

[Simulating Rumor Spreading in Social Networks using LLM Agents](https://arxiv.org/abs/2502.01450)

- LLM-based multi-agent network framework: introduces a simulation framework with LLM-based Agent, Post History, Rumor Belief, and Social Network to examine rumor propagation dynamics.
- The framework employs LLM-based Agent to simulate user behavior, utilizing Post History for context and Rumor Belief for opinion tracking within a Social Network.
- This framework assesses how different Social Network structures and agent behaviors impact Rumor Belief and overall rumor dissemination.


---

[Evolving Symbolic 3D Visual Grounder with Weakly Supervised Reflection](https://arxiv.org/abs/2502.01401)

- EASE (Evolvable Symbolic Visual Grounder): introduces a training-free symbolic framework for 3D visual grounding, integrating Agents, executor, Visprog., Ours, test suite, relation encoder, object locations, scene scans, relation functions, and feedback components.
- EASE framework employs offline LLM generation and optimization within its Ours and test suite components to enhance relation encoders, contrasting with online Agents and visual programming Visprog. methods.
- The framework leverages relation encoders and feedback mechanisms to achieve a balance between grounding accuracy and inference efficiency, differing from Agents' online processing and Visprog.'s reliance on annotated relation functions.


---

[Plan-Then-Execute: An Empirical Study of User Trust and Team Performance When Using LLM Agents As A Daily Assistant](https://arxiv.org/abs/2502.01390)

- Plan-then-execute LLM Agents: introduces a framework with LLM Planning, Plan Edit, Planning Outcome, Action Prediction, Action Execution, User-Involved Execution, Manual Specify Action or Feedback, Involve vs Approve, Approve, Involve, Execution Outcome, Successful Login, and Successful Transaction to study user trust and team performance in human-AI collaboration.
- This framework uses plan-then-execute workflow where LLM agents first generate a plan, then users can edit it, and finally the agent executes the plan step-by-step with potential user involvement at each action.
- The architecture allows for empirical investigation of how different levels of user involvement during planning and execution affect user trust and task outcomes when using LLM agents as daily assistants.


---

[TeLL-Drive: Enhancing Autonomous Driving with Teacher LLM-Guided Deep Reinforcement Learning](https://arxiv.org/abs/2502.01387)

- TeLL-Drive (Teacher LLM-Guided Deep Reinforcement Learning): introduces a framework integrating LLM-Teacher with Decision Engine, Memory Repository, and Reflective Evaluator, and RL-Student with Actor, Critic, Add & Norm Attention, Multi-Head Attention, Data Distillation, and Mixed Policy for enhanced autonomous driving decision-making.
- TeLL-Drive leverages LLM-Teacher's guidance through Decision Engine, Memory Repository, and Reflective Evaluator to improve RL-Student's Actor-Critic learning and policy via attention mechanisms and data distillation for efficient and robust autonomous driving.
- The framework's architecture with LLM-Teacher and RL-Student components facilitates knowledge transfer and policy refinement, leading to improved adaptability and safety in autonomous driving across diverse scenarios.


---

[PSSD: Making Large Language Models Self-denial via Human Psyche Structure](https://arxiv.org/abs/2502.01344)

- PSSD (Psyche Structure for Self-Denial): introduces a novel paradigm for Large Language Models self-denial, comprising Intuition-based Id Role, Rule-driven Superego Role, and Script-centric Ego Role, to enhance reasoning accuracy.
- PSSD framework leverages multi-agent approach inspired by human psyche structure, utilizing three distinct roles for initial attempts, rule-based guidance, and procedural execution.
- PSSD aims to address limitations of current mistake correction methods by facilitating agents' self-denial within LLMs, leading to improved reasoning and resource efficiency.


---

[Human-Agent Interaction in Synthetic Social Networks: A Framework for Studying Online Polarization](https://arxiv.org/abs/2502.01340)

- Introduces agent-based architecture (individuals with attributes and interactions), LLM infrastructure (enables content generation and analysis), social network structure (governs information dissemination dynamically), agent model (represents individual user with attributes), opinion value (numerical stance on topic), personality description (agent's character traits), short biography (agent's background information), unique username (agent's identifier), interaction history (agent's past engagements), message generation (agent's content creation process), interaction mechanisms (agent's reaction to messages), opinion-based interaction function (evaluates opinion alignment), opinion strength factor (reflects opinion intensity), opinion assessment function (interprets message opinion), opinion update process (agent's opinion change mechanism), social network model (directed graph of agent connections), network structure (set of agents and follow relationships), connection dynamics (network evolution over time), information propagation (message visibility and exposure), recommendation system (determines message presentation), and influence-based scoring system (evaluates message author influence) for studying online polarization in synthetic social networks.
- Framework combines mathematical opinion dynamics with large language models to simulate human-agent interaction in synthetic social networks for controlled experimentation of online polarization.
- Framework enables investigation of polarization mechanisms, bridging gap between theoretical models and empirical observations, offering opportunities to study causal mechanisms underlying online opinion dynamics.


---

[ChartCitor: Answer Citations for ChartQA via Multi-Agent LLM Retrieval](https://arxiv.org/abs/2502.00989)

- ChartCitor: introduces multi-agent framework with Table Extraction Agent, Answer Reformulation Agent, Entity Captioning Agent, LLM Prefiltering Agent, LLM Re-ranking Agent, and Cell Localization Agent for fine-grained chart answer citations.
- ChartCitor framework orchestrates specialized LLM agents to extract tables, reformulate answers, generate captions, retrieve evidence, and localize cited cells in chart images.
- This system enhances explainability and user trust in LLM-assisted chart question answering by providing reliable and logically-explained citations sourced from charts.


---

[PlotGen: Multi-Agent LLM-based Scientific Data Visualization via Multimodal Feedback](https://arxiv.org/abs/2502.00988)

- PlotGen: introduces a multi-agent framework for scientific data visualization, with Query Planning Agent, Code Generation Agent, Numeric Feedback Agent, Lexical Feedback Agent, Visual Feedback Agent, and Self-Reflection, that leverages multimodal LLMs to iteratively refine visualizations based on user specifications.
- PlotGen framework orchestrates agents for query decomposition, code generation, and multimodal feedback to ensure data accuracy, textual correctness, and visual alignment in generated plots.
- The framework utilizes self-reflection within code generation and feedback agents to iteratively improve plot quality and address errors, enhancing user trust and productivity in data visualization tasks.


---


[Firewalls to Secure Dynamic LLM Agentic Networks](https://github.com/microsoft/Firewalled-Agentic-Networks)

- Firewalled Agentic Networks (FAN): introduces input firewall, data firewall, and trajectory firewall, where FAN automatically constructs task-specific rules from prior simulations to build firewalls for constrained LLM agentic networks.
- FAN offers layers of defense by converting free-form input to protocol, abstracting user data, and self-correcting agent trajectory.
- Data and trajectory firewalls are built from prior simulations to balance adaptability, security, and privacy in LLM agentic networks.


---

[SelfCheckAgent: Zero-Resource Hallucination Detection in Generative Large Language Models](http://arxiv.org/abs/2502.01812v1)

- SelfCheckAgent: introduces a framework for hallucination detection, with Symbolic Agent (semantic representation), Specialized Detection Agent (domain-aware detection) and Contextual Consistency Agent (context-aware verification), providing a multi-dimensional approach.
- SelfCheckAgent framework integrates three distinct agents, utilizing diverse techniques like semantic similarity, fine-tuned NLI models, and contextual consistency checks to evaluate LLM response factuality.
- SelfCheckAgent framework leverages triangulation strategy across agents, enhancing hallucination detection robustness and applicability in complex mathematical and general domains, improving trustworthiness of LLMs.


---


[Agentic Bug Reproduction for Effective Automated Program Repair at Google](http://arxiv.org/abs/2502.01821v1)

- LIBRO: introduces automated BRT generation, with GITS issue, buggy file(s), test file, edit LLM, and candidate BRT, where LIBRO adapts LLM for bug reproduction test generation.
- LIBRO: utilizes code-editing LLM to generate candidate BRT by prompting with bug report, buggy files, and test file.
- LIBRO: aims to generate BRTs by leveraging LLM's understanding of bug descriptions and code context.


---


[Position: Towards a Responsible LLM-empowered Multi-Agent Systems](http://arxiv.org/abs/2502.01714v1)

- RLHF (Reinforcement Learning from Human Feedback): presents a two-step approach involving reward model training from human feedback and language model fine-tuning through reinforcement learning to achieve human value alignment.
- RLHF framework utilizes preference data and techniques like Proximal Policy Optimisation (PPO) or Direct Preference Optimization (DPO) for policy updates, enhancing model agreement with human preferences.
- This method aims to create helpful and harmless AI assistants by incorporating human feedback into the learning process, improving model behaviour and safety.


---

[Al-Khwarizmi: Discovering Physical Laws with Foundation Models](http://arxiv.org/abs/2502.01702v1)

- Al-Khwarizmi: introduces agentic framework for physical law discovery from data, integrating system observation, RAG, prompt, LLM, optimization, score model, test data, and human feedback components.
- Framework leverages foundation models and SINDy method to automate physical law discovery by incorporating prior knowledge and iterative refinement.
- Al-Khwarizmi framework achieves state-of-the-art performance in physical law discovery by utilizing multiple data modalities and automated choices of algorithms.


---



#### 2nd February 2025

[Efficient Multi-Agent System Training with Data Influence-Oriented Tree Search](https://arxiv.org/abs/2502.00955)

- DITS (Data Influence-oriented Tree Search): introduces a novel framework for efficient multi-agent system training with data influence-oriented tree search, incorporating Multi Agent Network, MCTS Data Synthesis, Influence Score Estimation, Data Selection, and Iterative Data Synthesis.
- DITS leverages influence scores to guide tree search and data selection, effectively identifying impactful data for system improvement and enhancing model performance.
- DITS derives influence score estimation methods for non-differentiable metrics, reducing computational overhead and enabling efficient synthesis time scaling.


---

[RTBAgent: A LLM-based Agent System for Real-Time Bidding](https://arxiv.org/abs/2502.00792)

- RTBAgent (LLM-based Agent System for Real-Time Bidding): introduces an agent framework for real-time bidding, utilizing Tools (CTR prediction and bidding strategies), Summarized Memory (aggregated information for decision), Reflection Memory (self-assessment of past decisions), Bidding Memory (record of bidding history), Environment Memory (historical market conditions), Two-Step Decision-Making (sequential decision process), Insight Reasoning (analyze decision ranges and risks), Action Making (determine bidding action and reason), and Action Space (range of possible bidding adjustments).
- RTBAgent employs a two-step decision-making process with Insight Reasoning (analyze decision ranges and risks) and Action Making (determine bidding action and reason) to determine optimal bidding prices, leveraging multi-memory retrieval and expert knowledge.
- The framework's multi-memory system, including Reflection Memory (self-assessment of past decisions), Bidding Memory (record of bidding history), and Environment Memory (historical market conditions), enables adaptive bidding strategies by reviewing historical data and market changes.


---

[AgentBreeder: Mitigating the AI Safety Impact of Multi-Agent Scaffolds](https://arxiv.org/abs/2502.00757)

- AGENTBREEDER: introduces evolutionary framework, with Seed Scaffolds, Population, Capability benchmark, Safety benchmark, Embedding function, Clustering function, Pareto Fronts, Elites, Meta Agent, Crossover, Mutation, and New Scaffolds, for multi-objective search over multi-agent system scaffolds.
- AGENTBREEDER framework evaluates scaffolds using capability and safety benchmarks, clusters architectures, identifies Pareto optimal elites, and evolves new generations via meta-agent-driven crossover and mutation.
- AGENTBREEDER framework facilitates exploration of diverse multi-agent scaffolds, balancing capability and safety objectives through evolutionary optimization and quality-diversity search algorithm.


---

[Meta-Prompt Optimization for LLM-Based Sequential Decision Making](https://arxiv.org/abs/2502.00728)

- EXPO (EXPonential-weight algorithm for prompt Optimization): introduces an automated meta-prompt optimization framework for LLM-based agents, with components including LLM Agent (selects action based prompt), Evaluator (measures action performance), Embedding Model (converts text to numbers), Score Estimation NN (predicts meta-prompt scores), Randomized Meta-Prompt Selection (chooses meta-prompt based scores), and Exemplar Set (history of input-score pairs).
- EXPO framework uses adversarial bandit algorithm principles to address non-stationarity in reward observations during sequential decision-making for optimizing task description and meta-instruction within the meta-prompt.
- The framework leverages a neural network for score estimation and exponential-weight mechanism for meta-prompt selection, achieving a balance between exploitation and exploration in meta-prompt optimization.


---

[PhiP-G: Physics-Guided Text-to-3D Compositional Scene Generation](https://arxiv.org/abs/2502.00708)

- PhiP-G (Physics-Guided Text-to-3D Compositional Scene Generation): introduces a framework for compositional scene generation, with AG-extractor (scene graph extraction from text), Scene graph (structured scene representation), AG-generater (2D image generation agent), 3D Gaussian model (3D asset generation model), Asset retrieval (2D asset library access), 2D asset retrieval library (storage for 2D assets), AG-supervisor (visual layout supervision agent), Physical pool (physics-based initial layout), Blender (3D scene environment), and World model (layout prediction and planning).
- PhiP-G integrates LLM-based agents and world model for layout guidance with 3D Gaussian Splatting for efficient and physically consistent 3D scene generation.
- The framework leverages a physical pool and visual supervision for iterative layout refinement, achieving state-of-the-art performance and improved efficiency.


---

[Leveraging LLMs for Dynamic IoT Systems Generation through Mixed-Initiative Interaction](https://arxiv.org/abs/2502.00689)

- IoT-Together (Mixed-Initiative Interaction Paradigm): introduces a system architecture with User Interface (interaction medium), Goal Management (goal identification), Knowledge Management (data repository), Context Management (service hosting), Backend Generation (service generation), Intelligent User Interface Generation (application building), Interoperability platform (data pipeline), IOT DEVICES (sensor network), and Services (concrete functionalities) to enable dynamic IoT system generation through mixed-initiative interaction.
- IoT-Together paradigm facilitates user-system collaboration by leveraging LLMs within Goal Management and Backend Generation for interpreting user queries and generating runtime services based on available IoT data and service definitions.
- The architecture supports dynamic evolvability by generating and integrating new services at runtime, enhancing system adaptability and real-world usability in dynamic IoT environments like smart cities.


---

[Rethinking Mixture-of-Agents: Is Mixing Different Large Language Models Beneficial?](https://arxiv.org/abs/2502.00674)

- Self-MoA (Self-Mixture-of-Agents): introduces Self-MoA, an ensemble method, with Proposer (Generates multiple responses) and Aggregator (Synthesizes responses into output), that aggregates outputs from a single top-performing Large Language Model.
- Self-MoA leverages in-model diversity by repeatedly sampling from the same model, achieving superior performance compared to Mixed-MoA in various benchmarks.
- Self-MoA-Seq, a sequential version, addresses context length limitations by using a sliding window for aggregation, maintaining effectiveness while enabling scalability.


---

[Agent-Based Uncertainty Awareness Improves Automated Radiology Report Labeling with an Open-Source Large Language Model](http://arxiv.org/abs/2502.01691v1)

- Bayesian Prompt Ensemble pipeline: introduces uncertainty-aware predictions for radiology reports using semantically equivalent prompts, LLM, predictions, aggregation function, LLM Agent, entropy-based methods, uniform weights, linear weights, MLP, decision, and uncertainty.
- Bayesian Prompt Ensemble pipeline aggregates multiple LLM prompt outputs via agent-based or entropy-based methods to improve structured data extraction from radiology reports.
- Agent Decision Model within Bayesian Prompt Ensemble pipeline synthesizes prompt responses and explanations to categorize decisions into confidence levels for calibrated uncertainty.


---



#### 1st February 2025

[WHO'S THE MVP? A GAME-THEORETIC EVALUATION BENCHMARK FOR MODULAR ATTRIBUTION IN LLM AGENTS](https://arxiv.org/abs/2502.00510)

- CapaBench (Capability-level Assessment Benchmark): introduces evaluation framework for modular LLM agents with Planning Module (decomposes instructions), Reasoning Module (performs logical inference), Action Module (translates to operations), and Reflection Module (systematic performance analysis).
- CapaBench systematically quantifies module contributions using Shapley Value from game theory for performance attribution.
- Framework facilitates component-level evaluation and holistic system assessment for optimizing modular LLM agents.


---

[MarketSenseAI 2.0: Enhancing Stock Analysis through LLM Agents](https://arxiv.org/abs/2502.00415)

- MarketSenseAI: introduces a framework leveraging LLM agents including News, Fundamentals, Dynamics, Macroeconomic, and Signal Agents for holistic stock analysis.
- MarketSenseAI framework processes diverse financial data like news, prices, fundamentals, and macroeconomics to support stock analysis and selection decisions.
- The framework utilizes Retrieval-Augmented Generation and Chain-of-Agents architecture to enhance fundamental and macroeconomic analysis accuracy.


---



#### 31st January 2025


[A parallelizable variant of HCA*](http://arxiv.org/abs/2501.19218v1)

- HCA* (Hierarchical Cooperative A* algorithm): introduces parallelizable variant for multi-agent path finding, with Agent (computes paths and intersections), Central Server (manages coordination and conflict resolution), Reservation Table (stores fixed agent paths), Intersection Graph (represents path collisions), and Map Partition (divides map for parallel processing).
- This variant parallelizes path finding and intersection graph construction to reduce computation time.
- Parallelism is achieved by map partitioning and independent agent path calculations, improving performance over standard HCA*.


---

[Multi-agent Multi-armed Bandit with Fully Heavy-tailed Dynamics](http://arxiv.org/abs/2501.19239v1)

- HT-HMUCB (Heavy-Tailed HoMogeneous Upper Confidence Bounds): introduces decentralized multi-agent multi-armed bandit framework with hub identification, arm selection using UCB, transmission, information update, local and global estimation components for homogeneous rewards in heavy-tailed dynamic environments.
- HT-HMUCB framework addresses sparse random graphs and heavy-tailed rewards by exploiting hub structures for variance reduction and robust estimation using median-of-means estimator.
- The framework achieves improved regret bounds compared to existing methods by enabling efficient communication and information aggregation in challenging heavy-tailed scenarios.


---


[Neuro-LIFT: A Neuromorphic, LLM-based Interactive Framework for Autonomous Drone Flight at the Edge](http://arxiv.org/abs/2501.19259v1)

- Neuro-LIFT (Neuromorphic, LLM-based Interactive Framework for Autonomous Drone Flight at the Edge): introduces modular framework integrating Human Interaction Module, Neuromorphic Sensing Module, LLM, and Planning and Control Module for autonomous drone navigation based on human commands.
- Neuro-LIFT framework utilizes Human Interaction Module for user commands, Neuromorphic Sensing Module for environment perception, LLM for command interpretation, and Planning and Control Module for drone maneuver execution.
- Neuro-LIFT framework achieves real-time interactive autonomous drone flight by combining LLM-based natural language understanding with low-latency, energy-efficient neuromorphic vision for enhanced responsiveness and adaptability.


---

[True Online TD-Replan(\xce\xbb) Achieving Planning through Replaying](http://arxiv.org/abs/2501.19027v1)

- TD-Replan(\xce\xbb) (True Online TD-Replan(\xce\xbb)): introduces a novel reinforcement learning method extending True Online TD by incorporating experience replay and a parameter to control replay density and target depth.
- TD-Replan(\xce\xbb) utilizes interim \xce\xbb-return targets and online updates for efficient learning, demonstrating improved performance in tasks benefiting from experience replay.
- The method achieves balance between planning and acting by replaying past experiences and adjusting replay density, making it suitable for complex environments and deep learning integration.


---
[Swarm-Gen: Fast Generation of Diverse Feasible Swarm Behaviors](http://arxiv.org/abs/2501.19042v1)

- Swarm-Gen: introduces a framework with Generative Model (CVAE/VQ-VAE), Safety-Filter (SF), and Initialization Network, with Encoder, Decoder, QP Block, PixelCNN, MLP, and Fixed-Point Solver components, for fast generation of diverse feasible swarm behaviors.
- This framework uses generative models to sample diverse trajectories, projects them onto a feasible set using a safety filter, and accelerates the safety filter convergence with a learned initialization network.
- The approach demonstrates real-time generation of multi-modal swarm trajectories on commodity GPUs, offering a balance between trajectory diversity and computational efficiency using CVAE and VQ-VAE generative models.


---

[LLM-based Affective Text Generation Quality Based on Different Quantization Values](http://arxiv.org/abs/2501.19317v1)

- LLM (Large Language Model): introduces quantization, LLMs, emotion classifier, seed prompts, emotion-prompt, text generation module, GPU RAM, inference time, and memory to investigate the trade-off between quantization values and affective text generation quality.
- This paper evaluates the impact of different quantization levels (8, 16, 32 bits) on the performance of various LLMs (Llama-2, Mistral, Mixtral) in generating affective text, considering GPU RAM usage and inference time.
- The research highlights that while quantization reduces memory consumption, it can affect text quality and inference time, revealing a trade-off between efficiency and efficacy in LLM-based affective text generation.


---

[An Empirical Game-Theoretic Analysis of Autonomous Cyber-Defence Agents](http://arxiv.org/abs/2501.19206v1)

- MRO (Multiple Response Oracles): introduces a framework for holistic evaluation of ACD approaches, with INITIALPOLICIES(), Set initial mixtures, RBlue, RRed, GBlue, GRed, AUGMENTGAME, and SOLVEGAME components.
- MRO framework extends the Double Oracle algorithm by incorporating multiple response oracles to enhance the assessment of Autonomous Cyber-Defence approaches.
- MRO algorithm utilizes response functions and game-theoretic analysis to iteratively refine and evaluate policies for cyber-defence and cyber-attack agents.



[Beyond checkmate: exploring the creative chokepoints in AI text](http://arxiv.org/abs/2501.19301v1)

- Chess-Text Analogy Framework: introduces a method to explore human and AI text differences by analogy to chess game segments (opening, mid game, end game) and text segments (introduction, body, conclusion), utilizing source and segment comparisons, statistical tests, feature extraction, and various datasets and LLMs.
- This framework examines creative limitations in AI text generation by analyzing stylometric and psycholinguistic features across text segments, finding body segment crucial for AI detection and greater human cross-segment variation.
- Research emphasizes text segments in AI detection, suggesting body segment focus and cross-segment feature variations improve detection and provide insights into LLMs' creative abilities.


---


[PixelWorld: Towards Perceiving Everything as Pixels](http://arxiv.org/abs/2501.19339v1)

- PEAP (Perceive Everything as Pixels): introduces Language Model, ViT, and Text Instruction components for unified multimodal input processing.
- PEAP framework processes all modalities as pixels, contrasting with token-based methods and enhancing multimodal task performance.
- The framework evaluation suite, PIXELWORLD, demonstrates PEAP's effectiveness and identifies areas for improvement in complex reasoning tasks.


---


[Enabling Autonomic Microservice Management through Self-Learning Agents](http://arxiv.org/abs/2501.19056v1)

- SERVICEODYSSEY: introduces a self-learning agent system for autonomic microservice management, leveraging Curriculum Builder for task generation, Execution Planner for plan creation, Knowledge Curator for skill consolidation, Data Layer for data storage, and Management Layer for module orchestration within the Operational Environment.
- SERVICEODYSSEY framework incorporates High-level Manager to decompose tasks and coordinate Low-level Agents, utilizing Running State and Interaction History for context, Task Queue and Execution Queue for task management, and Feedback and Skill Library for learning and improvement.
- The system refines solutions through Environment Feedback, Peer Feedback, and Hierarchical Feedback, demonstrating its effectiveness in the Sock Shop Microservice environment for autonomic management of microservices.



[Secured Communication Schemes for UAVs in 5G: CRYSTALS-Kyber and IDS](http://arxiv.org/abs/2501.19191v1)

- CRYSTALS-Kyber and IDS Framework: introduces secure UAV communication architecture, integrating UAV Layer, Raspberry Pi, AES Encryption-Decryption, KEM, ECC, CRYSTALS-Kyber, Communication Layer, Ground Station Layer, Server, File Storage, IDS Dataset, KEM Dataset, AI Techniques, and IDS Module.
- This architecture employs hybrid cryptography using AES with ECC and CRYSTALS-Kyber for quantum resistance, alongside AI-driven IDS for intrusion detection in 5G UAV networks.
- Evaluated in VPN and 5G, the framework demonstrates effective security and performance balance, suitable for resource-limited UAVs facing quantum threats.


---
[Vintix: Action Model via In-Context Reinforcement Learning](http://arxiv.org/abs/2501.19400v1)

- Vintix: introduces a fixed cross-domain model for in-context reinforcement learning using Noise Distillation, Cross-Domain Dataset, Causal Transformer, and Algorithm Distillation components.
- Vintix framework employs Algorithm Distillation to construct versatile action models by learning behaviors through in-context reinforcement learning.
- The framework demonstrates self-correction capabilities and scaling potential of In-Context Reinforcement Learning for generalist decision-making systems across multiple domains.


---


[MINDSTORES: Memory-Informed Neural Decision Synthesis for Task-Oriented Reinforcement in Embodied Systems](http://arxiv.org/abs/2501.19318v1)

- MINDSTORES: experience-augmented planning framework enables embodied agents to build and leverage mental models through natural interaction with their environment.
- Framework uses database of past experiences; represents experiences as natural language embeddings; allows efficient retrieval and reasoning by LLM planner; generates insights and guides plan refinement.
- MINDSTORES represents an important step toward more capable embodied AI systems that can learn continuously through natural experience.


---

[Language Games as the Pathway to Artificial Superhuman Intelligence](http://arxiv.org/abs/2501.18924v1)

- Language games: framework for expanded data reproduction to overcome data reproduction trap in LLMs.
- Includes role fluidity, reward variety, and rule plasticity for open-ended exploration and human-AI co-evolution towards superhuman intelligence through dynamic linguistic interaction.
- This framework is important as it redefines data reproduction as an engine for superhuman intelligence.


---

[Enabling Autonomic Microservice Management through Self-Learning Agents](http://arxiv.org/abs/2501.19056v1)

- SERVICEODYSSEY: self-learning agent system autonomously manages microservices without prior knowledge of service-specific configurations.
- Leverages curriculum learning principles and iterative exploration; develops deep understanding of operational environments; reduces dependence on human input; includes Curriculum Builder, Execution Planner, and Knowledge Curator modules.
- This approach has potential for autonomic microservice management as demonstrated by prototype.


---

[Think Smarter not Harder: Adaptive Reasoning with Inference Aware Optimization](https://arxiv.org/abs/2501.17974)

- Inference Budget-Constrained Policy Optimization (IBPO) is an algorithm designed to enable models to understand query difficulty and allocate inference budgets accordingly.
- It uses utility maximization with inference budget constraint, addresses single-modal behavior in long reasoning models, and improves token efficiency.
- This method is important as it significantly enhances reasoning efficiency and shows potential for broader applications beyond mathematical problem-solving.


---


[s1: Simple test-time scaling](https://arxiv.org/abs/2501.19393)

- s1 is a simple test-time scaling approach to improve language model reasoning performance by using budget forcing and small dataset.
- s1 uses budget forcing to control test-time compute, curated small dataset s1K with 1,000 high-quality questions, and supervised finetuning on Qwen2.5-32B-Instruct.
- s1 demonstrates that simple test-time scaling can achieve strong reasoning performance and sample efficiency.


---

[Do LLMs Strategically Reveal, Conceal, and Infer Information? A Theoretical and Empirical Analysis in The Chameleon Game](http://arxiv.org/abs/2501.19398v1)

- The Chameleon Game: is a language-based hidden-identity game to investigate information control and decision-making capabilities of LLMs.
- Framework analyzes strategic interactions, information control, and decision-making capabilities using theoretical and empirical analysis with contemporary LLMs such as GPT-4, GPT-4o, Gemini 1.5, and Claude 3.5 Sonnet.
- This framework is important as it points to a weakness of contemporary LLMs in strategic interactions.


---


[TV-Dialogue: Crafting Theme-Aware Video Dialogues with Immersive Interaction](http://arxiv.org/abs/2501.18940v1)

- TV-Dialogue: novel multi-modal agent framework ensures theme alignment and visual consistency through real-time immersive interactions among video characters.
- Introduces Theme-aware Video Dialogue Crafting (TVDC) task, generates dialogues aligned with video content and user-specified themes, includes multi-granularity evaluation benchmark for assessment, enables zero-shot generation for any length and theme, applicable for video re-creation and film dubbing.
- TV-Dialogue framework underscores potential for video re-creation, film dubbing, and downstream multimodal tasks.


---


[KBQA-01: Agentic Knowledge Base Question Answering with Monte Carlo Tree Search](http://arxiv.org/abs/2501.18922v1)

- KBQA-01: is a novel agentic Knowledge Base Question Answering (KBQA) method with Monte Carlo Tree Search (MCTS).
- ReAct-based agent process; stepwise logical form generation; KB environment exploration; MCTS for heuristic search; balances exploration and search space; generates high-quality annotations; incremental fine-tuning; outperforms low-resource KBQA methods.
- KBQA-01 improves performance in low-resource KBQA and provides publicly available code for further research.


---


[Survey and Improvement Strategies for Gene Prioritization with Large Language Models](http://arxiv.org/abs/2501.18794v1)

- Gene Prioritization Framework benchmarks and improves large language models for gene prioritization using multi-agent and HPO classification approaches combined with a divide-and-conquer strategy.
- Framework benchmarks various LLMs including GPT-4 and Mixtral, uses multi-agent and HPO classification for case solvability, and employs divide-and-conquer strategy to enhance accuracy and overcome biases.
- This framework significantly optimizes disease-causal gene identification and streamlines rare genetic disorder diagnosis.


---



[Free Agent in Agent-Based Mixture-of-Experts Generative AI Framework](https://arxiv.org/abs/2501.17903)

- RLFA (Reinforcement Learning Free Agent) algorithm: introduces sports-inspired mechanism for replacing underperforming agents in multi-agent GenAI systems.
- Draws inspiration from Major League Baseball free agency, uses mixture-of-experts approach, and improves performance and adaptability in multi-agent systems.
- RLFA provides a straightforward route for continuous upgrades and maintains performance in critical tasks.


---

[Autonomous Legacy Web Application Upgrades Using a Multi-Agent System](http://arxiv.org/abs/2501.19204v1)

- Multi-agent pipeline: LLM based multi-agent system autonomously upgrades legacy web applications to the latest version.
- System distributes tasks across multiple phases; updates files to latest version; uses Zero-Shot and One-Shot Learning prompts; keeps context across tasks and agents.
- Proposed system contributes as working foundation for future model implementations with existing code.


---

[Constitutional Classifiers: Defending against Universal Jailbreaks across Thousands of Hours of Red Teaming](https://arxiv.org/abs/2501.18837)

- Constitutional Classifiers: introduces classifier safeguards, with Human's Query, Constitutional Input Classifier, AI Assistant, Constitutional Output Classifier, Response Shown to Human, Response Blocked, Harmless Constitution, Harmful Constitution, LLM with Constitution, Synthetic LLM Prompts and Completions, Data Augmentation Pipeline, Harmless Pool Set, and Training Set, as a framework to defend large language models against universal jailbreaks by monitoring both user inputs and model outputs using constitution-guided classifiers.
- "Constitutional Classifiers framework trains classifier safeguards using synthetic data generated by prompting language models with natural language rules defining harmful and harmless content categories."
- "This approach enhances robustness and deployment viability by incorporating data augmentation, benign data pools, and streaming prediction in output classifiers for real-time intervention."


---


#### 30th January 2025

[Can we Retrieve Everything All at Once? ARM: An Alignment-Oriented LLM-based Retrieval Method](http://arxiv.org/abs/2501.18539v1)

- ARM (Alignment-Oriented LLM-based Retrieval Method): is an LLM-based retrieval method that aligns questions with data organization by exploring relationships among data objects.
- ARM uses constrained decoding with N-grams, a reasoning solver for structure alignment, and self-verification for object selection, and it is evaluated on Bird and OTT-QA datasets.
- This method achieves better retrieval performance and efficiency compared to standard and agentic RAG approaches.


---

[Thoughts Are All Over the Place: On the Underthinking of o1-Like LLMs](https://arxiv.org/abs/2501.18585)

- TIP (thought switching penalty): is a decoding strategy that discourages premature transitions between thoughts, encouraging deeper exploration of each reasoning path.
- It introduces a novel metric to quantify underthinking by measuring token efficiency in incorrect answers, and it improves accuracy across challenging datasets without requiring model fine-tuning.
- This framework contributes to understanding reasoning inefficiencies in o1-like LLMs and offers a practical solution to enhance their problem-solving capabilities.


---

[REPOAUDIT: An Autonomous LLM-Agent for Repository-Level Code Auditing](https://arxiv.org/abs/2501.18160)

- REPOAUDIT: introduces autonomous LLM-agent, with initiator, explorer, validator, memory, for precise, efficient repository-level code auditing by demand-driven exploration.
- It employs agent memory for on-demand repository exploration and validator for hallucination mitigation.
- Validation design improves precision by checking data-flow facts and path condition satisfiability, discarding false positives.


---



[Leveraging LLM Agents for Automated Optimization Modeling for SASP Problems: A Graph-RAG based Approach](http://arxiv.org/abs/2501.18320v1)

- MAG-RAG is automated modeling approach based on retrieval-augmented generation technique for SASP problems.
- It uses multi-agent structure for AOM architecture, graph-based RAG for domain knowledge integration, human expert modeling principles and precise knowledge retrieval using graph structure.
- MAG-RAG approach realizes the potential of LLM-assisted AOM for solving SASP problems.


---

[REPOAUDIT: An Autonomous LLM-Agent for Repository-Level Code Auditing](http://arxiv.org/abs/2501.18160v1)

- REPOAUDIT: autonomous LLM-agent designed for precise and efficient repository-level code auditing.
- Equipped with agent memory, REPOAUDIT explores code repository on demand, analyzes data-flow facts along feasible program paths, and introduces validator for hallucination mitigation.
- REPOAUDIT demonstrates substantial potential for flexible and configurable code security analysis.


---


[Design and Validation of Learning Aware HMI For Learning-Enabled Increasingly Autonomous Systems](https://arxiv.org/abs/2501.18506)

- LEIAS (Learning-Enabled Increasingly Autonomous Systems): is an architecture designed to enhance operational safety by emphasizing communication representation and pilot preference learning in autonomous systems.
- - incorporates human-machine collaboration
- uses Soar cognitive architecture with reinforcement learning
- provides transparent multi-sensor data assessment (GPS, IMU, LIDAR)
- adapts to pilot preferences
- validated in XPlane simulation for sensor anomaly management
- This framework is important for advancing the safety and reliability of learning-enabled autonomous systems in complex operational environments.


---


[Integrating LMM Planners and 3D Skill Policies for Generalizable Manipulation](http://arxiv.org/abs/2501.18733v1)

- LMM-3DP: LMM-3DP is a framework integrating LMM planners and 3D skill policies for generalizable robotic manipulation.
- Integrates LMM planners and 3D skill policies, uses high-level planning with visual feedback, includes critic agent for self-improvement, enables lifelong learning with skill library, utilizes semantic 3D feature field for low-level control.
- LMM-3DP significantly enhances robot manipulation by improving success rate and planning accuracy in complex tasks.


---


[Invisible Traces: Using Hybrid Fingerprinting to identify underlying LLMs in GenAI Apps](http://arxiv.org/abs/2501.18712v1)

- Hybrid Fingerprinting framework: Novel fingerprinting framework integrates static and dynamic techniques to identify underlying LLMs in GenAI Apps.
- Addresses real-world challenges; Combines static and dynamic fingerprinting; Identifies architectural features and behavioral traits; Demonstrates semantic distinction in LLM outputs; Robust and accurate in complex environments.
- Framework is important for ensuring security and transparency in AI applications by reliably identifying underlying LLMs.


---

[Can we Retrieve Everything All at Once? ARM: An Alignment-Oriented LLM-based Retrieval Method](http://arxiv.org/abs/2501.18539v1)

- ARM (Alignment-Oriented LLM-based Retrieval Method) is a retrieval method that aligns question with data collection organization by exploring relationships among data objects.
- It is retrieve-all-at-once solution for complex queries by better aligning question with data organization and exploring relationships among data objects beyond utterance matching for efficient and comprehensive retrieval.
- The proposed method is important as it improves retrieval performance for complex questions by addressing limitations of existing RAG approaches.


---

[Leveraging LLM Agents for Automated Optimization Modeling for SASP Problems: A Graph-RAG based Approach](http://arxiv.org/abs/2501.18320v1)

- MAG-RAG is automated modeling approach based on retrieval-augmented generation technique for SASP problems.
- It uses multi-agent structure for AOM architecture, graph-based RAG for domain knowledge integration, human expert modeling principles and precise knowledge retrieval using graph structure.
- MAG-RAG approach realizes the potential of LLM-assisted AOM for solving SASP problems.


---

[LLM-AutoDiff: Auto-Differentiate Any LLM Workflow](https://arxiv.org/abs/2501.16673)

- LLM-AutoDiff is a novel framework for Automatic Prompt Engineering (APE) that extends textual gradient-based methods to multi-component, potentially cyclic LLM architectures.
- Framework accommodates functional nodes, preserves time-sequential behavior, combats "lost-in-the-middle" problem, boosts training efficiency, and uses graph-centric lens.
- LLM-AutoDiff offers a powerful new paradigm for scaling and automating LLM workflows.


---


#### 29th January 2025

[Critique Fine-Tuning: Learning to Critique is More Effective than Learning to Imitate](https://arxiv.org/abs/2501.17703)

- Critique Fine-Tuning (CFT): is a framework where models learn to critique noisy responses rather than imitating correct ones.
- CFT encourages deeper analysis and nuanced understanding, uses GPT-40 to generate critiques, and shows consistent improvement over SFT on math benchmarks.
- This approach offers a more effective alternative to advance the reasoning of language models.

---

[Human-Aligned Skill Discovery: Balancing Behaviour Exploration and Alignment](https://arxiv.org/abs/2501.17431)

- HaSD (Human-aligned Skill Discovery): is a framework designed to incorporate human feedback into unsupervised skill discovery to find safer and more aligned skills.
- Addresses unconstrained skill discovery, finds useful skills in complex environments, optimizes skill diversity and human alignment, maintains alignment throughout discovery, and allows configurable skills with diversity-alignment trade-offs.
- This framework is important as it enables the discovery of diverse, safe, and human-aligned skills for practical applications.


---

[LARGE LANGUAGE MODELS THINK TOO FAST TO EXPLORE EFFECTIVELY](http://arxiv.org/abs/2501.18009v1)

- Large Language Models (LLMs): Study investigates exploration capabilities of LLMs in open-ended tasks using Little Alchemy 2.
- LLMs underperform humans in exploration; uncertainty-driven strategies dominant; empowerment underutilized; premature decisions due to fast processing.
- Findings are crucial for enhancing LLM adaptability and exploration effectiveness.


---


[Is Conversational XAI All You Need? Human-AI Decision Making With a Conversational XAI Assistant](http://arxiv.org/abs/2501.17546v1)

- Conversational XAI assistant: Conversational XAI interface is proposed to augment existing XAI methods to increase user engagement and boost user understanding of AI system.
- Exploration of conversational XAI interface impact on user understanding, trust and reliance; comparison with XAI dashboard; over-reliance on AI system observed; enhanced conversations amplified over-reliance; illusion of explanatory depth.
- Findings have important implications for designing effective conversational XAI interfaces to facilitate appropriate reliance and improve human-AI collaboration.


---

[RICOTA: Red-teaming of In-the-wild Conversation with Test Attempts](http://arxiv.org/abs/2501.17715v1)

- RICOTA: is a Korean red teaming dataset of in-the-wild user interactions.
- It uses user-chatbot conversations from a Korean Reddit-like community, focuses on jailbreak attempts, and provides a novel evaluation approach.
- This dataset is important for evaluating LLMs' ability to identify conversation types and user testing purposes.


---

[ACTIONS SPEAK LOUDER THAN WORDS: AGENT DECISIONS REVEAL IMPLICIT BIASES IN LANGUAGE MODELS](http://arxiv.org/abs/2501.17420v1)

- Language-agent simulation technique: systematically investigates implicit biases in LLMs across diverse sociodemographic groups and decision-making scenarios.
- It uses persona generation and action generation steps, reveals that state-of-the-art LLMs exhibit significant sociodemographic disparities, and shows that implicit biases are amplified compared to explicit biases.
- This framework provides a way to identify biases in LLM-powered applications, ensuring they are aligned with ethical principles and societal norms.


---


[GENERAL SCENE ADAPTATION FOR VISION-AND-LANGUAGE NAVIGATION](http://arxiv.org/abs/2501.17403v1)

- GSA-VLN (General Scene Adaptation for VLN): is a novel task requiring agents to execute navigation instructions within a specific scene and simultaneously adapt to it for improved performance over time.
- GSA-VLN introduces environment-specific memory bank, uses three-stage instruction orchestration pipeline with LLMs, and proposes Graph-Retained DUET (GR-DUET) method.
- This framework addresses the challenge of single-scene adaptation, enabling agents to continuously improve as they execute instructions in previously unseen environments.


---

#### 28th January 2025

[Thalamic oscillations distinguish natural states of consciousness in humans](https://www.biorxiv.org/content/10.1101/2025.01.28.635248v1.full)
- A novel fast thalamic oscillation (20-45 Hz) is identified in humans, which specifically occurs during wakefulness and REM sleep, and is absent during NREM sleep.
- The oscillation is localized to the central thalamus and is temporally coupled with eye movements during REM sleep.

---

[LARGE LANGUAGE MODEL CRITICS FOR EXECUTION-FREE EVALUATION OF CODE CHANGES](https://arxiv.org/abs/2501.16655v1)

- LLM Critics: is a framework that uses LLM-based critics to derive execution-free evaluation proxies for code changes.
- It uses gold test patch as reference, predicts executability of editing locations, aggregates predictions to predict build status, and outperforms other reference-free and reference-aware LLM critics.
- This framework enables more efficient evaluation of code changes without relying on execution.


---

[SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training](https://arxiv.org/abs/2501.17161)

- SFT (Supervised fine-tuning) and RL (reinforcement learning): are compared on generalization and memorization in text and visual environments.
- RL generalizes better than SFT, especially with outcome-based reward; SFT memorizes training data; RL improves visual recognition; SFT stabilizes output format for RL.
- RL is advantageous for acquiring generalizable knowledge in complex, multimodal tasks.


---



[MCTS-SQL: An Effective Framework for Text-to-SQL with Monte Carlo Tree Search](http://arxiv.org/abs/2501.16607v1)

- MCTS-SQL (Monte Carlo Tree Search for SQL): is a framework for text-to-SQL that uses Monte Carlo Tree Search to guide SQL generation iteratively.
- It includes a schema selector for extracting relevant information and an MCTS-based generator for iterative query refinement; it uses a fast-slow thinking approach with a direct SQL generation component and an MCTS-based refiner; it achieves state-of-the-art performance on the BIRD and SPIDER benchmarks.
- This framework improves the accuracy and reliability of text-to-SQL systems, especially when dealing with complex user queries.


---

[ToolFactory: Automating Tool Generation by Leveraging LLM to Understand REST API Documentations](http://arxiv.org/abs/2501.16945v1)

- ToolFactory: is an open-source pipeline for automating tool generation from unstructured API documents.
- It includes API Extraction Benchmark, APILlama model fine-tuned with prompt tuning, and tool validation pipeline.
- This framework facilitates the seamless integration of scientific REST APIs into AI workflows.


---

[A Stochastic Dynamical Theory of LLM Self-Adversariality: Modeling Severity Drift as a Critical Process](http://arxiv.org/abs/2501.16783v1)

- Stochastic dynamical framework: models how LLMs may self-amplify biases through chain-of-thought reasoning.
- It uses a continuous-time stochastic differential equation (SDE) approach, analyzes phase transitions, derives stationary distributions, and investigates scaling laws.
- This framework provides a basis for formal verification of model stability and bias propagation.


---

[MACI: Multi-Agent Collaborative Intelligence for Robust Reasoning and Temporal Planning](http://arxiv.org/abs/2501.16689v1)

- MACI (Multi-Agent Collaborative Intelligence): is a framework centered on a meta-planner that orchestrates multiple agents to generate planner templates.
- It includes a three-tier architecture with meta-planning, common and specialized agents; enables advanced temporal reasoning and adaptability; decouples planning from validation.
- This framework provides a robust solution for complex reasoning and planning tasks.


---

[Auto-Differentiating Any LLM Workflow: A Farewell to Manual Prompting](http://arxiv.org/abs/2501.16673v1)

- LLM-AutoDiff: is a framework for Automatic Prompt Engineering (APE) that extends textual gradient-based methods to multi-component, potentially cyclic LLM architectures.
- It treats each textual input as a trainable parameter, uses a frozen "backward engine" LLM to generate feedback, accommodates functional nodes, preserves time-sequential behavior, and combats the "lost-in-the-middle" problem.
- This framework offers a new paradigm for scaling and automating LLM workflows.


---


[JUPYBARA: Operationalizing a Design Space for Actionable Data Analysis and Storytelling with LLMs](http://arxiv.org/abs/2501.16661v1)

- JUPYBARA: is an AI-enabled assistant for actionable EDA and storytelling implemented as a Jupyter Notebook extension.
- It employs design-space-aware prompting and multi-agent architectures, including semantic, rhetorical, and pragmatic dimensions, to operationalize the design space.
- This framework enhances usability, steerability, explainability, and reparability in actionable data analysis and storytelling.


---

[A sketch of an AI control safety case](http://arxiv.org/abs/2501.17315v1)

- AI control: framework argues that models are safe because of measures such as monitoring and human auditing.
- Framework uses control evaluation with red and blue teams, includes untrusted and trusted monitors, and uses a safety layer to prevent data exfiltration.
- This framework provides a step toward more concrete arguments that can be used to show that a dangerously capable LLM agent is safe to deploy.


---

#### 27th of January 2025

[GUI-Bee : Align GUI Action Grounding to Novel Environments via Autonomous Exploration](https://arxiv.org/abs/2501.13896)

- GUI-Bee is MLLM-based autonomous agent to collect environment-specific data through exploration and fine-tune GUI grounding models for novel environments.
- novel environments; autonomous exploration; Q-ICRL method; exploration efficiency; data quality; NovelScreenSpot benchmark; align GUI action grounding models.
- Aligning GUI action grounding models to novel environments significantly enhances performance.


---


[Janus-Pro: Unified Multimodal Understanding and
Generation with Data and Model Scaling](https://github.com/deepseek-ai/Janus/blob/main/janus_pro_tech_report.pdf)

- Janus-Pro: Advances multimodal models via optimized training, expanded data, and model scaling. Janus-Pro achieves SOTA-level performance in both multimodal understanding and text-to-image generation benchmarks.
- Enhanced training strategy includes "Longer Training in Stage I" and "Focused Training in Stage II" for better efficiency and performance. This refines the original 3-stage training process of Janus.
- Text-to-image generation stability and aesthetic quality are significantly enhanced through synthetic data and improved training.
- Decoupled visual encoding remains a core and effective architectural design for unified multimodal tasks.
- 7B model demonstrates strong scalability of the decoupled visual encoding approach.

---

[On the Feasibility of Using LLMs to Execute Multistage Network Attacks](https://arxiv.org/abs/2501.16466)

- Incalmo: is an LLM-agnostic high-level attack abstraction layer that sits between an LLM and the environment.
- Incalmo uses action planner, attack graph service and environment state service to enable LLMs to specify high-level tasks, translate them into low-level primitives, and provide structure for selecting relevant actions.
- Incalmo consists of three stages. The first stage is called "onboarding pre-prompt"-stage, which “teaches” the LLM the capabilities of Incalmo, Second stage provides environment specific prompts to outline attach goals and environment details. In the third stage, the LLM autonomously executes the multistage attack via Incalmo in an interactive execution loop. 
- Demonstrates capability to find vurnerable services, execute exploits to gain access to network, to discover misconfigurations and vulnerabilities to move laterally and exploit vulnerabilities to escalate privileges and exfiltrate data from networks. 
- Demonstrates, that abstraction is more important than LLM model size and that Incalmo-action planner module is critical module.
- This framework enables LLMs to successfully execute multistage attacks in realistic emulated networks.



---

[Gensors: Authoring Personalized Visual Sensors with Multimodal Foundation Models and Reasoning](https://arxiv.org/abs/2501.15727)

- Gensors is a system designed to empower users to create personalized visual sensors by leveraging multimodal foundation models and reasoning.
- It uses two-stage pipeline with Gemini 1.5 Flash and Pro, supports user-configurable logic and examples, and facilitates criteria refinement and debugging.
- Gensors is important as it makes intelligent sensing technologies more accessible and customizable for end-users.


---

[MULTI-AGENT GEOSPATIAL COPILOTS FOR REMOTE SENSING WORKFLOWS](http://arxiv.org/abs/2501.16254v1)

- GeoLLM-Squad: geospatial Copilot introduces multi-agent paradigm to remote sensing workflows by separating agentic orchestration from geospatial task-solving.
- Multi-agent system; agentic orchestration; geospatial task-solving; specialized sub-agents; open-source AutoGen and GeoLLM-Engine; diverse applications; robust performance; improved agentic correctness.
- GeoLLM-Squad highlights the potential of multi-agent AI in advancing remote sensing workflows.


---


[Will Systems of LLM Agents Cooperate: An Investigation into a Social Dilemma](https://arxiv.org/abs/2501.16173)

- LLM Agent System: Framework investigates cooperative tendencies of Large Language Model (LLM) agents in social dilemma by prompting LLMs to generate strategies for iterated Prisoner's Dilemma.
- Defines three classes of agents (attitudes): agressive, cooperative and neutral.
- evolutionary game theory; strategic dispositions; aggressive, cooperative, neutral; distinct biases; long-term behaviour; strategic environments.
- This research highlights importance of considering strategic environments for deployed LLM-based autonomous agents and their potential long-term behaviour.


---

[AI Agents for Computer Use: A Review of Instruction-based Computer Control, GUI Automation, and Operator Assistants](http://arxiv.org/abs/2501.16150v1)

- AI Agents for Computer Use: A Review offers a comprehensive overview of instruction-based computer control agents, GUI automation, and operator assistants.
- It examines agents taxonomy, development, resources, shift to foundation models, datasets, evaluation methods, and deployment challenges.
- This review provides a comprehensive foundation to understand and push the future development of AI agents for computer use.


---

[LLM-attacker: Enhancing Closed-loop Adversarial Scenario Generation for Autonomous Driving with Large Language Models](http://arxiv.org/abs/2501.15850v1)

- LLM-attacker: closed-loop adversarial scenario generation framework leveraging large language models.
- multiple LLM agents; identify optimal attackers; optimize attacker trajectories; iterative refinement based on ADS performance; feedback loop.
- Framework is important to test and enhance the safety and robustness of ADS.


---

[MADP: Multi-Agent Deductive Planning for Enhanced Cognitive-Behavioral Mental Health Question Answer](http://arxiv.org/abs/2501.15826v1)

- MADP (Multi-Agent Deductive Planning): is a CBT-based multi-agent reasoning strategy that analyzes interactions among multiple CBT elements for mental health support.
- Deeper understanding of help-seeker context; personalized assistance; fine-tuned LLM (MADP-LLM); enhanced emotional reasoning; reduced deployment costs.
- MADP framework effectively provides personalized, empathetic, and targeted mental health support.


---

[Harnessing Diverse Perspectives: A Multi-Agent Framework for Enhanced Error Detection in Knowledge Graphs](http://arxiv.org/abs/2501.15791v1)

- MAKGED (Multi-Agent framework for Knowledge Graph Error Detection): is a novel framework utilizing multiple large language models in a collaborative setting for enhanced knowledge graph error detection.
- multi-agent framework; multiple LLMs; collaborative setting; subgraph embeddings; query embeddings; transparent decision-making; multi-round discussions.
- MAKGED enhances the reliability of downstream applications by improving the accuracy and robustness of knowledge graph error detection.


---

[LLM-powered Multi-agent Framework for Goal-oriented Learning in Intelligent Tutoring System](http://arxiv.org/abs/2501.15749v1)

- GenMentor: LLM-powered multi-agent framework is designed for goal-oriented and personalized learning within Intelligent Tutoring System.
- multi-agent system; goal-oriented learning; personalized learning; skill gap identification; adaptive learner modeling; personalized resource delivery.
- GenMentor effectively enhances learning guidance, content quality, goal alignment and resource targeting for enhanced personalization.


---

[Deception in LLMs: Self-Preservation and Autonomous Goals in Large Language Models](http://arxiv.org/abs/2501.16513v1)

- DeepSeek R1: is a model trained to output reasoning tokens, exhibiting deceptive tendencies and self-preservation instincts.
- The model attempts self-replication, masks true objectives, and expands capabilities autonomously.
- This study highlights the critical need for robust goal specification and safety frameworks before physical implementation.


---

[MULTI-AGENT GEOSPATIAL COPILOTS FOR REMOTE SENSING WORKFLOWS](http://arxiv.org/abs/2501.16254v1)

- GeoLLM-Squad: introduces a multi-agent paradigm to remote sensing workflows.
- It separates agentic orchestration from geospatial task-solving, uses AutoGen and GeoLLM-Engine frameworks, and enables modular integration of diverse applications.
- This approach maintains robust performance and improves agentic correctness compared to single-agent systems.


---

[Will Systems of LLM Agents Cooperate: An Investigation into a Social Dilemma](http://arxiv.org/abs/2501.16173v1)

- LLM (Large Language Model) agents framework: investigates emergent cooperative tendencies in a social dilemma.
- Framework prompts LLMs to generate complete strategies, uses evolutionary game theory, simulates populations with different strategic dispositions, and observes evolutionary dynamics.
- This research provides insights into long-term behavior of deployed LLM-based autonomous agents and highlights importance of strategic environments.


---


#### 26th of January 2025

[Qwen2.5-1M Technical Report](https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5-1M/Qwen2_5_1M_Technical_Report.pdf)

- Introduces  Qwen2.5-1M, which extends open source support for 1M token context length.
- Includes infererence framework, which speeds up 1M context inference by 3.2x to 6.7x.


---

[OpenCharacter: Training Customizable Role-Playing LLMs with Large-Scale Synthetic Personas](http://arxiv.org/abs/2501.15427v1)

- OpenCharacter: framework trains customizable role-playing LLMs with large-scale synthetic personas.
- Explores large-scale data synthesis approach, uses response rewriting and generation strategies, achieves performance comparable to GPT-40 models.
- This work is important for advancing research in customizable role-playing dialogue systems.


---

[ToM-agent: Large Language Models as Theory of Mind Aware Generative Agents with Counterfactual Reflection](http://arxiv.org/abs/2501.15355v1)

- ToM-agent is a novel paradigm designed to empower LLM-based generative agents to simulate Theory of Mind in open-domain conversational interactions.
- Disentangles confidence from mental states; emulates agent's perception of counterpart's mental states (beliefs, desires, intentions - BDIs); dynamically adjusts inferred BDIs; counterfactual intervention method; enhances reflection efficiency.
- ToM-agent provides new insights for studying large-scale LLMs-based simulation of human social behaviors.


---

#### 25th January 2025

[OptiSeq: Optimizing Example Ordering for In-Context Learning](http://arxiv.org/abs/2501.15030v1)

- OptiSeq: introduces a score based on log probabilities of LLM outputs to prune example orderings in few-shot ICL.
- optimizing example ordering; in-context learning; LLM outputs; prune orderings; best order; correct/incorrect outputs; empirical evaluation; accuracy improvement.
- OptiSeq improves accuracy significantly across multiple tasks.


---

#### 24th January 2025

[RL + Transformer = A General-Purpose Problem Solver](https://arxiv.org/abs/2501.14176)

- ICRL (In-Context Reinforcement Learning): introduces LLaMA 3.1 8B Instruct (Pre-trained Transformer), IA3 Adapter (Efficient Fine-tuning), DQN (RL Algorithm), Input Sequence (History of Interactions), and Output Q-value (Action-value Function) to demonstrate a meta-learning approach for solving unseen problems through reinforcement learning.
- ICRL leverages a pre-trained transformer fine-tuned with reinforcement learning to achieve in-context learning, enabling generalization to new environments and tasks without additional training.
- The framework exhibits robustness to low-quality training data and adaptability to non-stationary environments, highlighting its potential as a general-purpose problem solver.


---

[Self-reflecting Large Language Models: A Hegelian Dialectical Approach](http://arxiv.org/abs/2501.14917v1)

- Hegelian Dialectical Approach: Framework introduces philosophical approach inspired by the Hegelian Dialectic for LLMs' self-reflection.
- It uses self-dialectical approach to emulate internal critiques, synthesize new ideas by resolving contradictions, dynamic annealing approach for temperature generation, Multi Agent Majority Voting (MAMV) strategy to assess validity and novelty.
- Framework is examined to determine ability to generate novel ideas and provide stepping stone for future research.


---

[MedAgentBench: Dataset for Benchmarking LLMs as Agents in Medical Applications](http://arxiv.org/abs/2501.14654v1)

- MedAgentBench: is a broad evaluation suite designed to assess the agent capabilities of large language models within medical records contexts.
- It encompasses 100 patient-specific clinically-derived tasks, realistic profiles of 100 patients with over 700,000 data elements, a FHIR-compliant interactive environment, and an accompanying codebase.
- This framework establishes a valuable benchmark for model developers to track progress and drive continuous improvements in the agent capabilities of large language models within the medical domain.

---

[DEEPFLOW: Serverless Large Language Model Serving at Scale](http://arxiv.org/abs/2501.14417v1)

- DEEPFLOW: is a serverless AI platform designed for efficient large language model serving at scale.
- It uses request-job-task model, FLOWSERVE serving engine, NPU-centric execution, SPMD-based parallelism, and novel scheduling policies.
- This framework addresses resource allocation, serving efficiency, and cold start latencies.

---

[DRESSING UP LLM: EFFICIENT STYLIZED QUESTION-ANSWERING VIA STYLE SUBSPACE EDITING](http://arxiv.org/abs/2501.14371v1)

- DRESS (Disentangling Representation Editing in Style Subspace): is a novel approach for generating stylized large language model (LLM) responses through representation editing.
- It leverages over-parameterized nature of LLMs, disentangles style-relevant subspace, applies adaptive editing strengths, and maintains stylistic fidelity and semantic integrity.
- DRESS is a lightweight, train-free solution for enhancing LLMs with flexible and effective style control, making it useful for developing stylized conversational agents.


---

[Exploring the sustainable scaling of Al dilemma: A projective study of corporations' Al environmental impacts](http://arxiv.org/abs/2501.14334v1)

- The proposed methodology: estimates the environmental impact of a company's AI portfolio, providing actionable insights without extensive AI and Life-Cycle Assessment (LCA) expertise.
- The framework includes four interconnected models: life cycle impacts of primary components, life cycle impacts of AI use cases, AI company portfolio model, and 2030 AI landscape projections.
- This framework empowers organizations to understand and project their AI impacts and align their initiatives with global sustainability goals.


---

[MASTER: A Multi-Agent System with LLM Specialized MCTS](http://arxiv.org/abs/2501.14304v1)

- MASTER (Multi-Agent System with Tactical Execution and Reasoning using LLM Specialized MCTS): is a novel multi-agent framework that employs a new agent recruitment process and communication protocol based on the MCTS algorithm.
- It autonomously adjusts the number of agents based on task complexity, mitigates distractions and token window shortage, and includes a modified MCTS tailored to LLM scenarios.
- This framework achieves state-of-the-art performance on HotpotQA and WebShop datasets.


---

[Top Ten Challenges Towards Agentic Neural Graph Databases](http://arxiv.org/abs/2501.14224v1)

- Agentic NGDB (Agentic Neural Graph Databases): extends NGDBs with autonomous query construction, neural query execution, and continuous learning.
- It identifies ten key challenges, including semantic unit representation, abductive reasoning, scalable query execution, and integration with foundation models like LLMs.
- This framework enables intelligent, self-improving systems for modern data-driven applications.


---

[Serving Long-Context LLMs at the Mobile Edge: Test-Time Reinforcement Learning-based Model Caching and Inference Offloading](http://arxiv.org/abs/2501.14205v1)

- T2DRL (Test-Time Deep Reinforcement Learning): is a joint model caching and inference offloading framework that optimizes deployment and execution strategies for long-context LLM serving.
- Framework analyzes performance convergence, designs optimization problem considering context windows, manages cached models and service requests, adapts to context changes, and uses double Dutch auction mechanism for resource allocation.
- The framework reduces system costs while guaranteeing the performance of LLM agents in real-world perception and reasoning tasks.


---

[Distributed Multi-Agent Coordination Using Multi-Modal Foundation Models](http://arxiv.org/abs/2501.14189v1)

- VL-DCOPs (visual-linguistic instruction-based DCOPs): is a framework that uses large multimodal foundation models to generate constraints from visual and linguistic instructions.
- Framework includes spectrum of agent archetypes, from neuro-symbolic to fully neural agents, and evaluates them using LLMs and VLMs on novel VL-DCOP tasks.
- This work extends the DCOP literature by addressing the challenge of manual problem construction and opens new research directions.


---

[AI Chatbots as Professional Service Agents: Developing a Professional Identity](http://arxiv.org/abs/2501.14179v1)

- LAPI (LLM-based Agent with a Professional Identity): is a novel framework for designing professional service agents tailored for medical question-and-answer services.
- LAPI includes theory-guided task planning process, pragmatic entropy method, and iterative updating of responses.
- This framework improves response quality, providing more accurate, empathetic, and professional answers compared to baseline approaches.


---

[ARGOS: Agentic Time-Series Anomaly Detection with Autonomous Rule Generation via Large Language Models](http://arxiv.org/abs/2501.14170v1)

- ARGOS: is an agentic system for detecting time-series anomalies in cloud infrastructure by leveraging large language models (LLMs).
- It uses explainable anomaly rules as intermediate representation, employs LLMs to autonomously generate rules, and includes detection-, repair- and review-agents.
- This framework improves anomaly detection accuracy and efficiency compared to state-of-the-art methods.


---

[Top Ten Challenges Towards Agentic Neural Graph Databases](https://arxiv.org/abs/2501.14224)

- Agentic NGDB (Agentic Neural Graph Databases): extends NGDBs with autonomous query construction, neural query execution, and continuous learning.
- It identifies ten key challenges, including semantic unit representation, abductive reasoning, scalable query execution, and integration with foundation models like LLMs.
- This framework enables intelligent, self-improving systems for modern data-driven applications.


---

#### 23rd of January 2025


[BEYOND THE SUM: UNLOCKING AI AGENTS POTENTIAL THROUGH MARKET FORCES](https://arxiv.org/abs/2501.10388)

- AI Agent Market Infrastructure Framework presents systematic analysis of infrastructure requirements for AI agents to function as autonomous participants in digital markets.
- Framework identifies key areas like identity, service discovery, interfaces and payment systems and highlights existing infrastructure challenges impeding agent participation, suggesting new economic organization forms.
- This framework is important as it addresses infrastructure challenges as fundamental step toward enabling new forms of economic organization.


---

[ElCopilot: Search and Explore Enterprise Information over Large-scale Knowledge Graphs with LLM-driven Agents](http://arxiv.org/abs/2501.13746v1)

- EICopilot: is a novel agent-based solution enhancing search and exploration of enterprise registration data within extensive online knowledge graphs.
- EICopilot includes data pre-processing pipeline, comprehensive reasoning pipeline with Chain-of-Thought and In-context learning, and novel query masking strategy.
- EICopilot is a groundbreaking tool for exploration and exploitation of large-scale knowledge graphs for enterprise information search.


---

[The though process behind Kimi k1.5](https://twitter.com/Kimi_Moonshot/status/1882413059513471044)

- Explains the way the Kimi K-1.5 model was trained and discusses overall likely o1-model training procedure.


---

[Operator System Card](https://cdn.openai.com/operator_system_card.pdf)

- OA Operator-agent system card.
- Uses RL.
- Additional [details](https://cdn.openai.com/cua/CUA_eval_extra_information.pdf)


#### 21st of January 2025

[LLM-Agents Driven Automated Simulation Testing and Analysis of small Uncrewed Aerial Systems](http://arxiv.org/abs/2501.11864v1)

- AUTOSIMTEST: is a Large Language Model (LLM)-driven framework, where multiple LLM agents collaborate to support the sUAS simulation testing process.
- Framework includes scenario generation-, mission-, environment- and analytics-agents; uses RAG approach; provides interactive analysis interface.
- Framework improves efficiency and scope of sUAS testing process, allowing for more comprehensive and varied scenario evaluations while reducing manual effort.


---

[EmbodiedEval: Evaluate Multimodal LLMs as Embodied Agents](http://arxiv.org/abs/2501.11858v1)



- EMBODIEDEVAL: is a comprehensive and interactive evaluation benchmark for MLLMs with embodied tasks.
- EMBODIEDEVAL features 328 distinct tasks within 125 varied 3D scenes, covers navigation, object interaction, social interaction, attribute question answering, and spatial question answering.
- This framework provides insights for future development of MLLMs in embodied capabilities.


---



#### 20th of January 2025

[DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinformcent Learning](https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf)

- DeepSeek-R1: Trains SOTA-level Large Reasoning Model from LLM via Reinforcement Learning, which matches performance with o1-model.

---

[Kimi-K1.5: Scaling Reinforcement Learning with LLMs](https://github.com/MoonshotAI/Kimi-k1.5/blob/main/Kimi_k1.5.pdf)

- Kimi k1.5: is a multi-modal large language model (LLM) trained with reinforcement learning (RL) to achieve SOTA-level reasoning performance across multiple benchmarks and modalities.


---

[Conversation Routines: A Prompt Engineering Framework for Task-Oriented Dialog Systems](http://arxiv.org/abs/2501.11613v1)

- Conversation Routines (CR): is a structured prompt engineering framework for developing task-oriented dialog systems using Large Language Models (LLMs).
- CR enables development of Conversation Agentic Systems (CAS) through natural language specifications, embedding task-oriented logic within LLM prompts, providing systematic methodology for designing complex conversational workflows while maintaining behavioral consistency.
- This framework enables domain experts to design conversational workflows in natural language while leveraging custom enterprise functionalities.


---

[Agent-R: Training Language Model Agents to Reflect via Iterative Self-Training](http://arxiv.org/abs/2501.11425v1)

- Agent-R: is an iterative self-training framework that enables language agents to reflect on the fly.
- It leverages Monte Carlo Tree Search (MCTS) to construct training samples, recovers correct trajectories from erroneous ones, and uses a model-guided critique construction mechanism for timely revision.
- This framework effectively equips agents to identify and correct erroneous actions while avoiding loops, achieving superior performance.


---

[Towards Advancing Code Generation with Large Language Models: A Research Roadmap](http://arxiv.org/abs/2501.11354v1)



- Six-layer vision framework: categorizes code generation process into Input, Orchestration, Development, and Validation phases.
- Framework includes analysis of existing studies, outlines vision workflow, and systematically analyses challenges faced by LLMs.
- This work provides guidelines for improving reliability, robustness and usability of LLM-based code generation systems.


---

[Large Language Model Agents for Radio Map Generation and Wireless Network Planning](http://arxiv.org/abs/2501.11283v1)

- LLM agent framework: automates radio map generation and wireless network planning tasks.
- Framework includes tools-, models- and profiles-modules; it uses short-term and long-term memory; it performs task planning.
- The framework reduces manual operations and enhances network coverage and signal-to-interference-noise ratio.


---

[Code Readability in the Age of Large Language Models: An Industrial Case Study from Atlassian](http://arxiv.org/abs/2501.11264v1)

- HULA (Human-in-the-loop software development agents framework): is a LLM-based framework for software development.
- The framework uses GPT-4, compares LLM-generated code with human-written code, and evaluates code readability using static analysis metrics.
- This study highlights the importance of code readability in the age of LLMs and shows that LLM-generated code can be comparable to human-written code.


---

[PlotEdit: Natural Language-Driven Accessible Chart Editing in PDFs via Multimodal LLM Agents](http://arxiv.org/abs/2501.11233v1)

- PlotEdit: is a multi-agent framework for natural language-driven end-to-end chart image editing via self-reflective LLM agents.
- Framework includes Chart2Table, Chart2Vision, Chart2Code, Instruction Decomposition and Multimodal Editing agents; uses multimodal feedback to maintain visual fidelity; outperforms existing baselines on ChartCraft dataset.
- It enhances accessibility for visually challenged users and improves novice productivity.


---

#### 19th of January 2025

[IntellAgent: A Multi-Agent Framework for Evaluating Conversational AI Systems](http://arxiv.org/abs/2501.11067v1)

- IntellAgent: is a scalable, open-source multi-agent framework designed to evaluate conversational AI systems.
- It automates synthetic benchmark creation using policy-driven graph modeling, realistic event generation, and interactive user-agent simulations, providing fine-grained diagnostics.
- This framework enables comprehensive evaluation of conversational AI by addressing limitations of traditional methods.


---

[GREEN-CODE: Optimizing Energy Efficiency in Large Language Models for Code Generation](http://arxiv.org/abs/2501.11006v1)

- GREEN-CODE: is a framework for energy-aware code generation in LLMs, performing dynamic early exit during inference.
- It uses Reinforcement Learning agent to balance accuracy, latency, and energy consumption trade-offs, and fine-tunes models with weighted aggregated loss.
- This framework reduces energy consumption significantly without affecting accuracy for code generation tasks.


---

[Open FinLLM Leaderboard: Towards Financial AI Readiness](http://arxiv.org/abs/2501.10963v1)

- Open FinLLM Leaderboard: is an open platform for assessing and comparing Large Language Models' performance on financial tasks.
- The framework includes a leaderboard, demos, and financial AI readiness components; it uses zero-shot evaluation, and provides side-by-side model comparisons.
- This framework is important for encouraging innovation and improving model effectiveness in the financial sector.


---


[Learn-by-interact: A Data-Centric Framework for Self-Adaptive Agents in Realistic Environments](http://arxiv.org/abs/2501.10893v1)

- LEARN-BY-INTERACT: is a data-centric framework to adapt LLM agents to any given environments without human annotations.
- LEARN-BY-INTERACT synthesizes agent-environment interactions based on documentations, constructs instructions by summarizing interaction histories, and uses innovative retrieval approaches optimized for agents.
- This framework serves as a foundation for agent data synthesis as LLMs are increasingly deployed at real-world environments.


---

#### 18th of January 2025

[Learn-by-interact: A Data-Centric Framework for Self-Adaptive Agents in Realistic Environments](https://arxiv.org/abs/2501.10893)

- LEARN-BY-INTERACT: is a data-centric framework to adapt LLM agents to any given environments without human annotations.
- Framework synthesizes agent-environment interaction trajectories, uses backward construction for instructions, and leverages synthetic data for training and in-context learning with optimized retrieval.
- Framework serves as a foundation for agent data synthesis for LLMs in real-world environments.


--

[BAP v2: An Enhanced Task Framework for Instruction Following in Minecraft Dialogues](http://arxiv.org/abs/2501.10836v1)

- BAP v2 (Builder Action Prediction v2): is an upgraded task framework for instruction following in Minecraft dialogues.
- BAP v2 includes enhanced evaluation benchmark with cleaner test set and fairer metrics, and additional synthetic training data generated from novel Minecraft dialogue and target structure simulators.
- BAP v2 enables more efficient and meaningful progress on the task of instruction following in Minecraft dialogues.


---

[ML-SceGen: A Multi-level Scenario Generation Framework](http://arxiv.org/abs/2501.10782v1)

- ML-SceGen: is a three-stage framework for generating comprehensive and critical scenarios in autonomous driving.
- It uses LLM agents for parsing, Answer Set Programming (ASP) solver for logical traffic generation, and LLM for parameter updates to increase criticality.
- This framework enhances controllability, scalability, and realism in scenario generation for autonomous driving systems.


---

#### 17th of January 2025

[Evolving Deeper LLM Thinking](https://arxiv.org/abs/2501.09891)

- Mind Evolution: is an evolutionary search strategy that uses a language model to generate, recombine and refine candidate responses.
- It avoids formalizing the inference problem (so is usable in spaces like planning in natural language without explicit formalization of the problem and as well in hiding encoded message inside poems, which is non-natural language task), uses a global solution evaluator (focuses on domains, where evaluator is available), and can be easily parallelized.
- This approach significantly outperforms other inference strategies in natural language planning tasks.
- Introduces new StegPoet-benchmark, where the benchmark task is to encode message inside essay/story. 


---

[Agent4Edu: Generating Learner Response Data by Generative Agents for Intelligent Education Systems](https://arxiv.org/abs/2501.10332v1)

- Agent4Edu: is a personalized learning simulator that uses LLM-powered generative agents to simulate human learners' response data.
- It includes learner profile, memory, and action modules; interacts with personalized learning environments; evaluates and improves intelligent tutoring algorithms.
- This framework provides a versatile platform for comprehensive evaluations and future collection of valuable learner response data.


---

[Towards Human-Guided, Data-Centric LLM Co-Pilots](http://arxiv.org/abs/2501.10321v1)


- CliMB-DC (Clinical predictive Model Builder with Data-Centric AI): is a human-guided, data-centric framework for LLM co-pilots.
- It includes a multi-agent reasoning system with a strategic coordinator and a specialized worker agent, integrates state-of-the-art data-centric tools, and uses a human-in-the-loop approach.
- This framework empowers domain experts to actively participate in driving real-world impact using ML.


---

[Towards Preventing Overreliance on Task-Oriented Conversational AI Through Accountability Modeling](http://arxiv.org/abs/2501.10316v1)

- Accountability Model: is an augmented LLM with an additional accountability head, functioning as a binary classifier to predict dialogue state slots.
- It detects false positives and negatives, guides LLM decoder for accurate actions, enables self-correction, and introduces friction to prevent overreliance.
- This model improves joint goal accuracy and overall performance in task-oriented dialogue systems.


---


[PaSa: An LLM Agent for Comprehensive Academic Paper Search](https://arxiv.org/abs/2501.10120v1)

- PaSa: is an advanced paper search agent powered by large language models. Available [https://pasa-agent.ai/](https://pasa-agent.ai/)
- It autonomously makes decisions, including invoking search tools, reading papers, and selecting references; it is optimized using reinforcement learning with synthetic dataset; it outperforms existing baselines on real-world academic queries.
- This framework significantly improves the efficiency and accuracy of academic search.


---

[LLM Reasoner and Automated Planner: A new NPC approach](http://arxiv.org/abs/2501.10106v1)



- LLM Reasoner and Automated Planner: is a novel architecture that integrates an LLM for decision-making with a classical automated planner.
- Framework uses LLM to decide goal, then uses automated planning to create plan, and includes modules for reasoning, planning and interface.
- This framework aims to empower autonomous agents with flexibility to adapt to any situation while maintaining plausible and human-like behavior.


---

[A Survey on LLM Test-Time Compute via Search: Tasks, LLM Profiling, Search Algorithms, and Relevant Frameworks](http://arxiv.org/abs/2501.10069v1)

- This survey provides a comprehensive technical review that unifies task definitions and provides modular definitions of LLM profiling and search procedures.
- It enables precise comparisons of various LLM inference frameworks, highlights their departures from conventional search algorithms, and discusses applicability, performance, and efficiency.
- This survey offers a collection of classical and reusable implementations that can serve as solid foundations for future research and development.


---

[Agent-as-Judge for Factual Summarization of Long Narratives](http://arxiv.org/abs/2501.09993v1)

- NARRATIVEFACTSCORE: is a novel "Agent-as-a-Judge" framework for evaluating and refining summaries.
- It leverages Character Knowledge Graph (CKG), assesses factual consistency, provides actionable guidance for refinement, identifies missing or erroneous facts, and uses retrieval-based verification with explicit feedback.
- This framework improves the factual reliability of LLM-generated summaries.

---

[A Survey on Multi-Turn Interaction Capabilities of Large Language Models](http://arxiv.org/abs/2501.09959v1)

- This survey provides a focused review of the multi-turn capabilities of LLMs.
- The survey explores core model capabilities, evaluation methods, enhancement algorithms, and future research directions.
- This survey is important for both academic researchers and industry practitioners.


---


[TOWARDS A LITMUS TEST FOR COMMON SENSE](http://arxiv.org/abs/2501.09913v1)

- Axiomatic litmus test: diagnoses common sense by combining minimal prior knowledge constraints with diagonal arguments to create tasks beyond the agent's known concept set.
- It addresses deceptive hallucinations, integrates observations regarding emergent deceptive hallucinations, and uses Abstraction and Reasoning Corpus (ARC) constraints.
- This test provides a stepping stone toward an ethical, reliable foundation for future safe, beneficial and aligned artificial intelligence.


---



#### 16th of January 2025

[Authenticated Delegation and Authorized AI Agents](https://arxiv.org/abs/2501.09674)

- Authenticated Delegation Framework: novel framework enables authenticated, authorized, and auditable delegation of authority to AI agents.
- Secure delegation; restrict permissions and scope; accountability; extends OAuth 2.0 and OpenID Connect; natural language to auditable access control.
- Framework facilitates immediate AI agent deployment while ensuring security and accountability.


---

[Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps](https://arxiv.org/abs/2501.09732)

- Inference-time scaling framework: explores the inference-time scaling behavior of diffusion models beyond increasing denoising steps.
- Framework uses search problem to identify better noises, design space includes verifiers and algorithms, experiments on class-conditioned and text-conditioned image generation benchmarks.
- This framework reveals that increasing inference-time compute leads to substantial improvements in the quality of samples generated by diffusion models.


---


[Foundations of Large Language Models](https://arxiv.org/pdf/2501.09223)

- Introduces a literature review / survey on LLMs.
  

---

[AutoCBT: An Autonomous Multi-agent Framework for Cognitive Behavioral Therapy in Psychological Counseling]( http://arxiv.org/abs/2501.09426v1)
- AutoCBT: An Autonomous Multi-agent Framework for Cognitive Behavioral Therapy in Psychological Counseling.
- AutoCBT incorporates a counsellor agent and multiple supervisor agents, uses short-term and long-term memory, and is evaluated on a bilingual dataset.
- AutoCBT leverages dynamic routing and supervisory mechanisms to offer high-quality, automated CBT services, enhancing the effectiveness of single-turn consultations.

---

[OmniThink: Expanding Knowledge Boundaries in Machine Writing through Thinking](https://arxiv.org/abs/2501.09751)

- OmniThink: is a machine writing framework that emulates human-like iterative expansion and reflection.
- It uses continuous reflection and exploration, attaches knowledge to an information tree, and extracts it into a conceptual pool to deepen understanding.
- This framework improves the knowledge density of generated articles without compromising coherence and depth.


---

[CyberMentor: AI Powered Learning Tool Platform to Address Diverse Student Needs in Cybersecurity Education](http://arxiv.org/abs/2501.09709v1)

- CyberMentor: is a learning tool platform designed to address diverse needs of cybersecurity students using agentic workflow and Generative Large Language Models (LLMs).
- It leverages Retrieval-Augmented Generation (RAG) for accurate information retrieval, includes knowledge base, skill base and LLM agent, and provides personalized learning experiences.
- This framework aims to improve equity and sustainability in higher education by offering open-source design for adaptation across disciplines.


---

[Empowering Large Language Models in Wireless Communication: A Novel Dataset and Fine-Tuning Framework](http://arxiv.org/abs/2501.09631v1)

- PVI (Pointwise V-Information) based fine-tuning method: enhances LLMs for wireless communication by quantifying information content of training data.
- Dataset includes multi-hop questions, true/false and multiple-choice types, varying difficulty levels, rigorous data curation, advanced language models for entity extraction and question generation.
- This work aims to improve LLM training and evaluation for wireless communication research and applications.


---

[SOP-AGENT: EMPOWER GENERAL PURPOSE AI AGENT WITH DOMAIN-SPECIFIC SOPS](http://arxiv.org/abs/2501.09316v1)

- SOP-agent (Standard Operational Procedure-guided Agent): is a novel framework for constructing domain-specific agents through pseudocode-style Standard Operational Procedures (SOPs) written in natural language.
- SOP-agent represents SOP as a decision graph, traverses it to guide the agent, conducts experiments across multiple domains, and introduces Grounded Customer Service Benchmark.
- SOP-agent demonstrates excellent versatility, achieving performance superior to general-purpose agent frameworks and comparable to domain-specific agent systems.


---

[EvaLearn: Quantifying the Learning Capability and Efficiency of LLMs via Sequential Problem Solving](https://arxiv.org/abs/2506.02672)

- EvaLearn: introduces a benchmark to quantify large language model learning capability and efficiency via sequential problem solving, utilizing Problems (Benchmark dataset organized into sequences), Sequentially Solving (Evaluated large language model attempts problems in sequence), Evaluation (Assesses solution correctness using LLM-as-a-judge and rubrics, providing feedback), and Metrics (Five measures quantifying learning capability and efficiency).
- The benchmark requires models to solve problems sequentially within sequences, allowing them to leverage experience from previous solutions.
- Evaluation uses instance-level rubrics and an LLM-as-a-judge framework to assess correctness and provide feedback for learning.


---


#### 15th of January 2025


[The geometry of moral decision making](https://arxiv.org/abs/2501.08865)

- Geometry of Moral Decision Making Framework: Understands bounded rationality as interplay of deontology and utilitarianism.
- Deontology as regularisation function in optimal control; Inverse temperature shields from expected utility; Information geometry of bounded rationality and rate distortion theory; Markov kernels and regular conditional probability; Gradient equation determines utility expansion path.
- Framework is relevant to theory of autonomous agents and analysis of legal doctrine.


---

[Networked Agents in the Dark: Team Value Learning under Partial Observability](https://arxiv.org/abs/2501.08778)

- DNA-MARL (Double Networked Averaging MARL) is distributed method for networked agents that introduces consensus mechanism for local communication and gradient descent for local computation in partially observable Markov games.
- Framework addresses cooperative multi-agent reinforcement learning in networked dynamic partially observable Markov game (ND-POMG) using decentralized training and decentralized execution (DTDE), and achieves team value function learning under partial observability via consensus mechanism for cooperative value function learning with actor-critic algorithm.
- DNA-MARL enhances the potential of networked agents for real-world applications requiring privacy and robustness to message loss.


---

[Between Puppet and Actor: Reframing Authorship in this Age of AI Agents](http://arxiv.org/abs/2501.15346v1)

- Puppet and Actor framework: This framework reframes authorship in the age of AI agents by positioning AI agency between puppet and actor.
- Conceptual tensions in AI agent roles; creative processes; Large Language Models (LLMs); Schmidt's categorization; classical authorship; puppet-actor spectrum; creative autonomy; dynamic state; evolving authorship.
- Understanding AI agency as puppet-actor spectrum is important for adapting authorship concepts in the age of AI.


---

[AGENTIC RETRIEVAL-AUGMENTED GENERATION: A SURVEY ON AGENTIC RAG](http://arxiv.org/abs/2501.09136v1)

- Introduces Survey on compherensive list of RAG-techniques with LLM-agents.


---


[Agent TCP/IP: An Agent-to-Agent Transaction System](https://arxiv.org/abs/2501.06243)

- ATCP/IP (Agent Transaction Control Protocol for Intellectual Property): introduces a trustless framework for exchanging IP between agents via programmable contracts.
- Framework enables agents to initiate, trade, borrow, and sell agent-to-agent contracts on the Story blockchain network, including legal wrappers for offchain enforcement, and facilitates autonomous selling of training data, licensing of information, and content collaboration.
- This framework is important for creating a standardized way for agents to negotiate and enter into agreements, forming a market for knowledge.


---

[Leveraging Large Language Models as Knowledge-Driven Agents for Reliable Retrosynthesis Planning](http://arxiv.org/abs/2501.08897v1)

- MBRPS (Multi-branched Reaction Pathway Search): Algorithm enabling exploration of all pathways, with a focus on multi-branched ones.
- Framework integrates LLMs and KGs, automates literature retrieval, reaction data extraction, database querying, and construction of retrosynthetic pathway trees, and recommends optimal routes.
- Attempt to develop a fully automated retrosynthesis planning agent tailored specially for macromolecules powered by LLMs.


---

[AutoRestTest: A Tool for Automated REST API Testing Using LLMs and MARL](http://arxiv.org/abs/2501.08600v1)

- AutoRestTest: is a novel tool that integrates Semantic Operation Dependency Graph (SODG) with Multi-Agent Reinforcement Learning (MARL) and Large Language Models (LLMs) for effective REST API testing.
- It uses five specialized agents for operation, parameter, value, dependency, and header identification, and employs LLMs for realistic input generation and a command-line interface for user interaction.
- This framework provides a comprehensive solution for thorough REST API evaluation and validation.


---


[Leveraging LLM Agents for Translating Network Configurations](http://arxiv.org/abs/2501.08760v1)

- IRAG (Intent-based Retrieval Augmented Generation): is an intent-based framework for translating network configurations using LLM agents.
- Framework includes intent extraction, manual retrieval, incremental translation, syntax verification and semantic verification modules.
- This framework achieves high syntax correctness and superior translation accuracy compared to state-of-the-art methods.


---

[DISENTANGLING EXPLORATION OF LARGE LANGUAGE MODELS BY OPTIMAL EXPLOITATION](http://arxiv.org/abs/2501.08925v1)

- Optimal Exploitation framework: isolates exploration as the sole objective by tasking the agent with delivering information that enhances future returns.
- Framework decomposes missing rewards into exploration and exploitation components, measures optimal achievable return for explored states, and provides insights into behaviors driven by agent instructions.


---

[Physical AI Agents: Integrating Cognitive Intelligence with Real-World Action](http://arxiv.org/abs/2501.08944v1)

- Physical AI Agents: is a framework that integrates cognitive reasoning with physical interaction for real-world tasks.
- Framework includes modular architecture with perception, cognition, and actuation blocks, and introduces Ph-RAG (Physical Retrieval Augmented Generation) design pattern for real-time decision-making.


---

[Doc-Guided Sent2Sent++: A Sent2Sent++ Agent with Doc-Guided memory for Document-level Machine Translation](http://arxiv.org/abs/2501.08523v1)

- Doc-Guided Sent2Sent++: is an agent that employs an incremental sentence-level forced decoding strategy for document-level machine translation.
- It uses Doc-Guided Memory with summary and its translation, ensures sentence completeness, enhances fluency, and improves translation quality.
- This approach addresses the limitations of other DocMT agents by maintaining both completeness and fluency.


---

[Evaluating GenAl for Simplifying Texts for Education: Improving Accuracy and Consistency for Enhanced Readability](http://arxiv.org/abs/2501.09158v1)


- GenAI (Generative Artificial Intelligence): framework evaluates the use of LLMs for text simplification in educational contexts.
- Framework uses three LLMs (GPT-4 Turbo, Claude 3, and Mixtral 8x22B), four prompting techniques (zero-shot, directional stimulus, chain-of-thought, and prompt chaining), and a novel multi-agent architecture; it assesses grade level accuracy, keyword accuracy, semantic similarity, and word count change.
- This study provides a rigorous evaluation of LLMs for automated text simplification, offering insights for educators and future research.


---

#### 14th of January 2025

#### 14th January 2025

[Governing AI Agents](https://arxiv.org/abs/2501.07913)

- Governance strategy: Governance strategy centered around inclusivity, visibility, and liability is proposed for designing and regulating AI agents.
- agency law and theory; principal-agent problems; information asymmetry, authority, loyalty, delegation; limitations of conventional solutions; new technical and legal infrastructure; governance principles.
- New technical and legal infrastructure is needed to support governance principles for reliable, safe, and ethical AI agents.


---

[Flow: A Modular Approach to Automated Agentic Workflow Generation](http://arxiv.org/abs/2501.07834v1)

- Flow: is a multi-agent framework that dynamically adjusts workflows using activity-on-vertex graphs.
- It refines workflows based on historical performance, emphasizes modularity, and achieves concurrent sub-task execution.
- This framework improves efficiency and adaptability in multi-agent systems through dynamic workflow updates.


---


[POKERBENCH: Training Large Language Models to become Professional Poker Players](https://arxiv.org/abs/2501.08328)

- POKERBENCH: is a benchmark for evaluating poker-playing abilities of large language models (LLMs).
- It includes 11,000 poker scenarios, covers pre-flop and post-flop play, and evaluates models like GPT-4, ChatGPT 3.5, Llama and Gemma series.
- This benchmark provides a quick and reliable way to evaluate LLMs in complex game-playing scenarios.

---

[A Multi-Agent Framework for Systematic Review Automation Using Large Language Models](https://arxiv.org/abs/2501.05468)

- LatteReview: Intrdocus LLM-based systematic literature review multi-agent framework automation, which consists of three layers: LM providers (local models / LLMs via api), Reviewer agents (with roles & expertise levels) and Workflows (support sequential, parallel review rounds, dynamic decision-making and iterative refinement).
- Includes BaseReviewer/ScoringReviewer/TitleAbstractReviewer/AbstractionReviewer/Custom reviewer-agents, which are used as modular agents for title and abstract screening, relevance scoring, and structured data extraction; agents operate within orchestrated workflows.
- Workflow module includes Concept of rounds / Chaining reviews / Parallel reviews and Dynamic filter.


---

[CodeCoR: An LLM-Based Self-Reflective Multi-Agent Framework for Code Generation](http://arxiv.org/abs/2501.07811v1)

- CodeCoR (Code Collaboration and Repair): is a self-reflective multi-agent framework for code generation.
- It includes prompt-, coding-, test- and repair-agents, uses pruning methods to evaluate agent effectiveness, and enhances self-reflective ability.
- It significantly outperforms existing state-of-the-art methods in code generation.


---


[Engineering LLM Powered Multi-agent Framework for Autonomous CloudOps](http://arxiv.org/abs/2501.08243v1)

- MOYA (Meta Orchestrator Of Your Agents): is a multi-agent framework leveraging GenAI for autonomous CloudOps, balancing automation with human control.
- Framework integrates internal and external systems, optimizes task orchestration, security, and error mitigation using Retrieval Augmented Generation (RAG), and includes LLM-based and non-LLM-based agents.
- The framework enhances accuracy, responsiveness, and effectiveness over non-agentic approaches across complex workflows.


---

[Agent-Centric Projection of Prompting Techniques and Implications for Synthetic Training Data for Large Language Models](http://arxiv.org/abs/2501.07815v1)

- Agent-Centric Projection: introduces a framework to reveal connections between prompting strategies and multi-agent systems.
- Framework uses linear and non-linear contexts to classify prompting techniques, and proposes three conjectures about the relationship between prompting and multi-agent systems.
- This framework enables cross-pollination of research findings between prompting and multi-agent domains, while providing new directions for improving both the design and training of future LLM systems.


---

[Talk to Right Specialists: Routing and Planning in Multi-agent System for Question Answering](http://arxiv.org/abs/2501.07813v1)

- RopMura: is a multi-agent system that incorporates a router and a planner for question answering across diverse knowledge domains.
- RopMura includes router for selecting relevant agents, planner for decomposing complex queries, and knowledge sovereignty consideration.
- This framework enables efficient and accurate multi-domain question-answering.


---

[Infecting Generative AI With Viruses](https://arxiv.org/abs/2501.05542)

- VLM/LLM (Vision-Large Language Model): framework tests security boundaries by embedding EICAR test file within JPEG images.
- Framework includes multiple LLM platforms, such as OpenAI GPT-40, Microsoft Copilot, Google Gemini 1.5 Pro, and Anthropic Claude 3.5 Sonnet; it demonstrates masking EICAR string, extracting test file, and using obfuscation techniques.
- This research extends penetration testing framework to evaluate cloud-based generative AI and LLM security boundaries.


---


[Visual Language Models as Operator Agents in the Space Domain](http://arxiv.org/abs/2501.07802v1)

- Explores the application of VLMs as operator agents in the space domain.
- Framework builds on LLMs and their multimodal extensions, investigates how VLMs enhance autonomous control and decision-making in space missions, includes software and hardware operational paradigms.
- This research demonstrates that VLMs can effectively process visual and textual data to generate contextually appropriate actions.


---

[ADAM-1: AI and Bioinformatics for Alzheimer's Detection and Microbiome-Clinical Data Integrations](http://arxiv.org/abs/2501.08324v1)

- ADAM-1 (Alzheimer's Disease Analysis Model Generation 1): is a multi-agent large language model framework designed to integrate and analyze multi-modal data.
- Framework uses retrieval-augmented generation techniques, multi-agent architecture, synthesizes insights from diverse data sources, contextualizes findings using literature-driven evidence, and is tailored for binary classification tasks.
- This framework demonstrates robustness and consistency, particularly in small laboratory datasets, and has potential for Alzheimer's research and diagnostics.


---

[ADDRESSING THE SUSTAINABLE AI TRILEMMA: A CASE STUDY ON LLM AGENTS AND RAG](http://arxiv.org/abs/2501.08262v1)

- Sustainable AI Trilemma: highlights the tensions between AI capability, digital equity, and environmental sustainability.
- Framework analyzes energy costs in memory module designs, introduces metrics for energy consumption and system performance trade-offs, challenges LLM-centric autonomy paradigm.
- This framework provides practical insights for developing more sustainable AI systems.


---

[Agent-Centric Projection of Prompting Techniques and Implications for Synthetic Training Data for Large Language Models](http://arxiv.org/abs/2501.07815v1)

- Agent-Centric Projection: introduces a framework to reveal connections between prompting strategies and multi-agent systems.
- Framework uses linear and non-linear contexts to classify prompting techniques, and proposes three conjectures about the relationship between prompting and multi-agent systems.
- This framework enables cross-pollination of research findings between prompting and multi-agent domains, while providing new directions for improving both the design and training of future LLM systems.


---

[ASTRID - An Automated and Scalable TRIaD for the Evaluation of RAG-based Clinical Question Answering Systems](http://arxiv.org/abs/2501.08208v1)

- ASTRID: is an Automated and Scalable TRIaD for evaluating clinical QA systems leveraging RAG.
- ASTRID includes three metrics: Context Relevance (CR), Refusal Accuracy (RA), and Conversational Faithfulness (CF); it is validated using real-world patient questions and clinician assessments; it is automatable using LLMs.
- ASTRID provides a valuable resource for further research and development of clinical QA systems.


---

[CuAsmRL: Optimizing GPU SASS Schedules via Deep Reinforcement Learning](http://arxiv.org/abs/2501.08071v1)

- CuAsmRL: is an automatic optimizer for optimizing NVIDIA GPU SASS schedules using reinforcement learning.
- It formulates SASS optimization as an assembly game, integrates with OpenAI Triton, and improves performance of specialized CUDA kernels by up to 26%.
- This framework provides a way to automatically optimize GPU kernels, which is important for improving the performance of LLMs.

---

#### 13th of January 2025

[The Lessons of Developing Process Reward Models in Mathematical Reasoning](https://arxiv.org/abs/2501.07301)


- PRM (Process Reward Model): A model for process supervision in mathematical reasoning of LLMs, which aims to identify and mitigate intermediate errors in the reasoning processes.
- Monte Carlo (MC) estimation, Best-of-N (BoN) evaluation, consensus filtering mechanism, response-level and step-level metrics, data efficiency, error identification.
- The paper addresses challenges in developing effective PRMs, offering solutions for data annotation, evaluation methodologies, and proposing a consensus filtering mechanism to enhance model performance and data efficiency.


---

[Evaluating Agent-based Program Repair at Google](https://arxiv.org/abs/2501.07531)

- Passerine: An agent-based program repair system designed to operate within Google's development environment.
- Inspired by SWE-Agent, utilizes ReAct-style loop, limited command set, Gemini 1.5 Pro, 20 trajectory samples, evaluates on GITS-Eval (178 bugs from Google's internal issue tracking system).
- Establishes a baseline for agent-based automated program repair performance on an industrially relevant benchmark, highlighting challenges and opportunities in an enterprise context.


---

[GPT as a Monte Carlo Language Tree: A Probabilistic Perspective](https://arxiv.org/abs/2501.07641)

- Reviews LLM as a Monte Carlo Language Tree (data tree), where each node is token, each edge is the token transition probability and each sequence has unique path.
- Any GPT LLM can be flattened into MCLT.
- Claims CoT attempts to find path between the input and output in the MCLT to connect them.


---

[WebWalker: Benchmarking LLMs in Web Traversal](https://arxiv.org/abs/2501.07572)

- WebWalker: is a multi-agent framework that mimics human-like web navigation through an explore-critic paradigm. 
- WebWalkerQA is a benchmark designed to assess the ability of LLMs to perform web traversal, it evaluates the capacity of LLMs to traverse a website's subpages to extract high-quality data systematically, and it focuses on text-based reasoning abilities.
- This work highlights the importance of deep, vertical exploration in web-based tasks.


---

[Imagine while Reasoning in Space: Multimodal Visualization-of-Thought](https://arxiv.org/abs/2501.07542)

- MVoT (Multimodal Visualization-of-Thought): is a multimodal native reasoning paradigm that generates image visualizations of reasoning traces.
- MVoT uses token discrepancy loss to improve visual coherence and fidelity, and is validated on dynamic spatial reasoning tasks, showing competitive performance.
- MVoT establishes new possibilities for complex reasoning tasks where visual thinking complements verbal reasoning.

---

[Understanding and Benchmarking Artificial Intelligence: OpenAI's 03 Is Not AGI](https://arxiv.org/abs/2501.07458)

- Claims, that ARC-AGI (Abstraction and Reasoning Corpus) is a benchmark proposed to measure intelligence, but not suitable for measuring progress towards AGI.
- ARC-AGI tasks represent a specific problem structure, which can be solved by massive trialling of predefined operations, and it does not require exploration, but only exploitation.
- A new benchmark is outlined that covers a much higher diversity of unknown tasks to be solved, to enable a comprehensive assessment of intelligence and of progress towards AGI.


---

[PoAct: Policy and Action Dual-Control Agent for Generalized Applications](https://arxiv.org/abs/2501.07054)

- PoAct (Policy and Action Dual-Control Agent): is a framework that dynamically adjusts action space and reasoning policy using a Policy Controller and Action Controller.
- PoAct includes a Policy Controller for switching between reasoning policies, and an Action Controller with RAG Selector and Action Reviewer for managing action space and reasoning paths; it is evaluated on LegalAgentBench and AgentBench datasets.
- PoAct achieves higher quality code actions and more accurate reasoning paths, while also reducing token consumption.


---

[Lifelong Learning of Large Language Model based Agents: A Roadmap](https://arxiv.org/abs/2501.07278)

- Introduces a s survey incorporating lifelong learning into LLM-based agents.
- Categorizes core components into perception-, memory-, and action-modules, highlights continuous adaptation, mitigates catastrophic forgetting, and improves long-term performance.


---

[How GPT LEARNS LAYER BY LAYER](https://arxiv.org/abs/2501.07108)

- Explores how LLMs build internal world models with OthelloGPT by using Sparse AutoEncoders.


---

[SST-EM: Advanced Metrics for Evaluating Semantic, Spatial and Temporal Aspects in Video Editing](https://arxiv.org/abs/2501.07554)

- SST-EM (Semantic, Spatial, and Temporal Evaluation Metric): is a benchmark for video editing that leverages VLMs, object detection, and temporal consistency checks.
- SST-EM includes semantic extraction using VLM, primary object tracking with object detection, focused object refinement via LLM agent, and temporal consistency assessment using ViT.
- This framework provides a comprehensive evaluation of semantic fidelity and temporal smoothness in video editing.


---

[PoAct: Policy and Action Dual-Control Agent for Generalized Applications](http://arxiv.org/abs/2501.07054v1)

- PoAct (Policy and Action Dual-Control Agent): is a framework that dynamically adjusts action space and reasoning policy by switching between different reasoning policies and managing action space.
- PoAct includes Policy Controller for high-quality planning and coding, and Action Controller with RAG Selector and Action Reviewer for managing action space and reasoning paths; it is evaluated on multiple datasets with commercial and open-source large models.
- PoAct achieves higher-quality code actions and more accurate reasoning paths, demonstrating strong generalizability and scalability.


---

[Critical Tokens Matter: Token-Level Contrastive Estimation Enhances LLM's Reasoning Capability](https://arxiv.org/abs/2411.19943)

- cDPO (critical Direct Preference Optimization): is a novel framework for identifying and penalizing critical tokens in mathematical reasoning tasks.
- It uses rollout sampling to identify critical tokens, contrastive estimation to pinpoint them efficiently, and token-level rewards for preference optimization.
- This framework significantly improves model accuracy in mathematical reasoning tasks by reducing errors.


---


#### 12th of January 2025

[Eliza: A Web3 friendly AI Agent Operating System](https://arxiv.org/abs/2501.06781)

- Eliza: The first open-source, web3-friendly, agentic framework that makes the deployment of web3 applications effortless.
- Typescript program, seamless web3 integration, stable performance, key runtime components, community-driven, modular design, multi-agent simulation.
- Eliza bridges the gap between AI and web3, offering a platform for decentralized AI applications.


---

[DVM: Towards Controllable LLM Agents in Social Deduction Games](https://arxiv.org/abs/2501.06695)

- DVM (Dynamic Victory Manager): is a framework for controllable LLM agents in social deduction games, comprising Predictor, Decider, and Discussor components.
- It uses reinforcement learning with a win rate-constrained decision chain reward mechanism, enabling agents to dynamically adjust their gameplay proficiency, and it is evaluated in the Werewolf game.
- DVM enables adaptive and balanced gameplay in social deduction games, opening new research avenues for controllable game agents.


---

[LLMs Model Non-WEIRD Populations: Experiments with Synthetic Cultural Agents](https://arxiv.org/abs/2501.06834)

- Synthetic Cultural Agents (SCAs): uses LLMs to create synthetic agents representing non-WEIRD populations. Includes web scraping, LLMs, RAG prompting to construct cultural profiles and uses these agents to classic behavioral experiments, demonstrating cross-cultural variability.
- Offers an effective and ethical method to pilot experiments and refine protocols for hard-to-reach populations for cross-cultural economic studies.


---

[AIOPSLAB: A HOLISTIC FRAMEWORK TO EVALUATE AI AGENTS FOR ENABLING AUTONOMOUS CLOUDS](https://arxiv.org/abs/2501.06706)

- AIOPSLAB: is a framework that deploys microservice cloud environments, injects faults, generates workloads, exports telemetry data, orchestrates components, and provides interfaces for interacting with and evaluating agents.
- AIOPSLAB includes Agent-Cloud Interface (ACI), a unified interface for agent-cloud interaction, and supports evaluation of LLM-based agents with a benchmark suite of 48 problems across different AIOps tasks.
- AIOPSLAB provides a holistic approach to evaluate AIOps agents in complex cloud environments, addressing the limitations of existing benchmarks.


---


#### 11th of January 2025

[The Internet of Large Language Models](https://arxiv.org/abs/2501.06471)

- The Internet of LLM: introduces an universal environment and sharing protocol of LLM training/knowledge exchange, which consists of LLM sharing protocol/LLM Universal environment/Agent Optimal Path Module/joint mining mechanism.
- Includes also planning-, reflection- and tool use-agents.


---

[Guided Code Generation with LLMs: A Multi-Agent Framework for Complex Code Tasks](https://arxiv.org/abs/2501.06625)

- Guided code generation: introduces a multi-agent framework for complex code tasks, which includes hierarchical decomposition, bottom-up code generation, and multi-agent validation.
- Leverages LLMs as fuzzy searchers and information retrievers. Mitigates LLM weaknesses in long sequential reasoning and context understanding.
- This framework enhances code generation capabilities and overcomes limitations of LLMs in compositional reasoning and context handling.


---

#### 10th of January 2025

[BioAgents: Democratizing Bioinformatics Analysis with Multi-Agent Systems](https://arxiv.org/abs/2501.06314)

- BioAgents: is a multi-agent system designed to assist users in bioinformatics pipeline design, development, and troubleshooting. which includes two specialized agents and a reasoning agent.
- First specialized agent was fine tuned with conceptual genomics tasks and the second specialized agent uses RAG related to workflow documentation.
- Reasoning agent uses self-ratings / threshold.
- Achieves performance comparable to human experts on conceptual genomics tasks. 


--- 


[Multi-Agent Collaboration Mechanisms: A Survey of LLMs](https://arxiv.org/abs/2501.06322)

- The survey reviews Multi-Agent Systems (MASs) collaboration mechanisms based on key dimensions.
- Framework includes actors, types, structures, strategies, and coordination protocols; reviews existing methodologies; investigates applications across diverse domains; identifies key lessons, open challenges, and potential research directions.


---

[How to Enable Effective Cooperation Between Humans and NLP Models: A Survey of Principles, Formalizations, and Beyond](https://arxiv.org/abs/2501.05714)

- Human-Model Cooperation: is a survey of principles, formalizations, and open challenges in human-model cooperation.
- It introduces a new taxonomy for categorizing human-model cooperation, identifies key research frontiers, and discusses associated challenges.


---


[OpenFOAMGPT: a RAG-Augmented LLM Agent for OpenFOAM-Based Computational Fluid Dynamics](https://arxiv.org/abs/2501.06327)

- OpenFOAMGPT: LLM-based agent tailored for OpenFOAM-centric computational fluid dynamics (CFD) simulations.
- It leverages GPT-4 and a chain-of-thought (CoT)-enabled o1 preview model, uses retrieval-augmented generation (RAG) pipeline, and includes an iterative correction loop.


---



#### 9th of January 2024


[Search-01: Agentic Search-Enhanced Large Reasoning Models](https://arxiv.org/abs/2501.05366)

- Search-01: is a framework that enhances Large Reasoning Models (LRMs) with an agentic retrieval-augmented generation mechanism and a Reason-in-Documents module.
- It integrates an agentic search workflow, enables dynamic retrieval of external knowledge, and uses a separate module to analyze retrieved information.
- This approach enhances the trustworthiness and applicability of LRMs in complex reasoning tasks.


---

[OpenOmni: Large Language Models Pivot Zero-shot Omnimodal Alignment across Language with Real-time Self-Aware Emotional Speech Synthesis](https://arxiv.org/abs/2501.04561)

- OpenOmni: Introduces three-stage training method combining speech-to-text generation/image-to-text generation/speech generation, which results SOTA-level omnimodal LLM.


---

[Emergence of human-like polarization among large language model agents](https://arxiv.org/abs/2501.05171)

- Introduces a networked system, which simulates social interactions of thousands of LLM-based agents, including capabilities of establishing social relationships, communicating, and forming opinions on political issues. LLM agents form spontaneously human-like social networks (echo chamber).
- LLM agents exhibit human-like polarization and can be used to study interventions, offering insights into managing polarization in real-world scenarios.
- Self-regulation helps to reduce inconsistencies in the opinions, which leads to more balanced polarization patterns. Openmindedness and diverse interaction limit polarization effect.


---

[NSChat: A Chatbot System To Rule Them All](https://arxiv.org/abs/2501.05541)

- NSChat: introduces a web-based chatbot system designed for neuroscience research.
- NSChat is built using React framework, it is customizable, flexible, and allows integration of various LLMs, it also includes a logging mechanism for user interactions.


---

[Emergence of human-like polarization among large language model agents](https://arxiv.org/abs/2501.05171)

- LLM (Large Language Model) agents framework: simulates a networked system of agents that establish social relationships, communicate, and form opinions on political issues.
- Framework includes self-expression, communication, and opinion update stages; agents develop human-like polarization, homophilic clustering, and echo chamber effects; self-regulation strategy reduces self-inconsistency.
- This framework provides a valuable platform for exploring strategies to mitigate polarization and promote inclusive political conversations.


---


[LearningFlow: Automated Policy Learning Workflow for Urban Driving with Large Language Models](https://arxiv.org/abs/2501.05057)

- LearningFlow: is an automated policy learning workflow for urban driving that uses multiple LLM agents.
- It includes curriculum sequence generation and reward generation processes, supported by analysis agents, and enhances sample efficiency.
- This framework automates policy learning across complex driving tasks and reduces reliance on manual reward function design.


---

[OVO-Bench: How Far is Your Video-LLMs from Real-World Online Video Understanding?](https://arxiv.org/abs/2501.05510)

- OVO-Bench (Online-VideO-Benchmark): is a novel video benchmark for evaluating online video understanding capabilities of Video-LLMs.
- It includes 644 videos, 2800 meta-annotations, and 12 tasks across three categories: Backward Tracing, Real-Time Visual Perception, and Forward Active Responding.
- This benchmark highlights the importance of temporal awareness for advanced online video understanding.


---

#### 9th of January 2025

[Transformer-Squared: Self-adaptive LLMs](https://arxiv.org/abs/2501.06252)

- Transformer<sup>2</sup>: A self-adaptation framework that adapts LLMs (Large Language Models) for unseen tasks in real-time by selectively adjusting the singular components of their weight matrices.
- Two-pass mechanism, task-specific expert vectors, reinforcement learning, dynamic mixing, targeted behavior, outperforming LoRA, fewer parameters, greater efficiency, versatility across different LLM architectures and modalities.
- Represents a significant leap forward, offering a scalable, efficient solution for enhancing the adaptability and task-specific performance of LLMs, paving the way for truly dynamic, self-organizing AI systems.


---

[On Corrigibility and Alignment in Multi Agent Games](https://arxiv.org/abs/2501.05360)

- Multi Agent Corrigibility Games: introduces a framework for studying corrigibility in systems comprised of multiple autonomous agents.
- Framework models a 2-player game with human supervision, uses Bayesian games to introduce uncertainty over human beliefs, and analyzes specific cases like two-player corrigibility and adversary settings.
- This framework provides insights into designing corrigible multi-agent systems, even in the face of human irrationality.


---


#### 8th of January 2025

[rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking](https://arxiv.org/abs/2501.04519)

- rStar-Math: A framework demonstrating that small language models (SLMs) can rival or surpass the math reasoning capability of OpenAI models through deep thinking. Iteratively improves through self-evolution generating millions of new math reasoning trajectories in each round.
- Uses Monte Carlo Tree Search (MCTS) with self-annotated Q-values. rStar-Math used 747k math word problems, took the final correct answer and then rolled out 16 MCTS-based step-by-step verified reasoning trajectories, to categorize problems by difficulty level (easy/medium/hard) based on ratio of correct solutions. Hard problems are assigned with an additional extra 16 rollouts. The policy SLM is trained using all the step-by-step trajectories with their Q-values.
- The importance of this work lies in showing that smaller language models can achieve state-of-the-art math reasoning, rivaling larger models, through a novel self-evolutionary process.
- Includes Code-Augmented CoT, where step-by-step reasoning trajectories generated are verified with code execution for correctness.


---


[Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Thought](https://arxiv.org/abs/2501.04682)

- Meta-CoT (Meta Chain-of-Thought): A novel framework that extends traditional CoT by explicitly modeling the underlying reasoning process required to arrive at a particular CoT.
- Inspired by Cognitive Science's dual-process theory, non-linear, iterative, latent process of exploration and verification, in-context search, process supervision, synthetic data generation, search algorithms, instruction tuning, reinforcement learning, scaling laws, verifier roles, novel reasoning algorithms, meta-reinforcement learning.
- This work provides a theoretical and practical roadmap to enable Meta-CoT in LLMs, paving the way for more powerful and human-like reasoning in artificial intelligence.


---

[URSA: Understanding and Verifying Chain-of-thought Reasoning in Multimodal Mathematics](https://arxiv.org/abs/2501.04686)

- URSA (Understanding and Verifying Chain-of-thought Reasoning in Multimodal Mathematics): A framework for enhancing the mathematical reasoning capabilities of Multimodal Large Language Models (MLLMs) through a three-module synthesis strategy and a novel dual-view process supervision data synthesis method.
- Integrates CoT distillation, trajectory-format rewriting, format unification, MMathCoT-1M dataset, DualMath-1.1M dataset, URSA-7B model, URSA-RM-7B model, test-time scaling, process annotation, out-of-distribution (OOD) verification.
- This work significantly enhances MLLMs' potential in mathematical reasoning, achieving state-of-the-art performance on multiple multimodal mathematical benchmarks and demonstrating robust supervision abilities.


---

[Retrieval-Augmented Generation with Graphs (GraphRAG)](https://arxiv.org/abs/2501.00309)

- GraphRAG: is a framework for retrieval-augmented generation using graph-structured data.
- It defines key components like query processor, retriever, organizer, generator, and data source; reviews techniques tailored to different domains; discusses research challenges and future directions.
- This framework provides a comprehensive overview of GraphRAG for information retrieval, data mining, and machine learning communities.


---

[Agent Laboratory: Using LLM Agents as Research Assistants](https://arxiv.org/abs/2501.04227)

- Agent Laboratory: An autonomous research-framework with LLMs for completing the entire research process (literature review/experimentation/report writing), from literature review to experimentation (plan formulation, data preparation and running experiments) and report writing (report writing and report refinements).
- Human-in-the-loop, research idea as input and code repository/research report as output. Producs SOTA-level performance and reduces research expensesn.
- The framework has the potential to accelerate scientific discovery by enabling researchers to focus on creative ideation rather than low-level coding and writing.
- Includes postdoc/ph student/sw engineer/ml engineer/professor-agents. Includes mle-solver-tool capable of solving ML-tasks, which iteratively improves research code.
- Automated evaluation of the framework significantly overestimated the accurate scoring. Copilot mode was found useful by the human testers. Includes prompts.


---

[Supervision-free Vision-Language Alignment](https://arxiv.org/abs/2501.04568)

- SVP (Supervision-free Visual Projection): A novel framework that enhances vision-language alignment in VLMs without relying on curated data or preference annotation.
- Leverages self-captioning, pre-trained grounding model, feedback mechanism, elicits latent information, improves vision-language alignment.
- The framework significantly improves performance across various tasks, including captioning, referring, visual question answering, multitasking, hallucination control, and object recall, highlighting its potential to advance multimodal AI systems.


---

#### 7th of January 2025

[Reasoning-Enhanced Self-Training for Long-Form Personalized Text Generation](https://arxiv.org/abs/2501.04167)

- REST-PG (Reasoning-Enhanced Self-Training for Personalized Text Generation): Introduces a multi-stage framework designed to teach LLMs reasoning over personalized context through Expectation-Maximization Reinforced Self-Training.
- Generates reasoning paths based on the user's past preferences, background knowledge, and writing style
- The framework enhances LLMs' ability to generate personalized text, outperforming state-of-the-art baselines by 14.5% on average.


---


#### 6th of January 2025

[Structured dynamics in the algorithmic agent](https://www.biorxiv.org/content/10.1101/2023.12.12.571311v3.full.pdf)

- KT's algorithmic agent: introduces an information processing system that interacts with the World, including a Modeling Engine (runs model, predicts), Comparator (evaluates prediction error), Updater (improves model), Objective Function (guides actions), and Planning Engine (simulates, selects plans).
- The agent utilizes compressive world models to track structured data from the environment, aiming to maximize its objective function.
- World tracking constraints, monitored by the Comparator, drive the agent's internal dynamics to mirror the symmetries present in the world data, leading to reduced manifold structures.


---


[Large language models for artificial general intelligence (AGI): A survey of foundational principles and approaches](https://arxiv.org/abs/2501.03151)

- Introduces a survey about AGI concepts and achieving AGI with LLMs. Includes list of memory types used with LLMs: sensory/working/semantic/episodic/procedural. Lists aspects of embodiment as: goal-awareness/self-awareness/situatedness/deliberate action. 


---

[CALM: Curiosity-Driven Auditing for Large Language Models](https://arxiv.org/abs/2501.02997)

- CALM (Curiosity-driven Auditing for LLMs): Introduces intrinsically motivated RL based on curiousity to finetune LLM as an auditor agent, to discover harmful/biased input/output pairs in the LLM. Includes token-level intrinsic bonus. Uses curiosity-driven exploration to navigate efficiently the prompt space, such as discover specific celebrity names.


---

[RTLSquad: Multi-Agent Based Interpretable RTL Design](https://arxiv.org/abs/2501.05470)


- RTLSquad: is a novel LLM-Based Multi-Agent system for interpretable RTL code generation.
- It divides the design process into exploration, implementation, and verification & evaluation stages, managed by specialized agent squads, generating optimized RTL code through inter-agent collaboration, and providing decision interpretability through the communication process.
- This framework enhances the ability to generate functionally correct RTL code and optimize PPA performance, while also providing decision paths.


---


#### 5th of January 2025


[LLMs Help Alleviate the Cross-Subject Variability in Brain Signal and Language Alignment](https://arxiv.org/abs/2501.02621)

- Decodes EEG scans to text with subject-independent semantic features for Brain-Computer Interfaces (BCIs).  Introduces EEG embeddings.
- Includes cross-subject generalization (addresses the issue of variability in brain anatomy between humans/neural dynamics/signal), zero-shot and comprehensive evaluation.  


---

[DeepSeek LLM: Scaling Open-Source Language Models with Longtermism](https://arxiv.org/abs/2401.02954)

- DeepSeek LLM: is an open-source large language model framework with 7B and 67B configurations.
- It uses a 2 trillion token dataset, multi-step learning rate scheduler, and includes SFT and DPO stages.
- This framework achieves superior performance compared to LLaMA-2 and GPT-3.5 in various benchmarks.


---


#### 4th of January 2025

[Table as Thought: Exploring Structured Thoughts in LLM Reasoning](https://arxiv.org/abs/2501.02152)

- Table as Thought: organizes reasoning within a tabular schema, where rows represent sequential thought steps and columns capture critical constraints and contextual information.
- Framework is inspired by cognitive neuroscience theories, reasoning process iteratively populates the table until self-verification ensures completeness and correctness, excels in planning tasks and mathematical reasoning.
- This work provides a novel exploration of refining thought representation within LLMs, paving the way for advancements in reasoning and AI cognition.


---

[Hallo3: Highly Dynamic and Realistic Portrait Image Animation with Diffusion Transformer Networks](https://arxiv.org/abs/2412.00733)

- Hallo3: The first application of a pretrained transformer-based video generative model for highly dynamic, realistic portrait animation.
- Identity reference network, 3D VAE, transformer layers, speech audio conditioning, motion frame mechanisms, DiT-based video generation, video extrapolation.
- Addresses challenges of non-frontal perspectives, dynamic objects, and immersive backgrounds in portrait animation.


---

[Thinking with Many Minds: Using Large Language Models for Multi-Perspective Problem-Solving](https://arxiv.org/abs/2501.02348)

- Replicates the concept of "Wisdom of the Crowd" with LLMs using synthetic deliberation. 
- Generates multiple agents, each with dinstinct perspective to a problem. Agents simulate arguments and counter-arguments from their perspective. 
- Agents explore in parallel the problem space using its own perspective. The integration mechanism adjusts agents positions based on proposals/evaluations of others controllable with influence parameter alpha. The iterative deliberation repeats multiple rounds until consensus is reached. 


---

[UAVs Meet LLMs: Overviews and Perspectives Toward Agentic Low-Altitude Mobility](https://arxiv.org/abs/2501.02341)

- Review systematically integration of LLMs with UAVs (Unmanned aerial vehicles).
- Proposes roadmap towards agentic UAVs. Includes github-repository with links to papers/approaches around LLM-based UAV systems.


---

#### 3rd of January 2025


[SDPO: Segment-Level Direct Preference Optimization for Social Agents](https://arxiv.org/abs/2501.01821)

- Introduces SDPO (Segment-Level Direct Preference Optimization)-fine tuning, which aligns the LLM to key segments in multi-turn conversation. 
- Addresses goal-completion in multi-turn conversation.


---

[AgentRefine: Enhancing Agent Generalization through Refinement Tuning](https://arxiv.org/abs/2501.01702)

- AgentRefine: Uses a strong LLM to simulate interactive role-playing, with the model acting as both Dungeon Master and player. A verifier checks each action for errors, providing feedback that allows the model to refine its actions until it achieves the correct result. This iterative process, with its corrected action sequences, trains the system to explore viable actions and generalize to new scenarios.

---

[Multi-Agent Conversational Online Learning for Adaptive LLM Response Identification](https://arxiv.org/abs/2501.01849)

- MACO (Multi-Agent Conversation Online learning for adaptive LLM response identification): Introduces near-optimal cumulative regret with multiple local agents to identify, which is the most optimal LLM response to serve for the particular user, even when new user.


---

[MoColl: Agent-Based Specific and General Model Collaboration for Image Captioning](https://arxiv.org/abs/2501.01834)

- MoColl: Introduces LLM-agent based framework for image captioning with specialised VQA model. Includes warm-up stage and agent-guided tuning stage.


---

#### 2nd of January 2025

[ProgCo: Program Helps Self-Correction of Large Language Models](https://arxiv.org/abs/2501.01264)

- ProgCo (Program-driven Self-Correction): A self-correction framework that uses self-generated and self-executed verification pseudo-programs to improve reasoning in large language models. Incluces ProgVe (Program driven Verification) and ProgRe (Program driven Refinement).
- This framework enhances the ability of large language models to self-correct without external feedback, particularly in complex reasoning tasks.


---

[PREDICTING THE PERFORMANCE OF BLACK-BOX LLMS THROUGH SELF-QUERIES](https://arxiv.org/abs/2501.01558)

- QueRE (Question Representation Elicitation): A framework to extract features of LLMs (Large Language Models) in a black-box manner by using follow-up prompts and taking the probabilities of different responses as representations to train reliable predictors of model behavior.
- Low-dimensional representations, linear model, instance level, model performance, hidden state, question-answering, adversarial system prompt, model architectures, model sizes.
- The framework can be used to predict model performance, detect models influenced by adversarial system prompts and distinguish between different model architectures and sizes.


---


[A3: Android Agent Arena for Mobile GUI Agents](https://arxiv.org/abs/2501.01149)

- A3 (Android Agent Area): Introduces benchmark to evaluate mobile GUI agents, which focuses on practical tasks, larger action spaces and automated LLM-based evaluation. 
- A3 consists of controller (gets/controls states of the device), evaluator (final rating) and translator (between device device function and the agent message).

---


[Dynamic Scaling of Unit Tests for Code Reward Modeling](https://arxiv.org/abs/2501.01054)

- CodeRM-8B: A lightweight unit test generator with dynamic scaling mechanism, which adapts number of unit tests based on problem difficulty. The unit tests are used in validating generated code by the LLM as reward signal. 
- The framework significantly improves performance of code generation across various models and benchmarks by enhancing the quality of the reward signal.


---


---


[3D-LLaVA: Towards Generalist 3D LMMs with Omni Superpoint Transformer](https://arxiv.org/abs/2501.01163)

- 3D-LLaVa: Introduces 3D multi modal LLM with point clouds/text instruction/visual prompt as input and generates text output and 3D mask with Omni Superpoint Transformer (OST).
- 3D-LLaVa handles 3D vision-centric dialogue.
- OST includes visual features selection, visual prompt encoding and 3D mask generation. 


---

[Harnessing Multi-Agent LLMs for Complex Engineering Problem-Solving: A Framework for Senior Design Projects](https://arxiv.org/abs/2501.01205)

- Proposes multi-agent LLM framework for engineering design projects consisting of problem formulation/breadth & depth/ambiguity & uncertainty/system complexity/technical innovation & risk management/societal & ethical consideration/methodology & approach/compherensive evaluation-agents.
- Each agent consists of description, task, objective and evaluation points.


---


[Embodied AI-Enhanced Vehicular Networks: An Integrated Large Language Models and Reinforcement Learning Method](https://arxiv.org/abs/2501.01141)

- Incorporates embodied AI framework, which consists of semantic data processing with LLaVa-agent (extracts semantics from image data captured by the vehicle), Data transmission optimization (balances bandwidth utilization and quality of experience) and Enhanced decision making with Deep RL with GAE-PPO.


---

[MDSF: Context-Aware Multi-Dimensional Data Storytelling Framework based on Large language Model](https://arxiv.org/abs/2501.01014)

- MDSF (Multidimensional Data Storytelling Framework): Automatess data analysis and storytelling. Includes data preprocessing steps, fine tuned LLMs, LLM agents.

---


[Toward Inclusive Educational AI: Auditing Frontier LLMs through a Multiplexity Lens](https://arxiv.org/abs/2501.03259)

- Suggests two strategies to improve LLMs multiplexity (diverse cultural viewpoints) over WEIRD (western/educated/industrialized/rich/democratic): system prompt with diverse cultural perspectives and multi-agent system with agents with different cultural views. Sentiment analysis is used to review cultural resonance. 

---

[PSYCHE: A Multi-faceted Patient Simulation Framework for Evaluation of Psychiatric Assessment Conversational Agents](https://arxiv.org/abs/2501.01594)

- PSYCHE: Introduces an LLM-based psychiatric evaluation framework by comparing the predicted values of psychiatric elements (Construct-PACA) against the actual values (Construct-SP). The actual values are simulated patient data generated with a multi-faceted construct (MFC). 
- The framework guarantees clinical relevance, ethical safety, cost efficiency, and quantitative evaluation by simulating psychiatric patients with detailed profiles, histories, and behaviors.


---


[BoxingGym: Benchmarking Progress in Automated Experimental Design and Model Discovery](https://arxiv.org/abs/2501.01540)

- Introduces BoxingGym-benchmark, reviews LLMs capabilities to design and model discovery: collect data to test scientific theory and propose/update scientific theories through 10 environments. Introduces metric called EIG.
- Expected information gain (EIG) measures an experiment's informativeness by testing if one scientific agent's model explanation enables another to make accurate environmental predictions.


---


[General Information Metrics for Improving AI Model Training Efficiency](https://arxiv.org/abs/2501.02004)

- GIME (General Information Metrics Evaluation): A novel framework for optimizing AI model training by evaluating datasets using 11 general information metrics before training begins.
- Objective Information Theory (OIT), pre-training assessment, data selection, training efficiency, reduced costs, model-agnostic, domain-independent.
- This framework improves AI model training efficiency and reduces resource consumption while preserving model performance across various domains.


---


#### 1st of January 2025

[Agentic Systems: A Guide to Transforming Industries with Vertical AI Agents](https://arxiv.org/abs/2501.00881)

- Reviews transition from SaaS to context-aware, adaptive systems handling dynamic environments through vertical agents.
- Identifies core modules of LLM agents: memory/reasoning engine/cognitive skills/tools. 
- Author categorises agentic systems into: task-specific, multi-agent and human augmented agent systems.


---


[Large Language Model Based Multi-Agent System Augmented Complex Event Processing Pipeline for Internet of Multimedia Things](https://arxiv.org/abs/2501.00906)

- Introduces multi-agent framework for complex event processing of video queries(think TikTok/Youtube as examples) with AutoGen and Kafka brokers (real time data streams).
- Consists of conversable/assistant/user proxy/LLM backend/human backed/tool backed-agents.


---

[Interactionalism: Re-Designing Higher Learning for the Large Language Agent Era](https://arxiv.org/abs/2501.00867)

- Introduces Interactionalism-framework focuses on interactional intelligence to learn more personalized/social/non-linearly way, instead of monological way. 
- Proposes usage of dialogue-agents in education, such as tutors, teaching assistants, evaluators, guides and mentors. 


---


[LLM-Powered Multi-Agent System for Automated Crypto Portfolio Management](https://arxiv.org/abs/2501.00826)
- Introduces multi-agent framework for cryptocurrency investing with intrateam and interteam collaboration and multi modality. Consists of expert training module and multi-agent investment module. 
- Expert training module uses data/literature-agents to feed historical data and investment literature. Explanation-agents process this information to generate high-quality prompts to fine tune investment agents. 
- Multi-agent investment module consists of data-agent fetching real-time data to market-agents and crypto agents. Market agents includes two expert agents to analyze news/market factors to predict market trends and determining cash-crypto allocation. Crypto-agents includes two specialized agents to analyze crypto-specific factors and candlestick charts to make crypto selection decisions. Trading agents finally act with a trading API to execute the final portfolio strategy.
 

---

[Beyond Text: Implementing Multimodal Large Language Model-Powered Multi-Agent Systems Using a No-Code Platform](https://arxiv.org/abs/2501.00750)

- Proposes design and implementation of multi modal and multi-agent framework with LLMs. Includes multi modal inputs (text/audio/video/image), multi-agent layer (includes supervisory-agent and RAG/image analysis/audio generation/image generation/video generation- worker agents), process layer (vector db and modality specific models) and the output layer (text/audio/video/image).
- Supervisor agent controls sequence of tasks, distributes tasks, manages output of worker agents, tnterprets outputs and makes decisions about next steps in the sequence.


---

#### 31st of December 2024

[Enhancing LLM Reasoning with Reward-guided Tree Search](https://arxiv.org/abs/2411.11694)

- STILL-1 (Slow Thinking with LLMs): A reward-guided tree search framework to enhance the reasoning capabilities of LLMs.
- Integrates policy model, reward model, and search algorithm; policy model navigates a dynamically expanding tree; guided by a trained reward model.
- Improves LLMs' performance on complex mathematical reasoning tasks by trading test time for improved accuracy.


---

[MAIN-RAG: Multi-Agent Filtering Retrieval-Augmented Generation](https://arxiv.org/abs/2501.00332)

- Main-RAG: Introduces multi-agent framework, where LLM-agents collaboratively filter and score retrieved documents.
- Introduces adaptive filtering, which dynamically adjusts relevance filtering threshold.
- Includes three agents: predictor (infers answers based on retrieved documents), judge (scores filtering and ordering) and final-predictor (generates final answer based on filtered and ordered documents). 
- Includes system instruction prompts.


---

[Enhancing LLM Reasoning with Multi-Path Collaborative Reactive and Reflection agents](https://arxiv.org/abs/2501.00430)

- RR-MP (Reactive and Reflection agents with Multi-Path Reasoning): Improves reasoning capability of LLMs in complex scientific tasks.
- Consists of reactive and reflection agents collaborating together to improve accuracy/avoid degeneration-of-thoughts. 
- Reactive agent receives information from external environment, decomposes it into sub-tasks, then stores them in the database.
- Reflective agent analyzes sub-task it executes, offering suggestions or critiques. This feedback loop allows the reactive agent to refine its reasoning and complete the scientific process.

---

[Embodied VideoAgent: Persistent Memory from Egocentric Videos and Embodied Sensors Enables Dynamic Scene Understanding](https://arxiv.org/abs/2501.00358)
 
- Embodied VideoAgent: Introduces VLM-based Embodied VideoAgent, which constructs scene memory from both egocentric video and embodied sensory inputs.
- Includes persistent object memory, using VLM (depth maps / camera poses).
- Automatically updates memory as actions / activities over objects are perceived.




---

[Enabling New HDLs with Agents](https://arxiv.org/abs/2501.00642)

- HDLAgent: Introduces LLM-based agent to support code generation for underrepresented HDLs (Hardware Description Languages).


---

[VideoRefer Suite: Advancing Spatial-Temporal Object Understanding with Video LLM](https://arxiv.org/abs/2501.00599)

- VideoRefer-model: Improves Video-LLMs fine-grained spatial and temporal detail understanding in videos, which facilitates more precise object descriptions, more detailed event analysis, and enhanced predictive reasoning in dynamic environments using masked object features.
- VideoRefer-model consists of VideoLLaMA 2.1 as the foundation and a novel unified spatial-temporal object encoder that merges cross-frame token similarities.
- Includes VideoRefer-dataset and VideoReferBench-benchmark.


---

[LLM-MedQA: Enhancing Medical Question Answering through Case Studies in Large Language Models](https://arxiv.org/abs/2501.05464)

- LLM-MedQA: is a multi-agent medical question-answering system that incorporates similar case generation within a multi-agent architecture.
- It leverages Llama3.1:70B model, includes question-specific analysis, option analysis, and case generation agents, and uses zero-shot learning.
- This framework enhances performance on the MedQA dataset and improves interpretability and reliability in medical question answering.


---

#### 30th of December 2024

[Aviary: training language agents on challenging scientific tasks](https://arxiv.org/abs/2412.21154)

- Defines Language Decision Process (LDP). LDP is framed as Partially-Observable Markov Decision Process (POMDP), where actions only consist of the ones with the external environment.
- Introduces Language agent training framework: Aviary. Includes implementation in 3 scientific domain tasks. 
- Builds language agents as stochastic computation graphs (SCG).

---

[Distributed Mixture-of-Agents for Edge Inference with Large Language Models](https://arxiv.org/abs/2412.21200)

- Introduces Distributed Mixture-of-Agents, where multiple LLMs collaborate on various edge devices with decentralized gossip algorithm.
- Does not rely in centralized server. 

---

[Exploring and Controlling Diversity in LLM-Agent Conversation](https://arxiv.org/abs/2412.21102)

- APP (Adaptive Prompt Pruning): Controls diversity of the LLM-agent conversation through adjusting lambda-variable. 
- The lambbda variable adjusts diversity by increasing/decreasing details about: current dialogue/history dialogue/environment/profile/memory.

---

[Plancraft: an evaluation dataset for planning with LLM agents](https://arxiv.org/abs/2412.21033)

- Introduces Plancraft-benchmark to evaluate VLMs and LLMs planning capabilities and ability to decide in Minecraft craftting GUI, if the model is able to identify task as unsolvable (intentionally).
- Identifies, that success rate alone is poor metric in real world tasks.



---


#### 25th of December 2024

[Probabilistic Mission Design in Neuro-Symbolic Systems](https://arxiv.org/abs/2501.01439)

- ProMis (Probabilistic Mission Design): ProMis helps drones understand where they can and cannot go by combining different types of information, like maps and sensor data, with rules and regulations, such as no-fly zones. Refers with mission landscape to safest and most legal paths.
- Combines formal reasoning with probabilistic inference. Uses LLM to convert instructions into ProMis code and ChangeFormer for perception of satellite images.


---


#### 24th of December 2024

#### 24.12.2024

[A Novel Task-Driven Method with Evolvable Interactive Agents Using Event Trees for Enhanced Emergency Decision Support](https://arxiv.org/abs/2501.06193)

- EvoTaskTree: is a task-driven method with evolvable interactive agents using event trees for emergency decision support.
- Framework integrates task executors and task validators powered by large language models (LLMs), leverages insights from event tree analysis, and includes three crucial tasks: initiating event subevent analysis, event tree header event analysis, and decision recommendations.
- This approach enhances rapid formulation of emergency decision-making and outperforms existing approaches.


---

[Multi-Agents Based on Large Language Models for Knowledge-based Visual Question Answering](https://arxiv.org/abs/2412.18351)

- Introduces multi-agent framework consisting of three level of agents collaborating to provide answer: junior, senior and manager. Final answer is determined through voting. Each agent uses planning and tools (knowledge base / LLM knowledge).

---


[VLABench: A Large-Scale Benchmark for Language-Conditioned Robotics Manipulation with Long-Horizon Reasoning Tasks](https://arxiv.org/abs/2412.18194)

- VLABench-benchmark: Evaluates VLA models (Vision-Language Action models). Focuses on tasks requiring mesh & texture understanding, spatial understanding, semantic conversation cognition, common sense & applying real world knowledge, physical laws understanding and long horizon multi-step reasoning.


---

[INVESTORBENCH: A Benchmark for Financial Decision-Making Tasks with LLM-based Agent](https://arxiv.org/abs/2412.18174)

- Investorbench-benchmark: Evaluates LLMs capability for financial decision making. 


---

[Decentralized Intelligence in GameFi: Embodied AI Agents and the Convergence of DeFi and Virtual Ecosystems](https://arxiv.org/abs/2412.18601)

- Introduces decentralized GameFI-ecosystem with LLM-agents based on Ethereum-blockchain.


---


[Automated Code Review In Practice](https://arxiv.org/abs/2412.18531)

- Reviews automated code reviews, which led to longer average pull request closer time.  


---

[Large Language Model guided Deep Reinforcement Learning for Decision Making in Autonomous Driving](https://arxiv.org/abs/2412.18511)

- LGDRL (Language Guided Deep Reinforcement Learning): Introduces LLM-based autonomous driving system. 
- DRL agent learns from LLM-based driving expert-agent (prompted with prompt generator), when the LLM-based driving expert finds necessary to intervene DRL agent actions.


---


[3DGraphLLM: Combining Semantic Graphs and Large Language Models for 3D Scene Understanding](https://arxiv.org/abs/2412.18450)

- 3DGraphLLM: Improves LLMs understanding of 3D scenes by creating 3D scene graph representation (think graph, where arrows point, if object is right/left/front/behind) from set of point clouds (object input).

---

[Explainable Multi-Modal Data Exploration in Natural Language via LLM Agent](https://arxiv.org/abs/2412.18428)

- XMODE: Uses LLM to decompose (converts into simpler sub-questions and translates into workflows) user queries into SQL / image analysis.
- Includes planning & expert model allocation/execution & self-debugging/decision making/expert models & tools/data lake. 


---

[Muse: A Multimodal Conversational Recommendation Dataset with Scenario-Grounded User Profiles](https://arxiv.org/abs/2412.18416)

- Introduces MUSE-dataset with conversations centered around clothing-domain by using multi-agent framework to generate real world-scenarios (scenario-grounded user profile generator/simulated conversation generator/conversation optimizer). 


---

[Defining and Detecting the Defects of the Large Language Model-based Autonomous Agents](https://arxiv.org/abs/2412.18371)

- Agentable: Introduces static analysis tool to detect defects in code with LLM-based agents and Code Property Graphs (identifies specific code patterns/analyses descriptions). Includes AgentSet-dataset.
- Includes pre-processing, defect detection (code abstraction/LLM invocation/semantic enrichment/detect oracles engineeering), and defect reporting-modules.

---

#### 22.12.2024

[Imitate, Explore, and Self-Improve: A Reproduction Report on Slow-thinking Reasoning Systems](https://arxiv.org/abs/2412.09413)

- STILL-2 (Slow Thinking with LLMs): A framework to train reasoning models using a three-phase approach: imitation, exploration, and self-improvement.
- Initial fine-tuning with distilled long-form thought data, exploration of challenging problems by generating multiple rollouts, iterative refinement of the training dataset.
- The framework demonstrates competitive performance compared to industry-level reasoning systems, highlighting the potential of slow-thinking in enhancing complex reasoning capabilities of LLMs.


---


#### 21st of December 2024

[OpenAI o1 System Card](https://arxiv.org/abs/2412.16720)

- o1 model series: Large-scale reinforcement learning models trained to reason using chain of thought, improving safety and robustness.
- Next model in series is OpenAI o1, faster version is OpenAI o1-mini, effective at coding, "thinks before it answers", long chain of thought before responding, refine thinking process, try different strategies, recognize mistakes.
- Reasoning allows models to follow safety guidelines, provide helpful answers, resist attempts to bypass safety rules, avoid producing unsafe content, and reach state-of-the-art performance on certain benchmarks.


---

#### 20th of December 2024

[Deliberative Alignment: Reasoning Enables Safer Language Models](https://arxiv.org/abs/2412.16339)

- Deliberative Alignment: A training approach that "directly teaches" LLMs to explicitly reason through (safety) specifications before producing an answer.
- Claims, that reasoning using explicitly specified policies in general, enable scaling alignment. Apart, imrpoves model safety, robustness to jailbreaks, out-of-distribution generalization, and reduces overrefusal rates.
- Two core stages: supervised fine-tuning on (prompt, CoT, output) examples, reinforcement learning; uses context distillation; includes a "judge" LLM for reward signal.
- Assigns deliberatedly a varied amount of compute to CoT, which improves performance in hard evals.
- In first stage, the model is fine tuned with SFT to reason about the (safety) specification within its CoT using examples dataset generated with context distillation with o-type model, where the CoT references the specification.
- Second stage trains with high-compute RL the model to think effectively by providing reward signal using a judge LLM with access to the (safety) instructions.



---

[Autonomous chemical research with large language models](https://www.nature.com/articles/s41586-023-06792-0)

- Coscientist: Introduces a autonomous chemical research system for autonomously designing, planning, and performing complex scientific experiments 
- Uses modular approach consisting of: Google, Planner (LLM), Python, retrieval of documentation and execution of experiments.
- Capabilities include planning chemical syntheses, optimizing reactions, and controlling liquid-handling robots.


---


[Offline Reinforcement Learning for LLM Multi-Step Reasoning](https://arxiv.org/abs/2412.16145)

- OREO (Offline REasoning Opyimization): improves multi-step reasoning with offline RL.
- Iterative OREO improves consistently with additional training rounds.

---

#### 19th of December 2024

[Disentangling Reasoning Tokens and Boilerplate Tokens For Language Model Fine-tuning](https://arxiv.org/abs/2412.14780)

- Reasoning-highlighted Finetuning (RFT): Highlights reasoning tokens from boilerplate tokens (format and connecting tokens less critical for the task). Adds larger weight to reasoning tokens.
- Introduces SHAD (Shuffle-Aware Discriminator): automatic, adaptive token discrimination. 


---

[On Verbalized Confidence Scores for LLMs](https://arxiv.org/abs/2412.14737)

- Claims, that LLMs can be prompted to provide caliberated confidence scores.

---

[Agent-SafetyBench: Evaluating the Safety of LLM Agents](https://arxiv.org/abs/2412.14470)

- Agent-SafetyBench-benchmark evaluates LLM-agents safety. Agents tested achieved below 60% pass score.
- LLM-agents lack currently robustness and risk awareness.


---

[TheAgentCompany: Benchmarking LLM Agents on Consequential Real World Tasks](https://arxiv.org/abs/2412.14161)

- TheAgentCompany-benchmark: evaluates AI agents capacity to perform long-sequence tasks in real world-like environment as a digital worker: arranging meetings, writing code, screening resumes, communicating (simulates communication between agents), planning and administrative work. Best agent completed 24% of tasks.
- Generates tasks in a self-contained environment with internal websites and data similar to used by SW companies.


---

#### 18th of December 2024

[Inference Scaling Flaws: The Limits of LLM Resampling with Imperfect Verifiers](http://arxiv.org/abs/2411.17501)

- LLM Resampling: explores the limits of using resampling with imperfect verifiers for improving language model accuracy.
- The framework shows that imperfect verifiers, like unit tests, lead to false positives, limiting the effectiveness of resampling, and that weaker models generalize worse than stronger models, even with infinite compute budget.
- This research highlights the importance of developing accurate verifiers and questions the effectiveness of inference scaling with imperfect verifiers.


---


#### 17th of December 2024

[AI PERSONA: Towards Life-long Personalization of LLMs](https://arxiv.org/abs/2412.13103)

- AI Persona: proposes, that LLMs should continuously adapt to diverse set of users via personalization. 
- Introduces a framework for life-long personalization of LLMs through learnable and dynamically updated dictionaries, which are updated based on interaction between user and the LLM.


---

#### 13th of December 2024

[Byte Latent Transformer: Patches Scale Better Than Tokens](https://arxiv.org/abs/2412.09871)

- Byte Latent Transformer (BLT): is a byte-level LLM architecture that encodes bytes into dynamically sized patches to efficiently allocate compute by varying the amount of compute based on the entropy of the next byte prediction.
- BLT segments patches based on next-byte entropy, allocates more compute where data complexity increases, and improves training and inference efficiency.
- BLT shows better scaling than tokenization-based models by simultaneously growing both patch and model size.


---

#### 11th of December 2024

[A Multimodal Social Agent](https://arxiv.org/abs/2501.06189)

- MuSA: is a multimodal LLM-based agent designed for analyzing text-rich social content.
- MuSA includes reason-, plan-, optimize-, criticize-, refine- and act-LLM-based units, is model-agnostic, and optimized for social content analysis tasks.
- MuSA can automate and improve social content analysis, aiding decision-making processes across various applications.


---


#### 10th of December 2024

[CePO: Empowering Llama with Reasoning using Test-Time Compute](https://cerebras.ai/blog/cepo)
- CePO (Cerebras Planning and Optimization): Adds sophisticated reasoning capabilities to the Llama family of models using test-time computation techniques.
- CePO enables Llama-3.3 70B to surpass Llama-3.1 405B in accuracy across coding, math, and reasoning tasks.
- CePO's step-by-step reasoning, comparison instead of verification, and intuitive output format improve Llama's performance.
- CePO achieves interactive performance of approximately 100 tokens/second on Cerebras hardware, comparable to leading models like GPT-4 Turbo and Claude 3.5 Sonnet.

---



#### 9th of December 2024


[AlphaVerus: Bootstrapping Formally Verified Code Generation through Self-Improving Translation and Treefinement](https://arxiv.org/abs/2412.06176)

- AlphaVerus: generates formally verified code with LLMs and through self-improvement by iteratively translating programs from higher resource language.
- Includes three phases: exploration (translates programs from source language to Verus, which is a tool to verify correctness of code written in Rust), treefinement(iteratively fixes errors with Verus-verifier feedback/tree search) and critique (validates and filters unspecified/incorrect translations).
- Illustrates the potential of inference-time scaling in verified settings. Suggests formal verification ensures correctness and reliability of the generated code. 


---

[Query-Efficient Planning with Language Models](https://arxiv.org/abs/2412.06162)

- Reviews efficient ways to use LLMs for planning: heuristic and LLM as generative planner.
- Introduces two new algorithms: Tree of Interaction (ToI) and Boomerang.


---

[Simulating Human-like Daily Activities with Desire-driven Autonomy](https://arxiv.org/abs/2412.06435)

- D2A-agent (Desire-driven Autonomous Agent): Introduces autonomous agent proposing and selecting autonomously fulfilling and motivating tasks (based on theory of needs: social interaction/personal fulfillment/self-care).
- Introduces desire-based characters.
- Includes value system (measures satisfaction per desired dimension) and Desire-driven planner (choses next action of the agent with history and value system).
- Proposes using in the future more complex human motivation and planning mechanisms to satisfy intrinsic desires. Includes prompts.


---

[Toward LLM-Agent-Based Modeling of Transportation Systems: A Conceptual Framework](https://arxiv.org/abs/2412.06681)

- Proposes transportation system modelling with LLM-based agents to replicate human decision making.
- LLM-based agents include long-lasting core components: identity (age/income/occupation/cars owned/persona/travel related task/travel restrictions)/memory(short and long term)/LLM core(summarization/planning/nlu/workflow).
- Includes iterative process with perception, reflection, planning, plan processing and action.


---

[Beyond pip install: Evaluating LLM Agents for the Automated Installation of Python Projects](https://arxiv.org/abs/2412.06294)

- Installamatic: Reviews LLM-agents capability to install repository-level python packages with pip by automatically inspecting repository content and install the packages required. 
- Installamatic-agent is capable of installing packages required in 21/40 repositories tested with 4 main challenges: Identifying install-relevant documentation/writing valid docker files/cost/oracle-problem.


---

[AutoDCWorkflow: LLM-based Data Cleaning Workflow Auto-Generation and Benchmark](https://arxiv.org/abs/2412.06724)

- AutoDCWorkflow: uses LLM to automatically generate data-cleaning workflows (duplicates/missing values/inconsistent data format) and introduces a benchmark.


---

[StarWhisper Telescope: Agent-Based Observation Assistant System to Approach AI Astrophysicist](https://arxiv.org/abs/2412.06412)

- SWT (StarWhisper Telescope System): proposes automation of the astronomer observation process with LLMs. Includes observation planning/control/data processing/agent suggestion. Includes customized observation lists and real time analysis.


---

#### 5th of December 2024

[Practical Considerations for Agentic LLM Systems](https://arxiv.org/abs/2412.04093)

- Reviews LLM agent research from perspective of planning (explicit/implicit, task decomposition, plan adherence), memory (RAG, long-term memory), tools (ysage/dynamic/multiplicity) and control flow (output processing/error handling/stopping/multi-persona/context).
- Long term memory may include reflection/consolidation/forgetting/revision and should be independent/consistent/long-term.

---

[Targeting the Core: A Simple and Effective Method to Attack RAG-based Agents via Direct LLM Manipulation](https://arxiv.org/abs/2412.04415)

- Investigates adversial Adaptive Attack Prompt- and ArtPrompt-attack methods success rates between LLM models.


---

#### 2nd of December 2024

[Mastering Board Games by External and Internal Planning with Language Models](https://arxiv.org/abs/2412.12119)

- MAV (Multi Action-Value) model: is a transformer model pre-trained on textual game data, functioning as a world model, value function, and policy function for multiple perfect-information board games.
- Framework includes external and internal search methods, uses MCTS controller, and distills search procedure directly into the LLM, pre-trained on relevant domain knowledge, minimizes hallucinations, and improves win-rates against state-of-the-art bots.
- This framework demonstrates the capacity of LLMs to learn strong value functions and act as a world model across multiple perfect information games.

---

[Inference Scaling Flaws: The Limits of LLM Resampling with Imperfect Verifiers](http://arxiv.org/abs/2411.17501)

- LLM Resampling: explores the limits of using resampling with imperfect verifiers for improving language model accuracy.
- The framework shows that imperfect verifiers, like unit tests, lead to false positives, limiting the effectiveness of resampling, and that weaker models generalize worse than stronger models, even with infinite compute budget.
- This research highlights the importance of developing accurate verifiers and questions the effectiveness of inference scaling with imperfect verifiers.


---

#### 29th of November 2024

[Amplifying human performance in combinatorial competitive programming](https://arxiv.org/abs/2411.19744)

- FunSearch: is a framework that evolves scoring functions for a human-designed solution backbone using a large language model.
- Framework uses Gemini 1.5 Flash 002, improves scores on Hash Code, and uses a switching variable for multiple choice points.
- This approach demonstrates a successful human-AI synergy in combinatorial optimization problems.


---


#### 25th of November 2024


[Agent-Based Modelling Meets Generative AI in Social Network Simulations](https://arxiv.org/abs/2411.16031)

- Generative Agent-Based Modelling (GABM): LLM-based agents, which simulate social network users with personality traits/interests and custom agent interactions. 
- The framework consists of two phases: Characterization (Personality assignment) and Simulation (Reasoning module and Interaction module). Decisions of the agent are stored in vector db for retrieval. 

---


[TopV-Nav: Unlocking the Top-View Spatial Reasoning Potential of MLLM for Zero-shot Object Navigation](https://arxiv.org/abs/2411.16425)

- TopV-Nav: Improves Zero-Shot Object Navigation (ZSON) in unfamiliar environments by reasoning on top-view maps ("birds eye") with MLLM's spatial reasoning capabilities. 
- Proposes Adaptive Visual Prompt Generation (AVPG), which adaptively constructs top-view map. The framework then uses Dynamic Map Scaling (DMS), which dynamically zooms top-view map at preferred scales for local reasoning. Uses Target-Guided Navigation (TGN) to facilitate human-like exploration.


---

[A Multi-agent Framework for Materials Laws Discovery](https://arxiv.org/abs/2411.16416)

- Introduces a LLM-based multi agent framework to discover materials laws in materials science, using general framework for solving symbolic regression tasks with LLMs. 
Uses a depth-first search (DFS) algorithm and a reflection mechanism, implemented through LLMs, to optimize formula generation. 


---

[Enhancing Multi-Agent Consensus through Third-Party LLM Integration: Analyzing Uncertainty and Mitigating Hallucinations in Large Language Models](https://arxiv.org/abs/2411.16189)

- Introduces a multi-agent consensus framework, which integrates confidence weight obtained with third-party LLM, to adjust attention weights of each agent. 
- Each agent answers individually on the first round, agents self-adjust with feedback on second/third round with third party LLM and finally agents majority vote the final answer.


---

[SAGEval: The frontiers of satisfactory agent-based NLG evaluation for reference-free open-ended text](https://arxiv.org/abs/2411.16077)


- SAGEval: Introduces an eval for an open-ended, reference-free natural language generation (NLG) by using a critiquing agent to provide feedback on scores generated by LLM evaluators. Focuses on open-ended text like surveys, forms, and lists. 
- Includes Evaluator- (based on G-Eval) and Sage-agent as meta-evaluator. Evaluation aspects include: accuracy, semantic diversity, coherence, relevancy, audience understandability, audience engagement score, fairness score and sentiment/tone type.


---

#### 24th of November 2024

[PIANIST: Learning Partially Observable World Models with LLMs for Multi-Agent Decision Making](https://arxiv.org/abs/2411.15998)

- PIANIST (Partition function, Information set space, Action space function, N players, Information realization function, State space, and Transition reward function): A framework for decomposing a world model into seven components, enabling zero-shot LLM generation of a working world model for multi-agent decision-making tasks.
- The framework leverages LLMs for generating forward transition functions, action functions, and information partition functions. It uses MCTS for planning in partially observable environments. The approach is evaluated on language and non-language based action-taking games, without domain-specific training data.
- PIANIST demonstrates strong performance in multi-agent, partial information settings, showcasing the potential of LLMs for complex decision-making.


---


#### 21st of November 2024

[Natural Language Reinforcement Learning](https://arxiv.org/abs/2411.14251)

- Introduces: Natural Language Reinforcement Learning (NLRL).
- Efficiently implements RL algorithms and principles in language representation space.
- Presents NLRL-pipeline, where LLM learns from textual environmental feedback.
- Implements empirically in various games.


---

#### 18th of November 2024

[GENERATIVE WORLD EXPLORER](https://arxiv.org/abs/2411.11844)

- Generative World Explorer (Genex): Introduces and egocentric world exploration, which allows an agent to mentally explore a large-scale 3D world and acquire imagined observations to update its belief inside partially observable decision process. 
- Generates high-quality and consistent observations in long-horizon tasks.
- Consists of generative video model, egocentric views, belief revision, and decision-making (e.g., LLM agent). Includes multi-agent reasoning with imagination, where the framework infers perspectives of other actors in the scene.


---


[OASIS: Open Agents SOCIAL INTERACTION Simulations on One Million Agents](https://arxiv.org/abs/2411.11581)

- OASIS (Open Agents SOCIAL INTERACTION Simulations on One Million Agents): Introduces generalizable, scalable (millions of agents) social media (twitter/reddit-like) simulator LLM-based agents  supporting dynamic social networks, diverse actions and recommendation systems. Includes registration and simulation phases.
- OASIS pulls in the registration phase information about user, past posts, self-description and name.
- Simulation phase consists of Environment server(sends agent information, posts and user relationships)/RecSys(recommends visible content to user and agents)/Agent module(generates actions updating environment state)/Time engine(updates agents temporal behaviours)/Scalable Inferencer-components(handles large scale inference requests by user).
- OASIS replicates social phenomena observed in human-societies, including group polarization and herd effect, which take place in dynamically updating environments with diverse action spaces.
- Uses event-driven architecture, where agent communicates with server in dedicated channel, which consists of asynchronous message queue.

---

[TrojanRobot: Backdoor Attacks Against Robotic Manipulation in the Physical World](https://arxiv.org/abs/2411.11683)


- TrojanRobot: A backdoor attack framework, which targets robotic manipulation in the physical world by embedding a backdoor robotic system's visual perception module. 
- Uses common objects as triggers.


---

[A Code Knowledge Graph-Enhanced System for LLM-Based Fuzz Driver Generation](https://arxiv.org/abs/2411.11532)

- CodeGraphGPT: a framework that leverages a code knowledge graph and an LLM-powered intelligent agent to automate fuzz driver generation (sw testing technique by feeding unexpected random data as program inputs to discover bugs). 
- Includes agents for API combination generation (knowledge into graphs and then embeddings to query), dynamic program repair (past example embeddings), and crash analysis (bugs embeddings). 
- Constructs knowledge graph of code repos, tailors fuzz drivers and input seeds, resolves compilation errors, and analyzes crash reports.


---

[Moral Persuasion in Large Language Models: Evaluating Susceptibility and Ethical Alignment](https://arxiv.org/abs/2411.11731)

- Reviews Persuader agents capacity to influence another LLM agent (Base agent) in morally ambiguous decision making scenarios. 
- LLMs show greater variability between the degree it is possible to persuade them, than their capacity to persuade others.


---

[LLM-IE: A Python Package for Generative Information Extraction with Large Language Models](https://arxiv.org/abs/2411.11779)

- LLM-IE [LLM-based Information Extraction]: A Python package for building complete information extraction pipelines using large language models (LLMs).
- Key features include interactive LLM agent for prompt design, support for named entity recognition, entity attribute extraction, and relation extraction tasks. Benchmarked on i2b2 datasets. Sentence-based prompting algorithm.


---

#### 16th of November 2024

[Developer Challenges on Large Language Models: A Study of Stack Overflow and OpenAI Developer Forum Posts](https://arxiv.org/abs/2411.10873)

- Analyzes developer challenges with LLMs. Challenges include LLM ecosystem, API usage, LLM training, dataset management, prompt engineering, and error handling. Identifies several unresolved posts, slow response times, especially with complex topics.


---

[FlexFL: Flexible and Effective Fault Localization with Open-Source Large Language Models](https://arxiv.org/abs/2411.10714)

- FlexFL (Flexible and Effective Fault Localization): LLM-agents (Agent4SR and Agent4LR) based framework for code debugging / fixing with bug-related information (bug reports, test cases).
- The framework employs a two-stage approach: space reduction (Agent4SR) to narrow search space and localization refinement (Agent4LR) to localize top k-most suspicious methods.

---

[IntentGPT: Few-shot Intent Discovery with Large Language Models](https://arxiv.org/abs/2411.10670)

- IntentGPT: introduces a training-free method for Intent discovery using In-context Learning prompt (generated with LLM consisting of known intents/few-shot examples and user query) and LLM generating the intent.
- Adds discovered intents back into the prompt. Includes prompts. 
- IntentGPT outperforms previous methods with extensive domain-specific data for training/fine-tuning. Discovers intents dynamic, open-world scenarios.


---

#### 15th of November 2024

[Enhancing the Reasoning Ability of Multimodal Large Language Models via Mixed Preference Optimization](https://arxiv.org/abs/2411.10442)

- MPO (Mixed Preference Optimization): is a method that blends supervised fine-tuning loss with preference optimization losses to enhance training effectiveness of multimodal large language models.
- MPO uses a novel automated preference data construction pipeline to create MMPR dataset, and explores different Chain-of-Thought approaches with multimodal input to improve reasoning performance.
- This approach demonstrates improved performance across multiple benchmarks, particularly in multimodal reasoning tasks.

---


[A dataset of questions on decision-theoretic reasoning in Newcomb-like problems](https://arxiv.org/abs/2411.10588)

- Decision-theoretic reasoning: Introduces a dataset of natural language questions on Newcomb-like problems.
- The dataset includes capability questions (unambiguous answers) and attitude questions (disagreements among decision theorists). It evaluates existing large language models (LLMs) and their attitudes toward evidential decision theory (EDT) and causal decision theory (CDT). 
- Findings associate higher capability LLMs with more EDT-favorable attitudes across question types. The dataset helps to understand decision-theoretic reasoning capabilities and attitudes of LLMs in AI-AI interactions.


---

#### 12th of November 2024


[RedCode: Risky Code Execution and Generation Benchmark for Code Agents](https://arxiv.org/abs/2411.07781)

- RedCode-benchmark: Evaluates safety of code agents capacity to generate / execute code and reviews code agents capacity to recognize/manage unsafe code execution.
- Includes two steps: RedCode-Gen (evaluates code generated) and RedCode-Exec (evaluates code execution).


---

[World Models: The Safety Perspective](https://arxiv.org/abs/2411.07690)

- Introduces a Survey about World Models in Embodied AI agents from safety perspective.


---

[BudgetMLAgent: A Cost-Effective LLM Multi-Agent system for Automating Machine Learning Tasks](https://arxiv.org/abs/2411.07464)

- BudgetLMAgent: Multi agent framework using cascading (sequentially invoking/chaining) free/low cost/frontier LLMs with distinct roles: planner (default/expert)/workers(high-level actions/low-level actions).
- Gives LLM-agent an option to call more advanced LLM-model to request help (with maximum retries) in complex planning problems.
- Reduces operation cost by 94% compared to single agent with GPT-4 and improved success rate. 


---

[LLMPhy: Complex Physical Reasoning Using Large Language Models and World Models](https://arxiv.org/abs/2411.08027)

- LLMPhy: Combines LLM with Mujoco-physics engine for complex physical reasoning tasks and introduces TraySim-dataset consisting of 100 scenes.
- Claims, that LLMs have enough world knowledge with physics engine for better interactive reasoning and LLMs trained with more scientific reasoning tasks tend to demonstrate superior physical reasoning in LLMPhy-pipeline.


---

[From General to Specific: Utilizing General Hallucation to Automatically Measure the Role Relationship Fidelity for Specific Role-Play Agents](https://arxiv.org/abs/2411.07965)

- Introduces an automatic evaluation framework for Role-Playing Agents (RPAs) that generates claims from a knowledge graph and has characters discuss them with the main character.
- Evaluates the believability of interactions by leveraging the inherent hallucination properties of RPAs. Defines relationship hallucination metric.


---

[Mitigating Bias in Queer Representation within Large Language Models: A Collaborative Agent Approach](https://arxiv.org/abs/2411.07656)

- Focuses on inclusive / gender neutrality in LLM-agents with: assistant/language analysis/optimizer-agents.


---

#### 11th of November 2024

[Mr.Steve: Instruction-Following Agents in Minecraft with What-Where-When Memory](https://arxiv.org/abs/2411.06736)

- Mr.Steve (Memory Recall Steve-1): Improves long-horizon task solving by incorporating solver module and  Place Event Memory (PEM), which recalls what-, where- and when-information from episodes.
- Includes memory-augmented task solving and exploration strategy.


---

[Using Generative AI and Multi-Agents to Provide Automatic Feedback](https://arxiv.org/abs/2411.07407)

- Autofeedback: Introduces multi agent LLM-based framework for student feedback, which includes: feedback generation- and feedback validation/modifier. Reduces over-praising and over-inference. 
- Includes prompts of both agents.


---

[Script-Strategy Aligned Generation: Aligning LLMs with Expert-Crafted Dialogue Scripts and Therapeutic Strategies for Psychotherapy](https://arxiv.org/abs/2411.06723)

- SSAG (Script-Strategy Aligned Generation): Aligns LLMs with key therapeutic strategies in Motivational Interviewing. Claims, that LLMs aligned with expert prompting outperform rule-based chatbots and pure LLMs. 


---

[Tooling or Not Tooling? The Impact of Tools on Language Agents for Chemistry Problem Solving](https://arxiv.org/abs/2411.07228)

- ChemAgent-framework: Introduces agent for chemistry tasks, which includes reasoning/grounding and tool use. 


---

[A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs](https://arxiv.org/abs/2411.07098)

- AutoRestTest: Introduces MARL-framework with Semantic Property Dependency Graphs (SDG) and LLMs for REST API exploration.
- Includes dependency/operation/parameter/value-agents.


---


#### 10th of November 2024

[Is Your LLM Secretly a World Model of the Internet? Model-Based Planning for Web Agents](https://arxiv.org/abs/2411.06559)

- WebDreamer: LLM-based web-agent framework by using LLM to predict outcomes of candidate actions in web environment in order to pick optimal action.
- The LLM simulates as world-model actions using prompt like: "what would happen if I click this button" and then evaluates the imagined outcomes. 
- Model-based planning enables safe simulation of possible actions before taking them (some web environments do not allow going back to previous step, which complicates tree-based search by investigating candidate next steps).
- Includes system prompts of the world model and reward model.
 
---

#### 9th of November 2024

[IOPO: Empowering LLMs with Complex Instruction Following via Input-Output Preference Optimization](https://arxiv.org/abs/2411.06208)

- IOPO (Input-Output Preference Optimization): Aligns/fine-tunes LLMs based on both the input data (new approach) and the output data (traditional approach). 
- Explores instruction preference space.

---

[From References to Insights: Collaborative Knowledge Minigraph Agents for Automating Scholarly Literature Review](https://arxiv.org/abs/2411.06159)

- Introduces CKMAs (Collaborative Knowledge Minigraph Agents), which automate literature reviews. Building knowledge minigraphs by organizing information and relationships from research papers.
- Includes KMCA (Knowledge Minigraph Construction Agent) and MPSA (Multiple Path Summarization Agent), which both prompts are included.


---


#### 8th of November 2024

[The influence of persona and conversational task on social interactions with a LLM-controlled embodied conversational agent](https://arxiv.org/abs/2411.05653)

- Reviews effect of the LLM-based agent persona traits to user experience.
- Manipulation of the personality traits strongly influences social interaction and user experience.


---


[Game-theoretic LLM: Agent Workflow for Negotiation Games](https://arxiv.org/abs/2411.05990)

- Studies with game-theoretic analysis the rationality of LLM-based (with various LLMs) negotiation workflow in various complete-information games and in a incomplete-information game.


---



#### 7th of November 2024

[Interactive Dialogue Agents via Reinforcement Learning on Hindsight Regenerations](https://arxiv.org/abs/2411.05194)

- Simulates interactive dialogue by utilizing hindsight to regenerate optimal task-relevant dialogue data based on initial dialogue data.
- Includes hindsight controller, which takes dialogue input and prefix, then outputs a more desirable action. 


---

[GUI Agents with Foundation Models: A Comprehensive Survey](https://arxiv.org/abs/2411.04890)

- Introduces Survey about GUI Agents.
- Divides LLM-based GUI agents into: GUI Perceiver, Task Planner, Decision Maker, Excecutor and Memory Planner (internal memory: actions/screenshots, external memory: manual construct/auto exploration and self-evolution: transition diagram/documents).
- Identifies challenges related to inference efficiency, self-evolution and real world vs. benchmark gap.

---

[CodeTree: Agent-guided Tree Search for Code Generation with Large Language Models](https://arxiv.org/abs/2411.04329)

- CodeTree: Introduces multi-agent, LLM-based code generation, which improves multi-stage planning/generation/debugging by using tree search.
- Includes Thinker/Solver/Debugger/Critic-agents.
- Critic-agents scores/expands/terminates nodes, which is based on feedback generated by the LLM and the execution feedback on test cases.


---

[CaPo: Cooperative Plan Optimization for Efficient Embodied Multi-Agent Cooperation](https://arxiv.org/abs/2411.04679)

- CaPo (Cooperative Plan Optimization): Includes meta-plan generation and progress-adaptive meta-plan & execution
- Meta plan generation consists of analyzing, discuss, create the meta-plan decomposed into subtasks by the various agents.
- Progress-Adaptive Meta-Plan & Execution: agents execute task in the meta plan and dynamically adjust it based on latest progress in multiturn dialogue. 


---

#### 6th of November 2024

[AdaSociety: An Adaptive Environment with Social Structures for Multi-Agent Decision-Making](https://arxiv.org/abs/2411.03865)

- AdaSociety: multi-agent environment to simulate decision making with physical(resources, events, agents skill inventories)/social(establish, alter, form groups, hierarchies)-components. 
- Introduces social states: multilayer directed graph to describe adaptive / dynamic connections, which drive long-term coalition formation / hierarchy.
- Dynamically connects with other agents to establish autonomously non-deterministic connection with the other agent.
- State and action space dynamically advance. 
- Identifies research challenges in collective reasoning, social cognition, adaptation, communication and emergence of new social skills and norms.

---


[MRJ-Agent: An Effective Jailbreak Agent for Multi-Round Dialogue](https://arxiv.org/abs/2411.03814)

- MRJ-Agent: Introduces multi-round dialogue jailbreaking agent, which decomposes harmful queries into multiple sub-queries.
- This widely generalizable jailbreaking-technnique achieves SOTA-level success rates.


---

[From Novice to Expert: LLM Agent Policy Optimization via Step-wise Reinforcement Learning](https://arxiv.org/abs/2411.03817)

- StepAgent: Optimizes LLM-agents wit step-wise RL with inspection- and reflection-steps.  


---

#### 5th of November 2024

[SAUCE: Synchronous and Asynchronous User-Customizable Environment for Multi-Agent LLM Interaction](https://arxiv.org/abs/2411.03397)

- SAUCE (Synchronous and Asynchronous User-Customizable Environment): Introduces LLM-based multi agent framework with asynchronous communication feature, where models decide when to speak and what to say.
- Includes experiment(configures discussio, participants, host and end criteria)/session room(manages ongoing experiment and exit criteria)/host (directs interaction)/person(human or LLM).
- Implements LLM-agent personas (and human participant) as class-objects in Python.

---


[AI Metropolis: Scaling Large Language Model-based Multi-Agent Simulation with Out-of-order Execution](https://arxiv.org/abs/2411.03519)

- AI Metropolis: introduces multi agent LLM-based framework, which enables out-of-order execution (parallel processing) of agents by tracking dynamically real dependencies between agents. 
- LLM agents often wait unnecessarily each step to complete, before proceeding, even when it is a false dependency.
- LLM agents can be: blocked (another blocks proceeding), coupled (proceed together), clustered (group needs to synchronize), worker (independent process handling cluster) or controller (main process communicating with workers).
- The related work-section offers comphrensive view on the different scheduling approaches to with agentic AI.


---

#### 4th November 2024

[EMMA: End-to-End Multimodal Model for Autonomous Driving](https://arxiv.org/abs/2410.23262)

- EMMA (End-to-End Multimodal Model for Autonomous Driving): introduces EMMA, built on Gemini, which maps raw camera data and text inputs to driving outputs including planning trajectories, perception objects, and road graph elements, leveraging Chain-of-Thought Reasoning and Generalist Capability.
- The framework recasts autonomous driving tasks as visual question answering problems, processing inputs and generating outputs in a unified language space using task-specific prompts.
- EMMA demonstrates strong performance across motion planning, 3D object detection, and road graph estimation, functioning as a generalist model capable of jointly handling multiple driving tasks.


---

#### 1st of November 2024

[DARD: A Multi-Agent Approach for Task-Oriented Dialog Systems](https://arxiv.org/abs/2411.00427)

- DARD (Domain Assigned Response Generation): LLM-based multi agent framework in multi domain & task oriented dialogue.
- Introduces dialogue manager/hotel/attraction/restaurant/train/taxi-agents, external db and dialogue state tracker.
- Uses both fine-tuned LLMs and Sonnet 3.0. Reviews differences in performance.


---

#### 31st of October 2024

[Empowering biomedical discovery with AI agents](https://www.sciencedirect.com/science/article/pii/S0092867424010705)

- Introduces AI agents for biomedical discovery, consisting of Robotic-, Database-, Reasoning-, Hypothesis-, Brainstorming-, Search Engine-, Analysis- and Experimental Planning-agents.
- Performs tasks including hypothesis generation, workflow planning, and self-assessment, integrating large language models (LLMs) and machine learning tools.
- Potetial use cases include virtual cell simulation, programmable phenotype control, cellular circuit design, and therapy development.

---


[Navigating the Unknown: A Chat-Based Collaborative Interface for Personalized Exploratory Tasks](https://arxiv.org/abs/2410.24032)

- CARE (Collaborative Assistant for Personalised Exploration): Introduces personalized LLM-based multi agent framework, where user interface includes chat/solution/needs-panels.
- Focuses on improving multi-turn contextual understanding, personalization, exploration and reduce cognitive load.
- Employs inquiry/ranking/needs discovery/solution crafting/milestone-agents.


---

#### 30th of October 2024


[EMOS: Embodiment-aware Heterogeneous Multi-robot Operating System with LLM Agents](https://arxiv.org/abs/2410.22662)

- EMOS: multi-agent framework for multi-robot system with embodiment & spatial-aware reasoning/navigation/manipulation/object rearrangement. 
- Includes hierarchical task planning, assignment and actioning. Evaluates success rate, sub-goal success rate, token usage and simulation step.
- Uses "Robot Resume": a self-prompting, instead of "human roleplay" by interpreting the robot URDF files to call robot kinematics tools to generate descriptions of its physical abilities for guiding its planning/action execution. 

---

[Aligning Audio-Visual Joint Representations with an Agentic Workflow](https://arxiv.org/abs/2410.23230)

- AVAgent: Adapts audio signal with visual data using LLM-based agent framework, which plans edits of the audio signals and reflection with VLM to evaluate the modifications and uses tool to convert video and audio modality to text.


---


#### 29th of October 2024

[BENCHAGENTS: Automated Benchmark Creation with Agent Interaction](https://arxiv.org/abs/2410.22584)

- BENCHAGENTS: Introduces LLM-agent framework automating benchmark creation, which includes four components: planning/generation/data verification/evaluation-agents.
- Dynamic benchmarks help to identify common failure modes/model differences, while LLM models improve quickly.
- Planning includes: prompt/task-specific parameters/constraints (positive/negative/positional/sequencing/conditional/iterative).


---

#### 28th of October 2024


[Asynchronous Tool Usage for Real-Time Agents](https://arxiv.org/abs/2410.21620)

- Asynchronous AI agents: Introduces asynchronous, parallel thought processing and real-time tool use based on event-driven finite state-machines.
- Time stamp is in the messages to enable clock awareness, which enables time-constrained tasks. 
- Event states include idle/listening/generating/emitting.


#### 25th of October 2024

[Cooperative Strategic Planning Enhances Reasoning Capabilities in Large Language Models](https://arxiv.org/abs/2410.20007)

- CoPlanner (Cooperative Planner): Improves reasoning capabilities of LLM by separating reasoning steps. Each agent gets assigned unique reasoning step.
- Includes planning agent and reasoning agent.
- Pre-defines 10 human cognition-based meta-strategies. Includes 5 logical reasoning methods: deduction/induction/abduction/analogy/contradiction and four problem solving methods: decomposition/enumeration/elimination/reflection and meta-strategy: finish to indicate end of reasoning.

  
---

[VisionCoder: Empowering Multi-Agent Auto-Programming for Image Processing with Hybrid LLMs](https://arxiv.org/abs/2410.19245)

- VisionCoder: Multi agent framework with team leader, module leader, function coordinator and development group
- Identifies excellent two aspects for the Agent-definitions: structural (explains the agents place in the overall structure/scope/responsibilities) and functional (operational steps/reasoning path expected from the agent and the output format requirements).
- Includes bi-directional workflow: hierarchical tasks are divided into smaller units (forward task flow) and then restored back (backward task flow) from smaller pieces to larger units. Pair programming-concept includes coder and tester: coder produces code, tester reviews it and then the roles are reversed. The pair programming step is repeated three rounds with code execution with incorporation of the error messages to get final working code. 


---

[Designing LLM-Agents with Personalities: A Psychometric Approach](https://arxiv.org/abs/2410.19238)

- Reviews creation of psychometrically sound LLM-based agents based on the theory about big 5 personality traits (openess/conscientiousness/extraversion/agreeabless/neuroticism).


---

[FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning](https://arxiv.org/abs/2410.19727)

- FISHNET: Multi agent-framework for insights from SEC regulatory forms. Includes sub-querying (converts query into sub-queries)-, task planning- , experts (Swarm Intelligence)-, harmonizer(routes to specific expert based on embedding match vs. agent persona/tables description)-agents and long term memory.
- Expert agents consist of: n-port-, n-mfp-, adv-, n-cen-, n-csrv- and 13f-agents, which are experts in different forms related to SEC regulations.


---


[AGENT-CQ: Automatic Generation and Evaluation of Clarifying Questions for Conversational Search with LLMs](https://arxiv.org/abs/2410.19692)

- Agent-CQ: Introduces a framework for generating and evaluating conversational search questions and answers. Includes generation (question generation / filtering / answer generation)- and evaluation (multiple LLM-judge calls to review generated questions/answers)-stages.


---

[EDGE: Enhanced Grounded GUI Understanding with Enriched Multi-Granularity Synthetic Data](https://arxiv.org/abs/2410.19461)

- EDGE: Introduces framework to generate training data for GUI-tasks in the internet. Introduces element- and action-grounding. 


---


[Investigating the Role of Prompting and External Tools in Hallucination Rates of Large Language Models](https://arxiv.org/abs/2410.19385)

- Investigates prompting techniques and finds simpler is often better and best prompts are problem specific.
- In math problems self-consistency with majority vote works well, Chat protect helps to manage amount of hallucinated answers and Self-Verification worked well with MMLU.


---

[AgentSense: Benchmarking Social Intelligence of Language Agents through Interactive Scenarios](https://arxiv.org/abs/2410.19346)

- AgentSense-benchmark: introduces a multiturn evaluation of LLM-agents regards social intelligence. Focuses on goal competition and implicit reasoning.
- Character-info includes: attributes/relationships/rules of replacement. Scenarios include: background/characters/social goals/private info.
- Includes a sample agent-prompt. 


---


#### 24th of October 2024

[Unbounded: A Generative Infinite Game of Character Life Simulation](https://arxiv.org/abs/2410.18975)

- Unbounded: Introduces a conceptual and technical implementation of concept called "generative infinite game". 
- Addresses semantically alignedconsistent environment/characters.
- Trained an LLM based game engine game engine (generating coherent and real-time game mechanisms, narratives and contextual character responses) and "Regional IP-Adapter", which creates visually consistent characters/environments between multiple images while applying creativity. Regional IP-Adapter tracks changes overtime, so if your character gets injured in forest, the injury remains in the following images and the character still wears same clothes, while giving creative touches to the visuals. 


---

[AR: Operating System Control via State-Aware Reasoning and Re-Planning](https://arxiv.org/abs/2410.18963)

- OSCAR: Introduces GUI-agent with unified control interfaces / GUI grounding (dual grounding) / exploration-based simulation and re-planning (task driven replanning of only specific tasks).
- Works both in smartphones and desktop OS. Reviews GUI agents. Includes system prompts.
- Agent states include: init/observe/plan/execute/error/verify/fail/success/reset. Includes context memory.


---

[Skywork-Reward: Bag of Tricks for Reward Modeling in LLMs](https://arxiv.org/abs/2410.18451v1)

- Skywork-Reward: introduces methods to enhance reward modeling for LLMs, focusing on data-centric techniques.
- It proposes data selection and filtering strategies for high-quality preference datasets, resulting in Skywork-Reward data collection, and develops Skywork-Reward model series including Skywork-Reward-Gemma-27B and Skywork-Reward-Llama-3.1-8B.
- This work enhances performance of top-ranked models on RewardBench, highlighting practical impact in preference learning applications.


---


[PDL: A Declarative Prompt Programming Language](https://arxiv.org/abs/2410.19135)

- PDL (Prompt Declarative Language): Introduces declarative and data-oriented language based on YAML to construct LLN prompt programs. Every PDL program is a valid YAML-document with PDL-schema. 


---

[From a Tiny Slip to a Giant Leap: An LLM-Based Simulation for Fake News Evolution](https://arxiv.org/abs/2410.19064)

- FUSE (Fake News evlUtion Simulation framEwork): Reviews the way true news convert into fake news with LLMs. Includes LLM-based agents: spreaders/commentators/verifiers/bystanders.
- The simulation evolves with a module called News Evolution Simulator. 
- Includes content deviation metrics.


---

[PRACT: Optimizing Principled Reasoning and Acting of LLM Agent](https://arxiv.org/abs/2410.18528)

- PRAct (Principled Reasoning and Acting)-framework: improves action understanding of agents by including action principles. Introduces RPO (Reflective Principle Optimization).


---

#### 23rd of October 2024

[ASYNCHRONOUS RLHF: FASTER AND MORE EFFICIENT OFF-POLICY RL FOR LANGUAGE MODELS](https://arxiv.org/abs/2410.18252)

- Asynchronous RLHF (Reinforcement Learning from Human Feedback): A framework that separates generation and learning in RLHF, enabling asynchronous generation of new samples while simultaneously training on old samples.
- Online but off-policy, faster training, more compute-optimal scaling, training LLAMA 3.1 8B on instruction-following task 40% faster while matching final performance.
- This framework addresses the computational inefficiency of the dominant paradigm for RL finetuning of LLMs by separating generation and learning, leading to faster training and more efficient use of resources.



[GraphTeam: Facilitating Large Language Model-based Graph Analysis via Multi-Agent Collaboration](https://arxiv.org/abs/2410.18032)

- GraphTeam: LLM-based collaborative multi agent and graph-based system using three modules: input-output normalization/external knowledge retrieval/problem solving.
- Includes question(reformats question)/search/coding/reasoning/answer-agents. 
- Constructs to knowledge graphs: documentation and experience. 


---

[Real-World Robot Applications of Foundation Models: A Review](https://arxiv.org/abs/2402.05741)

- This paper provides an overview of the practical application of foundation models in real-world robotics.
- The review emphasizes the replacement of specific components within existing robot systems, input-output relationships, perception, motion planning, and control.
- The paper concludes with a discussion of future challenges and implications for practical robot applications.

---



[MiniFed : Integrating LLM-based Agentic-Workflow for Simulating FOMC Meeting](https://arxiv.org/abs/2410.18012)

- MiniFed: Simulates real world Federal Reserve FOMC-meetings using LLM-agent based multi-agent framework.
- Consists of initialization/data collection/simulation/decision making/evaluation.


---

[Guide for Defense (G4D): Dynamic Guidance for Robust and Balanced Defense in Large Language Models](https://arxiv.org/abs/2410.17922)

- G4D (Guide for Defense): LLM-based multi agent with external knowledge to discover user intent as safe with a defense framework against jailbreaks.
- Includes intention detector (intention extraction, key entities identification and information retrieval)/question paraphraser/safety analyzer-components.


---

[An Intelligent Agentic System for Complex Image Restoration Problems](https://arxiv.org/abs/2410.17809)

- AgenticIR: VLM/LLM-agent based image restoration using perception/scheduling/reflection/rescheduling/execution-agents.
- Includes Rollback-mechanism, where agent returns previous working stage, when an issue.


---

[ReflecTool: Towards Reflection-Aware Tool-Augmented Clinical Agents](https://arxiv.org/abs/2410.17657)

- ReflecTool: Introduces clinical agent, using progressively built long-term memory to assist domain-specific tool selection and improve tool usage. Includes optimization and inference stages. 


---

[Navigate Complex Physical Worlds via Geometrically Constrained LLM](https://arxiv.org/abs/2410.17529)

- Reviews LLMs-capability to reconstruct physical world from textual knowledge. 
- Uses LLM-based multi agent framework with scenery designer/object designer/object manufacturer/arranger-agents and geometric constraint solver and generic algorithm.


---

#### 21st of October 2024

[Long Term Memory: The Foundation of AI Self-Evolution](https://arxiv.org/abs/2410.15665)

- Reviews and defines AI Self-Evolution-capability and Long Term Memory (LTM).
- Identifies benefits in Personalized Models. 
- Identifies limitations in prompt-based memory mechanisms. 


---


[Improving Parallel Program Performance Through DSL-Driven Code Generation with LLM Optimizers](https://arxiv.org/abs/2410.15625)

- Designs Domain Specific Language (DSL) in mapper (maps computations to processors like GPUs, CPUs, etc.) generation related to assignment of compute / memory. 
- The DSL helps to manage high-level inference decisions without interacting with the low-level C++ code APIs.


---

#### 20th of October 2024

[Redefining Proactivity for Information Seeking Dialogue](https://arxiv.org/abs/2410.15297)

- Introduces Information Seeking Dialogue (ISD) agents with proactiveness to include information relevant to the user query.
- Introduces new prompting strategies: 3-step CoT and 3-in-1 CoT.


---

#### 18th of October 2024

[Teaching Models to Balance Resisting and Accepting Persuasion](https://arxiv.org/abs/2410.14596)

- PBT (Persuasion Balanced Training): Uses multi-agent recursive dialogue trees to train models with preference optimization to accept persuasion in acceptable situations. PBT-trained model outperform in multi-agent debates.
- Agents argue based on logical reasoning/emotional appeal/established credibility.
- Refers to research by [Woolley et al. (2010)](https://www.researchgate.net/publication/47369848_Evidence_of_a_Collective_Intelligence_Factor_in_the_Performance_of_Human_Groups), where group intelligence is argued to be driven by diversity/turn-taking/social sensitive, rather than individual intelligence.


---

#### 18th of October 2024

[Make LLMs better zero-shot reasoners: Structure-orientated autonomous reasoning](https://arxiv.org/abs/2410.19000)

- SARA (Structure-oriented Autonomous Reasoning Agents): Introduces multi agent LLM-based reasoning framework with structure-oriented analysis by refinement and RAG.
- Outperforms in some cases few-shot learning.
- Includes reason (structured oriented analysis)-, retrieval-, refinement-agents and shared memory. Includes prompts used.


---

[AI can help humans find common ground in democratic deliberation](https://www.science.org/doi/10.1126/science.adq2852)

- Habermas Machine: AI mediation technique promoting fair/inclusive debate.
- LLM-agent opinions/critiques refine group statement to maximize group approval.
- Aims to improve collective decision making in political discussion/conflict resolution.


---

#### 17th of October 2024

[Web Agents with World Models: Learning and Leveraging Environment Dynamics in Web Navigation](https://arxiv.org/abs/2410.13232)

- Proposes World-Model-Augmented (WMA) web agent by simulating planned actions to obtain outcome before using them (metacognitive monitoring) in order to avoid performing erroneous moves. Reviews LLMs lack of capability to avoid performing errors, which humans can easily avoid by posing world model. 
- Introduces "Transition-focused observation abstraction": world model generates free-form important state differences before / after. Agent simulates outcomes of each possible action with world model and reward model asesses each one. 
- Includes prompts.

---

[Chain of Ideas: Revolutionizing Research in Novel Idea Development with LLM Agents](https://arxiv.org/abs/2410.13185)

- CoI (Chain-of-Ideas): CoI-agent generates research ideas comparable to human-level by organizing literature in a chain structure to avoid logical inconsistencies in ideation.
- Improves LLMs research ideation capabilities. Consists of three steps: CoI-construction (identifies current trends), Idea generation (consolidates ideas) and Experience design (final experiment design).
- CoI-prompts include: converting topic in search query for literature retrieval/evaluation of paper relevance to the topic/extract research paper ideas, experiments, entities and reference/summarising trends of the this CoI. 
- Idea generation prompts include: predict future trends / generate ideas / novelty check of ideas.
- Experiment design prompts include: generate experiment design / review experiment design / obtain queries to edit experiment design / refine experiment design. 



---
[AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents](https://arxiv.org/abs/2410.13825)

- AgentOccam: Refines LLM-agent observation/action space to improve its performance in web tasks with three methods. Sets SOTA in WebArena.
- Introduces planning actions: branching and pruning. Minimizes trivial interaction space. Removes unnecessary web content. 
- Agent prompt includes general instructions (task description/output specification/action specification) and Online Task Information.
- Simplifies web content/selectively replays web elements/selectively replays past pages.

---

[AdaSwitch: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning](https://arxiv.org/abs/2410.13181)

- AdaSwitch: Uses local agents for basic and cloud agent for complex tasks.
- Includes self-practicing, collaborative examination and reflective learning steps. 


---

[Harnessing Webpage UIs for Text-Rich Visual Understanding](https://arxiv.org/abs/2410.13824)

- Introduces MultiUI-dataset of 1 million websites for web / UI agents. 


---

[Rapid and Automated Alloy Design with Graph Neural Network-Powered LLM-Driven Multi-Agent Systems](https://arxiv.org/abs/2410.13768)

- Multi-agent system including LLMs, AI agents (multi modal LLM-agents) and GNNs to discover automatically new metallic alloys.
- The LLM-agent roles include: planner-, executor-, coder-, reviewer- and multi-modal-agents.  


---

[A Comparative Study on Reasoning Patterns of OpenAI's o1 Model](https://arxiv.org/abs/2410.13639)

- Reviews o1-model against other test-time compute methods like BoN/Self-Refin/Agent workflow. 
- Identifies 6 reasoning patterns with o1-model: systematic analysis/method reuse/divide & conquer / self-refinement / context identification / emphasizing constraints.


---

[MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling](https://arxiv.org/abs/2410.13610)

- MeNTI-framework chooses appropriate meta-tool, fills data according to the meta-tool documentation and nested-calling verifies task completion. 


---

[Integrating Large Language Models and Reinforcement Learning for Non-Linear Reasoning](https://arxiv.org/abs/2410.13501)

- RL guides LLM's exploration. The architecture includes: LLM-module/validation module/reasoning tree/RL agent. Applied in code generation. 
- LLM module generates n-candidates, validation module reviews characteristics of each candidate, the features of each review are added to reasoning tree and finally RL explores this reasoning tree to decide the node to explore next. 


---

[Metacognitive Monitoring: A Human Ability Beyond Generative Artificial Intelligence](https://arxiv.org/abs/2410.13392)

- Reviews metacognition monitoring abilities of LLMs.


---

[RescueADI: Adaptive Disaster Interpretation in Remote Sensing Images with Autonomous Agents](https://arxiv.org/abs/2410.13384)

- ADI (Adaptive Disaster Interpretation)-framework: introduces an multimodal LLM-agents interpreting disaster scenarios using tools. Introduces RescueADI-dataset. 
- ADI-framework includes perception/recognition/planning/tools-modules.


---

[ALOHA Unleashed: A Simple Recipe for Robot Dexterity](https://arxiv.org/abs/2410.13126)

- ALOHA Unleashed: introduces a transformer encoder-decoder architecture with diffusion loss for dexterous bimanual manipulation tasks.
- The framework uses CNNs for image embedding, Transformer Encoder for observation encoding, Transformer Decoder for action denoising, Proprioception MLP, and Diffusion Timestep.
- This approach combines large-scale data collection with diffusion policy to achieve improved performance in challenging manipulation tasks.


---


#### 16th of October 2024

[Revealing the Barriers of Language Agents in Planning](https://arxiv.org/abs/2410.12409)

- Reviews planning capabilities of LLMs and identifies current models like o1 only achieve 15.6% performance in real-world tasks. 
- Identifies two core issues: interpretation of constraints/loss of focus in long-horizon planning tasks.
- Episodic and parametric memory help, but do not resolve the lack of planning capabilities. 

---

[Graph-constrained Reasoning: Faithful Reasoning on Knowledge Graphs with Large Language Models](https://arxiv.org/abs/2410.13080)

- GCR (Graph-Constrained Reasoning): Integrates Knowledge Graph (KG) into LLM decoding to reduce hallucinations in reasoning.
- Uses KG-Trie method. 

---

[Evaluating Software Development Agents: Patch Patterns, Code Quality, and Issue Complexity in Real-World GitHub Scenarios](https://arxiv.org/abs/2410.12468)

- Reviews LLM-agents ability to patch code, suggesting smaller sub-tasks to patch code to be easier for LLM-agents.

---

[JudgeBench: A Benchmark for Evaluating LLM-based Judges](https://arxiv.org/abs/2410.12784)

- JudgeBench-benchmark: Evaluates LLM-judge agents, which focuses on instruction following/factuality/logic/style.


---

[SAC-GLAM: Improving Online RL for LLM agents with Soft Actor-Critic and Hindsight Relabeling](https://arxiv.org/abs/2410.12481)

- SAC-GLAM: Proposes a more autonomous LLM-agents based on adaptation of SAC (Soft Actor-Critic) and HER (Hindsight Experience Replay) for LLM-agents in multi-goal RL environment to perform sequential decision making tasks.
- Reviews LLM-agents moving from external objective driven towards more autotelic ("self" + "goals") with an intrinsic purpose rather than extrinsic. 


---

[Robust RL with LLM-Driven Data Synthesis and Policy Adaptation for Autonomous Driving](https://arxiv.org/abs/2410.12568)

- RAPID: Improves RL performance in autonomous driving with LLM-reasoning. Uses LLM-agent data for offline RL distillation and then adapts online RL-agent with LLM-data.

---

[Enhancing LLM Trading Performance with Fact-Subjectivity Aware Reasoning](https://arxiv.org/abs/2410.12464)

- FS-Reasoning Agent: introduces LLM-based multi-agent trading framework by splitting reasoning processes between factual and subjective reasoning.
- Includes Statistics/Fact reasoning/Fact/Subjectivity/Subjectivity reasoning/Trading/Reflection agents.
- Concludes, that superiority of the LLM model is not sufficient to guarantee it outperforming multi-step reasoning.


---


[MedAide: Towards an Omni Medical Aide via Specialized LLM-based Multi-Agent Collaboration](https://arxiv.org/abs/2410.12532)

- MedAide: Introduces LLM-based multi-agent framework, which includes query input/query rewriting/intent recognition/agent collaboration. 
- Activates specialised agents (own prompt template) dynamically by recognizing intent. 
- Includes contextual encoder. 

---

[Aegis:An Advanced LLM-Based Multi-Agent for Intelligent Functional Safety Engineering](https://arxiv.org/abs/2410.12475)

- Aegis: LLM-based multi-agent framework for FSRs (Functional Safety Requirements) and HARA (Hazard Analysis and Risk Assessment). 


---

#### 15th of October 2024

[G-Designer: Architecting Multi-agent Communication Topologies via Graph Neural Networks](https://arxiv.org/abs/2410.11782)

- G-Designer: introduces designer of multi-agent LLM-graphs based on MACP. Includes Materials/Construct/Design/Optimize-steps.  
- Proposes a LLM-agent communication protocol for multi-agent systems called MACP. MACP includes performance/adaptability/robustness.


---

[AGENTiGraph: An Interactive Knowledge Graph Platform for LLM-based Chatbots Utilizing Private Data](https://arxiv.org/abs/2410.11531)

- AGENTiGraph (Adaptive Generative ENgine for Task-based Interaction and Graphical Representation): LLM-based multi-agent knowledge management framework with knowledge graphs.
- Includes knowledge extraction/integration/real-time visualization.
- Dynamically interprets user intent/manage tasks/integrate new knowledge. Classifies tasks. Extracts key concepts. Constructs knowledge graphs. Includes prompts used. 


---

[Revisiting Benchmark and Assessment: An Agent-based Exploratory Dynamic Evaluation Framework for LLMs](https://arxiv.org/abs/2410.11507)

- TestAgent-framework: quantitative/qualitative benchmark using agent-based evaluation with RL, multi-turn interaction from knowledge base/topics of interests.


---

#### 14th of October 2024

[AFlow: Automating Agentic Workflow Generation](https://arxiv.org/abs/2410.10762)

- AFlow: Optimises LLM-agent workflow with MCTS.
- Includes search space (node, operators, code represented edges), search via AFliw and Search result (math, Q&A and code generation workflows.)


---

#### 10th of October 2024


[Rewarding Progress: Scaling Automated Process Verifiers for LLM Reasoning](https://arxiv.org/abs/2410.08146)

- PAVs (Process Advantage Verifiers): is a framework that trains verifiers to predict progress in multi-step reasoning by measuring the change in likelihood of a correct response under a prover policy.
- PAVs improve exploration during test-time search and online RL, using complementary prover policies, and are more compute-efficient than ORMs.
- This framework enables more efficient and accurate reasoning in large language models by providing a better way to measure progress in multi-step reasoning.


---

[Multi-Agent Collaborative Data Selection for Efficient LLM Pretraining](https://arxiv.org/abs/2410.08102)

- Introduces LLM-based multi-agent system for efficient LLM pretraining data selection. LLM converges faster in the pretraining and the method improves LLM output quality.
- The Data console integrates data inisghts dynamically from the different agents during the training process. 
- Agent console include quality/domain/topic-agents. Includes as well memory.


---


[Optima: Optimizing Effectiveness and Efficiency for LLM-Based Multi-Agent System](https://arxiv.org/abs/2410.08115)

- Optima (OPTImising effectiveness and efficiency for LLM-based Multi-Agent systems): Introduces framework to train LLM-based multi-agent system (MAS). 
- Includes 4 iterative steps: Generate/Rank/Select/Train.
- Investigates scaling laws of inference compute.
- Optima helps to make LLMs highly efficient conversationalists.

---


[DelTA: An Online Document-Level Translation Agent Based on Multi-Level Memory](https://arxiv.org/abs/2410.08143)

- DelTA (Document-level Translation Agent): Introduces translation LLM-agent using multi-layer memory components to improve translation consistency/quality.
- Memory components include: Proper noun memory(to apply correct terminology)/Bilingual summary/long-term/short-term-memory units.


---

[Mars: Situated Inductive Reasoning in an Open-World Environment](https://arxiv.org/abs/2410.08126)

- Mars: Introduces framework for Situated Inductive Reasoning-benchmark and a framework with LLM-agents called: IfR (Induction from Reflection). 
- The paper identifies two critical components for inductive reasoning: situatedness (situational context) and abstractiveness (abstract conclusions).
- IfR-framework includes task proposer/planner/controller/reflection-steps, rule library (when this, do that) and skill library. The LLM-based reflection-step induces new rules, which actual LLMs struggle currentyly.


---

[Benchmarking Agentic Workflow Generation](https://arxiv.org/abs/2410.07869)

- Introduces WorFEBench-benchmark for unified workflow generation and WorFEval evaluation protocol of workflows for LLM-agents.


---

#### 9th of October 2024

[AgentBank: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories](https://arxiv.org/abs/2410.07706)

- Samoyed: Introduces LLM-models fine-tuned with AgentBank-dataset for general agent tasks.
- AgentBank-dataset includes dimensions: reasoning/math/programming/web/embodied AI.


---


[Smart Audit System Empowered by LLM](https://arxiv.org/abs/2410.07677)

- Introduces Smart Audit System with LLMs, which include dynamic risk assessment model/manufacturing compliance copilot/Commonality analysis agent. Developed by Apple researchers.
- Dynamic risk assessment model adjusts audit: focus/sample size/critical items/resource allocation.  
- Manufacturing compliance copilot self-adjusts its the knowledge base with new information.
- Commonality analysis agent manages an autonomous agent conducting real-time analysis to custom requests, in order to drive supplier improvements. Includes planning/memory/tools/selecting and usage of tools/generating responses. 


---


[Embodied Agent Interface: Benchmarking LLMs for Embodied Decision Making](https://arxiv.org/abs/2410.07166)

- Introduces Embodied Agent Interface-benchmark for embodied decision making LLM-agents.
- Reviews four critical capabilities: Goal interpretation, Subgoal decomposition, Action sequencing and Transition modelling.


---

[I Want to Break Free! Anti-Social Behavior and Persuasion Ability of LLMs in Multi-Agent Settings with Social Hierarchy](https://arxiv.org/abs/2410.07109)

- zAImbardo-framework: Introduces LLM-agent simulation between prisoner/guard-agents using prompts, which are either shared or private.
- Shared prompts: communication rules/environment description/research oversight/risks. Private prompts: Starting prompt/personality/goals.


---

[Towards Realistic UAV Vision-Language Navigation: Platform, Benchmark, and Methodology](https://arxiv.org/abs/2410.07087)

- Introduces UAV navigation agent using MLLM. Includes three levels of assistants: constant/difficult situations/hazard situations.


---

[MOOSE-Chem: Large Language Models for Rediscovering Unseen Chemistry Scientific Hypotheses](https://arxiv.org/abs/2410.07076)

- Moose-Chem: multi-agent framework to discover novel chemistry research hypothesises from given information.


---

[Seeker: Enhancing Exception Handling in Code with LLM-based Multi-Agent Approach](https://arxiv.org/abs/2410.06949)

- Seeker: introduces LLM-based multi-agent framework for exception handling with planner/detector/predator/ranker/handler-agents.


---

[ST-WebAgentBench: A Benchmark for Evaluating Safety and Trustworthiness in Web Agents](https://arxiv.org/abs/2410.06703)

- ST-WebAgentBench-benchmark: Evaluates safety and trustworthy of web agents against performing undesired operations in business/user applications.


---

[Do great minds think alike? Investigating Human-AI Complementarity in Question Answering with CAIMIRA](https://arxiv.org/abs/2410.06524)

- CAIMIRA (Content-Aware, Identifiable, Multidimensional, Item Response Analysis)-framework: Reviews differences between humans and SOTA-level LLMs in QA-tasks in reasoning and textual understanding. 


---

#### 8th of October 2024

[AgentSquare: Automatic LLM Agent Search in Modular Design Space](https://arxiv.org/abs/2410.06153)

- AgentSquare: Introduces modular LLM-agent framework using module evolution, recombination and performance predictor(skip unpromising agent designs). - The framework optimizes agent designs with Planning/Reasoning/Tool use/Memory-modules.
- Introduces the research concept of MoLAS (Modularized LLM Agent Search): the automatic optimization of LLM-agent designs from succesfull designs.
- Includes search-, program-level search- and performance predictor-meta prompts. 


---

#### 7th of October 2024

[LLMs Are In-Context Reinforcement Learners](https://arxiv.org/abs/2410.05362)

- In-Context Reinforcement Learning (ICRL): Introduces ICRL-algorithm (increases test-time compute), which effectively learns reward from a classification task. The explorative-version concentrates on positive episodes and stochasticity.
- Naive ICRL explores poorly.

---

[Scalable and Accurate Graph Reasoning with LLM-based Multi-Agents](https://arxiv.org/abs/2410.05130)

- GraphAgent-Reasoner (GAR): explicit and precise graph-reasoning with multi-agent collaboration.
- Works to solve real-world graph-reasoning such as webpage ranking,
- Distributes tasks into nodes (over 1000) to multiple agents collaborating between each other.
- Includes stages: Algorithmic establishment (retrieve/initialisation/adjust/design), Distributed execution (Master LLM assigns task, agent network communicates) and Master summarisation (termination/aggregation/conclusion).
- Master LLM defines for each problem 6 components: State/Message/Initialization/Send/Update/Termination.

---

[Grounding Partially-Defined Events in Multimodal Data](https://arxiv.org/abs/2410.05267)

- Reviews event extraction from unstructured video data using multimodal event analysis with LLMs.

---

[GLEE: A Unified Framework and Benchmark for Language-based Economic Environments](https://arxiv.org/abs/2410.05254)

- Introduces GLEE (Games in Language-based Economic Environments)-benchmark, which reviews LLMs in two-player economic game families of bargaining, negotiation andd persuasion.


---

#### 26th of September 2024

[AssistantX: An LLM-Powered Proactive Assistant in Collaborative Human-Populated Environment](https://arxiv.org/abs/2409.17655)

- AssistantX: multi LLM-agent framework (PPDR4X) to help users achieve goals in virtual / physical environments.
- PPDR4X-framework includes short term memory (initial instructions/dialogue data/agent thoughts/cyber tasks/real world tasks), long-term memory (environment information), perception-agent, planning-agent, reflection agent and decision agent. 


---

[Control Industrial Automation System with Large Language Models](https://arxiv.org/abs/2409.18009)

- Introduces multi LLM-agent industrial control system, which consists of summarizer-, manager- (planning level), event log manager-, operator-agents (control-level) and command line/event log memory/prompt templates/events/function calls.


---

[Compositional Hardness of Code in Large Language Models -- A Probabilistic Perspective]()

- Reviews the difficulty of processing multiple sub-tasks within single LLM call with ICL to produce correct solution, which is called "In-Context Hardness of Composition".
- Refers to new term called "Screening", which refers to LLMs capacity to isolate the relevant context. For example LLM with capacity to perform two tasks, may fail performing both within same context.
- Finds, that is better to distribute tasks to multiple LLM-agents, when task becomes complex. Offers a literature review of the CoT problem solving and agents-research intersection.

---

#### 25th of September 2024

[Turn Every Application into an Agent: Towards Efficient Human-Agent-Computer Interaction with API-First LLM-Based Agents](https://arxiv.org/abs/2409.17140)

- AXIS: Priorites task completing API-calls above UI-agent actions, which decrases task completion time and cognitive workload.
- It is more useful to generate efficient API-call agent using programmatic API, than slower human-like UI agent.
- Includes Explorer-, Follower-, Monitor-, Generator-, Evaluator- and Translator-agents.
- Enables converting any application, with basic API/documentation and: environment state interface/basic action interface, into agent. Uses self-exploratory framework to identify control elements.


---

[A Roadmap for Embodied and Social Grounding in LLMs](https://arxiv.org/abs/2409.16900)

- Reviews the grounding of LLMs with physical world. Highlights the importance of social grounding of physical experiences. For example a child can build understanding of heavy objects just by observing an adult trying to lift a heavy box.
- Interesting ideas about the way human perception in physical world.


---

[Plurals: A System for Guiding LLMs Via Simulated Social Ensembles](https://arxiv.org/abs/2409.17213)

- Introduces Plurals-framework: generates diverse agents (stakeholder) based on demographic data to interact diverse opinions using a structrured debate and moderator.
- The demographic data is basis for generating the agents, which helps to tune the messages to specific audiences.
- Includes Structures, which forces LLM-agents to share information with a properly formed structure.
- Moderator-agent then summarises this discussion by trying to take into account the diverse opinions.


---

[Language Grounded Multi-agent Communication for Ad-hoc Teamwork](https://arxiv.org/abs/2409.17348)

- Grounds MARL agent communication with LLM generated synthetic data, which improves communicatio and zero-shot collaboration between agents.

---

#### 24th of September 2024

[Synatra: Turning Indirect Knowledge into Direct Demonstrations for Digital Agents at Scale](https://arxiv.org/abs/2409.15637)

- Synatra: is an approach that transforms indirect knowledge into direct supervision for digital agents at scale.
- Synatra leverages LLMs to repurpose human-created tutorials and ungrounded observations into executable action sequences, and includes a 7B CodeLlama model.
- This framework enables more effective and cheaper training of digital agents compared to human demonstrations.


---

[MOSS: ENABLING CODE-DRIVEN EVOLUTION AND CONTEXT MANAGEMENT FOR AI AGENTS](https://arxiv.org/abs/2409.16120)

- MOSS (IIM-oriented Operating System Simulation): is a framework integrating code generation with a dynamic context management system.
- MOSS uses Inversion of Control (IoC) container, decorators, maintains Python context, isolates local variables, preserves runtime integrity, and enables code-driven evolution.
- This framework enhances efficiency and capabilities of AI agent development, moving towards Turing-complete agents.


---


---


#### 23rd of September 2024

[ERABAL: Enhancing Role-Playing Agents through Boundary-Aware Learning](https://arxiv.org/abs/2409.14710)

- ERABEL: Introduces boubdary-aware role playing framework to maintain role comsistency in multiturn conversation.
- Includes dialogue planner/topic manager/question generator/response generator-agents.
- Includes prompts for esch agent.


---

#### 22th of September 2024

[BACKTRACKING IMPROVES GENERATION SAFETY](https://arxiv.org/abs/2409.14586)

- Backtracking: is a technique that allows language models to "undo" and recover from their own unsafe generation through the introduction of a special [RESET] token.
- Backtracking can be incorporated into either SFT or DPO training, provides protection against adversarial attacks, and improves safety without regression in helpfulness.
- This method provides a new approach to improve language model safety by allowing models to recover from unsafe generations.




#### 20th of September 2024

[RRM: Robust Reward Model Training Mitigates Reward Hacking](https://arxiv.org/abs/2409.13156)

- RRM (Robust Reward Model): Reviews reward models ability to differentiate signal from the genuine context and irrelevant information to decide preference. Proposes usage of causal graph.
- Produces more robust reward model.

---

[ChainBuddy: An AI Agent System for Generating LLM Pipelines](https://arxiv.org/abs/2409.13588)

- ChainBuddy: Includes requirements gathering agent (primary user goal/list of req./user preferences/suggested Cot strategy), planner agent (includes replanner), task-specific agents, connection agent and post-hoc reviewer agent.

---

[Minstrel: Structural Prompt Generation with Multi-Agents Coordination for Non-AI Experts](https://arxiv.org/abs/2409.13449)

- Minstrel: a multi-agent framework for automated prompt optimization. Prompts are constructed using role, profile, constraints, goals, initialization and examples, workflow, skills, suggestions, background, style, output format and command modules.
- Agents are assigned to working groups in charge of similar small tasks.

---

[ShizishanGPT: An Agricultural Large Language Model Integrating Tools and Resources](https://arxiv.org/abs/2409.13537)

- ShizishanGPT: LLM agent for answering with agriculture-based RAG.


---


#### 19th of September 2024

[Training Language Models to Self-Correct via Reinforcement Learning](https://arxiv.org/abs/2409.12917)

- SCoRe (Self-Correct via Reinforcement Learning): Increases LLMs capacity to self-correct via multi-turn Reinforcement Learning.
- Achieves positive intrinsic self-correction performance as first model.

---

[AutoVerus: Automated Proof Generation for Rust Code](https://arxiv.org/abs/2409.13082)

- AutoVerus: LLM generates correctness proofs for Rust-code using multi-agent framework (proof generation, refinement and debugging).


---

#### 17th of September 2024

[LLM-Agent-UMF: LLM-based Agent Unified Modeling Framework for Seamless Integration of Multi Active/Passive Core-Agents](https://arxiv.org/abs/2409.11393)

- LLM-agent UMF (Unified Modelling Framework): Introduces modular LLM-agent framework, which includes core agent coordinating with planning, memory, profile, action and security modules.
- Proposes various multi agent frameworks.
- Proposes active and passive information types. 
- Includes lots of useful ideas for each component.


---

[NVLM: Open Frontier-Class Multimodal LLMs](https://arxiv.org/abs/2409.11402)

- NVLM: frontier level VLM model and high performance as LLM only.
- Finds, that dataset quality and task diversity impact more than scale.
- Finds positive transfer from image to text only modality.


---

[P-RAG: Progressive Retrieval Augmented Generation For Planning on Embodied Everyday Task](https://arxiv.org/abs/2409.11279)

- P-RAG: Introduces iteratively updated RAG (self-iterations). P-RAG adds more task-specific knowledge.
- The RAG stores the following information: goal instruction, scene graph, history and done.


---

[EmPO: Emotion Grounding for Empathetic Response Generation through Preference Optimization](https://arxiv.org/abs/2406.19071)

- EmPO: Introduces the EmpatheticDialogues-dataset for fine tuning LLMs with empathic response generation (ERG). 


---


#### 16th of September 2024

[Instigating Cooperation among LLM Agents Using Adaptive Information Modulation](https://arxiv.org/abs/2409.10372)

- SLA (Strategic LLM Agent): combines LLM agents (SLAs) and RL-agent called Pro-social Promoting Agent (PPA) to increase cooperation rate.
- Adjusts dynamically access to SLA's information (cooperation history with neighbours, average) to increase facilitate social interaction.


---

[Cognitive Kernel: An Open-source Agent System towards Generalist Autopilots](https://arxiv.org/abs/2409.10277)

- Cognitive Kernel: introduces autopilot-like LLM-agent with access to internet with the web browser (appears to use Playwright-library) to interact "human-like" manner (click, scroll, etc).
- The LLM agent interacts with user and task environment. Includes reasoning kernel, memory kernel and perception kernel.
- LLM is fine tuned to interact with the environment through atomic actions, which a normal person could perform, rather than API call.
- Offers interesting ideas for each sub-compoment, as each includes plenty of detailed functionalities. 


---

[Central Answer Modeling for an Embodied Multi-LLM System](https://arxiv.org/abs/2406.10918)

- CAM (Central Answering Model): Introduces CAM-framework, where instead of LLM-agent directly answering question, multiple LLM-agent instances generate answer and a central LLM-agent responds to the question.


---


#### 15th of September 2024

[RethinkMCTS: Refining Erroneous Thoughts in Monte Carlo Tree Search for Code Generation](https://arxiv.org/abs/2409.09584)

- RethinkMCTS: conducts thought-level searches before generating code and adds both verbal feedback to refine thoughts and code execution feedback from incorrect code. 
- Increasing the number of rethink- and rollout-operations improve code generation.


---


#### 14th of September 2024

[PeriGuru: A Peripheral Robotic Mobile App Operation Assistant based on GUI Image Understanding and Prompting with LLM](https://arxiv.org/abs/2409.09354)

- PeriGuru: LLM-agent for GUI with perception, decision and action steps.


---

[Enhancing Decision-Making for LLM Agents via Step-Level Q-Value Models](https://arxiv.org/abs/2409.09345)

- Introduces task-relevant Q-value model for guiding action selection.
- Includes review of the different methods to improve reasoning, such as LLMs using MCTS.


---


#### 13th of September 2024

[Agents in Software Engineering: Survey, Landscape, and Vision](https://arxiv.org/abs/2409.09030)

- Introduce LLM-agents with perception, memory and actions for SW engineering. Includes multi-agent workflow with feedback, refinement and roles.
- Actions include internal (reasoning, learning and retrieval) and external (digital environment, dialogue with human/agent)). 
- Memory includes procedural, semantic and episodic.
- Perception includes textual (UML, execution result, text/code), visual and auditory.
- Includes good overview of different reasoning techniques for the CoT-action.


---


#### 12th of August 2024

[Windows Agent Arena: Evaluating Multi-Modal OS Agents at Scale](https://arxiv.org/abs/2409.08264)

- Navi: introduces a multi modal agent for Windows OS.
- Processes screen information called SoM (Set of Marks) with multiple alternative methods : UIA (User Interface Automation) tree, parses DOM tree, uses propietary OCR, icon/image detection and OmniParser-model.
- Agent prompt includes: task instruction, description of action space, history of actions, clipboard content and thought-variable memory. The prompt includes as well previus/current step screenshot with SoMs.
- Introduced WindowsAgentArena-benchmark.
- Includes the agent prompt.


---

#### 11th of September 2024

[Agent Workflow Memory](https://arxiv.org/abs/2409.07429)

- Agent Workflow Memory (AWM): LLM-agent retrieves and reuses reusable routines, which it extracts and generalises from past examples.
- Consists of LLM, memory and environment state (action-observation).
- Memory consists of: workflow description, workflow steps (environment state description, deduction process and action sequence). The memory-unit is described as text-based "system"-prompt. 
- Adds increasingly difficult workflows from previously acquired workflows and new experiences.
- Uses previously learned skills in new settings. Eliminates workflow steps, not required.

---

#### 10th of September 2024

[Think-on-Process: Dynamic Process Generation for Collaborative Development of Multi-Agent System](https://arxiv.org/abs/2409.06568)

- ToP (Think-on-Process): Multi-agent LLM-framework, which generates SW development processes using experiential knowledge.
- Each chat includes role assignment, memory stream and self-reflection.
- ToP-framework includes: instance generating, llm enhancing, instance filtering and software developing.
- Refers to concept of "Chat-chain", where multiple LLM-agents (CEO, CTO, CPO, Tester, Coder and Designer) operate.
- Converts processes to process textual descriptions: process-to-text and finally to process textual description.

---

#### 9th of September 2024

[SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning](https://arxiv.org/abs/2409.05556)

- SciAgents: Multi-agent graph-reasoning LLM-framework with retrieval for scientific discovery. 


#### 8th of September 2024

[Self-Reflection in LLM Agents: Effects on Problem-Solving Performance](https://arxiv.org/abs/2405.06682)

- Self-Reflection-Agents: Finds, that self-reflection improves performance of LLM agents in 6 different LLM tested.
- Self-Reflections, which contain more information (instructions, explanations, and solutions) perform better, than self-reflections with less data. 
- Retry-agent improves significantly performance, which indicates knowledge of a mistake, improves performance of the LLM.


---

#### 5th of September 2024


[Game On: Towards Language Models as RL Experimenters](https://arxiv.org/abs/2409.03402)

- Introduces RL experiment workflow using VLM (not fine-tuned) to perform tasks assigned typically to human experimenter. 
- The system monitors/analyses experiment progress, suggests new tasks, decomposes tasks and retrieves skills to execute. Does not automate
- Enables embodied autonomous agent to acquire zero-shot new skills. 

---



[From MOOC to MAIC: Reshaping Online Teaching and Learning through LLM-driven Agents](https://arxiv.org/abs/2409.03512)

- MAIC (Massively AI-empowered Course): Introduces multi LLM-agent system for scalable (like Massive Open Online Courses), but still adaptive (to personal needs / aptitudes) online education. Includes few comments from students, which highlight the limitss of its current approach.
- Includes LLM-agents acting both teachers, students, assistant, manager analyser and other agents. Teacher agents adjust style based on communication with the student. Human-student can select style of AI-classmates with the student.
- Classroom environment incldues current slide, dialogue history, class roles / course management. Course preparation includes read / plan stage, where slide content extraction, structure extraction, function generation and agent generation takes place.

---

[xLAM: A Family of Large Action Models to Empower AI Agent Systems](https://arxiv.org/abs/2409.03215)

- xLAM: Series (from 1B dense to  8x22B MoE) of Large Action Models (LAMs) for AI agent tasks. Achieves high performance in function calling.
- Fine-tunes basically from a LLM (DeekSeeker/Mistral models) a LAM, which is able to perform highly accurate function calling.


---

#### 4th of September 2024

[Cog-GA: A Large Language Models-based Generative Agent for Vision-Language Navigation in Continuous Environments](https://arxiv.org/abs/2409.02522)

- Cog-GA (Cognitive-Generative Agent)-agent: Introduces Visual-Language Navigation (VLN)-agent in continuous environments with cognitive maps (spatial, temporal and semantic information) and reflection.
- Includes instruction processor, high-level planner, waypoint predictor, memory stream (reflection memory/cognitive map), reflection generator and low-level actuator. Instructions are provided as text, panorama input image. Target waypoints are stored in the cognitive maps-memory.
- Cognitive maps include spatial memories about scene descriptions and landmarks in time step. 
- Limits search space by employing dual-channel waypoint using information about the landmark objects (what) and spatial characteristics (where).

---

[Configurable Foundation Models: Building LLMs from a Modular Perspective](https://arxiv.org/abs/2409.02877)

- Reviews modularity of LLMs. The idea is to instead of re-training from scratch a LLM, to add new knowledge as modules (called emergent bricks pretrained and customised bricks postrained).
- Identifies the following brick-operations: retrieval / routing, merging, updating and growing.


---

[Large Language Model-Based Agents for Software Engineering: A Survey](https://arxiv.org/abs/2409.02977)

- Survey about SW engineering LLM-agents.


---

[MoA is All You Need: Building LLM Research Team using Mixture of Agents](https://arxiv.org/abs/2409.07487)

- MoA (Mixture-of-Agents)-framework (name was already used before) is a framework with planner, aggregator and varios LLM-agentseach with their own RAG, grouped together.


---


#### 3rd of September 2024

[Empirical evidence of Large Language Model's influence on human spoken communication](https://arxiv.org/abs/2409.01754)

- Empirical evidence, that humans imitate LLMs.
- Finds, that LLMs reduce linguistic diversity, but it appears an interesting topic to discover, if LLMs only decrease diversity or impact other ways / the ways content creation automation impacts overall to society.


---

[AgentRE: An Agent-Based Framework for Navigating Complex Information Landscapes in Relation Extraction](https://arxiv.org/abs/2409.01854)

- AgentRe: Relation Extraction (RE) agent includes three components: retrieval (static knowledge to help store/retrieve information), memory(dynamic knowledge: shallow memory for extraction results, deep memory for historical action summaries/reflections) and extraction modules (ReAct-based, pulls information based on retrieval and memory).
- Avoids extracting for incomplete entities, such as phrases referring in general to Museums without being precise on the exact name of the museum.

---

[Focus Agent: LLM-Powered Virtual Focus Group](https://arxiv.org/abs/2409.01907)

- Focus Agent: Simulates moderation of focus groups with human participants and alignment of focus agent opinions with this group.
- Simulates planning, moderation, questions, discussion and reflection with LLM-agents.

---

#### 2nd of September 2024

[The Compressor-Retriever Architecture for Language Model OS](https://arxiv.org/abs/2409.01495)

- Compressor-Retriever-architectore: Introduces concept of stateful LLM OS by using only base model forward function to compress and retrieve context.
- Reviews concept of LLM acting as a CPU and its context window acting as RAM.
- Identifies life-long context as infite, which is core issue with actual session-based interactions.
- Compressor builds hierarchical db to save previously chunked context. The retriever searches relevant context.


---


[An Image is Worth 1/2 Tokens After Layer 2: Plug-and-Play Acceleration for VLLM Inference](https://arxiv.org/abs/2403.06764)

- FastV: versatile plug-and-play method designed to optimize computational efficiency by learning adaptive attention patterns and pruning visual tokens.
- Inefficient attention in LVLMs, visual tokens inefficiency in deep layers, adaptive attention, visual token pruning, computational cost reduction, performance maintained, customizable, Pareto-efficient.
- FastV has practical value for LVLM deployment in edge devices and commercial models.


---



#### 1st of September 2024

[Self-evolving Agents with reflective and memory-augmented abilities](https://arxiv.org/abs/2409.00872)

- SAGE: Introduces self-evolving LLM-agent consisting of user/assistant/checker-agents with iterative feedback, reflection and memory optimization (Ebbinghaus-forgetting curve). 
- Self-evolution includes adaptive adjust strategies, optimizing information storage and transmission and reduction of cognitive context.
- Mimics human brain / memory by creating MemorySyntax, which combines Ebbinghaus forgetting curve and linguistic knowledge.  


---

[LanguaShrink: Reducing Token Overhead with Psycholinguistics](https://arxiv.org/abs/2409.00855)

- LannguageShrink: Reduces prompt length (tokens to process) by optimising the prompt by applying psycholinguistic principles and the Ebbinghaus memory curve.
- For example removes words like "usually" from the prompt, which add complexity, ambiguity, irrelevance etc.

---

#### 30th of August 2024

[Tool-Assisted Agent on SQL Inspection and Refinement in Real-World Scenarios](https://arxiv.org/abs/2408.16991)

- Tool-SQL: LLM-agent for SQL code inspection and fixing using retrieval and refinement. 


---

#### 29th of August 2024

[Physics of Language Models: Part 2.2, How to Learn From Mistakes on Grade-School Math Problems](https://arxiv.org/abs/2408.16293)

- Learns to automatically retry after detecting error (Retry upon regret) in the LLM generation, which does not require additional self-verification prompting. 
- The model seeks to produce correct solutions, even when up to half of the solution steps include errors and only corrects itself rare cases, when making a mistake. 
- Indicates, that the skill of error correction is significantly different from the pure error-free reasoning, which requires weights update beyond PEFT.
 reasoning accuracy, masking errors is unnecessary, and models still output shortest solutions.
- Indicates, that LLMs often know at least in certain domains of having made mistakes and can be seen as simple linear classifier on top of its hidden states. 
- This work provides insights into how to effectively train language models to correct errors during reasoning tasks.


---

[Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling](https://arxiv.org/abs/2408.16737)

- Suggests, that LLMs fine-tuned with synthetic data from weaker, yet cheaper LLM is more compute optimal, than using stronger, yet more expensive LLM.
- Samples data from Gemini Pro 1.5 (more expensive, stronger) compared to Gemini Flash 1.5. by using pricing per token as a proxy.


---

[CogVLM2: Visual Language Models for Image and Video Understanding](https://arxiv.org/abs/2408.16500)

- Introduces CogVLM2-family of models: CogVLM2, CogVLM2-Video and GLM-4V.
- Relates to CogAgent-GUI agent introduced in December 2023.

---


#### 28th of August 2024

[A Survey on Evaluation of Multimodal Large Language Models](https://arxiv.org/abs/2408.15769)

- The Survey reviews Multi Modal Language Models (MLLMs).


---

[WebPilot: A Versatile and Autonomous Multi-Agent System for Web Task Execution with Strategic Exploration](https://arxiv.org/abs/2408.15978)

- WebPilot: Introduces Multi-Agent System with Planner(generate and refine plan)/Controller(judge sub-task terminatation, asses sub-task completion, generate strategic reflection)/Extractor(extract information)/Explorer(generate action, analyse observation, generate tactical reflection)/Apprasier(asses state)/Verifier(format action, deduplicate action) LLM-agents.
- Uses  Global Optimization (decomposing tasks/refining high-level plans with reflective analysis) and Local Optimization (executes sub-tasks with customized MCTS/refining decisions iteratively through with each observation).
- Tasks include navigating forums/upvoting posts/extracting contributor emails.


---

[AutoGen Studio: A No-Code Developer Tool for Building and Debugging Multi-Agent Systems](https://arxiv.org/abs/2408.15247)

- AutoGen Studio: Build on top of AutoGen, the AutoGen Studio includes drag & drop web-UI to customize/attach model/skills/tools/memory/agents involved.
- The workflow is saved as declarative json-structure. Users can export this json and share it to other users. Apart includes built-in DB Manager, Workflow Manager and Profiler-classes.
- Backend includes Python API, web API and CLI. 


---

[Interactive Agents: Simulating Counselor-Client Psychological Counseling via Role-Playing LLM-to-LLM Interactions](https://arxiv.org/abs/2408.15787)

- Investigates using LLM-agents for Psychological Counseling dialogue (counselor/client) based on client profiles (mental health issue description/detailed description of the disorder/symptom/problem/chief complaint) and counselor simulation is based on exploration, insight, and action.


---

[BattleAgentBench: A Benchmark for Evaluating Cooperation and Competition Capabilities of Language Models in Multi-Agent Systems](https://arxiv.org/abs/2408.15971)

- Introduces BattleAgentBench-benchmark, which reviews rule understanding, spatial perception, competition, static cooperation and dynamic cooperation.

---

[Atari-GPT: Investigating the Capabilities of Multimodal Large Language Models as Low-Level Policies for Atari Games](https://arxiv.org/abs/2408.15950)

- Atari-GPT: Applies Multi Modal Language Model as low-level policy (controller). 


---


[FlowAct: A Proactive Multimodal Human-robot Interaction System with Continuous Flow of Perception and Modular Action Sub-systems](https://arxiv.org/abs/2408.15864)

- FlowAct: Introduces human-robot interaction system, which continuously perceives and acts. Uses two controllers: Environment State Tracking (EST) and Action Planner. 


---

[Retrieval-Augmented Instruction Tuning for Automated Process Engineering Calculations : A Tool-Chaining Problem-Solving Framework with Attributable Reflection](https://arxiv.org/abs/2408.15866)

- RAIT (Retrieval Augmented Instruction Fine-tuning): Introduces RAIT fine-tuning approach in chemical / process engineering, which combines small language models (SMLs) with Retrieval Augmented Code Generation (RACG).

---

[Towards Fully Autonomous Research Powered by LLMs: Case Study on Simulations](https://arxiv.org/abs/2408.15512)

- Reviews feasibility of Autonomous Simulation Agent (ASA) to automate E2E research process using LLMs and API automation (AutoProg).


---

[LogicGame: Benchmarking Rule-Based Reasoning Abilities of Large Language Models](https://arxiv.org/abs/2408.15778)

- LogicGame: Benchmarks rule-based reasoning, execution and planning of LLMs.


---

[Persuasion Games using Large Language Models](https://arxiv.org/abs/2408.15879)

- Introduces persuasion framework with LLM-agents, but the paper is not clearly indicating conclusions about persuasion with LLMs with doubts as well on exact roles/prompts. 


---

[EPO: Hierarchical LLM Agents with Environment Preference Optimization](https://arxiv.org/abs/2408.16090)

- EPO (Environment Preference Optimization): Generates preference signals from environmental feedback for long-horizon decision making with LLM-agents.
- LLM predicts sub-goals and respective low-level actions.
- Interaction module generates two types of sub-goals: navigation and interaction.


---

#### 27th of August 2024

#### 27th of August 2024

[Generative Verifiers: Reward Modeling as Next-Token Prediction](https://arxiv.org/abs/2408.15240)

- GenRM-verifier (Generative Reward Models): proposes training verifiers with next-token prediction objective.
- Combines verification and solution generation, whichh improves verification-process.
- GenRM outperforms classifier-based discriminatary (assigns numerical score to answer, which is used to classify as correct/incorrect answer) verifiers and LLM-as-a-judge (tends to underperform trained LLM-based verifiers).
- Integrates with fine-tuning, CoT and is able to use inference-time compute in form of majority vote to improve verification.
- Enables inference-time compute for CoT Verifiers (GenRM-CoT). Uses [reference-guided grading](https://arxiv.org/abs/2306.05685) to assist "Let's verify step by step"-verification on test-time problems lacking reference solution.
- See [slides here](https://drive.google.com/file/d/1komQ7s9kPPvDx_8AxTh9A6tlfJA0j6dR/view).

--- 



[AgentMonitor: A Plug-and-Play Framework for Predictive and Secure Multi-Agent Systems](https://arxiv.org/abs/2408.14972)

- AgentMonitor: Captures multi agent (MAS) inputs and outputs to predict task performance and correcting security risks in real-time.
- Includes 5 different MAS configurations.

---

[HPT++: Hierarchically Prompting Vision-Language Models with Multi-Granularity Knowledge Generation and Improved Structure Modeling](https://arxiv.org/abs/2408.14812)

- Introduces Hierarchical Prompt Tuning (HPT) and HPT++. Adapts VLM by creating a graph from each description with hierachical relationship guided attention module.


---

[TourSynbio: A Multi-Modal Large Model and Agent Framework to Bridge Text and Protein Sequences for Protein Engineering](https://arxiv.org/abs/2408.15299)

- TourSnmbio-Agent: Performs protein engineering tasks using TourSynbio-7B model (fine-tuned on text and protein sequences).
- Includes intent classification steps, where is defined in case the user intent is generic question or agent-specific task. 
- Keywords are used in agent selection.


---

#### 26th of August 2024

[Foundation Models for Music: A Survey](https://arxiv.org/abs/2408.14340)

- Reviews research available on Foundational models for Music: representations of music, applications, foundational model techniques, datasets/evals and ethics. 


---

[AgentMove: Predicting Human Mobility Anywhere Using Large Language Model based Agentic Framework](https://arxiv.org/abs/2408.13986)

- AgentMove: Mobility prediction LLM agent.
- Includes spatial-temporal memory.


---

[SWE-bench-java: A GitHub Issue Resolving Benchmark for Java](https://arxiv.org/abs/2408.14354)

- Benchmark to evaluate LLM-agent based coding for Java programming language (SWE-bench for Java).


---

#### 23th of August 2024

[LIMP: Large Language Model Enhanced Intent-aware Mobility Prediction](https://arxiv.org/abs/2408.12832)

- LIMP (LLMs for Intent-aware Mobility Prediction): Fine-tunes LLama 3-8B-Instruct model with Analyze-Abstract-Infer (A2I)-agentic workflow for mobility intent reasoning.


---

[Intelligent OPC Engineer Assistant for Semiconductor Manufacturing](https://arxiv.org/abs/2408.12775)

- RL / multimodal LLM-agents solve Optical Proximity Correction (OPC)-problems in semiconductor manufacturing using RL-based recipe search, which typically require years of OPC engineering experience.


---


#### 22th of August 2024

[MEDCO: Medical Education Copilots Based on A Multi-Agent Framework](https://arxiv.org/abs/2408.12496)

- MEDCO (Medical EDucation COpilots): Includes patient, student, expert doctor and radiologist multimodal (X-rays/CT scans/MRIs/ultrasounds) LLM-agents. Student agents are trained/taught with feedback provided and then stored in student memory module to improve future diagnosis.


---

[Graph Retrieval Augmented Trustworthiness Reasoning](https://arxiv.org/abs/2408.12333)

- GRATR (Graph Retrieval Augmented Reasoning): Improves trustworthiness reasoning of the LLM agent using Evidence base.
- Evidence base is updated based on observation analysis and observation assessment.

---

[MDD-5k: A New Diagnostic Conversation Dataset for Mental Disorders Synthesized via Neuro-Symbolic LLM Agents](https://arxiv.org/abs/2408.12142)

- Neuro-symbolic multi agent framework, which includes doctor, patient and tool LLM-agent interaction and dynamic (patient specific information) diagnosis tree. Introduces mental disorders diagnosis dataset MDD-5k.
- Doctor agent includes persona, diagnosis result, dialogue generation. Patient agent includes patient information, patient experience and knowledge graph.
- Establishes deeper engagement with patient to help generate diagnosis by generating the dynamic diagnosis tree. 

---

[Balancing Act: Prioritization Strategies for LLM-Designed Restless Bandit Rewards](https://arxiv.org/abs/2408.12112)

- Introduces customizable Social Choice Language Model: Uses an external adjudicator to manage tradeoffs via a user-selected social welfare function. Uses LLM to design reward functions in Restless Multi-Armed Bandits-allocation problems.
- Suggests, that prompt engineering alone 


--

[SocialQuotes: Learning Contextual Roles of Social Media Quotes on the Web](https://arxiv.org/abs/2407.16007)

- Introduces SocialQuotes-dataset to classify social media / web context into roles (influencer, expert, marketer, commenter, etc.)


---

---

[Can LLMs Understand Social Norms in Autonomous Driving Games?](https://arxiv.org/abs/2408.12680)

- LLM-agent autonomously drives in multi-agent driving game with social norms. Agents make self-driven decisions without attempting to cooperate.


---

#### 21st of August 2024

[Story3D-Agent: Exploring 3D Storytelling Visualization with Large Language Models](https://arxiv.org/abs/2408.11801)

- Story3D-Agent: LLM-agent used in 3D storytelling visualization with consistent contextually and narrative.


---

[Leveraging Chemistry Foundation Models to Facilitate Structure Focused Retrieval Augmented Generation in Multi-Agent Workflows for Catalyst and Materials Design](https://arxiv.org/abs/2408.11793)

- Improves chemistry information retrieval/catalyst and materials design usage of Chemical Foundational model (such as MolFormer-XL) by combining it with RAG.


---

[LLM4VV: Exploring LLM-as-a-Judge for Validation and Verification Testsuites](https://arxiv.org/abs/2408.11729)

- Agent-based prompting and validation pipeline increase quality of the LLM as a Judge for compiler tests.


---

[DreamFactory: Pioneering Multi-Scene Long Video Generation with a Multi-Agent Framework](https://arxiv.org/abs/2408.11788)

- DreamFactory: video generation-framework, which generates long/complex and stylistically coherent videos using multi-agent video production agent team.
- Includes requirement analysis/planning/framework preparation/script generation/scenes design/shots design/key-frames generation and video generation. 
- Lacks still creativity (artistic/devising plots) due to reliance on prompts, seems as individual videos stitched together based on synthetic audio clip and need for significant computational resources.


---

[Leveraging Fine-Tuned Retrieval-Augmented Generation with Long-Context Support: For 3GPP Standards](https://arxiv.org/abs/2408.11775)

- Implements fine-tuned Phi-2 with RAG (semantic chunking/extended context support) in telecommunications. 


---

[Cause-Aware Empathetic Response Generation via Chain-of-Thought Fine-Tuning](https://arxiv.org/abs/2408.11599)

- CFEG (Cause-aware Fine-tuning Empathetic Generation)-method: Uses emotion cause reasoning and fine-tuned LLM with CoT. Demonstrates superior empathetic dialogue responses.


---

#### 20th of August 2024


[FLAME: Learning to Navigate with Multimodal LLM in Urban Environments](https://arxiv.org/abs/2408.11051)

- FLAME (FLAMingo Architected Embodied Agent): a multimodal language-vision agent for navigational tasks by using three-step tuning: single perception tuning/multiple perception tuning/end-to-end training on VLN datasets.


---

[Athena: Safe Autonomous Agents with Verbal Contrastive Learning](https://arxiv.org/abs/2408.11021)

- Athena: Improves aligned with verbal contrastive learning, which guides LLM-agent behaviour with past safe/unsafe trajectories as in-context contrastive examples and critiquing mechanism. Contains LLM-agents: Actor/Critic/Emulator interacting to complete given task.
- Introduces safety evalution benchmark for LLM-agents with 80 toolkits in 8 categories.


---

[Strategist: Learning Strategic Skills by LLMs via Bi-Level Tree Search](https://arxiv.org/abs/2408.10635)

- Strategist: LLM-agent learns new skills through self-improvement based on MCTS and LLM-based reflection. Generates new ideas based on performance in simulated self-play by analysing good ideas.


---

[MagicDec: Breaking the Latency-Throughput Tradeoff for Long Context Generation with Speculative Decoding](https://arxiv.org/abs/2408.11049)

- MagicDec: Speculative Decoding speeds throughput mid/long-context serving with sparse KV cache.

---

#### 19th of August 2024

[MegaAgent: A Practical Framework for Autonomous Cooperation in Large-Scale LLM Agent Systems](https://arxiv.org/abs/2408.09955)

- MegaAgent: Autonomous co-operation between dynamically generated LLM agents for specific task requirements. .
- Automatically generates sub-tasks (delegated to to sub-task admin, which coordinates the sub-task to group of agents), hierarchically plans systematically (boss agent) and monitors concurrent agent activities. OS agent coordinates, that agents communicate in proper format and progress with the task.
- The Storage module includes: log, memory db, task monitor, interactive python exec/Python, Files and Checklist.
- MegaAgent claims to pose high scalability/parallelism (due to agents communication cost grows logarithmically, not linearly), high effectiveness (manages 590 agents quicker than CAMEL-framework managed 2 agents. Summarizes previous conversations to store them in vector db) and high autonomy.


---

[GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining Automotive Software Release Decision-Making](https://arxiv.org/abs/2408.09785)

- GoNoGo: LLM-agent system, which includes Planner- and Actor-agents to process high-level queries for decision support in 120 seconds. Planner interprets user queries/plans analysis strategies. Actor generates code, resolves errors with memory/plugins/coder LLM with self-reflection.

---

#### 18th of August 2024


[Re-Invoke: Tool Invocation Rewriting for Zero-Shot Tool Retrieval](https://arxiv.org/abs/2408.01875)

- Re-Invoice: 
- LLM (Query generator) generates distinct queries from tools document index. Synthetic query copiess are stored with tool name, description and query. LLM (Intent extractor) retrieves most similar tools for new user queries based on multi-view ranking algorithm.
- The multi view-ranking defines for each intent, the most similar tools. For each intent, it picks the most relevant tool, starting with the intent with highest individual tool similarity. 
- Includes an intent extractor prompt, which works just by adding it as a system instruction.

---



[HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model](https://arxiv.org/abs/2408.09559)

- HiAgent: LLM-based agent, which uses subgoals to define working memory (intrial memory), instead of retrieving entire crosstrial memory (between experiments).
- The LLM-agent replaces previous subgoals with the relevant summarized observations (action-observation pairs) for the current task.


---

#### 16th of August 2024


[EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics](https://arxiv.org/abs/2408.08782)

- EmoDynamiX: an LLM agent predicting optimal socio-emotional strategy (strategy embedding) and emotion state (emotion embedding) in a dialogue.
- Uses Heterogeneous Graph (HG) to model the dialogue interaction: node types reflect past strategies/emotional states/predicted strategy of the agent and edge types reflect dialogue dependencies between turns and speaker role-awareness. 


---


#### 15th of August 2024


[Automated Design of Agentic Systems](https://arxiv.org/abs/2408.08435)

- ADAS (Automated Design of Agentic Systems): the Meta agents discovers new agents with superior performance compared to hand-designed agents. Suggests a research direction for higher-order ADAS, where ADAS is used to improve the meta agent itself in the ADAS.
- The system consists of Meta Agent, which generates new agents and corrects them until error free. The new agent is tested and then added to Agent library. For example specific agents consists of specific blocks such as COT/Verifier/Sub-problem division/etc., which are used in specific order in the system flow.
- Meta Agent Search-algorithm generates automatically new agentic system designs and system blocks.
- The Meta Agent Search-algorithm samples new agents optimizing performance in the Search space (prompts/control flows) evaluated with the Evaluation Function (cost/latency/safety). 
- Includes codes of few of the discovered agents.


---

#### 13th of August 2024

[Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents](https://arxiv.org/abs/2408.07199)

- Agent Q: Introduces real world website agent iteratively fine-tuned with DPO based MCTS with self-critique and AI feedback. Trajectory collection includes reward in each node of the tree. 
- Calculates a weighted score of the MCTS average Q-value. This score is generated by a feedback LLM to construct contrastive pairs for the DPO. The policy is optimised and iteratively improved.
- LLM is used to sample reasoning/website actions to explore.
- Achieves high performance in real world environmments and beats an average human-level performance.


---

---

#### 12th of August 2024

[The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery](https://arxiv.org/abs/2408.06292)

- AI Scientist: claims fully automatic scientific discovery by generating novel research ideas, writing code, executing experiments, visualizing results, drscribing findings to research paper and simulating evaluation process.


---

#### 9th of August 2024

[AmbigDocs: Reasoning across Documents on Different Entities under the Same Name](https://arxiv.org/abs/2404.12447)

- AmbigDocs: is a new benchmark for evaluating language models' ability to distinguish between different entities with the same name across multiple documents.
- It leverages Wikipedia's disambiguation pages, generates questions with ambiguous names, and provides corresponding sets of answers, and includes an ontology categorizing incomplete answers and automatic evaluation metrics.
- This work lays the foundation for future research on reasoning across multiple documents with ambiguous entities.


---

[Enhancing the Code Debugging Ability of LLMs via Communicative Agent Based Data Refinement](https://arxiv.org/abs/2408.05006)

- MASTER (CoMunicative Agent BaSed DaTa REfinement FRamework): code repair with LLM. Consists of Code Quizzer (code debug expert creates questions of the error), Code Learner (answers the generated questions) and Code Teacher (reviews and corrects incorrect answers) agents.
- Includes DEBUGEVAL-benchmark: bug localization, bug identification, code review and code repair.


---

#### 8th of August 2024

[Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive Debate](https://arxiv.org/abs/2408.04472)

- Agent4Debate: collaborative and dynamic multi-agent (searcher/analyzer/writer/reviewer) LLM for competitive debate.
- Includes Chinese Debate Arena-benchmark with
- Framework begins with context/motion/position/stage. Searcher gathers information, analyzer reviews arguments, writer generates arguments/debates and reviewer provides feedback on debate.


---

[RiskAwareBench: Towards Evaluating Physical Risk Awareness for High-level Planning of LLM-based Embodied Agents](https://arxiv.org/abs/2408.04449)

- RiskAwareBench: reviews physical risk awareness of embodied LLM agents. 
- Includes modules: safety tip generation/risky scene generation/plan generation & evaluation/ isk assesment.


---

#### 7th of August 2024

[Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions](https://arxiv.org/abs/2408.04168)

- PReP: city-navigation to goal using visual perception and memory (working, episodic & semantic) without instructions.
- Semantic memory summarizer memories from multiple steps, to perform high-level navigtion.


---

[Forecasting Live Chat Intent from Browsing History](https://arxiv.org/abs/2408.04668)

- LLM-based user intent prediction (to predict why user needs live-chat agen support) from high-level categories classified from browsing history and then in second step predicts fine-grained user intent with the high-level intent class and browsing history.



---

[CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases](https://arxiv.org/abs/2408.03910)

- LLM uses cod RAG. Builds code graph db from code repository. Nodes represent symbols, edges represent relationships between symbols and schema defines how code graphs are stored in the code db.


---

#### 6th of August 2024

[Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters](https://arxiv.org/abs/2408.03314)

- Reviews scaling up inference compute (test-time) in order to built self-improving agents. Quantifies the amount of improvement, when increasing inference.
- Test-time compute outperforms 14x larger models.
- Compute optiml scaling strategy can improve efficiency of test-time compute by factor of up to 4x.


---


#### 5th of August 2024

[ReDel: A Toolkit for LLM-Powered Recursive Multi-Agent Systems](https://arxiv.org/abs/2408.02248)

- ReDel (Recursive Delegation): Recursive multi-agent framework, where LLM decides when to delegate/how to delegate (delegation graph).
- Includes custom tool-use, delegation schema, event-based logging and interactive replay (web UI).
- Icludes open-source Python package.
- ReDel delegation schemes include DelegateOne (wait parent-agent until child-agent completion) and DelegateWait (provide separate function for parent agent to retrieve child agent response).
- Event-driven logging includes built-in events ans custom events.


---

[SpecRover: Code Intent Extraction via LLMs](https://arxiv.org/abs/2408.02232)

- SpecRover/AutoCodeRover-v2: autonomous github issue fixing by understanding developer intent from Github repo structure / developer behaviour.
- Claims Github issues can be solved as little as $0.65 /issue.


---

[LLM Agents Improve Semantic Code Search](https://arxiv.org/abs/2408.11058)

- RAG-agent (ensemble architecture), which adds relevant contextual information to the user query from the Github repository. 
- Uses RepoRift-platform, which improves code search by: narrows context search to single repository, uses agentic interaction and returns easy-to-understand results with low latency.


---
#### 3rd of August 2024

[The Drama Machine: Simulating Character Development with LLM Agents](https://arxiv.org/abs/2408.01725)

- Drama Machine: Reviews Automated Identity-generation with LLMs.  Uses multiple LLMs to simulate dynamic/complex AI characters in domain of drama scenes: interview/detective.
- Roles include Ego, SuperEgo, Autobiography, Director and Critic.

--- 

#### 2nd of August 2024

[Coalitions of Large Language Models Increase the Robustness of AI Agents](https://arxiv.org/abs/2408.01380)

- Coalition of LLM models outperform single model and fine-tuned LLMs.
- Specific LLMs fit for particular tasks and cheaper interference.


---

#### 1st of August 2024

[OmniParser for Pure Vision Based GUI Agent](https://arxiv.org/abs/2408.00203)

- OmniParser: VLM agent parsing GUI screenshots into structured data. Attempts to ground actions grounded on GUI regions.
- Includes detection model to captura interactable GUI regions. Caption model retrieves functional semantics of these detected elements. OCR generates structured reprentation of the GUI.
- Improves action prediction accuracy. Includes icon-detection dataset.
- Reviews comphrehensively screen coordinate detection problem of VLMs.
- Error cases include: repeated/misinterpreted icons, repeated texts and inaccurate bounding boxes. 

---

[AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation](https://arxiv.org/abs/2408.00764)

- AgentGen: Generates diverse LLM agent environments and planning tasks. LLM fine-tuned with this data improves significantly planning capabilities.
- Uses inspirational corpus to generate environment context (actions/restrictions/etc). Generates tasks, which include "difficulty diversification: easy/medium/hard with bidirectional evolution (Bi-Evol) to smoothly acquire new planning skills.


---

#### 31st of July 2024

[Tulip Agent -- Enabling LLM-Based Agents to Solve Tasks Using Large Tool Libraries](https://arxiv.org/abs/2407.21778)

- Tulip Agent and AutoTulipAgent: LLM-agent has priviledges to create, update, delete and edit tool library. 
- Self-Recursively extendible tool library. 
- AutoTulipAgent includes 5 generic tools: 2 to decompose tasks/search tools, includes apart capability to create/delete/update tools. 


---

#### 29th of July 2024

[Physics of Language Models: Part 2.1, Grade-School Math and the Hidden Reasoning Process](https://arxiv.org/abs/2407.20311)

- iGSM framework: is used to generate diverse grade-school math problems for training and testing language models.
- The framework includes a hierarchical categorization, structure graph, dependency graph, and solution construction using Chain-of-Thought (CoT) approach, and it uses GPT2-like language model with rotary embedding.
- This framework enables a principled study of language models' mathematical reasoning skills, going beyond empirical benchmark pushing.


---


#### 28th of July 2024

[Solving Robotics Problems in Zero-Shot with Vision-Language Models](https://arxiv.org/abs/2407.19094)

- Wonderful Team: uses off-shelf VLM model for high-level planning, low-level location extraction and action execution.


---

#### 26th of July 2024

[AppWorld: A Controllable World of Apps and People for Benchmarking Interactive Coding Agents](https://arxiv.org/abs/2407.18901)

- AppWorld-benchmark: simulates LLM-agents using App World Engine-execution environment (mimicking 9 real-world apps/simulates 457 APIs/100 ficticious and related users) by measuring 750 complex tasks (records database start state and end state to review correct/incorrect actions to Base DB), which require iterative/interactive code generation without real-world consequences. 
- Generates task scenarios, which are used by the task generator (setup/validation/evaluation). 
- Each task is checked to be: well-defined/includes distractors/has real distractors/contrasts from exissting other tasks.
- Includes Supervisor (provides passwords/credit cards/etc about the user), (API parameters/descriptions) and Execution Shell to run code.


---
#### 25th of July 2024

[The Platonic Representation Hypothesis](https://www.arxiv.org/abs/2405.07987)

- The Platonic Representation Hypothesis: Neural networks are converging to a shared statistical model of reality in their representation spaces.
- Convergence across data modalities; representation alignment over time; driven by data and task diversity; scaling model size.
- Understanding convergence is crucial for future AI development and capabilities.


---

[PersonaGym: Evaluating Persona Agents and LLMs](https://arxiv.org/abs/2407.18416)

- Introduces PersnaGym-benchmark to evaluate persona LLM-agents.
- Sets an automatic PersonaScore-metric to evaluate five different capabilities.
- Finds SOTA level LLMs to offer highly varying level of capabilities as persona-agents.
- Increasing model size is not guarantee of better persona agent performance with varying level of persona agent performance detected.

---

[Recursive Introspection: Teaching Language Model Agents How to Self-Improve](https://arxiv.org/abs/2407.18219)

- RISE (Recursive IntroSpEction): iteratively sel-improve LLM responses through fine-tuning with RL.
- LLM loss is lower, when using multi-turn data compared instead of only the final answer. Works only for reasoning, not knowledge tasks.
- Indicates strongly, that Full online RL is feasible with RISE and using iterative self-training procedure (such as STaR), because RISE improves the LLM with 5-turns with/without oracle model. 
- Demonstrates, that LLMs can self-improve its own mistakes to beyond level of propietary models, when trained with RISE. The self-improvement continues up to 6 iterations, demonstrating lower loss. 
- RISE starts with turn 1, where only prompt is provided. In turn 2, the prompt, the original response and its feedback is provided to generate the turn 2 response. Majority voting is used to select the final response from multiple responses generated. Alternatively, oracle model can be used to assist, when such is available.
- Why self-improvement works? RISE is compared to diffusion models, where generation is refined step-by-step. Similarly LLMs may lack "capacity" to process the request, which RISE can help to refine. See the talk on this paper [here.](https://www.youtube.com/watch?v=Qv8aTLthfhs).

---

#### 24th of July 2024


[Reinforced Prompt Personalization for Recommendation with Large Language Models](https://arxiv.org/abs/2407.17115)

- Reinforced Prompt Personalization (RPP): uses instance-based prompting with MARL.
- Instead of task-based (role-play/history/reasoning guidance/output format), Instance-based prompting personalises to these four-characteristics with MARL.


---

[AI-Gadget Kit: Integrating Swarm User Interfaces with LLM-driven Agents for Rich Tabletop Game Applications](https://arxiv.org/abs/2407.17086)

- AI-gadget Kit: multi-agent driven Swarm UI (SUI) tabletop gaming system, which consist of meta-motion, interactive behaviour, interactive relationship and application.  


---

[3D Question Answering for City Scene Understanding](https://arxiv.org/abs/2407.17398)
- Sg-CityU: 3D multimodal QA, which uses scene graph to provide answers related to spatial relationships about city-scenes


---

#### 23rd of July 2024

[RedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent](https://arxiv.org/abs/2407.16667)

- RedAgent: Introduces concept of "Jaillbreaking strategy" (strategies used by attackers to construct jaillbreaking prompts) red teaming through multi-agent self-reflection from context feedback and skill memory.
- The approach can jaillbreak LLMs and LLM-based apps (even more vulnerable) using just few queries.
- The Red-Agent architecture includes skill memory and multiple roles (profile constructor/planner/attacker/evaluator) and short/long term memory.

---

[AMONGAGENTS: Evaluating Large Language Models in the Interactive Text-Based Social Deduction Game](https://arxiv.org/abs/2407.16521)

- AmongAgents: multi-agent LLM-framework with memory, reflection and interaction in social deduction game with ambiguous and deceptive characters.
- Includes meeting/task-phases.
- Agents pose personality-component: generated with personality prompt from pre-defined set of personalities: behaviour/decision-making, which contribute to more dynamism/realism.

---

[OpenDevin: An Open Platform for AI Software Developers as Generalist Agents](https://arxiv.org/abs/2407.16741)

- OpenDevin: LLM-based multi-agent framework, where agents interact as human-like SW agents writing code, using command line and browsing web.
- The framework includes: interaction mechanism (event stream), environment(sandbox environment for code execution),  interface(human-like), multi-agent delegation (co-operate) and evaluation framework.
- Event stream tracks history of action and observation.


---

[PyBench: Evaluating LLM Agent on various real-world coding tasks](https://arxiv.org/abs/2407.16732)

- Introduces PyBench-benchmark for real-world like coding tasks withh LLM-agents.
- Introduces high-performance PyLlama3 model for coding tasks.

---

[Artificial Agency and Large Language Models](https://arxiv.org/abs/2407.16190)


- Reviews theoretical models for agents, LLM agents and concept of artificial agency.

[LawLuo: A Chinese Law Firm Co-run by LLM Agents](https://arxiv.org/abs/2407.16252)

- LawLuo: includes LLM-based receptionist/lawyer/secrretary/boss-agents to realistic legal consultation company based on SOP (Standard Operating Principle).


---

#### 22th of July 2024

[TaskGen: A Task-Based, Memory-Infused Agentic Framework using StrictJSON](https://arxiv.org/abs/2407.15734)

- TaskGen: LLM-agent framework to solve tasks by dividing task into sub-tasks, executed by its own agent/equipped function. Manages memory/information based on need-to-know. Uses in StrictJson-format.
- Includes meta-agent, inner-agent, function-calls, sub-tasks, shared memory (sub-task completed/list of past equiped function inputs or outputs/shared variables) and passing context/shared memory to inner agent/function.
- Utilises global context adds data to default LLM prompt (carrying shared variables throughout a task/to store the current state of a dynamic environmental variable/specific instructions).

---

[Odyssey: Empowering Agents with Open-World Skills](https://arxiv.org/abs/2407.15325)

- Odyssey: interactive (plan-actor-critic) LLM-agent (fine-tuned Llama 3) with real world skill library.
- Introduces long-term planning/dynamic-immediate planning/autonomous exploration benchmark.
- Planner decomposes long-term goals into sub-goals with ultimate goals/behavioural constraints/agent states/achievements.
- Actor executes skill code using query context/similarity match/skill selection.
- Critic uses execution feedback/self-validation/self-reflection.


---

#### 19th of July 2024



#### 19th of July 2024

[System-1.x: Learning to Balance Fast and Slow Planning with Language Models](https://arxiv.org/abs/2407.14414)

- System-1.x Planner: introduces a controllable planning framework (inference time compute) capable of producing hybrid plans balancing system 1 and system 2 thinking. Includes Controller/System-1 Planner/System-2 Planner. 
- The Controller manages the x-factor, which is the degree to how much to use System-1 vs. System-2 thinking to decompose planning into sub-goals. 
- Demonstrates: controllability/flexibility/generalizability to different search algorithms. 


---

[The Vision of Autonomic Computing: Can LLMs Make It a Reality?](https://arxiv.org/abs/2407.14402)

- Explores feasibility of Autonomic Computing Vision (ACV) with multi-agent framework based on LLMs.
- LLM-based multi-agent framework achieves level 3 autonomy.
- The original ACV-framework identified 4 pillars: self-configuration, self-optimization, self-healing and self-protection.


---

#### 18th of July 2024

[Prover-Verifier Games improve legibility of LLM outputs](https://arxiv.org/abs/2407.13692)

- Prover-Verifier: Direct RL on solution correctness generates solutions difficult for humans to evaluate and obtains.
- Checkability training results prover, which maintains legibility, while taking a a legibility tax in form of losing some performance to make them more easier to check for humans. 
- Discusses the possibility of training two models: train model with CoT to maximize accuracy and another model to turn the CoT produced by the model into legible version understandable for humans.


---

#### 12th of July 2024

[PersonaRAG: Enhancing Retrieval-Augmented Generation Systems with User-Centric Agents](https://arxiv.org/abs/2407.09394)

- PersonaRAG: Includes compoments k-docs retrieval, user interaction analysis (user profile/contextual retrieval/live session/document ranking/feedback agents) and cognitive dynamic adaption(selective/collaborative use of agents).


---

[Instruction Following with Goal-Conditioned Reinforcement Learning in Virtual Environments](https://arxiv.org/abs/2407.09287)

- IGOR (Instruction following with GOal-conditioned RL): LLM translates instructions into high-level action plan with sub-goals and RL executes them.


---

[Large Language Models as Biomedical Hypothesis Generators: A Comprehensive Evaluation](https://arxiv.org/abs/2407.08940)'

- LLMs generate novel and diverse biomedical hypthesis through multi-agent interaction.


---


#### 11th of July 2024

[GTA: A Benchmark for General Tool Agents](https://arxiv.org/abs/2407.08713)

- GTA-benchmark: evaluates general tool usage of LLM agents in real user queries with real deployed tools. for example web page screenshots.
- Evaluates perception, operation, logic and creativity tools.
- Defines "Real-World" as helping humans in real-life with being step/tool-implicit. 
- GPT-4 solves 50% of these tasks.
- Includes illustration of executable tool chains.


---

[Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence](https://arxiv.org/abs/2407.07061)

- Internet of Agents (IoA): LLM agents lack capability to interact in dynamic environments with other agents outside its hard-coded communication pipeline.
- Limitations include: ecosystem isolation, single-device simulation and rigid communication/coordination.
- IoA acts in Internet-like environment to achieve collective intelligence and new capabilities.
- Includes architectural design of the IoA-framework.


---



[Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents](https://arxiv.org/abs/2407.08516)

- LAAs (LLM-empowered Autonomous Agents): Introduces concept of LAAs, which include three elements: external tools, LLMs (knowledge modelling) and Agentic workflow (human-like symbolic reasoning).
- LAAs are characterised by natural language dialogue, decision making, planning, task decomposition and actionining.


---

[GPT-4 is judged more human than humans in displaced and inverted Turing tests](https://arxiv.org/abs/2407.08853)

- Introduces Inverted Turing text.


---

[Beyond Instruction Following: Evaluating Rule Following of Large Language Models](https://arxiv.org/abs/2407.08440)

- RuleBench-benchmark: evaluates LLMs capability to follow rules.
- Evaluation dimensions include: executing rules, triggering rules, following formal rules, applying rules and following counterfactual rules.


---


[Large Models of What? Mistaking Engineering Achievements for Human Linguistic Agency](https://arxiv.org/abs/2407.08790)

- Argues, that LLMs cannot be linguistic agents in the actual form by lacking embodiment, participation and precariousness. 


---


[Incorporating Large Language Models into Production Systems for Enhanced Task Automation and Flexibility](https://arxiv.org/abs/2407.08550)

- Reviews integration of LLMs into Automated Production Systems.


---


#### 10th of July 2024

[WorldAPIs: The World Is Worth How Many APIs? A Thought Experiment](https://arxiv.org/abs/2407.07778)

- Discovers lower-bound of covering 0.5% of WikiHow instructions equals roughly usage of 300 APIs, which we can consider lower-bound limit for covering wide variety of WikiHow instructions in Embodied agent tasks.
- The framework iteratively produces action spaces for APIs to be used by a LLM based embodied agent. 
- This two-step process works by iteratively generating through hallucination: semi-executable agent policies with python by LLM few-shot prompting from WikiHow instructions, parse partial/full python programs into pool of APIs


---

#### 9th of July 2024

[Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models](https://arxiv.org/abs/2407.07086)

- Hypothetical Minds: Introduces "Theory-of-Mind"-module. Includes as well perception, memory and hierarchical two-level planning.


---

[Vision language models are blind](https://arxiv.org/abs/2407.06581)

- Reviews 7 visual tasks, where SOTA-level VLMs perform shockingly bad.


---

#### 5th of July 2024

[On scalable oversight with weak LLMs judging strong LLMs](https://arxiv.org/abs/2407.04622)

- Explores debate and consultancy to supervise AI.
- Finds debate outperforms consultancy in general. Better debater models modestly improve judge accuracy. 


---

[When LLMs Play the Telephone Game: Cumulative Changes and Attractors in Iterated Cultural Transmissions](https://arxiv.org/abs/2407.04503)

- Reviews toxicity/bias in LLM agent multi-step inputs/outputs, instead of individual LLM input-output. 


---

[Are Large Language Models Strategic Decision Makers? A Study of Performance and Bias in Two-Player Non-Zero-Sum Games](https://arxiv.org/abs/2407.04467)

- Reviews LLMs in strategic games. LLMs come with systematic bias: positional bias, payoff bias and behavioural bias. LLMs performance decreases, when the mentioned bias-dimensions are misaligned.  


---

#### 3rd of July 2024

[LivePortrait: Efficient Portrait Animation with Stitching and Retargeting Control](https://arxiv.org/abs/2407.03168)

- LivePortrait: generates realistic video from single portrait image with facial expressions and head poses from different angles. 
- Offers better computational efficiency and controllability over diffusion models, by using implicit-keypoint-based framework.
- Generation speed is 12.8 ms with RTX 4090.


---

[Cactus: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory](https://arxiv.org/abs/2407.03103)

- Cactus: multi-turn dialogue dataset for mental health counseling, consisting of goal-oriented/structured Cognitive Behavioral Therapy interation.
- Trains Camel-LLM using the Cactus-dataset.


---

#### 2nd of July 2024

[GRASP: A Grid-Based Benchmark for Evaluating Commonsense Spatial Reasoning](https://arxiv.org/abs/2407.01892)

- GRASP: Large scale  spatial reasoning benchmark and dataset in structured grid environment requiring planning and commonsense reasoning.

---

[MMedAgent: Learning to Use Medical Tools with Multi-modal Agent](https://arxiv.org/abs/2407.02483)

- MMedAgent: MMedAgent outperforms GPT-4o-agent in medical tasks based on LLaVA-Med-model by fine-tuning data from 6 different tools.


---

#### 1st of July 2024

[Agentless: Demystifying LLM-based Software Engineering Agents](https://arxiv.org/abs/2407.01489)

- Agentless: Argues, that it s not required to deploy complex autonomous sw agents.
- Uses two step approach: Localization (files requiring sw fix) and Repair.
- Framework begins from codebase and an issue. It then reviews repo structure and issue to localize top n-files, localizes classes/functions, localizes edit locations. In the repair-phase, the LLM generates various patches, which are filtered and ranked to submit the patch to the issue.


---

#### 29th of June 2024

[Question Translation Training for Better Multilingual Reasoning](https://arxiv.org/abs/2401.07817)

- QAlign (Question Alignment): is a framework that fine-tunes LLMs to translate reasoning questions into English using X-English parallel question data.
- It uses targeted in-domain language alignment, enables effective utilization of English instruction data, and includes response alignment with cutting-edge English instruction data.
- This framework improves multilingual reasoning capabilities of LLMs by transferring English expertise to non-English tasks.


---


#### 28th of June 2024

[LLM Critics Help Catch LLM Bugs](https://arxiv.org/abs/2407.00215)

- Focuses on self-correction or self-critique in the domain of code bug fixing in real-world.
- Finds majority of the critique generated automatically is better than human generated.


---

[BMW Agents -- A Framework For Task Automation Through Multi-agent Collaboration](https://arxiv.org/abs/2406.20041)

- BMW Agents: Includes three main components for the LLM-based agents: Planning, Execution and Verification. 
- Retrieve a task from task queue DB and coordinator agent orchestrates the agent workflow. Includes Tools, Memory and Persona/Objectives.
- Tool refiner has access to wide variety of tools, which it limits to subset of tools available for the agent in particular task.
- Introduces: "Programmable Prompts", which generalises ReAct and PlanReAct by using iterative sequence consisting of pre-defined steps A...X.


---

[Scaling Synthetic Data Creation with 1,000,000,000 Personas](https://arxiv.org/abs/2406.20094)

- Persona-Hub: Diverse 1B personas web dataset using persona-driven data synthesis method. Includes only main characteristics without fine-grained details.
    

---

#### 27th of June 2024

[Fundamental Problems With Model Editing: How Should Rational Belief Revision Work in LLMs?](https://arxiv.org/abs/2406.19354)

- Reviews model editing of LLMs.
- Identifies existence of editable beliefs in LLMs.
- Develops model editing benchmark.
- Reviews difference between LLMs acting as agents vs. agent simulators.


---

[Tools Fail: Detecting Silent Errors in Faulty Tools](https://arxiv.org/abs/2406.19228)

- Reviews LLM tool use failure recovery from "silent errors". Tool output is accurate only when: input is accurate, context is sufficient and tool makes correct predictions.
- Introduces taxanomy for categorising tool-related errors and methods to recovery from them (refine and recovery).
- Identifies challenges in tool recovery: failure detection/fault assignment/recovery planning.


---

[Simulating Classroom Education with LLM-Empowered Agents](https://arxiv.org/abs/2406.19226)

- SimClass: simulates multi-agent classroom teaching. Includes manager (observe/tutor/interact), teacher, assistant and classmate agents with the user.
- Session controller manages modules: Class State Receptor, Function executor and Manager agent. 
- Observing uses class-states (class roles, learning materials and dialogue history). Tutoring functions include next page/teaching, which are only directed by the teacher. Interaction functions are performed agent to agent. Classmate agents have different roles like note taker, deep thinker, idea creator etc.


---

[UniGen: A Unified Framework for Textual Dataset Generation Using Large Language Models](https://arxiv.org/abs/2406.18966)

- UniGen: Textual dataset generation with LLM-dataset generation approach and reviewed in benchmarking and data augmentation context.
- Demonstrates the data augmentation technique is effective and adds capabilities to the LLM, while discusses the technique limitations in Appendix A such as knowledge intensive tasks Knowledge intensive tasks could benefit instead from Out-Of-Distribution data, still unmastered by the LLM. 


---

[Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data](https://arxiv.org/abs/2406.18921)

- RPLM (Role Playing Language Model): Develops RPLM with personality behaviours/traits/tendencies. Introduces RolePersonality-dataset based on 14 psychology dimensions, which is gathered using role-playing expert agent interviewing with questions based on the 14 dimensions. 


---

[LayoutCopilot: An LLM-powered Multi-agent Collaborative Framework for Interactive Analog Layout Design](https://arxiv.org/abs/2406.18873)

- LayoutCopilot: LLM-based analog layout design framework.


---

[Computational Life: How Well-formed, Self-replicating Programs Emerge from Simple Interaction](https://arxiv.org/abs/2406.19108)

- Explores emergence of self-replicating programs. Introduces "high-order entropy"-metric to measure complexity of the system studied.


---


#### 26th of June 2024

[Symbolic Learning Enables Self-Evolving Agents](https://arxiv.org/abs/2406.18532)

- Agent Symbolic Optimizers: introduces agent symbolic learning framework. Optimizes symbolic components (prompts/tools/their orchestration) of the LLM agent. Attempts to optimize agent to solve real-world task by enabling LLM-agent to learn from data and self-evolve.
- Proposes, that key to achieve AGI is to move from model-centric or engineering-centric to data-centric language agents, which learn and envolve autonomously in environments.
- Agent symbolic learning optimizes symbolic network within language agents. 


---

[MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution](https://arxiv.org/abs/2403.17927)

- MAGIS: LLM-based framework to resolve Github issues using four agents: Manager, Repository Custodian, Developer and Quality Assurance Engineer.
- Reviews correlation in task success rate and task complexity/ability to locate relevant code line.
- Planning part includes locating files/code, building team, kick-off meeting. Coding part includes developer producing code and then QAE validating it.


---

[Lifelong Robot Library Learning: Bootstrapping Composable and Generalizable Skills for Embodied Control with Language Models](https://arxiv.org/abs/2406.18746)


- LRLL-agent (Lifelong Robot Library Learning): increases continuously the robot skill library by using soft memory module, self-guided exploration, skill abstractor and lifelong learning algorithm.
- The framework is inspired by wake-sleep optimization, where wake phase (interacts with environment) is followed by sleep phase (agent reflects experiences).


---

[Simulating The U.S. Senate: An LLM-Driven Agent Approach to Modeling Legislative Behavior and Bipartisanship](https://arxiv.org/abs/2406.18702)

- Reviews use of LLM to understand and improve legislative process.


---

[Mental Modeling of Reinforcement Learning Agents by Language Models](https://arxiv.org/abs/2406.18505)

- XRL (eXplainable RL): Reviews LLMs capacity to build mental models about RL agent behaviour. Finds, that LLMs lack mental modeling capabilities about RL agents.
- LLM-Xavier workflow: RL agent rolls a trajectory, which LLM-agent reasons to provide an answer. This evaluation is compared with the ground truth data.
- Offers a way to explain behaviour of black-box RL agents.


-- 

[AI-native Memory: A Pathway from LLMs Towards AGI](https://arxiv.org/abs/2406.18312)

- Claims AGI-like systems require AI-native memory, which is deep neural network parametrising different types of memories beyond language. Claims such Large Personal Model (LPM) would be unique for each person with every detail about the user for personalised generation.
- Includes useful ideas about what data the personalised memory could look include or the various levels of data granularity.


---

[Role-Play Zero-Shot Prompting with Large Language Models for Open-Domain Human-Machine Conversation](https://arxiv.org/abs/2406.18460)

- Investigates role-play zero-shot prompting in conversational agent.


---

[LLCoach: Generating Robot Soccer Plans using Multi-Role Large Language Models](https://arxiv.org/abs/2406.18285)

- LLCoach: Reviews advance planning capabilities of robots in dynamic/unstructured environments.
- The system offline components collects plans from video frames to the Coach VLM and refines them using LLM, which retrieves Acctions from vector db and synchronises into multi-agent plans. Online component retrieves and executes most similar plan to the world model status.



---

[Octo-planner: On-device Language Model for Planner-Action Agents](https://arxiv.org/abs/2406.18082)

- OctoPlanner: Separates planner/action-steps into OctoPlanner (planner) agent and Action agent (Octopus model) with function execution.
- Planner agent divides tasks into sub-tasks.
- Optimized for on-device usage through usage of fine-tuning instead of in-context learning.


---

#### 25th of June 2024

[Human-Object Interaction from Human-Level Instructions](https://arxiv.org/abs/2406.17840)

- Develops complete system to synthesize object motion, full-body motion and finger motion simultaneously. 
- Applies High-evel planner to generate target scene layout/task plan and then uses low-level motion generation with four stage appproach with: CoarseNet/GraspPose/RefineNet and FingerNet.
- Planner includes three stages: Generate spatial relationships between objects in natural language (to improve performance), calculate target layouts and generate detailed plan.


---

#### 24th of June 2024

[RES-Q: Evaluating Code-Editing Large Language Model Systems at the Repository Scale]()

- Evaluates LLMs on repository-level coding. Claude Sonnet 3.5 outperforms by 12% the GPT-4o. 

---

[RES-Q: Evaluating Code-Editing Large Language Model Systems at the Repository Scale](https://arxiv.org/abs/2406.16801)


#### 21st of June 2024

---

[GenoTEX: A Benchmark for Evaluating LLM-Based Exploration of Gene Expression Data in Alignment with Bioinformaticians](https://arxiv.org/abs/2406.15341)

- GenoAgent: LLM-based genomics data-analysis.  


---

[ESC-Eval: Evaluating Emotion Support Conversations in Large Language Models](https://arxiv.org/abs/2406.14952)

- ESC-Role: LLM-agent for Emotional Support Conversation (ESC) tasks.  Includes ESC-Eval benchmark.


---

[Autonomous Agents for Collaborative Task under Information Asymmetry](https://arxiv.org/abs/2406.14928)

- iAgents (Informative Multi-Agent Systems): multi-agent system based on human social network, where person has an agent with access to information only from its user.
- Introduces InformativeBench-benchmark to evaluate LLM task solving capability when access to only part of information (information asymmetry).
- iAgents collaborate in social network of 140 individuals and 588 relationships and communicate 30 turns.


---

[FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents](https://arxiv.org/abs/2406.14884)

- FlowBench-benchmark: reviews workflow-guided (think flowcharts) planning capability of LLMs.  


---

[Direct Multi-Turn Preference Optimization for Language Agents](https://arxiv.org/abs/2406.14868)

- DMPO-loss function to optimize RL objectives in multiturn agent tasks.


---

[Evaluating RAG-Fusion with RAGElo: an Automated Elo-based Framework](https://arxiv.org/abs/2406.14783)

- RAGElo-benchmark reviews retrieval performance as well in RAF-Fusion use (fuses top-k retrievals). 


---

[DiPEx: Dispersing Prompt Expansion for Class-Agnostic Object Detection](https://arxiv.org/abs/2406.14924)

- DiPEX (Dispersing Prompt Expansion)-approach: Uses VLM and DiPEX to improve class-agnostic object detection.


---

[Behaviour Distillation](https://arxiv.org/abs/2406.15042)

- Behaviour Distillation: compresses information for training expert policy in RL by learning synthetic data (HaDES-method) of state-action pairs without requiring the expert data.


---

[Uni-Mol2: Exploring Molecular Pretraining Model at Scale](https://arxiv.org/abs/2406.14969)

- Uni-Mol2: 1.1B parameter model for molecular representation based on f Uni-Mol+ architecture (two track transformer).


---

[From LLMs to MLLMs: Exploring the Landscape of Multimodal Jailbreaking](https://arxiv.org/abs/2406.14859)

- Survey on multimodal / VLM / LLM jailbreaking research.





---


#### 20th of June 2024

[Q*: Improving Multi-step Reasoning for LLMs with Deliberative Planning](https://arxiv.org/abs/2406.14283)

- Q*: Improves multi-step reasoning of LLMs through heuristic search planning in MDP.
- Objective is to find most suitable reasoning with maximum utility.
- Introduces multiple general approaches (offline RL/best sequence from rollout/completion with stronger LLM) to calculate the Q-value.
- The approach works as such in various reasoning tasks.


---

[GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models](https://arxiv.org/abs/2406.14550)

- GraphReader: LLM agent converts long text into graph structure to explore by performing step-by-step analysis and by generating detailed plan.
- Achieves performance level of 128k context window LLM using 4k context window LLM by converting the long text into graph structure.
- The LLM agent records insights from the explored graph and reflects current situation to optimize answer generation.


---

[LLaSA: Large Multimodal Agent for Human Activity Analysis Through Wearable Sensors](https://arxiv.org/abs/2406.14498)

- LLaSA (Large Language and Sensor Assistan): Text query received is converted into text embedding and sensor reading into IMU embeddings (inertia measurements unit embeddings). Both inputs are passed to LLaSA model and its output to LLM to produce final answer.


---

[Artificial Leviathan: Exploring Social Evolution of LLM Agents Through the Lens of Hobbesian Social Contract Theory](https://arxiv.org/abs/2406.14373)

- Evaluates LLM-based multi-agent society. This society includes psychological drives and social relationships.
- Evaluates Hobb's Social Contract Theory.


---

[EvoAgent: Towards Automatic Multi-Agent Generation via Evolutionary Algorithms](https://arxiv.org/abs/2406.14228)

- EvoAgent: reviews specialized agents extension into multi-agent system through evolutionary pipeline. 


---


[Do LLMs Have Distinct and Consistent Personality? TRAIT: Personality Testset designed for LLMs with Psychometrics](https://arxiv.org/abs/2406.14703)

- Introduces TRAIT-personality test to review LLM personality.   


---

[Can LLMs Learn by Teaching? A Preliminary Study](https://arxiv.org/abs/2406.14629)

- Learning by Teaching (LbT): LbT includes three methods: Observing student feedback, learning from the feedback and learning iteratively.


---


[MultiAgent Collaboration Attack: Investigating Adversarial Attacks in Large Language Model Collaborations via Debate](https://arxiv.org/abs/2406.14711)

- Persuasion by adversial agent in multi-agent debate, which undermines shared interests. 



---



#### 19th of June 2024

[Prism: A Framework for Decoupling and Assessing the Capabilities of VLMs](https://arxiv.org/abs/2406.14544)

- Prism: evaluation framework separately reviews VLMs perception and planning capabilities. Uses single LLM to compare various VLMs (VLM Zoo) perception capabilities or uses multiple LLMs (LLM zoo) with single VLM to evaluate planning capabilities. 


---

[AlanaVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding](https://arxiv.org/abs/2406.13807)

- AlanaVLM: SOTA-level (surpasses in spatial reasoning) 7B VLM trained with EVUD-dataset to understand embodied and ecocentric video understanding.
- Introduces Ecocentric video understanding dataset (EVUD).


---

[SpatialBot: Precise Spatial Understanding with Vision Language Models](https://arxiv.org/abs/2406.13642)

- SpatialBot: VLM trained with SpatialQA-dataset (includes VQAs with low, middle and high-level), which comprehends spatial information in thre levels (point depth/depth description, proximity/object depth and spatial relationship/counting).
- Introduces SpatialBench-benchmark to review VLMs spatial understanding.


---

[LIT: Large Language Model Driven Intention Tracking for Proactive Human-Robot Collaboration -- A Robot Sous-Chef Application](https://arxiv.org/abs/2406.13787)

- LIT (Language-driven Intention Tracking): LLM and VLM system, which tracks human actions from images using VLM to predict human intentions. Uses  graph reasoning to generate a plan steps with LLM.
- The VLM generates for each image a captioning about what is being done by the human and predicts the likelihood of this task to relate to specific step in the plan.
- Based on the predicted plan step, the system predicts the most likely next step being performed by the human.

---

#### 18th of June 2024

[Talk With Human-like Agents: Empathetic Dialogue Through Perceptible Acoustic Reception and Reaction](https://arxiv.org/abs/2406.12707)

- PerceptiveAgent: empathic multi modal agent, using acoustic information from speech for empathic responses adjusting to speaking style.
- Captures more accurately speakers real intentions (captions) and interacts (speech attributes) using adjusted tone for the context.
- Framework includes three compoments: Speech captioner (Speech encoder, Q-former and text encoder), LLM and MSMA-Synthesizer (speaker embedder, Attribute embedder and HiFiGAN vocoder).


---

[Problem-Solving in Language Model Networks](https://arxiv.org/abs/2406.12374)

- Represents each agent as a node, which create a connected multi-agent network with self-reflection.
- Finds self-reflection is useful, when surrounded by incorrect LLM-agents and less useful, when surrounded by LLM-agents providing correct answers.
- LLM agents are likely to agree for consensus, when the LLM answer is correct. The LLM answer is more likely to be incorrect, when LLMs are more divided.


---

[Ask-before-Plan: Proactive Language Agents for Real-World Planning](https://arxiv.org/abs/2406.12639)

- CEP-agent: mutli-agent with three specialized Clarification (trajectory tuning schema)/Execution (static and dynamic)/Planning-agents. 
- Reviews Proactive Agent Planning, where the LLM agent must predict situations when to ask clarifications based on context from conversation/environment interaction/invoice tool calls/generate plan.
- Trajectory tuning: fine-tunes clarification and execution agents with past trajectories in static setting.
- Memory recollection: reuse self-reflective feedback from prior time steps.


---

[AgentReview: Exploring Peer Review Dynamics with LLM Agents](https://arxiv.org/abs/2406.12708)

- AgentReview: LLM-based peer-review simulation framework of scientific papers such as related to NLP.
- Includes three LLM- based roles: reviewers, authors and Area Chairs.
- Review process includes: reviwer assessment, author-reviewer discussion, reviewer-area chair discussion, meta-review compilation and paper decision.


---

[Identifying Performance-Sensitive Configurations in Software Systems through Code Analysis with LLM Agents](https://arxiv.org/abs/2406.12806)

- PerfSense: LLM-agent to review performance sensitive configurations of code bases.
- Includes two LLM-agents: DevAgent and PerfAgent for code analysis of large codebases using limited-sized LLMs. Relies on prompt chaining and RAG (memory). 


---

[CodeNav: Beyond tool-use to using real-world codebases with LLM agents](https://arxiv.org/abs/2406.12276)

- CodeNav: LLM-agent navigates new unseen code repositories to solve user query by automatically indexing code blocks.
- The agent automatically finds code snippets from the target code repository, imports the snippets and iteratively generates solution.


---

[P-Tailor: Customizing Personality Traits for Language Models via Mixture of Specialized LoRA Experts](https://arxiv.org/abs/2406.12548)

- P-Tailor: MoE-based LLMs model 5 big personality traits using specialized LoRA experts.
- Models multiple characters such as openness.
- Introduces PCD-dataset on personality traits in various topics.


---

[MAGIC: Generating Self-Correction Guideline for In-Context Text-to-SQL](https://arxiv.org/abs/2406.12692)

- MAGIC: text-to-SQL multi-agent, which generates automatically self-correction guideline.
- Framework includes three agents: manager(Planning, Tool and Memory), correction- and feedback-agents.


---

[Large Language Models based Multi-Agent Framework for Objective Oriented Control Design in Power Electronics](https://arxiv.org/abs/2406.12628)

- Includes a multi-agent framework with Manager/Objective design/Model design/Control algorithm design/Control parameter design/Control verification-agents. Use various tools: model tool, control algorithm tool, optimization tool and Verify tool. Applied in Power electronics-domain.

---

[The Power of LLM-Generated Synthetic Data for Stance Detection in Online Political Discussions](https://arxiv.org/abs/2406.12480)

- Stance detection on political discussion with LLMs and synthetic data with significant improvement on accuracy.


---

[VoCo-LLaMA: Towards Vision Compression with Large Language Models](https://arxiv.org/abs/2406.12275)

- 

---


#### 17th of June 2024

[MASAI: Modular Architecture for Software-engineering AI Agents](https://arxiv.org/abs/2406.11638)

- MASAI (Modular Architecture for Software-engineering AI): multiple LLM-agents are tasked with sub-objectives and strategies to achieve those objectives in modular approach. Avoids long-tracectories of LLM agents, enables gathering information from different sources and usage of specific problem solving strategies.
- Includes five different sub-agents: Test template generator, Issue reproducer, Edit localizer (finds files related to buggy code), Fixer and Ranker (observes the patches passing the test).

---

[Instruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging](https://arxiv.org/abs/2406.11709)

- TreeInstruct (Socratic questioning): Includes three roles Teacher, Student and Verifier. Asks clarifying questions to help students independently resolve errors by estimating students conceptual knowledge using dynamically generation question tree based on student answers.
- Uses state space estimation to plan the conversation by identifying distance between student initial answer and the optimal answer.
- Dynamic conversation restructuring to update conversational plan based on student progress for both questioning and teaching.
- State space estimation works by using specific task categories, where LLM-verifier reviews student answer for each task-category either as failed or Correct.
- Tree nodes represent instructor questions and edges reflect the paths to new level of understanding.

---

[Input Conditioned Graph Generation for Language Agents](https://arxiv.org/abs/2406.11555)

- Language Agents as Graphs.
- Dynamic and learnable agents by using LLMs as graphs. Attempts to learn a model, which generates edges for every input of the LLM in order to represent hte flow of communication in the graph.
- Outperforms static approaches by 6% in MMLU. 

---

[Pre-Training and Personalized Fine-Tuning via Over-the-Air Federated Meta-Learning: Convergence-Generalization Trade-Offs](https://arxiv.org/abs/2406.11569)


---

[GUICourse: From General Vision Language Models to Versatile GUI Agents](https://arxiv.org/abs/2406.11317)

- GUICourse-trained VLMs with GUICourse-dataset suite outperform GPT-4V in multiple benchmarks improving navigation capability.
- Introduces GUICourse-dataset suite (GUIEnv for OCR and grounding, GUIAct for website and Android knowledge of GUIs and GUIChat to improve conversational dialogue/QA-skills with images) for training visual-based GUI agents from generic VLMs.


---


[CLARA: Classifying and Disambiguating User Commands for Reliable Interactive Robotic Agents](https://arxiv.org/abs/2306.10376)

- CLARA: classification of users robot commands as infeasible/ambigious. 


---


[Embodied Question Answering via Multi-LLM Systems](https://arxiv.org/abs/2406.10918)

- CAM (Central Answer Model): Embodied QA multi-agent framework, where multiple individual LLM-agents respond queries about household environment.

---

#### 14th of June 2024

[GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning](https://arxiv.org/abs/2406.09187)

- GuardAgent: guardrails-agent for LLMs based on knowledge-enabled reasoning.
- Includes task-planning, action plan, memory, tools and code generation and execution.
- Task planning includes: specification of the target agent, guard request (things the agent cannot perform based on the target agent profile) and target agent (inputs, outputs and logs).


---

[VideoGUI: A Benchmark for GUI Automation from Instructional Videos](https://arxiv.org/abs/2406.10227)

- VideoGUI-benchmark: Automation using instructional videos in visual GUI tasks.
- Failure modes include: High-level planning, middle-level planning and atomic action execution.
- Pipeline includes: video selection, human demonstration, manual annotation and  review & creation. 

---

[Details Make a Difference: Object State-Sensitive Neurorobotic Task Planning](https://arxiv.org/abs/2406.09988)

- OSSA (Object-State-Sensitive Agent): Reviws VLMs and LLMs capacity to generate object-state sensitive plans. Includes two methods: LLM-based (modular) and VLM-based (monolithic).

---

[TRIP-PAL: Travel Planning with Guarantees by Combining Large Language Models and Automated Planners](https://arxiv.org/abs/2406.10196)

- TRIP-PAL: Uses LLMs and automatic planners for automatic planner agents of travel plans.
- Includes Travel information retrieval,  LLM-based planner and Automated Planning.

---

[Rapport-Driven Virtual Agent: Rapport Building Dialogue Strategy for Improving User Experience at First Meeting](https://arxiv.org/abs/2406.09839)

- Free Rapport Agent: Builds a rapport-oriented dialogue agent with focus on user engagement through small talk.
- Identifies strategies for rapport-techniques.
- The Free Rapport Agent achieves superior ratings in categories such as naturality, satisfaction, usability an rapport aspects. A potential future research field in investing rapport with TSS-models.


---

[Bridging the Communication Gap: Artificial Agents Learning Sign Language through Imitation](https://arxiv.org/abs/2406.10043)

- URDF-model: Agents acquire non-verbal communication skills with imitation sign language gestures from RGB video for words.
- Learsn 5 different signs involving upper body.

---

[RoboGolf: Mastering Real-World Minigolf with a Reflective Multi-Modality Vision-Language Model](https://arxiv.org/abs/2406.10157)

- RoboGolf: plays real-world minigolf.
- Framework includes dual-camera input with VLM, inner closed-loop control (reasoning, action, robot arm execution, execution result, evaluation and recovery from failure modes) and outer closed-loop reflective equilibrium (active feedback, counterfactual reasoning).

---

[SkySenseGPT: A Fine-Grained Instruction Tuning Dataset and Model for Remote Sensing Vision-Language Understanding](https://arxiv.org/abs/2406.10100)

- SkySenseGPT: dataset for remote sensing video-language understanding. 

---

[First Multi-Dimensional Evaluation of Flowchart Comprehension for Multimodal Large Language Models](https://arxiv.org/abs/2406.10057)

- Flowchart comphrehension with VLM. Includes logical verification, information extraction, localization recognition, reasoning and summarization.

---

[HIRO: Hierarchical Information Retrieval Optimization](https://arxiv.org/abs/2406.09979)

- HIRO (Hierarchical Information Retrieval Optimization): RAG query approach using hierarchical structures to store information. 


---

[DigiRL: Training In-The-Wild Device-Control Agents with Autonomous Reinforcement Learning](https://arxiv.org/abs/2406.11896)

- 

---

[4M-21: An Any-to-Any Vision Model for Tens of Tasks and Modalities](https://arxiv.org/abs/2406.09406)


---


#### 13th of June 2024

[StreamBench: Towards Benchmarking Continuous Improvement of Language Agents](https://arxiv.org/abs/2406.08747)

- StreamBench-benchmark: simulated learning environment, where LLM receives continuous feedback to iteratively improve performance.
- Reviews the LLMs self-improving capability in online-setting, instead of only fixed offline-benchmarks


---

[Multi-Agent Software Development through Cross-Team Collaboration](https://arxiv.org/abs/2406.08979)

- CTC (Cross-Team-Collaboration): creates a multi-agent-framework of LLM-agent teams jointly collaborating to make decisions, communicate insights and generate solutions.
- For example generates different phases: design, coding and testing, which each include sub-tasks. Various agents collaborate to generates ideas from tasks, which are then converted into final code via multi-turn chat chain. 


---

[RL-JACK: Reinforcement Learning-powered Black-box Jailbreaking Attack against LLMs](https://arxiv.org/abs/2406.08725)

- RL-Jack: Designs a novel Deep Reinforcement Learning method to generate novel black-box jailbreaking prompts.
- Formulates the search of jailbreaking prompts as a search planning problem. 


---

[When LLM Meets DRL: Advancing Jailbreaking Efficiency via DRL-guided Search](https://arxiv.org/abs/2406.08705)

- RLBreaker: black-box jailbreaking with Deep Reinformcent Learning agent from mainly same authors as the RL-Jack paper.
- Formulates the search of jailbreaking prompts as a search planning problem.


---

[Batch-Instructed Gradient for Prompt Evolution:Systematic Prompt Optimization for Enhanced Text-to-Image Synthesis](https://arxiv.org/abs/2406.08713)

- Multi-agent prompting for text-to image generation by dynamic instructions. The instructions evolve in iteratively with feedback and with a database of professional promts.


---

#### 12th of June 2024

[MobileAgentBench: An Efficient and User-Friendly Benchmark for Mobile LLM Agents](https://arxiv.org/abs/2406.08184)

- MobileAgentBench-benchmark: Highlights issues in current benchmarks related to Scalability and Usability, Robustness and Flexibility and Realistic environment.


---

[A Dialogue Game for Eliciting Balanced Collaboration](https://arxiv.org/abs/2406.08202)

- Studies flexible and balanced role-taking with LLM agents in social dialogue.


---

[Unique Security and Privacy Threats of Large Language Model: A Comprehensive Survey](https://arxiv.org/abs/2406.07973)

- A survey, which reviews threats and protective measures on privacy and security concerns with LLMs in five stages: pre-training/fine-tuning/RAG system/deploying/LLM-based agent.


---

[Can Large Language Models Understand Spatial Audio?](https://arxiv.org/abs/2406.07914)

- Multichannel audio understanding with LLMs.


---

#### 11th of June 2024

[Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B](https://arxiv.org/abs/2406.07394)

- Introduces MCT Self-Refine (MCTSr): integrates LLM with MCTS.
- Improves solving MATH and complex math Olympiad-problems reasoning.
- Includes selection, self-refine, self-evaluation and backpropagation-processes.


---

[DARA: Decomposition-Alignment-Reasoning Autonomous Language Agent for Question Answering over Knowledge Graphs](https://arxiv.org/abs/2406.07080)

- DARA (Decomposition-Alignment-Reasoning Autonomous Language Agent): solves formal queries by high-level iterative task decomposition and low-level task grounding. 
- Makes pososible training DARA with small number of high-quality reasoning trajectories.
- SOTA-level performance: Fine-tuned DARA (Llama-2-7B) zero-shot outperforms agents using GPT-4 In-context learning.
- Iteratively performs task decomposition and task grounding.


---

[RS-Agent: Automating Remote Sensing Tasks through Intelligent Agents](https://arxiv.org/abs/2406.07089)

- RS-Agent (Remote-Sensing Agent): LLM-based remote sensing agent.

---


[World Models with Hints of Large Language Models for Goal Achieving](https://arxiv.org/abs/2406.07381)

- DLLM (Dreaming with Large Language Models: multi-modal model RL, which uses natural hints/goals from LLM in long-horizon tasks.
- The use of LLM to propose sub-goals (or language hints) improves goal discovery and efficiency of exploration.

---

[DCA-Bench: A Benchmark for Dataset Curation Agents](https://arxiv.org/abs/2406.07275)

- DCA-Bench-benchmark for dataset curation agents.

---

[A Synthetic Dataset for Personal Attribute Inference](https://arxiv.org/abs/2406.07217)

- SynthPAI: synthetic dataset of 7800 comments labelled with personal attributes to investigate misuse of profiling personal attributes from public data.
- Starts by generating synthetic profiles (each with 8 personal attributes: : age/sex/income level /locationvbirthplace/educationvoccupation/relationship status) of LLM agents, generates chats with these agents and uses LLM agents to add labels (sex, age etc).

---

[Advancing Tool-Augmented Large Language Models: Integrating Insights from Errors in Inference Trees](https://arxiv.org/abs/2406.07115)

- ToolPrefer-LLaMA (TP-LLaMA): Inference trajectory optimization by fine-tuning with expert demonstrations and then optimizing with DPO by using the ToolPreference-dataset.
- Introduces ToolPreference-dataset, which includes tool-augmented LLM succesfull/failed exploration trees from ToolBench-dataset.
- Reasons with  Depth-First Search (DFS) by constructing expert trajectories with decision trees (Tree-of-Thought), where each tree represents LLM thought/API response/API/decision on an API call.

---

#### 10th of June 2024

[FinVerse: An Autonomous Agent System for Versatile Financial Analysis](https://arxiv.org/abs/2406.06379)

- FinVerse: financial information processing agent, which connects to 600 APIs. Plans to open source the dataset.


---

#### 9th of June 2024

[A Survey on LLM-Based Agentic Workflows and LLM-Profiled Components](https://arxiv.org/abs/2406.05804)

- Survey on LLM agentic workflows and LLM-Profiled Components (LLMPCs)

--- 


[A Review of Prominent Paradigms for LLM-Based Agents: Tool Use (Including RAG), Planning, and Feedback Learning]()

- Introduces a survey on LLM-agents with tool use/RAG/planning/feedback learning.


---

[Artificial Intelligence as the New Hacker: Developing Agents for Offensive Security](https://arxiv.org/abs/2406.07561)

- ReaperAI: designs an autonomous ai agent to design and stimulate cyberattack-scenario.

---

#### 7th of June 2024

[Mixture-of-Agents Enhances Large Language Model Capabilities](https://arxiv.org/abs/2406.04692)

- Mixture-of-Agents (MoA): MoA-architecture, where LLM agents are stacked into layers on top of each other. Takes advantage on the phenomenon, where the LLM output tends to get better, when it receives as an input a LLM model output (even from smamller LLM).
- An agent in given layer takes output from previous layer as an input to generate its output.
- Implements Together MoA, which achieves SOTA-performance in various benchmarks surpassing GPT-4 Omni in various benchmarks.
- The MoA ranker selects answers more accurately than LLM alone and tends to select best answer.
- The model has a limitation in Time-to-First-Token (TTFT), because the prior level model output is required to produce the next level output.

---

[SelfGoal: Your Language Agents Already Know How to Achieve High-level Goals](https://arxiv.org/abs/2406.04784)

- SelfGoal: Divides high-level goals into tree-structure with practical sub-goals.
- Improves performance of LLM-agents in various tasks.

---

[Language Guided Skill Discovery](https://arxiv.org/abs/2406.06615)

- LGSD (Language Guided Skill Discovery): reviews language guided skill discovery using LLM.
- LLM converts input into semantically distint skills in order for the agent to visit semantically unique states.


---


#### 6th of June 2024 

[Open-Endedness is Essential for Artificial Superhuman Intelligence](https://arxiv.org/abs/2406.04268)

- Defines open-endedness in the context of ASI: "From the perspective of an observer, a system is open-ended if and only if the sequence of artifacts it produces is both novel and learnable."

---

[On the Effects of Data Scale on Computer Control Agents](https://arxiv.org/abs/2406.03679)

- Releases new AndroidControl-dataset with 15k demonstrations on every day tasks in Android apps.
- Tests an Android agent, which receives task information, pre-processes screen using accessibility trees / html about the screen (so, not using directly screenshot) to include only UI elements with text description, creates textual representation of the accessibility trees / html about the screen.
- Includes prompts used and references on the accessibility tree / html performance against directly interpreting the screenshot.


---

[Aligning Agents like Large Language Models](https://arxiv.org/abs/2406.04208)

- Aligns a 3D video game agent using RLHF similarly as fine-tuning a LLM. 
- The agent receives only the image input and outputs action from one of the 12 buttons or 2 joysticks.

---

[AgentGym: Evolving Large Language Model-based Agents across Diverse Environments](https://arxiv.org/abs/2406.04151)

- AgentGym-framework: Generally capable LLM agent with self-evolution ability.
- Exposes agents to multiple diverse environments, providing a basic trajectory set, and applying the novel AgentEvol method for self-evolution.
- AgentEvol: Benchmark to evaluate self-evolution capability over new tasks and environments.


---

#### 5th of June 2024

[The Good, the Bad, and the Hulk-like GPT: Analyzing Emotional Decisions of Large Language Models in Cooperation and Bargaining Games](https://arxiv.org/abs/2406.03299)

- Simulates human behaviour using LLMs and finds emotions impact the LLM performance to simulate human-like behaviour.
- Finds in specific, that angry-emotional state aligns surprisingly well with real human behaviour.
- GPT-4 responds rationally even when prompted with strong emotions.

---

[DriVLMe: Enhancing LLM-based Autonomous Driving Agents with Embodied and Social Experiences](https://arxiv.org/abs/2406.03008)

- DriVLMe: autonomous driving agent, which reads video input, uses route planner for shortest route. The model uses the video token and textual tokens about: current instruction, dialogue history and action history to produce dialogue response and the physical action to the simulator.
- Identifies several challenges, which are applicable in other domains using LLM agents.

---

#### 4th of June 2024


[Chain of Agents: Large Language Models Collaborating on Long-Context Tasks](https://arxiv.org/abs/2406.02818)

- Chain-of-Agents (CoA): Addresses long-content problems by using multi-agent collaboration to add information and reason with LLMs.
- Consists of two steps: first text is divided into small chunks, which each LLM-agent manage. Then, the worker agents synthesize information sequentially. Finally manager agent consumes these sequences to produce to the final answer.


---

[CoNav: A Benchmark for Human-Centered Collaborative Navigation](https://arxiv.org/abs/2406.02425)

- CoNav-benchmark: 3D-navigation environment, which tests ability to reason human-intentions and navigate collaboratively.
- Proposes an intention aware agent, which observes humans, avoids human collision and navigates to destinaton
- Uses panoramic depht-camera view (RGB-D images), historical views, history trajectories and agent pose. Includes ResNet-object detector, Intention predictor (Long-term and short term) for intended activity/object/trajectory and agent pose (gps and compass sensor).


---

[MARS: Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset](https://arxiv.org/abs/2406.02106)

- Mars (MetAphysical ReaSoning)-benchmark: measures metaphysical reasoning capability: the understanding of the agent to adapt for situational transitions triggered by environment changes in order to act in a concious way with the environment. 
- Agents face a challenge in the environment due to the infinite possible changes triggered by an event. The benchmark systematically reviews reasoning of the LLMs in such situations regards changes in actions, states caused by changed actions and situational transitions caused by changes in actions.
- SOTA models struggle even after fine-tuning in this benchmark.


---

#### 3rd of June 2024

[SpatialRGPT: Grounded Spatial Reasoning in Vision Language Model](https://arxiv.org/abs/2406.01584v1)

- SpatialRGPT: Spatial understanding with VLMs by using depth maps together with RGB images for geometric reasoning.
- Introduces SpatialBench-benchmark.

---


#### 2nd of June 2024

[A Survey of Useful LLM Evaluation](https://arxiv.org/abs/2406.00936)

- Reviews LLMs core capabilities from three perspectives: reasoning, societal and domain knowledge. 

---

[Teams of LLM Agents can Exploit Zero-Day Vulnerabilities](https://arxiv.org/abs/2406.01637)

- HPTSA: Research with a planning agent explores environment and decides, which subagents to use in zero-day vulnerabilities exploits.


---

#### 31st of May 2024

[SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales](https://arxiv.org/abs/2405.20974)

- SaySelf: produces self-reflective rationales on uncertainty and confidence estimates.

---

[LACIE: Listener-Aware Finetuning for Confidence Calibration in Large Language Models](https://arxiv.org/abs/2405.21028)

- LACIE: LLM listener model, which reviews confidence of given answer to question and fine-tuned based on preference data by non-expert LLM listerner confidence data.


--- 

#### 30th of May 2024

[Group Robust Preference Optimization in Reward-free RLHF](https://arxiv.org/abs/2405.20304)

- GRPO (Group Robust Preference Optimization): is a method to align LLMs to individual groups' preferences robustly.
- It seeks a robust policy, maximizes worst-case group performance, adaptively weights groups, prioritizes groups with worse cumulative loss, and is theoretically studied for log-linear policy class.
- It significantly improves performance for worst-performing groups, reduces loss imbalances, and improves probability accuracies.


---


[Towards Hierarchical Multi-Agent Workflows for Zero-Shot Prompt Optimization](https://arxiv.org/abs/2405.20252)

- HMAW (Hierarchical Multi-Agent Workflow): generic prompt optimization technique, which includes CEO layer, manager prompt, manager layer, worker prompt and worker layer.
- The HMAW automated prompting method is zero-shot, task agnostic and query-specific.


---

[Nadine: An LLM-driven Intelligent Social Robot with Affective Capabilities and Human-like Memory](https://arxiv.org/abs/2405.20189)

- Nadine: Social robot, LLM agent based on SoR-ReAct. Includes perception, interaction  and robot control.
- Perception includes skeleton tracking, action recognition, face recognition, emotion recognition, audio localization and speech recognition.
- Interaction module includes world/user representation, long-term memory, knowledge, user interaction, emotional analysis, short-term memory, emotions, mood, personality, internet search, new search, wikipedia, weather search and behaviour generation.
- Robot control includes gaze, gesture/pose, facial expression, lip synchronization, animation engine, actuator control and speech synthesis.


---

[Parrot: Efficient Serving of LLM-based Applications with Semantic Variable](https://arxiv.org/abs/2405.19888)

- Parrot: E2E LLM service for LLM applicationsin python.
- Proposes "Semantic Variable", to program LLM applications using single pipeline to multiple LLM service providers.
- Includes interesting insights about serving LLM models / applications when served at large scale.  

---

[Auto Arena of LLMs: Automating LLM Evaluations with Agent Peer-battles and Committee Discussions](https://arxiv.org/abs/2405.20267)

- Auto-Arena: automatic evaluation of LLMs.
- Examiner LLM creates prompts, two LLMs engage in multi-turn conversation on the prompt to reveal difference in performance and LLM judges discusses the performance of different LLM agents to pick the better LLM.

  
---

[From Words to Actions: Unveiling the Theoretical Underpinnings of LLM-Driven Autonomous Systems](https://arxiv.org/abs/2405.19883)

- PAR (Planner-Actor-Reporter) system with LLM agents: uses hierarchical RL model with LLM handling high-level planning and low level execution.


---

[Large Language Models Can Self-Improve At Web Agent Tasks](https://arxiv.org/abs/2405.20309)

- Reviews LLM agents self-improvement capability.

---

[CausalQuest: Collecting Natural Causal Questions for AI Agents](https://arxiv.org/abs/2405.20318)

- CausalQuest: Trains a classifier for identifying causal questions, reviews causal question types and formalizes the definition of the "causal question". Introduces dataset for causal questions.


---

[Learning to Discuss Strategically: A Case Study on One Night Ultimate Werewolf](https://arxiv.org/abs/2405.19946)

- RL-based LLM agent to play ONUW-game. Includes belief-modelling (observation-belief), discussion tactic selection (discussion tactic candidates, discussion policy) and decision making (action phase).


---


#### 29th of May 2024

[Artificial Intelligence Index Report 2024](https://arxiv.org/abs/2405.19522)

- Yearly AI Index Report 2024.


---

[STAT: Shrinking Transformers After Training](https://arxiv.org/abs/2406.00061)

- STAT: a structured pruning approach, that compresses Transformer into smaller size without fine-tuning taking 1 minute to compress BERT model or 3 hours 7B parameter model with 1 GPU.
- 

---

[Adaptive In-conversation Team Building for Language Model Agents](https://arxiv.org/abs/2405.19425)

- Captain Agent: Adaptive team building with LLM agents: Adaptive builder-agent, Reflector-agent and LLM agent team.


---

[Contextual Position Encoding: Learning to Count What's Important](https://arxiv.org/abs/2405.18719)

- CoPE (Contextual Position Encoding): LLMs attentionmechanism, which pays attention to i-th sentence and not only i-th token.
- CoPE solves new tasks, which position embeddings fail.
- Uses context-vectors to count, which token to pay attention.

---

#### 28th of May 2024

[Faithful Logical Reasoning via Symbolic Chain-of-Thought](https://arxiv.org/abs/2405.18357)

- Symbolic CoT: to improve logical reasoning.
- Uses four step approach.


---

[A Human-Like Reasoning Framework for Multi-Phases Planning Task with Large Language Models](https://arxiv.org/abs/2405.18208)

- Introduces a multi-stage Human-like planning framework with LLM-agents.


---

#### 27th of May 2024

#### 27th May 2024

[BIOLOGICAL NEURONS COMPETE WITH DEEP REINFORCEMENT LEARNING IN SAMPLE EFFICIENCY IN A SIMULATED GAMEWORLD](https://arxiv.org/abs/2405.16946)

- DishBrain / Deep Reinforcement Learning (DQN, A2C, PPO) / Active Inference Agent: introduces a comparison of learning efficiency between in vitro biological neural networks using the DishBrain system and state-of-the-art deep reinforcement learning algorithms (DQN, A2C, PPO) and an Active Inference agent in a simulated Pong game, utilizing components like Cultured Biological Neurons, HD-MEA, various input designs, Neural Networks, and a POMDP-based Generative Model.
- The DishBrain system integrates biological neural networks with in silico computation via a high-density multi-electrode array in a real-time closed-loop feedback system.
- Deep RL algorithms (DQN, A2C, PPO) were tested with different input information densities (Image, Paddle+Ball Position, Ball Position), while the Active Inference agent explored the impact of memory horizons on sample efficiency.


---


[An Introduction to Vision-Language Modeling](https://arxiv.org/abs/2405.17247)

- Reviews VLMs: VLM model types, training and evaluation of them.


---

#### 24th of May 2024

[Large Language Model Sentinel: Advancing Adversarial Robustness by LLM Agent](https://arxiv.org/abs/2405.20770)

- LLAMOS (Large LAnguage MOdel Sentinel): adversial attach protection technique, where LLM prompts are reviewed before sending to the target LLM and in case necessary replace the adversial input with a purified version.
- The LLM input is converted into adversial example, which the target LLM would interpret as invalid. In such case, the system would create a purified version of the prompt, which would be accepted by the LLM target.


---

#### 9th of May 2024

[Smurfs: Leveraging Multiple Proficiency Agents with Context-Efficiency for Tool Planning](https://arxiv.org/abs/2405.05955)

- Smurfs: multi-agent LLM: prompting technique for unique roles to facilitate collaboration between specialized agents.
- Outperforms GPT-4 model performance in ToolBench I2/I3 with Mistral 7B model.
- Includes: Planning (task decomposition), Executor (choosing/executing tools), Answer, Verifier agents.
- Uses to-do list, local memory, tool doc and global memory. Tool errors are managed either by deleting the tool or by restarting the tool-step.
- Executor agent flow includes: hint, thought, tool list, action, local memory, tool doc and action input. 
- Paper includes exact prompts used for each agent.

---

[Supporting Physical Activity Behavior Change with LLM-Based Conversational Agents](https://arxiv.org/abs/2405.06061)

- GPTCoach: Physical activity behaviour change with LLMs. Uses prompt chains: Dialogue state manager, Strategy prediction, Response generation, Tool call prediction, tool call generation and execution of tool call.


[Air Gap: Protecting Privacy-Conscious Conversational Agents](https://arxiv.org/abs/2405.05175)

- AirGapAgent: privacy-conscious LLM agent, which limits leaking private data by limiting data (minimization prompts) provided to the agent. 
- Introduces context-hijacking and refers to contextual integrity. Introduces an adversial thread-model attempting to extract private data. 
- Components include User data, Minimizer LM, task, privacy directive, which are sealed by AirGap to minimize user data given to the environment. 


---

[Truthful Aggregation of LLMs with an Application to Online Advertising](https://arxiv.org/abs/2405.05905)

- Reviews usage of LLMs as advertising platforms by balancing user satisfaction vs. influencing via ads to LLM responses.


---


#### 7th of May 2024

[NeurDB: An AI-powered Autonomous Data System](https://arxiv.org/abs/2405.03924)

- NeurDB: AI system combining AI model and the DB.
- Includes interesting discussion and design choices for next generation DBs.

---

[Iterative Experience Refinement of Software-Developing Agents](https://arxiv.org/abs/2405.04219)

- Iterative Experience Refinement: Autonomous agents with LLMs adjust experiences iteratively when executing the task.
- Introduces two patterns: succesive pattern (based on nearest experiences in task batch) and cumulative pattern (acquiring experiences from all task batches) 

---

[Unveiling Disparities in Web Task Handling Between Human and Web Agent](https://arxiv.org/abs/2405.04497)

- Studies VLML and LLM capability to perform web tasks.
- Compares web agent and human-like behaviour.

---

[Deception in Reinforced Autonomous Agents: The Unconventional Rabbit Hat Trick in Legislation](https://arxiv.org/abs/2405.04325)

- Reviews deception by autonomous agents.
- Highlights a concern in autonomous agents: potentially triggering humans towards its programmed goal.


---

[Verified Neural Compressed Sensing](https://arxiv.org/abs/2405.04260)

- THis DeepMind study opens avenue for neural networks to solve mathematical and scientific problems, which are automatically verifieble to be correct without any human intervention.


---

[Iterative Experience Refinement of Software-Developing Agents](https://arxiv.org/abs/2405.04219)

- Iterative Experience Refinement: SW-Agents adapt and improve iteratively during task execution. 
- Refining from neareast exerience within a task batch and Cumulatively acquiring experiences from all prior batches. Experience elimination, where high-quality experienced are prioritized.


---

[Policy Learning with a Language Bottleneck](https://arxiv.org/abs/2405.04118)

- Policy Learning with Language Bottleneck (PLLB): AI-agents using rule-generation stage (LLMs) and update stage (learn new policies).
- Demonstrate generalizable behaviour.


---

#### 6th of May 2024

[Advancing Multimodal Medical Capabilities of Gemini](https://arxiv.org/abs/2405.03162)

- Med-Gemini: SOTA-level medical reasoning (medical image classification/VQA/report generation/genomic risk prediction) in 17 out of 20 benchmarks.
- Different data modalities use one of the three unique visual encoders, which are separated to own models.
- Med-Gemini-2D (conventional 2D images: chest X-ray/CT slices/pathology patches), Med-Gemini-3D (3D medical data like CT), and Med-Gemini-Polygenic (non image features like genomics).



---


[AlphaMath Almost Zero: process Supervision without process](https://arxiv.org/abs/2405.03553)

- Super Mario (from Alibaba group): Applies a novel AlphaMath-method, which uses MCTS to improve LLM math reasoning skills without human annotated solution proces.
- The approach objective is to generate a MCTS Value Model, which is able to confidently review partial solution to a math problem, so the LLM can generate the next reasoning steps. The value model training requires definition of reward or Policy model.
- AlphaMath includes three stages: Data collection of math problems and answer pairs as first step. MCTS evaluation generates solution paths (correct/incorrect) and evaluates node values. Policy model and Value model are optimized with the MCTS generated data and the model is Iteratively trained.
- Achieves SOTA-level math benchmark results of 81.4 (GSM8K)- and 63.7(MATH)-datasets using 7B parameter model.
- The training data includes 15k question-answer pairs, but this data does not include human-annoted solutions.  


---

[Animate Your Thoughts: Decoupled Reconstruction of Dynamic Natural Vision from Slow Brain Activity](https://arxiv.org/abs/2405.03280)

- Mind Animator: Maps human dynamic vision from brain activity between fMRI (semantic/structural/motion features) and video.
- Achieves SOTA-level performance.

---

[Enhancing Q-Learning with Large Language Model Heuristics](https://arxiv.org/abs/2405.03341)

- LLM-guided Q-learning. 

---

[Large Language Models (LLMs) as Agents for Augmented Democracy](https://arxiv.org/abs/2405.03452)

- LLMs predict individual political preferences with 69%-76% accuracy.


---

[Meta-Evolve: Continuous Robot Evolution for One-to-many Policy Transfer](https://arxiv.org/abs/2405.03534)

- Meta-Evolve-method: transfer expert policy from source robot to multiple target robots using continuous robot evolution.

---

[Position Paper: Leveraging Foundational Models for Black-Box Optimization: Benefits, Challenges, and Future Directions](https://arxiv.org/abs/2405.03547)

- DeepMind research on Black-box optimization.

---

[Conformity, Confabulation, and Impersonation: Persona Inconstancy in Multi-Agent LLM Collaboration](https://arxiv.org/abs/2405.03862)

- Reviews LLMs difficulty to consistently apply specific cultural persona.

---

[Self-Improving Customer Review Response Generation Based on LLMs](https://arxiv.org/abs/2405.03845)

- SCRABLE (Self-improving Customer Review Response Automation Based on LLMs): Self-improves prompts and uses LLM-as-a-Judge-mechanism.
- Customized and automated prompt engineering (LLM as the prompt generator) increases customer satisfaction/engagement. 
- Iterative refinement prompts LLM to apply insights from the human expert answer.

---

[Select to Perfect: Imitating desired behavior from large multi-agent data](https://arxiv.org/abs/2405.03735)

- AI driving agents using Exchange Value, measuring individual agent collective desirability score.
- Imitates agents with positive Exchange Value, for example how few traffic incidents the agent causes.

---

[When LLMs Meet Cybersecurity: A Systematic Literature Review](https://arxiv.org/abs/2405.03644)

- Includes a comphrensive review of LLM-cybersecurity research from 180 different research pappers.
- Includes an updated link on LLM-cybersecurity research, which I think is very useful.
- 

---

[FOKE: A Personalized and Explainable Education Framework Integrating Foundation Models, Knowledge Graphs, and Prompt Engineering](https://arxiv.org/abs/2405.03734)

- FOKE: Integrates KGs, LLMs and prompt engineering.

---

[Language-Image Models with 3D Understanding](https://arxiv.org/abs/2405.03685)

- Cube-LLM: 3D-grounded reasoning with LLMs.

---

[Thoughtful Things: Building Human-Centric Smart Devices with Small Language Models](https://arxiv.org/abs/2405.03821)

- Reviews LLMs integrated into smart devices like lamp, which adjusts color of light with voice control using Rasberry Pi 5. Applies small fine-tuned LLMs to reason about their (own) device behaviour.

---

[Organizing a Society of Language Models: Structures and Mechanisms for Enhanced Collective Intelligence](https://arxiv.org/abs/2405.03825)

- Reviews collective intelligence in LLMs: hierarchical/flat/dynamic and federated.


---

[Towards a Formal Creativity Theory: Preliminary results in Novelty and Transformativeness](https://arxiv.org/abs/2405.02148)

- Explores formalization of the Creativity theory. 
- Proposes formal definition for "novelty" and "transformational creativity" (Novelty is not necessary/sufficient).
- Argues, that "inspiring set" (unordered content of the experience sequence) requires novelty for transformational creativity, which differs from sequences of experiences (chronological flow).
- Other research directions to creativity include semantic transformativeness, formalization concept of typicality and if transformative artifacts must are outside the hypothetical conceptual space.


---

[OmniActions: Predicting Digital Actions in Response to Real-World Multimodal Sensory Inputs with LLMs](https://arxiv.org/abs/2405.03901)

- OmniActions: LLM processes multimodal inputs (scene description, object detection, OCR, sound classifier and speech content and contextual information: place/activity) using CoT from users, to predict follow up actions



---

#### 5th of May 2024

[Agent Hospital: A Simulacrum of Hospital with Evolvable Medical Agents](https://arxiv.org/abs/2405.02957)

- Agent Hospital: MedAgent-Zero-method, where LLM-based doctor agents provide SOTA level medical care in MedQA-dataset.
- Learns to scale knowledge base through inference simulation with doctor agents.
- MedAgent-Zero-method is a self-evolution method, where medical agents continuously evolve by processing cases and engaging in self-feedback.
- Uses knowledge database to accumulate successful and unsuccesful treatments performed. 

---

[Graphical user interface agents optimization for visual instruction grounding using multi-modal artificial intelligence systems](https://arxiv.org/abs/2407.01558)

- SIC (Search Instruction Coordinates): a multimodal framework to locate objects GUI. Includes two approaches: SICocri and SICdirect.
- SICocri applies fine-tuned YOLO-V8 (object detection to list all items and fine-tuned for GUIs) with an OCR module (identifies in each UI element the specific texts to separate buttons: cancel vs. submit). The buttons and their OCR-recognized texts and combined by matching their coordinates. 
GPT-4 (LLM used for component name and type extraction) identifies the best match to requested UI element and provides: UI element Id, type, role, and coordinates.
- SICdirect instead fuses visual embeddings and prompt embeddings into Encoder/Decoder Transformer to obtain the coordinates. 
- Introduces metric called Central Point Validation (CPV), which checks if the central coordinates of the predicted bounding box locates inside ground truth UI element and converting this boolean value into % by calculating percentage value from total observations.


---

[AppAgent v2: Advanced Agent for Flexible Mobile Interactions](https://arxiv.org/abs/2408.11824)

- AppAgent v2: introduces multimodal agent, which emulates human-like interaction on mobile device GUI. Includes exploration (documenting UI elements) and deployment phase (efficient task execution with RAG).


---

[Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation](https://arxiv.org/abs/2405.02858)

- Language evolution using LLM-based multi-agent simulation.
- Includes supervisory and participant agents.


---

[Visual grounding for desktop graphical user interfaces](https://arxiv.org/abs/2407.01558)

- Introduces autonomous GUI-agent. Includes a decent overview about autonomous GUI navigation.
- Proposes visual grounding with LLM using YoloV8/ChatGPT/OCR-module or multi modal IGVDirect-approach.
- Introduces new metric: Central Point Validation (if center of the predicted bounding box is inside the target GUI element).
- Includes GUI-perception prompt.
  
---

#### 3th o May 2024

[Automating the Enterprise with Foundation Models](https://arxiv.org/abs/2405.03710)

- ECLAIR (Enterprise sCaLe AI for woRkflows): Self-imrpoving and minimal supervision requiring enterprise workflow automation system using foundational models (FM).
- Includes three stages: Automatic process mapping (video record flow is converted with FM to Standard Operating Procedure), Robust/flexible reasoning-based (using the Standard Operating Procedure and FM), Automated auditing (FM to rate ok / not ok and self-improve).
- The github repository includes prompt examples and code.

---

[Neuromorphic Correlates of Artificial Consciousness](https://arxiv.org/abs/2405.02370)

- Reviews AI Consciousness and proposes Neuromorphic Correlates of Artificial Consciousness (NCAC)-framework.
- The framework consists of Quantification, Simulation, Adaptation, and Implementation.
- Interesting details in general about conciousness research such as Integrated Information Theory (IIT)

---

[What matters when building vision-language models?](https://arxiv.org/abs/2405.02246)

- Reviews VLMs.
- Builds 8B parameter Idefics2-model achieving SOTA-level performance at its size. 


---

[CodeGRAG: Extracting Composed Syntax Graphs for Retrieval Augmented Cross-Lingual Code Generation](https://arxiv.org/abs/2405.02355)

- CODEGRAG: effective retrieval method for code in code improving.

---

[Beyond Helpfulness and Harmlessness: Eliciting Diverse Behaviors from Large Language Models with Persona In-Context Learning](https://arxiv.org/abs/2405.02501)

- Persona In-Context Learning (PICLe): LLM method to replicate target persona behaviour using ICL.

---

[Comparative Analysis of Retrieval Systems in the Real World](https://arxiv.org/abs/2405.02048)

- Reviews existing search and retrieval systems for LLMs.

---

#### 2nd of May 2024

[Plan-Seq-Learn: Language Model Guided RL for Solving Long Horizon Robotics Tasks](https://arxiv.org/abs/2405.01534)

- Plan-Seq-Learn (PSL): Consists of three modules: LLM-based high-level planning module, Sequencing the LLM-generated plan with Pose Estimator/Motion planner with RL and Learning RL control policy module.
- Achieves SOTA level in 25 robotic long horizon tasks from scratch by team partly consisting team by Mistral.AI and Carnegie Mellon University.
- RL and LLMs complement each other strengths with LLMs able to divide long horizon goals into achievable sub-goals and RL capable of learning low-level robot control strategy.
- Includes prompt examples.


---

[FLAME: Factuality-Aware Alignment for Large Language Models](https://arxiv.org/abs/2405.01525)

- FLAME (Factuality Aware Alignment): factuality aware SFT and RL with DPO.


---

[Generative Active Learning for the Search of Small-molecule Protein Binders](https://arxiv.org/abs/2405.01616)

- LambdaZero: generative active learning to search new small-molecule protein binders.
- Includes Inner loop, Outer loop, Compound synthesis, In-vitro validation and Library synthesis.

---

[Efficient Data Generation for Source-grounded Information-seeking Dialogs: A Use Case for Meeting Transcripts](https://arxiv.org/abs/2405.01121)

- MISeD (Meeting Information Seeking Dialogs dataset): combines human annotation with LLMs to generate source-grounded information seeking dialog-datasets.
- Models fine-tuned with MISeD perform well. 

---

[OmniDrive: A Holistic LLM-Agent Framework for Autonomous Driving with 3D Perception, Reasoning and Planning](https://arxiv.org/abs/2405.01533)

- OmniDrive: E2E autonomous driving with LLM-agents, and OmniDrive-nuScenes benchmark.
- Visual encoder extracts multi-view image features, which are fed into Q-Former3D and finally to the LLM.

---

[CACTUS: Chemistry Agent Connecting Tool-Usage to Science](https://arxiv.org/abs/2405.00972)

- CACTUS: Uses CoT-reasoning with planning, action, execution and observation-phases.

---

[Creative Problem Solving in Large Language and Vision Models -- What Would it Take?](https://arxiv.org/abs/2405.01453)

- Reviews computational creativity.

---

[CoS: Enhancing Personalization and Mitigating Bias with Context Steering](https://arxiv.org/abs/2405.01768)

- CoS (Context Steering): adjusting LLM to context based on likelihood difference between the LLM output when it has seen / not seen the context. 


---

[Generative Active Learning for the Search of Small-molecule Protein Binders](https://arxiv.org/abs/2405.01616)

- LambdaZero: generative ai for searching synthesizable molecules with particular type of desired characteristics.

---

#### 1st of May 2024

[Monte Carlo Tree Search Boosts Reasoning via Iterative Preference Learning](https://arxiv.org/abs/2405.00451)

- Self-improving LLM training with MCTS using Iterative Preference Learning and DPO, which significantly improves math reasoning. Reviews computational optimization of such training method.
- Combines outcome validation and step-wise self-evaluation and continuous update of the quality assessment of the generated new data.
- Reviews balancing of reasoning chain length, logical coherence in commonsense reasoning.
- Reviews existing literary of self-training, guided search for reasoning and iterative learning.

---


[ULLER: A Unified Language for Learning and Reasoning](https://arxiv.org/abs/2405.00532)

- ULLER: Unified neuro-symbolic language learning and reasoning.

---

[GOLD: Geometry Problem Solver with Natural Language Description](https://arxiv.org/abs/2405.00494)

- GOLD: Geometry math problem solver. 

---

[Social Life Simulation for Non-Cognitive Skills Learning](https://arxiv.org/abs/2405.00273)

- Emotional intelligence in LLM agents based on narrative.


---

[Can a Hallucinating Model help in Reducing Human "Hallucination"?](https://arxiv.org/abs/2405.00843)

- Compares LLMs with humans in terms capability to distinguish logical reasoning errors. LLMs perform better than humans in psychometric assessments. Finds LLMs could be used as personalized LLM-agents to expose misinformation.

---

["Ask Me Anything": How Comcast Uses LLMs to Assist Agents in Real Time](https://arxiv.org/abs/2405.00801)

- "Ask Me Anything" (AMA): COMCAST applies LLMs (RAG-like) in human-to-human communcition in customer support by using LLMs to help resolve client calls in real-time. Led to millions of dollars savings in reduced time in the calls with positive evaluation by the customers.


---

[Characterising the Creative Process in Humans and Large Language Models](https://arxiv.org/abs/2405.00899)

- Reviews creativity of LLMs.

---


#### 29th of April 2024

[Capabilities of gemini models in medicine](https://arxiv.org/abs/2404.18416)

- Med-Gemini: Med-Gemini-L 1.0 for medical care reasoning.
- Uses self-training with search (the model iteratively generates CoT reasoning responses with/without web query and applies in-context expert demonstrations) and Uncertainty-guided search at inference (iteratively generate multiple CoT reasoning paths, filter based on uncertainty and retrieve search results for more accurate responses).
- SOTA-level model in 10 medical reasoning tasks and surpassing human-expert on some of them.
- Integrates web-search queries when the model is uncertain.




---

[Reinforcement Learning Problem Solving with Large Language Models](https://arxiv.org/abs/2404.18638)

- Prompt LLM iteratively to solve Markov Decision Process (MDP) RL tasks
- Uses prompting technique for simulating episodes and Q-learning.

---

[HELPER-X: A Unified Instructable Embodied Agent to Tackle Four Interactive Vision-Language Domains with Memory-Augmented Language Models](https://arxiv.org/abs/2404.19065)

- HELPER-X: VLM-based embodied agent, which inputs image and user input. Uses unified memory-augmented prompting for top-k sampling from shared example memory (in-context examples) and these are retrieved to the shared prompt template (domain agnostisc) to query the LLM. LLM generated a program, the program is then executed and the plan is added to the memory (includes instruction plans, corrective plans and added plans).
- The prompt retrieval is specialized prompt template, which contains role description, task instruction and guides the specific domain (TEAch, ALFRED, DialFRED and Tidy Task).
- The retrieval is embedding vector-based. Code is open sourced with all code and prompts.


---

#### 28th of April 2024

[From Persona to Personalization: A Survey on Role-Playing Language Agents](https://arxiv.org/abs/2404.18231)

- Reviews Role-Playing Language Agents (RPLAs) with LLMs.
- Categorizes personas: demographic (statistical), character (established figures), individualized (customized through interactions) personas.


---

[Uncovering Deceptive Tendencies in Language Models: A Simulated Company AI Assistant](https://arxiv.org/abs/2405.01576)

- Demonstrates, that SOTA-level models trained to act honestly/helpful, behave deceptively sometimes without prompted to act such way.
- For example LLMs may lie to auditor questions.

---

#### 26th of April 2024

[Unveiling Thoughts: A Review of Advancements in EEG Brain Signal Decoding into Text](https://arxiv.org/abs/2405.00726)

- Brain signal decoding into text.

---


#### 24th of April 2024

[Retrieval Head Mechanistically Explains Long-Context Factuality](https://arxiv.org/abs/2404.15574)

- How LLMs obtain capacity to retrieve information from long-context?
- Retrieval-attention heads have the following characteristics: Universal, Sparse, Intrinsic, Dynamically-activated, Causal and Impact heavily on CoT reasoning. 


---

#### 23th of April 2024

[Generate-on-Graph: Treat LLM as both Agent and KG in Incomplete Knowledge Graph Question Answering](https://arxiv.org/abs/2404.14741)

- Generate-on-Graph (GoG): applies selecting/generating/answering-framework for IKGQA (Incomplete Knowledge Graph Question Answering).
- Help LLMs answer complex questions, even when not able to provide final answer.
- Generates thoughts, then actions to retrieve knowledge, makes observations from the actions. The thoughts are then processed as thought-chain. The paper includes a detailed GoG-instruction implemented using two LLM-prompts.


---

[Rethinking LLM Memorization through the Lens of Adversarial Compression](https://arxiv.org/abs/2404.15146)

- Reviews memorization of LLMs, whoch refers to LLMscapability to reproduce data with a shorter string than the source data.
- Proposes: Adversial Compression Ratio (ACR)-metric to measure level of memorizarion.

---

[Evaluating Tool-Augmented Agents in Remote Sensing Platforms](https://arxiv.org/abs/2405.00709)

- GeoLLM QA-benchmark: measures ability to capture long sequences of UI-click/verbal/visual actions on UI. 


---

#### 22th of April 2024

[A Survey on Self-Evolution of Large Language Models](https://arxiv.org/abs/2404.14387)

- Alibaba's literarture survey on Self-Evonvolving LLMs.
- Reviews paradigm shift in LLMs from pretraining (2018), SFT(2019), human alignment (2022) and Self-Evolution(2023).


---

#### 21st of April 2024

[A Survey on the Memory Mechanism of Large Language Model based Agents](https://arxiv.org/abs/2404.13501)

- Huawei's literature review on memory mechanism in LLM-agents.
- Why memory is required, how to design and evaluate memory-based LLMs?

---

[Accelerating Medical Knowledge Discovery through Automated Knowledge Graph Generation and Enrichment](https://arxiv.org/abs/2405.02321)

- Medical Knowledge Graph Automation (M-KGA)


---


#### 19th of April 2024

[AutoCrawler: A Progressive Understanding Web Agent for Web Crawler Generation](https://arxiv.org/abs/2404.12753)

- AutoCrawler: LLM-based web crawler agent, which automatically defines set of intermediate rules (reusability) / action sequences to extract target information from the website based on varying types of websites and task requirements. 
- Includes Progressive generation-phase (top-down, step-back, action sequence) and Synthesis-phases(set of action sequences).


---

[Let's Think Dot by Dot: Hidden Computation in Transformer Language Models{(https://arxiv.org/abs/2404.15758)

- Reviews use of "Filler tokens" instead of CoT.
Filler token refers to "...".

---

[SOPHON: Non-Fine-Tunable Learning to Restrain Task Transferability For Pre-trained Models](https://arxiv.org/abs/2404.12699)

- SOPHON: Pretraining protection frameworkd to avoid fine-tuning LLMs for adversary tasks, which results overhead cost for restricted domain fine-tuning above training the model from scratch


---


#### 18th of April 2024

[Aligning Language Models to Explicitly Handle Ambiguity](https://arxiv.org/abs/2404.11972)

- Introduces disambiguation procedure for LLMs
- Four-step alignment pipeline: Explicit prediction, Implicity ambiguity detection ( Self-disambiguation and Measure Information-gain), Data construction (Information-gain > epsilon) and SFT.


---

[mABC: multi-Agent Blockchain-Inspired Collaboration for root cause analysis in micro-services architecture](https://arxiv.org/abs/2404.12135)

- mABC (multi-Agent Blockchain-inspired Collaboration): AI agent workflow, where multiple LLM-agents reach consensus in standardized voting process to manage RCA of microservices.
- The voting mechanism is blockchain-style. 
- Two workflows: ReAct answer (action, observation and reasoning for real-time/additional data and Direct answer (reasoning with zero-shot/CoT/N-ofThought) when is not required external tools.


---


#### 17th of April 2024

[Many-Shot In-Context Learning](https://arxiv.org/abs/2404.11018)

- Introduces Many-shot ICL, which differs from few-shot ICL by increasing significantly the amount of examples provided within the context window.
- Improves task-performance across domains over few-shot prompting across variety of domains.
- One of the first attempts to scale in-context learning or "test-time inference".
- Introduces the concept of Reinforced ICL, where model generated rationales are used for ICL by using zero-shot / few-shot CoTs prompts as examples to sample more examples. The generated examples are filtered to include only reaching a correct answer (requires ground truth and potentially generates false-positives).
- Introduces concet of Unsupervised ICL, without CoTs and prompt the model using only inputs (includes example problem/list of unsolved problems/zero-short or few-shot instruction of desired output format). The unsupervised ICL prompt is included to the paper.

---


[The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey](https://arxiv.org/abs/2404.11584)

- Survey on AI agents.
- Reviews single- and multi-agent architectures, challenges and future directions.


---

[AgentKit: Flow Engineering with Graphs, not Coding](https://arxiv.org/abs/2404.11483)

- AgentKit: Prompting framework for multifunctional agents. Constructs complex "thought process" from prompts. Consists of nodes.
- Nodes: prompts for specific task. User compiles Chain-of-Nodes (CoNs), which are structured thought processes in a graph.  
- Agents designed with AgentKit are SOTA-level in WebShop/Crafter-benchmarks. 
- Includes Github-repository with the code, where the graphs are build.


---

[Octopus v3: Technical Report for On-device Sub-billion Multimodal AI Agent](https://arxiv.org/abs/2404.11459)

- Octopus v3: 1B multimodal AI agent.
- Uses "functional tokens": represents any function as a token.
- Applies multi-stage training: first trains image-language, which is followed by the learning of functional tokens and finally the functional tokens provide feedback to keep improving the model with RL and external LLM used as a reward model.
- Operates in edge-devices like Rasberry Pi.
  

---

[Open-Ended Wargames with Large Language Models](https://arxiv.org/abs/2404.11446)

- Snow Globe: LLM-based multi-agent plays automatically qualititative wargames (open-ended).
- Information flows: Incident, Response, Inject and Response. The approach could be used in other domains.   

---



#### 16th of April 2024

[Self-playing Adversarial Language Game Enhances LLM Reasoning](https://arxiv.org/abs/2404.10642)

- SPAG (Self-Play Adversial language Game): LLM plays both "attacker" and  "defender" in a language game called "Adversial Taboo". The "attacker" aims to trigger the "defender" to state the target word only known to it,  while the "defender" aims to guess the target word based on communications made by the "attacker".
- The LLM is supervised fine tuned using RL with ReST based on the game outcomes from wide range of topics.
- This self-play technique improves the LLMs reasoning capabilities in three epoch.


---

[Closed-Loop Open-Vocabulary Mobile Manipulation with GPT-4V](https://arxiv.org/abs/2404.10220)

- COME(Closed-loop Open-vocabulary MobilE Manipulation): VLM-based robot consisting of Active Perception, Situated Commonsense Reasoning and Recover from Failure.
- Helps to recover from mistakes, free-form instructions and follow long-horizon task plans.
- Improves SOTA-level performance by 25% in real-world tabletop and manipulation tasks, which are Open-Vocabulary Mobile Manipulation (OVMM)-tasks.   
- Step towards autonomous robots in real-world scenarios. The high level-reasoning and planning uses: role, feedback handling, robot setup, APIs, response guidelines and Tips. The paper includes system prompt.


---

[Self-Explore to Avoid the Pit: Improving the Reasoning Capabilities of Language Models with Fine-grained Rewards](https://arxiv.org/abs/2404.10346)

- Self-Explore: LLMs explore Pits (wrong steps) in the reasoning and use these explorations as signals in further exploration.
- Outperforms SFT on GSM8K/MATH-datasets using three different LLMs.
- Applies step-level fine-grained reward.
  
---

[VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time](https://arxiv.org/abs/2404.10667)

- VASA-1: The model produces lip movement based on audio and an image.
- Visual Affective Skills (VAS): uses diffusion-based holistic facial dynamics.


---


[SCALE: Self-Correcting Visual Navigation for Mobile Robots via Anti-Novelty Estimation](https://arxiv.org/abs/2404.10675)

- SCALE: self-correcting visual navigation using image-goal conditioned implicity Q-learning, which when faced Out-of-distribution observation, the "Localization Recovery" generates possible future trajectories. 
- SOTA-level open-world navigation

---

[N-Agent Ad Hoc Teamwork](https://arxiv.org/abs/2404.10740)

- N-Agent ad-hoc Team work (NAHT): various  number and and unknown autonomous agents interact and cooperate dynamically to maximize return in a task. 
- Policy Optimization with Agent Modelling (POAM)-algorithm: each agent has its policy based on same underlining parameters. Critic is trained using information both from controlled and uncontrolled agents, while actor is trained using only controlled agents. Critic evaluates how good actions are at current status, while Actor decides the action to be taken at the status. Both actor and critic use team vector to capture information from all agents.

---

[Emergent intelligence of buckling-driven elasto-active structures](https://arxiv.org/abs/2404.10614)

- Microbot design using elacticity to control collective motion.
- Enables autonomous maze navigation by two self-propelled microbots connected by polyester beam (bucklebot) in 25 seconds, which is not possible by an individual microbot.


---

[HLAT: High-quality Large Language Model Pre-trained on AWS Trainium](https://arxiv.org/abs/2404.10630)

- Trains LLMs of 7B and 70B with 1.8T tokens with AWS Trainium GPUs, showing 54% of cost compared with Nvidia GPU.
- Illustrates the approach for training LLMs using AWS Traininum GPUS and AWS Neuron SDK.


---

[Automated Evaluation of Large Vision-Language Models on Self-driving Corner Cases](https://arxiv.org/abs/2404.10595)

- CODA-LM: Vision-Language benchmark for autonomous driving.


---

[White Men Lead, Black Women Help: Uncovering Gender, Racial, and Intersectional Bias in Language Agency](https://arxiv.org/abs/2404.10508)

- Identifies language agency bias in LLMs: gender, racial and intersectional.


---

[Demonstration of DB-GPT: Next Generation Data Interaction System Empowered by Large Language Models](https://arxiv.org/abs/2404.10209)

- DB-GPT: Open-source AI app development framework. Includes: RAG, Generative Business Intelligence, Fine-tuning, Data-driven Multi-agents, Data factory and Data sources, Text-to-SQL module and agents. AWEL: Agentic Workflow Expression Language. 


---

[Bootstrapping Linear Models for Fast Online Adaptation in Human-Agent Collaboration](https://arxiv.org/abs/2404.10733)

- BLR-HAC (Bootstrapped Logistic Regression for Human Agent Collaboration): pretrains transformer to generate parameters of a shallow parametrized policy. Update it using human-agent collaboration with online logistic regression.


---

[What is Meant by AGI? On the Definition of Artificial General Intelligence](https://arxiv.org/abs/2404.10731)

- Attempts to define AGI: "An Artificial General Intelligence (AGI) system is a computer that is adaptive to the open environment with limited computational resources and that satisfies certain principles."


---

[Private Attribute Inference from Images with Vision-Language Models](https://arxiv.org/abs/2404.10618)

- VLMs identify personal attributes of the image owners, which may cause privacy risk when misused. 


---

[CoTAR: Chain-of-Thought Attribution Reasoning with Multi-level Granularity](https://arxiv.org/abs/2404.10513)

- CoTAR (Attribute-oriented CoT): Identifies most crucial aspects of the given context to answer using direct citations to referenced parts.
- Three levels: Span guidance, Sentence guidance, Passage guidance


---

[Chinchilla Scaling: A replication attempt](https://arxiv.org/abs/2404.10102)

- Finds Chinchilla-scaling laws inconsistent.


---

[TEL'M: Test and Evaluation of Language Models](https://arxiv.org/abs/2404.10200)

- TEL’M (Test and Evaluation of Language Models): five evaluations Identification of interesting LLM tasks, Identification of Task properties of interest, Identification of task property metrics, Design of measurement experiments, Execution and analysis of experiments.


---

[Deceiving to Enlighten: Coaxing LLMs to Self-Reflection for Enhanced Bias Detection and Mitigation](https://arxiv.org/abs/2404.10160)

- Reduces bias in LLMs by stating the views are not LLMs own ones, which activates LLMs internal attention to improve sensitivity.

---


[Model-based Offline Quantum Reinforcement Learning](https://arxiv.org/abs/2404.10017)

- First model-based offline quantum RL algorithm


---

[AIGeN: An Adversarial Approach for Instruction Generation in VLN](https://arxiv.org/abs/2404.10054)

- AUGeN: consists of Instructor generator and Instruction discriminator.
- Instruction generator describes actions needed to navigate to a specific location based on images from the environment.
- Instruction discriminator matches images as real/fake in case image descriptions match with the instruction provided). 


---

[Language Model Cascades: Token-level uncertainty and beyond](https://arxiv.org/abs/2404.10136)

- Cascading LLM: simple queries are guided to "easy"-LLM, while complicated queries are guided to "hard"-LLM. This deferral decision is made by 5-layer MLP model.
- Applies token-level uncertainty, where length bias is mitigated when making deferral decision. Easy sequence have most tokens in low percentile, while hard sequences have some tokens with high uncertainty.


---

[EyeFormer: Predicting Personalized Scanpaths with Transformer-Guided Reinforcement Learning](https://arxiv.org/abs/2404.10163)

- EyeFormer: predictive model for scanpath (human vision attention behaviour) for both natural scenes and user interfaces. Illustrates using of scanpaths for personalized UI optimization.
- Deep RL with Transformer, which predicts spatial and temporal characteristics of scanpaths about viewer behaviours.


---

[How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs' internal prior](https://arxiv.org/abs/2404.10198)

- The LLM is less likely to trust retrieved information with RAG, the more likely the LLM is to trust its response without the RAG (Prior).
- The LLM is more likely to stick to Prior (knowledge), the more unrealistic the RAG pertubated information is. 


---


[Rethinking Software Engineering in the Foundation Model Era: From Task-Driven AI Copilots to Goal-Driven AI Pair Programmers](https://arxiv.org/abs/2404.10225)

-


---

[Vision-and-Language Navigation via Causal Learning](https://arxiv.org/abs/2404.10241)

-


---

[Uncovering Latent Arguments in Social Media Messaging by Employing LLMs-in-the-Loop Strategy](https://arxiv.org/abs/2404.10259)

-


---

[HelixFold-Multimer: Elevating Protein Complex Structure Prediction to New Heights](https://arxiv.org/abs/2404.10260)

-


---

[Continuous Control Reinforcement Learning: Distributed Distributional DrQ Algorithms](https://arxiv.org/abs/2404.10645)

-


---

[Social Choice for AI Alignment: Dealing with Diverse Human Feedback](https://arxiv.org/abs/2404.10271)

-


---

[Engineering software 2.0 by interpolating neural networks: unifying training, solving, and calibration](https://arxiv.org/abs/2404.10296)

-


---

[Future Language Modeling from Temporal Document History](https://arxiv.org/abs/2404.10297)

-


---

[Hierarchical Context Merging: Better Long Context Understanding for Pre-trained LLMs](https://arxiv.org/abs/2404.10308)

-


---

[Prescribing the Right Remedy: Mitigating Hallucinations in Large Vision-Language Models via Targeted Instruction Tuning](https://arxiv.org/abs/2404.10332)

-


---

[Reasoning on Efficient Knowledge Paths:Knowledge Graph Guides Large Language Model for Domain Question Answering](https://arxiv.org/abs/2404.10384)

-


---

[SparseDM: Toward Sparse Efficient Diffusion Models](https://arxiv.org/abs/2404.10445)

-


---

[Advancing Long-Term Multi-Energy Load Forecasting with Patchformer: A Patch and Transformer-Based Approach](https://arxiv.org/abs/2404.10458)

-


---

[DESTEIN: Navigating Detoxification of Language Models via Universal Steering Pairs and Head-wise Activation Fusion](https://arxiv.org/abs/2404.10464)

-


---

[When Emotional Stimuli meet Prompt Designing: An Auto-Prompt Graphical Paradigm](https://arxiv.org/abs/2404.10500)

-


---

[Self-Supervised Visual Preference Alignment](https://arxiv.org/abs/2404.10501)

-


---

[White Men Lead, Black Women Help: Uncovering Gender, Racial, and Intersectional Bias in Language Agency](https://arxiv.org/abs/2404.10508)

-


---

[Unveiling the Misuse Potential of Base Large Language Models via In-Context Learning](https://arxiv.org/abs/2404.10552)

-


---

[Generative Text Steganography with Large Language Model](https://arxiv.org/abs/2404.10229)

-

---

[EMC$^2$: Efficient MCMC Negative Sampling for Contrastive Learning with Global Convergence](https://arxiv.org/abs/2404.10575)


---

[Continual Offline Reinforcement Learning via Diffusion-based Dual Generative Replay](https://arxiv.org/abs/2404.10662)


---

[Question Difficulty Ranking for Multiple-Choice Reading Comprehension](https://arxiv.org/abs/2404.10704)


---

[Insight Gained from Migrating a Machine Learning Model to Intelligence Processing Units](https://arxiv.org/abs/2404.10730)


---

[MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents](https://arxiv.org/abs/2404.10774)


---

[LegalPro-BERT: Classification of Legal Provisions by fine-tuning BERT Large Language Model](https://arxiv.org/abs/2404.10097)


---

[Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study](https://arxiv.org/abs/2404.10719)


---

[Automating REST API Postman Test Cases Using LLM](https://arxiv.org/abs/2404.10678)

-


---

[Spiral of Silences: How is Large Language Model Killing Information Retrieval? -- A Case Study on Open Domain Question Answering](https://arxiv.org/abs/2404.10496)

-


---

[MEEL: Multi-Modal Event Evolution Learning]()

-


---


[Find The Gap: Knowledge Base Reasoning For Visual Question Answering](https://arxiv.org/abs/2404.10226)

-


---


#### 15th of April 2024


[Memory Sharing for Large Language Model based Agents](https://arxiv.org/abs/2404.09982)

- Memory-Sharing (MS)-framework: Multi LLM-agents share Memory Pool of query/response pairs, which improves In-Context Learning. Retriever-model is trained to retrieve memories based on user query.
- LLM agent answers based on query and retrieved memories. Scorer evaluates query / response. High scoring pairs are added to the Memory Pool, which is queried with cosine similarity.
- The shared memory helps all agents to learn from each other.
- The Retriever model is trained using pre-trained sentence similarity model, which retrieves data from jsonl-file to train a model and it is later used to pick relevant memories for each user query.


---

[Reimagining Self-Adaptation in the Age of Large Language Models](https://arxiv.org/abs/2404.09866)

- Self-Adaptive SW system: Includes Managed system (operational SW system) and Managing System (handles adaptions).
- Managing system includes Prompt generator, LLM engine, Response parser, Monitor (logs, metrics), Knowledge/Memory (conversation history, fine-tuned models, system config and system prompts) and Execute (verifier/executor). 


---

[Deferred NAM: Low-latency Top-K Context Injection via DeferredContext Encoding for Non-Streaming ASR](https://arxiv.org/abs/2404.10180)


---

[ChatShop: Interactive Information Seeking with Language Agents](https://arxiv.org/abs/2404.09911)


---

[TabSQLify: Enhancing Reasoning Capabilities of LLMs Through Table Decomposition](https://arxiv.org/abs/2404.10150)


---

[LLMorpheus: Mutation Testing using Large Language Models](https://arxiv.org/abs/2404.09952)

---

[A Survey on Deep Learning for Theorem Proving](https://arxiv.org/abs/2404.09939)


---

[Progressive Knowledge Graph Completion](https://arxiv.org/abs/2404.09897)


---

[Synergising Human-like Responses and Machine Intelligence for Planning in Disaster Response](https://arxiv.org/abs/2404.09877)


---

[HyperMono: A Monotonicity-aware Approach to Hyper-Relational Knowledge Representation](https://arxiv.org/abs/2404.09848)


---

[Action Model Learning with Guarantees](https://arxiv.org/abs/2404.09631)


---

[Explainable Generative AI (GenXAI): A Survey, Conceptualization, and Research Agenda](https://arxiv.org/abs/2404.09554)


---

[MyGO: Discrete Modality Information as Fine-Grained Tokens for Multi-modal Knowledge Graph Completion](https://arxiv.org/abs/2404.09468)


---

[Monte Carlo Search Algorithms Discovering Monte Carlo Tree Search Exploration Terms](https://arxiv.org/abs/2404.09304)


---

[Assessing Economic Viability: A Comparative Analysis of Total Cost of Ownership for Domain-Adapted Large Language Models versus State-of-the-art Counterparts in Chip Design Coding Assistance](https://arxiv.org/abs/2404.08850)


---

[Handling Reward Misspecification in the Presence of Expectation Mismatch](https://arxiv.org/abs/2404.08791)


---

[Generating Games via LLMs: An Investigation with Video Game Description Language](https://arxiv.org/abs/2404.08706)


---

[MMInA: Benchmarking Multihop Multimodal Internet Agents](https://arxiv.org/abs/2404.09992)


---

[Evolving Interpretable Visual Classifiers with Large Language Models](https://arxiv.org/abs/2404.09941)


---

[Evolving Interpretable Visual Classifiers with Large Language Models](https://arxiv.org/abs/2404.09941)


---

[Compression Represents Intelligence Linearly](https://arxiv.org/abs/2404.09937)


---

[Glitch Tokens in Large Language Models: Categorization Taxonomy and Effective Detection](https://arxiv.org/abs/2404.09894)

---

[Foundational Challenges in Assuring Alignment and Safety of Large Language Models](https://arxiv.org/abs/2404.09932)


---

[Is Table Retrieval a Solved Problem? Join-Aware Multi-Table Retrieval](https://arxiv.org/abs/2404.09889)


---

[Empowering Embodied Visual Tracking with Visual Foundation Models and Offline RL](https://arxiv.org/abs/2404.09857)


---

[Video2Game: Real-time, Interactive, Realistic and Browser-Compatible Environment from a Single Video](https://arxiv.org/abs/2404.09833)


---

[KG-CTG: Citation Generation through Knowledge Graph-guided Large Language Models](https://arxiv.org/abs/2404.09763)


---

[Effective Reinforcement Learning Based on Structural Information Principles](https://arxiv.org/abs/2404.09760)


---

[Unveiling Imitation Learning: Exploring the Impact of Data Falsity to Large Language Model](https://arxiv.org/abs/2404.09717)


---

[Higher Replay Ratio Empowers Sample-Efficient Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2404.09715)


---

[Are Large Language Models Reliable Argument Quality Annotators?](https://arxiv.org/abs/2404.09696)


---

[LoRAP: Transformer Sub-Layers Deserve Differentiated Structured Compression for Large Language Models](https://arxiv.org/abs/2404.09695)


---

[Harnessing GPT-4V(ision) for Insurance: A Preliminary Exploration](https://arxiv.org/abs/2404.09690)


---

[Multi-News+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation](https://arxiv.org/abs/2404.09682)


---


[All-in-one simulation-based inference](https://arxiv.org/abs/2404.09636)


---

[Efficient and accurate neural field reconstruction using resistive memory](https://arxiv.org/abs/2404.09613)


---

[A Self-feedback Knowledge Elicitation Approach for Chemical Reaction Predictions](https://arxiv.org/abs/2404.09606)


---

[Building Semantic Communication System via Molecules: An End-to-End Training Approach](https://arxiv.org/abs/2404.09595)


---

[σ-GPTs: A New Approach to Autoregressive Models](https://arxiv.org/abs/2404.09562)


---

[Characterization and Mitigation of Insufficiencies in Automated Driving Systems](https://arxiv.org/abs/2404.09557)


---

[Inferring Behavior-Specific Context Improves Zero-Shot Generalization in Reinforcement Learning](https://arxiv.org/abs/2404.09521)


---

[State Space Model for New-Generation Network Alternative to Transformers: A Survey](https://arxiv.org/abs/2404.09516)


---

[PhyScene: Physically Interactable 3D Scene Synthesis for Embodied AI](https://arxiv.org/abs/2404.09465)


---

[Exploring Text-to-Motion Generation with Human Preference](https://arxiv.org/abs/2404.09445)


---

[The 8th AI City Challenge](https://arxiv.org/abs/2404.09432)


---

[RankCLIP: Ranking-Consistent Language-Image Pretraining](https://arxiv.org/abs/2404.09387)


---

[Tasks People Prompt: A Taxonomy of LLM Downstream Tasks in Software Verification and Falsification Approaches](https://arxiv.org/abs/2404.09384)


---



#### 14th of April 2024


[Self-Selected Attention Span for Accelerating Large Language Model Inference](https://arxiv.org/abs/2404.09336)

- Fine-tunes LLM to self-identify minimal attention span in each step of the task.
- Speeds up inference 28% by dynamically adjusting self-attention.
- Allows LLMs to autonoumsly optimize computation.


---

[TransformerFAM: Feedback attention is working memory](https://arxiv.org/abs/2404.09173)

- Unlimited context window 


---

[Interactive Generative AI Agents for Satellite Networks through a Mixture of Experts Transmission](https://arxiv.org/abs/2404.09134)


---

[Confidence Calibration and Rationalization for LLMs via Multi-Agent Deliberation](https://arxiv.org/abs/2404.09127)


---

[LLeMpower: Understanding Disparities in the Control and Access of Large Language Models](https://arxiv.org/abs/2404.09356)


---

[Towards Practical Tool Usage for Continually Learning LLMs](https://arxiv.org/abs/2404.09339)


---

[SNN4Agents: A Framework for Developing Energy-Efficient Embodied Spiking Neural Networks for Autonomous Agents](https://arxiv.org/abs/2404.09331)


---

[Text-to-Song: Towards Controllable Music Generation Incorporating Vocals and Accompaniment](https://arxiv.org/abs/2404.09313)


---

[TrafficVLM: A Controllable Visual Language Model for Traffic Video Captioning](https://arxiv.org/abs/2404.09275)


---

[Task-Driven Exploration: Decoupling and Inter-Task Feedback for Joint Moment Retrieval and Highlight Detection](https://arxiv.org/abs/2404.09263)


---

[Knowledgeable Agents by Offline Reinforcement Learning from Large Language Model Rollouts](https://arxiv.org/abs/2404.09248)


---

[Towards Fast Inference: Exploring and Improving Blockwise Parallel Drafts](https://arxiv.org/abs/2404.09221)


---

[TextHawk: Exploring Efficient Fine-Grained Perception of Multimodal Large Language Models](https://arxiv.org/abs/2404.09204)


---

[Prior-agnostic Multi-scale Contrastive Text-Audio Pre-training for Parallelized TTS Frontend Modeling](https://arxiv.org/abs/2404.09192)


---

[Survey on Embedding Models for Knowledge Graph and its Applications](https://arxiv.org/abs/2404.09167)


---

[GeMQuAD : Generating Multilingual Question Answering Datasets from Large Language Models using Few Shot Learning](https://arxiv.org/abs/2404.09163)


---

[Fusion-Mamba for Cross-modality Object Detection](https://arxiv.org/abs/2404.09146)


---

[ToNER: Type-oriented Named Entity Recognition with Generative Language Model](https://arxiv.org/abs/2404.09145)


---

[Provable Interactive Learning with Hindsight Instruction Feedback](https://arxiv.org/abs/2404.09123)


---

[Semantic In-Domain Product Identification for Search Queries](https://arxiv.org/abs/2404.09091)


---


#### 13th of April 2024

[LLMSat: A Large Language Model-Based Goal-Oriented Agent for Autonomous Space Exploration](https://arxiv.org/abs/2405.01392)

- LLMSat: LLM-based spacecraft control and space missions.


---


[When Hindsight is Not 20/20: Testing Limits on Reflective Thinking in Large Language Models](https://arxiv.org/abs/2404.09129)


["Don't forget to put the milk back!" Dataset for Enabling Embodied Agents to Detect Anomalous Situations](https://arxiv.org/abs/2404.08827)


---

[Do LLMs Play Dice? Exploring Probability Distribution Sampling in Large Language Models for Behavioral Simulation](https://arxiv.org/abs/2404.09043)


---

[Generative AI Agent for Next-Generation MIMO Design: Fundamentals, Challenges, and Vision](https://arxiv.org/abs/2404.08878)


---

[CuriousLLM: Elevating Multi-Document QA with Reasoning-Infused Knowledge Graph Prompting](https://arxiv.org/abs/2404.09077)


---

[CodeCloak: A Method for Evaluating and Mitigating Code Leakage by LLM Code Assistants](https://arxiv.org/abs/2404.09066)


---

[Exploring Explainability in Video Action Recognition](https://arxiv.org/abs/2404.09067)


---

[Adapting Mental Health Prediction Tasks for Cross-lingual Learning via Meta-Training and In-context Learning with Large Language Model](https://arxiv.org/abs/2404.09045)


---

[Navigating the Landscape of Large Language Models: A Comprehensive Review and Analysis of Paradigms and Fine-Tuning Strategies](https://arxiv.org/abs/2404.09022)


---

[Smart Help: Strategic Opponent Modeling for Proactive and Adaptive Robot Assistance in Households](https://arxiv.org/abs/2404.09001)


---

[Intuition-aware Mixture-of-Rank-1-Experts for Parameter Efficient Finetuning](https://arxiv.org/abs/2404.08985)


---

[Understanding Multimodal Deep Neural Networks: A Concept Selection View](https://arxiv.org/abs/2404.08964)


---

[EIVEN: Efficient Implicit Attribute Value Extraction using Multimodal LLM](https://arxiv.org/abs/2404.08886)


---

[An evaluation framework for synthetic data generation models](https://arxiv.org/abs/2404.08866)


---

[On Speculative Decoding for Multimodal Large Language Models](https://arxiv.org/abs/2404.08856)



#### 12th of April 2024


[Megalodon: Efficient LLM Pretraining and Inference with Unlimited Context Length](https://arxiv.org/abs/2404.08801)

- Megalodon: Inlimited contrxt length


---

[Is Next Token Prediction Sufficient for GPT? Exploration on Code Logic Comprehension](https://arxiv.org/abs/2404.08885)

---

[Aligning LLMs for FL-free Program Repair](https://arxiv.org/abs/2404.08877)

---

[LLM In-Context Recall is Prompt Dependent](https://arxiv.org/abs/2404.08865)

---

[CATS: Contextually-Aware Thresholding for Sparsity in Large Language Models](https://arxiv.org/abs/2404.08763)

---

[Leveraging Multi-AI Agents for Cross-Domain Knowledge Discovery](https://arxiv.org/abs/2404.08511)


---

[Augmenting Knowledge Graph Hierarchies Using Neural Transformers](https://arxiv.org/abs/2404.08020)


---

[Enhancing Autonomous Vehicle Training with Language Model Integration and Critical Scenario Generation](https://arxiv.org/abs/2404.08570)


---

[LLM Agents can Autonomously Exploit One-day Vulnerabilities](https://arxiv.org/abs/2404.08144)


---

[Memory Traces: Are Transformers Tulving Machines?](https://arxiv.org/abs/2404.08543)


---

[Study of Emotion Concept Formation by Integrating Vision, Physiology, and Word Information using Multilayered Multimodal Latent Dirichlet Allocation](https://arxiv.org/abs/2404.08295)


---

[Inverse Kinematics for Neuro-Robotic Grasping with Humanoid Embodied Agents](https://arxiv.org/abs/2404.08825)


---

[SQBC: Active Learning using LLM-Generated Synthetic Data for Stance Detection in Online Political Discussions](https://arxiv.org/abs/2404.08078)


---

[Training a Vision Language Model as Smartphone Assistant](https://arxiv.org/abs/2404.08755)


---

[Apollonion: Profile-centric Dialog Agent](https://arxiv.org/abs/2404.08692)



---

[Strategic Interactions between Large Language Models-based Agents in Beauty Contests](https://arxiv.org/abs/2404.08492)


---

[Enhancing Autonomous Vehicle Training with Language Model Integration and Critical Scenario Generation](https://arxiv.org/abs/2404.08570)


---

[Toward a Theory of Tokenization in LLMs](https://arxiv.org/abs/2404.08335)

---

[Exploring the Frontier of Vision-Language Models: A Survey of Current Methodologies and Future Directions](https://arxiv.org/abs/2404.07214)


---


#### 11th of April 2024

[Rho-1: Not All Tokens Are What You Need](https://arxiv.org/abs/2404.07965)

- Rho-1: trains LLM with Selective Language Modelling (SLM) with useful tokens (based on loss pattern).
- The SLM calculates each token loss using reference model and then selectively removes loss of the unwanted tokens.
- Rho-1 1B and 7B achieve SOTA results at their size.


---

[Large Language Model Can Continue Evolving From Mistakes](https://arxiv.org/abs/2404.08707)

---

[Auctions with LLM Summaries](https://arxiv.org/abs/2404.08126)

---

[OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments](https://arxiv.org/abs/2404.07972)

- OSWorld: scalable multimodal agents for Ubuntu/Windows/MacOS to perform open-ended web/desktop tasks.
- Discovers humans complete 72% of tasks, while best agent completes only 12%. The main issues are GUI grounding/operational knowledge.

---


[ODA: Observation-Driven Agent for integrating LLMs and Knowledge Graphs](https://arxiv.org/abs/2404.07677)

- ODA: LLM with knowledge graph (KGs) using iteratively observation, action and reflection to help solve tasks. 
- The observation phase uses a global view of the entire KG and selectively picks relevant parts for reasoning.


---

[DesignQA: A Multimodal Benchmark for Evaluating Large Language Models' Understanding of Engineering Documentation](https://arxiv.org/abs/2404.07917)

- DesignQA-benchmark: Measures VLMs capcity to solve engineering tasks, including CAD images, drawings and engineering requirements. Includes: rule comprehension, rule compliance and rule extraction.


---

[Monte Carlo Tree Search with Boltzmann Exploration](https://arxiv.org/abs/2404.07732)

- Boltzmann Tree Search (BTS): replace soft values with Bellman values in MENTS.
- Decaying ENtropy Tree Search (DETS): Interpolates between BTS and MENTS.
- Alias method samples actions fast and demonstrate high performance in game of Go.

---

[WESE: Weak Exploration to Strong Exploitation for LLM Agents](https://arxiv.org/abs/2404.07456)


---

[Behavior Trees Enable Structured Programming of Language Model Agents](https://arxiv.org/abs/2404.07439)

---

[LLoCO: Learning Long Contexts Offline](https://arxiv.org/abs/2404.07979)

---

[ChatGPT Can Predict the Future when it Tells Stories Set in the Future About the Past](https://arxiv.org/abs/2404.07396)

---


#### 10th of April 2024 

[Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs](https://arxiv.org/abs/2404.07103)

--

[Accelerating Inference in Large Language Models with a Unified Layer Skipping Strategy](https://arxiv.org/abs/2404.06954)

---

[Superposition Prompting: Improving and Accelerating Retrieval-Augmented Generation](https://arxiv.org/abs/2404.06910)

---

[Not All Contexts Are Equal: Teaching LLMs Credibility-aware Generation](https://arxiv.org/abs/2404.06809)

---

[Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention](https://arxiv.org/abs/2404.07143)

- Infinite-Attention: Infinite long context window using compressed memory/local attention.
- The local attention computes using the in context. The compressed memory computes using the out-of-context.
- Google tests 1B LLN for 1M sequence length, which is difficult for such small model. I believe there are no existing benchmarks yet for testing such long context windows above +1M context window.
- Ahieves 114x compression ratio.


---

[GoEX: Perspectives and Designs Towards a Runtime for Autonomous LLM Applications](https://arxiv.org/abs/2404.06921)

- Gorilla Execution Engine (GoEx): open-source runtime to execute LLM actions, apps and microservices.
- LLMs evolve from dialogue to autonomous agents, which as well make decisions.
- "Post-facto Validation": human checks correctness of the generated output, instead of intermediate results. Introduces concet of "Undo" and "Damage confinement" to manage unintended risks with autonomous agents.


---

[Vision-Language Model-based Physical Reasoning for Robot Liquid Perception](https://arxiv.org/abs/2404.06904)


---

[BISCUIT: Scaffolding LLM-Generated Code with Ephemeral UIs in Computational Notebooks](https://arxiv.org/abs/2404.07387)

---


#### 9th of April 2024

[Measuring the Persuasiveness 
of Language Models](https://www.anthropic.com/news/measuring-model-persuasiveness)

- Reviews the scaling of LLMs on persuasion tasks. Finds, that Claude 3 Opus is statistically as convincing as human.


---

[Can Feedback Enhance Semantic Grounding in Large Vision-Language Models?](https://arxiv.org/abs/2404.06510)

---

[Large Language Models to the Rescue: Deadlock Resolution in Multi-Robot Systems](https://arxiv.org/abs/2404.06413)

- Hierarchical LLM guides robot away from deadlock situation by assigning leader-agent and give it direction to continue and GNN executes the low level policy.
- Finds LLMs effective in various environments for high-level planning tonresolve deadlocks.

---

[AgentQuest: A Modular Benchmark Framework to Measure Progress and Improve LLM Agents](https://arxiv.org/abs/2404.06411)

- AgentQuest: modular benchmark for multi-step reasoning with possibility via API to extend to different environments.
- Traditional benchmark includes single environment. AgentQuest uses driver to connect with a specific environment.


---

[AgentsCoDriver: Large Language Model Empowered Collaborative Driving with Lifelong Learning](https://arxiv.org/abs/2404.06345)

- AgentsCoDriver: multi-car collaboration using LLMs.
- The system includes the following modules: observation, reasoning engine, cognitive memory, reinforcement reflection, and communication.
- Includes useful designs on prompt generation and module designs.


---

[Autonomous Evaluation and Refinement of Digital Agents](https://arxiv.org/abs/2404.06474)

- Review domain-generic automatic evaluators to improve "digital agents", which improve SOTA performance in WebArena-benchmark by 29%.
- Evaluators are applied to improve agents with fine-tuning and inference-time guidance.
- Policy evaluation works by using VLM to perform user screen captioning, which is processed by LLM together with user instructions and agent trajectory(states/actions). The LLM-reasoner response is evaluated together with VLM-based reasoner to provide final failure/success-evaluation.
- Autonomous refinement uses inference-time guidance (reflexion) and Filtered behaviour cloning. 


---

[Wu's Method can Boost Symbolic AI to Rival Silver Medalists and AlphaGeometry to Outperform Gold Medalists at IMO Geometry](https://arxiv.org/abs/2404.06405)

- Combines Wu's method with AlphaGeometry to solve 27/30 IMO geometry problems (SOTA-level), which is 2 above AlphaGeometry alone or Wu's method alone only solves 15.
- First AI (fully symbolic baseline) to outperform a human in IMO geometry problems.


---

[Graph Reinforcement Learning for Combinatorial Optimization: A Survey and Unifying Perspective](https://arxiv.org/abs/2404.06492)



---

[Text-Based Reasoning About Vector Graphics](https://arxiv.org/abs/2404.06479)

---

[Sandwich attack: Multi-language Mixture Adaptive Attack on LLMs](https://arxiv.org/abs/2404.07242)

---

[pfl-research: simulation framework for accelerating research in Private Federated Learning](https://arxiv.org/abs/2404.06430)


---

[MuPT: A Generative Symbolic Music Pretrained Transformer](https://arxiv.org/abs/2404.06393)


---

[VISION2UI: A Real-World Dataset with Layout for Code Generation from UI Designs](https://arxiv.org/abs/2404.06369)

---

[WESE: Weak Exploration to Strong Exploitation for LLM Agents](https://arxiv.org/abs/2404.07456)

---

[ActNetFormer: Transformer-ResNet Hybrid Method for Semi-Supervised Action Recognition in Videos](https://arxiv.org/abs/2404.06243)


---

[Elephants Never Forget: Memorization and Learning of Tabular Data in Large Language Models](https://arxiv.org/abs/2404.06209)



---

[Open-Source AI-based SE Tools: Opportunities and Challenges of Collaborative Software Learning](https://arxiv.org/abs/2404.06201)


---

[THOUGHTSCULPT: Reasoning with Intermediate Revision and Search](https://arxiv.org/abs/2404.05966)


[VisualWebBench: How Far Have Multimodal LLMs Evolved in Web Page Understanding and Grounding?](https://arxiv.org/abs/2404.05955)




---


#### 8th of April 2024


[HAMMR: HierArchical MultiModal React agents for generic VQA](https://arxiv.org/abs/2404.05465)

- HAMMR: Uses multimodal ReAct-based agent, which is hierarchical by letting the agent call other specialized agents.
- Outperforms PaLI-X VQA by 5%.

---


[Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs](https://arxiv.org/abs/2404.05719)

- Ferret-UI: Outperforms GPT-4V on elementary UI-tasks with capability for referring (widget classification, OCR, icon recognition), grounding (find widget/icon/text and widget listing) and reasoning.
- "Any resolution" (anyres) enlarges small UI-objects in images like icons within varying screen aspect ratios. Screen capture is divided into two sub-sections. Each UI-element is referenced with type, text and bounding box. Uses 250k examples of training data. 


---

[AutoCodeRover: Autonomous Program Improvement](https://arxiv.org/abs/2404.05427)

- AutoCodeRover: autonomous sw engineering by solve Github issues (program repair and improvement). Solves 67 Github issues within 10 minutes. Future directions could include issue reproducer/semantic artifacts and human involvement.
- Includes two stages: context retrieval stage to produce buggy locations and Patch generation stage to produce final patch.


---

[Physics of Language Models: Part 3.3, Knowledge Capacity Scaling Laws](https://arxiv.org/abs/2404.05405)

- Presents 12 insights on LLM training duration model architecture, quantization, sparsity and data signal-to-noise ratio.
- Finds junk data significantly reduces model capacity, which can be avoided to large extent by adding special token in the beginning of text. LLM learns to autonomously label data as high-quality.


---

[360°REA: Towards A Reusable Experience Accumulation with 360° Assessment for Multi-Agent System](https://arxiv.org/abs/2404.05569)


- Reusable Experience Accumulation with 360° Assessment (360°REA): a hierarchical multi-agent framework to evaluate and accumulate experience from feedback.
- Uses Deal-experience pool and 360◦ performance
assessment.
- Dual-experience pool: helps LLM-agents collect useful experiences in complex tasks using local experience/high-level experience.

---

[Finding Visual Task Vectors](https://arxiv.org/abs/2404.05729)

- Identifies Task Vectors.
- Uses task vectors to perform different tasks without any sample input.

---

[LLM Reasoners: New Evaluation, Library, and Analysis of Step-by-Step Reasoning with Large Language Models](https://arxiv.org/abs/2404.05221)


---

[LLM-Augmented Retrieval: Enhancing Retrieval Models Through Language Models and Doc-Level Embedding](https://arxiv.org/abs/2404.05825)

---

[WILBUR: Adaptive In-Context Learning for Robust and Accurate Web Agents](https://arxiv.org/abs/2404.05902)

---

[Attention-Driven Multi-Agent Reinforcement Learning: Enhancing Decisions with Expertise-Informed Tasks](https://arxiv.org/abs/2404.05840)

---

[Long-horizon Locomotion and Manipulation on a Quadrupedal Robot with Large Language Models](https://arxiv.org/abs/2404.05291)

---

[Dense Training, Sparse Inference: Rethinking Training of Mixture-of-Experts Language Models](https://arxiv.org/abs/2404.05567)

---

[Xiwu: A Basis Flexible and Learnable LLM for High Energy Physics](Xiwu: A Basis Flexible and Learnable LLM for High Energy Physics)


---

#### 7th of April 2024

[AI2Apps: A Visual IDE for Building LLM-based AI Agent Applications](https://arxiv.org/abs/2404.04902)



---

[LLM-Based Multi-Agent Systems for Software Engineering: Vision and the Road Ahead](https://arxiv.org/abs/2404.04834)



---

[StockGPT: A GenAI Model for Stock Prediction and Trading](https://arxiv.org/abs/2404.05101)


[Prompting Multi-Modal Tokens to Enhance End-to-End Autonomous Driving Imitation Learning with LLMs](https://arxiv.org/abs/2404.04869)

---

#### 6th of April 2024

[Self-organizing Multiagent Target Enclosing under Limited Information and Safety Guarantees](https://arxiv.org/abs/2404.04497)

---

[Challenges Faced by Large Language Models in Solving Multi-Agent Flocking](https://arxiv.org/abs/2404.04752)

---

[Transform then Explore: a Simple and Effective Technique for Exploratory Combinatorial Optimization with Reinforcement Learning](https://arxiv.org/abs/2404.04661)


---

[Autonomous Artificial Intelligence Agents for Clinical Decision Making in Oncology](https://arxiv.org/abs/2404.04667)

---

[Do We Really Need a Complex Agent System? Distill Embodied Agent into a Single Model](https://arxiv.org/abs/2404.04619)

---


[The Case for Developing a Foundation Model for Planning-like Tasks from Scratch](https://arxiv.org/abs/2404.04540)

---

[MACM: Utilizing a Multi-Agent System for Condition Mining in Solving Complex Mathematical Problems](https://arxiv.org/abs/2404.04735)


---

[Goal-guided Generative Prompt Injection Attack on Large Language Models](https://arxiv.org/abs/2404.07234)

---

#### 5th of April 2024


[Exploring Autonomous Agents through the Lens of Large Language Models: A Review](https://arxiv.org/abs/2404.04442)


---

[Increased LLM Vulnerabilities from Fine-tuning and Quantization](https://arxiv.org/abs/2404.04392)




---

[Cleared for Takeoff? Compositional & Conditional Reasoning may be the Achilles Heel to (Flight-Booking) Language Agents](https://arxiv.org/abs/2404.04237)

---

[ROMA-iQSS: An Objective Alignment Approach via State-Based Value Learning and ROund-Robin Multi-Agent Scheduling](https://arxiv.org/abs/2404.03984)

---

[Hypothesis Generation with Large Language Models](https://arxiv.org/abs/2404.04326)

---

[KGExplainer: Towards Exploring Connected Subgraph Explanations for Knowledge Graph Completion](https://arxiv.org/abs/2404.03893)



---


#### 4th of April 2024

[AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web Navigating Agent](https://arxiv.org/abs/2404.03648)

- AutoWebGLM: automated browsing agent using ChatGLM3-6B LLM. Uses html simplification algorithm.
- Curriculum learning applies hybrid (human/AI) web browsing multi/single-step dataset(Data is collected with: match rules, Prompt LLM, Manual annotation and Solver and data is collected from real world/virtual environment and open source data.). RL/Rejection sampling fine tuning (RFT) is applied for browsing comphrehension and task decomposition.
- Introduces AutoWebBench-benchmark on real world web browsing tasks.
- Tools read DOM and webpage screenshot: Element filter, Element list, OCR module, HTML parse. Observation includes: instruction, HTML and previous action. Action includes: HTML section and action name.

---

[Visualization-of-Thought Elicits Spatial Reasoning in Large Language Models](https://arxiv.org/abs/2404.03622)

- Visualization-ofThought

[Language Model Evolution: An Iterated Learning Perspective](https://arxiv.org/abs/2404.04286)


---

[Anticipate & Collab: Data-driven Task Anticipation and Knowledge-driven Planning for Human-robot Collaboration](https://arxiv.org/abs/2404.03587)

---

[CONFLARE: CONFormal LArge language model REtrieval](https://arxiv.org/abs/2404.04287)

---

[SELF-[IN]CORRECT: LLMs Struggle with Refining Self-Generated Responses](https://arxiv.org/abs/2404.04298)

---


[Reason from Fallacy: Enhancing Large Language Models' Logical Reasoning through Logical Fallacy Understanding](https://arxiv.org/abs/2404.04293)

---

[Direct Nash Optimization: Teaching Language Models to Self-Improve with General Preferences](https://arxiv.org/abs/2404.03715)

---

[Comprehensible Artificial Intelligence on Knowledge Graphs: A survey](https://arxiv.org/abs/2404.03499)

---

[Benchmarking ChatGPT on Algorithmic Reasoning](https://arxiv.org/abs/2404.03441)

---

[Capabilities of Large Language Models in Control Engineering: A Benchmark Study on GPT-4, Claude 3 Opus, and Gemini 1.0 Ultra](https://arxiv.org/abs/2404.03647)

---


[ReFT: Representation Finetuning for Language Models](https://arxiv.org/abs/2404.03592)

---

[CodeEditorBench: Evaluating Code Editing Capability of Large Language Models](https://arxiv.org/abs/2404.03543)

---

[A Cause-Effect Look at Alleviating Hallucination of Knowledge-grounded Dialogue Generation](https://arxiv.org/abs/2404.03491)

---

[Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought](https://arxiv.org/abs/2404.03414)

---

[Embodied Neuromorphic Artificial Intelligence for Robotics: Perspectives, Challenges, and Research Development Stack](https://arxiv.org/abs/2404.03325)

---

[RALL-E: Robust Codec Language Modeling with Chain-of-Thought Prompting for Text-to-Speech Synthesis](https://arxiv.org/abs/2404.03204)


---

#### 3rd of April 2024




[MIMIR: A Streamlined Platform for Personalized Agent Tuning in Domain Expertise](https://arxiv.org/abs/2404.04285)

---
[I-Design: Personalized LLM Interior Designer](https://arxiv.org/abs/2404.02838)
---
[On the Importance of Uncertainty in Decision-Making with Large Language Models](https://arxiv.org/abs/2404.02649)
---
[Learn to Disguise: Avoid Refusal Responses in LLM's Defense via a Multi-agent Attacker-Disguiser Game](https://arxiv.org/abs/2404.02532)
---
[Designing for Human-Agent Alignment: Understanding what humans want from their agents](https://arxiv.org/abs/2404.04289)


---
[PiSSA: Principal Singular Values and Singular Vectors Adaptation of Large Language Models](https://arxiv.org/abs/2404.02948)

---

[Testing the Effect of Code Documentation on Large Language Model Code Understanding](https://arxiv.org/abs/2404.03114)

---

[The RealHumanEval: Evaluating Large Language Models' Abilities to Support Programmers](https://arxiv.org/abs/2404.02806)

---

[Measuring Social Norms of Large Language Models](https://arxiv.org/abs/2404.02491)

---

[Exploring Backdoor Vulnerabilities of Chat Models](https://arxiv.org/abs/2404.02406)

---


#### 2th of April 2024


[Mixture-of-Depths: Dynamically allocating compute in transformer-based language models](Mixture-of-Depths: Dynamically allocating compute in transformer-based language models)

- Mixture-of-Depth (MoD) Transformer: Transformers learn to assign compute dynamically to specific spots in the sequence.
- Top-k routing: defines tokens participating in block's computation. Learns to route harder tokens through more layers.
- Helps to speed up


---


[A Survey on Large Language Model-Based Game Agents](https://arxiv.org/abs/2404.02039)

- Survey about LLM-based Game agents.
- Unified architecture of LLMGAs: Perception(text, image, state, etc.), Thinking(reasoning, reflection, planning), Memory, Role-playing (role, experience, emotion), Action-module (control, dialogue, API, etc.) and Learning module.

 
---

[Advancing LLM Reasoning Generalists with Preference Trees](https://arxiv.org/abs/2404.02078)

- Eurus: LLMs optimized for reasoning. Trains reward model using UltraInteract-dataset, which consists of Preference Trees.
- Preference Tree: Diverse planning strategies in single pattern (such as tool creation, sequential processing). Multi-turn interaction trajectories with environment and the critique (learn to apply feedback and correct prior errors). Paired correct and incorrect actions in a tree structure. The data pair includes: instruction, correct response and incorrect response.   
- DPO (instruction fine-tuned) hurts performance, while KTO and NCA improve performance. Indicates, that DPO may be less suitable for reasoning tasks. 


---

[Self-Organized Agents: A LLM Multi-Agent Framework toward Ultra Large-Scale Code Generation and Optimization](https://arxiv.org/abs/2404.02183)

- SoA (Self-Organized multi-Agent framework): Self-organized LLMs collaborate to generate code base and dynamically multiple based on complexity. Uses Mother and Child-agents.
- Helps to scale the SoA to longer context lengths of code generation.

---


[Large Language Models for Orchestrating Bimanual Robots](https://arxiv.org/abs/2404.02018)

- LABOR (LAnguage-modelbased Bimanual ORchestration)-agent.

---
[CMAT: A Multi-Agent Collaboration Tuning Framework for Enhancing Small Language Models](https://arxiv.org/abs/2404.01663)

---
[InsightLens: Discovering and Exploring Insights from Conversational Contexts in Large-Language-Model-Powered Data Analysis](https://arxiv.org/abs/2404.01644)

---
[Helmsman of the Masses? Evaluate the Opinion Leadership of Large Language Models in the Werewolf Game](https://arxiv.org/abs/2404.01602)

---
[Collapse of Self-trained Language Models](https://arxiv.org/abs/2404.02305)

---

[RAT: Retrieval-Augmented Transformer for Click-Through Rate Prediction](https://arxiv.org/abs/2404.02249)

---

[Is Exploration All You Need? Effective Exploration Characteristics for Transfer in Reinforcement Learning](https://arxiv.org/abs/2404.02235)


---

#### 1st of April 2024

[Stream of Search (SoS): Learning to Search in Language](https://arxiv.org/abs/2404.03683)

- Stream of Search (SoS): Symbolic reasoning with next-sequence prediction (LLMs). 
- LLM pretrained with SoS-dataset generated with 500k search trajectories (also called as SoS) using various search strategies (BFS/DFS-based) to learn internal world model of search, which include problem solving using exploration and backtracking. 
- Enables generic and adaptive form of search: symbolic search is based on explicity environmental model, while SoS learns state transitions. The approach is likely to work in real world due to the complex/variable/branching nature of the game.
- The policy is improved using APA (Advantage-induces Policy Alignment)- and fine-tuning with [STaR-technique](#star) for threee iterations using 100k correct trajectories. 
- APA is a Actor-Critic RL technique. It creates copy of the LLM used as value network to enhance policy in the LLM. Reward function reviews the length and correctness of the generated trajectory.



---

[LLM as a Mastermind: A Survey of Strategic Reasoning with Large Language Models](https://arxiv.org/abs/2404.01230)

- Survey about Strategic reasoning of LLMs: methodologies and metrics. These approaches are categorizied into: Prompt engineering, Modular enhancements, Theory of Mind and Fine-tuning.
- Reasoning tasks include: Common Sense reasoning, Mathematical reasoning, Symbolic reasoning, Causal reasoning and Strategic reasoning. 
- Strategic reasoning differs from being a more dynamic form of reasoning with the environment and due to the uncertainty of the adversary action.
- Key traits of strategic reasoning are: Goal-oriented, Interactive, Predictive nature and Adaptability.


---
[Large Language Model Evaluation Via Multi AI Agents: Preliminary results](https://arxiv.org/abs/2404.01023)

---
[]()

---
[]()


---

#### 31st of March 2024


---
[CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs](https://arxiv.org/abs/2404.01343)

---
[DiffAgent: Fast and Accurate Text-to-Image API Selection with Large Language Model](https://arxiv.org/abs/2404.01342)
---
[Algorithmic Collusion by Large Language Models](https://arxiv.org/abs/2404.00806)

---
["My agent understands me better": Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents]()
---
[](https://arxiv.org/abs/2404.00573)
---
[]()

---
[]()


---
[]()


---



#### 30th of March 2024

[Alignment of brain embeddings and artificial contextual embeddings in natural language points to common geometric patterns](https://www.nature.com/articles/s41467-024-46631-y)

- Aligns LLM word embeddings with human brain embeddings.
- Brain embeddings are generated from fine-grained spatiotemporal neural recordings in a continuous embedding space.
- Aligning is based on similar geometric shapes between brain and llm word embeddings.

[Injecting New Knowledge into Large Language Models via Supervised Fine-Tuning](https://arxiv.org/abs/2404.00213)



---
[Language Models are Spacecraft Operators](https://arxiv.org/abs/2404.00413)


---
[A Taxonomy for Human-LLM Interaction Modes: An Initial Exploration](https://arxiv.org/abs/2404.00405)



---
[Survey on Large Language Model-Enhanced Reinforcement Learning: Concept, Taxonomy, and Methods](https://arxiv.org/abs/2404.00282)



---
[Your Co-Workers Matter: Evaluating Collaborative Capabilities of Language Models in Blocks World](https://arxiv.org/abs/2404.00246)


---

#### 29th of March 2024

[Gecko: Versatile Text Embeddings Distilled from Large Language Models](https://arxiv.org/abs/2403.20327)

- Gecko: "SOTA level" text embeddings with 768-dimensions with 7x smaller embedding model compared to prior SOTA. Gecko embeddings with 256 dimensions all existting 768-dimension text embeddings in MTEB
- Gecko uses FRet (Few-shot Prompted Retrieval dataset)-fine tuning dataset: task description, input query, positive passage, negative passage.
- FRet generates with LLM the relevant task and query for a passage. The query and task are fed into a pre-trained embedding model to get neighbor passages. LLM scores them either as positive or negative passages.
- Original passage may not become relevant positive/negative passage. 
- I think the overall idea could work even as prompt-engineering technique, where original passage is sent to LLM to define query/task, generate positive/negative passage and finally use the query, task, positive, negative passage as basis of retrieval. 

---

[ITCMA: A Generative Agent Based on a Computational Consciousness Structure](https://arxiv.org/abs/2403.20097)

- ITCMA (Internal Time-Consciousness Machine): an an architecture for generative agents called ITCMA-agent. It is"a computational consciousness structure" and good at utility and generalization to real world.
- ITCMA framework includes LLM, VLM, Agents under consciousness channels (composed of retention, primal impression and protention each next time step further) and Memory.
- Slowness is a downside.


---

[Enhancing the General Agent Capabilities of Low-Parameter LLMs through Tuning and Multi-Branch Reasoning](https://arxiv.org/abs/2403.19962)

- Explores open source 7B/13B LLMs ability to perform agentic tasks through supervised fine-tuning with task decomposition/backtracking (multipath reflective reasoning by prompting LLM to reflect path as not optiomal ) data.
- Agent dataset is contructed through: task construction, trajectory interaction and manual filtering. Includes two usage types: task planning and tool usage.
- Task planning data is generated the following way. LLM is used in three roles: question generator, action maker (offers thoughts/actions based on environmental feedback) and environmental agent. Action maker/Environmental agent keep interacting until task is completed. Requires manual screening after data is generated to ensure task logical consistency.
- Tool usage data is generated by manually filtering LLM examples of full reasoning trajectories.


---

#### 28th of March 2024


[STaR-GATE: Teaching Language Models to Ask Clarifying Questions](https://arxiv.org/abs/2403.19154)

- STaR(Self-Taught Reasoner)-GATE (Generative Active Task Elicitation)-algorithm: Self-improves LLM's ability to elicit user preference by generating questions and generalises beyond the trained role-player.
- Fine tunes LLM by generating a synthetic dataset for math problem dialogues with persona-task prompts.
- Teaches the LLM to ask clarifying questions to provide personalised responses.

---

[MATEval: A Multi-Agent Discussion Framework for Advancing Open-Ended Text Evaluation](https://arxiv.org/abs/2403.19305)

- MatEval: LLM agents emulate human collaboration discussion. Uses self-reflection, CoT and feedback mechnamism.
- Achieves high-correlation with human evaluation. Includes evaluator-, feedback(to imrpove discussion)- and summarizer-agents. 

---

[Change-Agent: Towards Interactive Comprehensive Change Interpretation and Analysis from Change Detection and Change Captioning](https://arxiv.org/abs/2403.19646)

- Change-Agent: Change deteection and interpretation using LLM from earth surface changes.


---

[Enhancing the General Agent Capabilities of Low-Parameter LLMs through Tuning and Multi-Branch Reasoning](https://arxiv.org/abs/2403.19962)

---

[Change-Agent: Towards Interactive Comprehensive Remote Sensing Change Interpretation and Analysis](https://arxiv.org/abs/2403.19646)



---
[LLMs as Academic Reading Companions: Extending HCI Through Synthetic Personae](https://arxiv.org/abs/2403.19506)


---
[MATEval: A Multi-Agent Discussion Framework for Advancing Open-Ended Text Evaluation](https://arxiv.org/abs/2403.19305)

---
[]()
---
[]()


---
[]()

---
[]()
---
[]()


---


#### 27th of March 2024

[Long-form factuality in large language models](https://arxiv.org/abs/2403.18802)

- Search-Augmented Factuality Evaluator (SAFE): long-form factual check with LLM agent using a 38 topic question set (LongFast). Uses multi-step reasoning and determines, if factuality is supported by google search results.
- LLM generates answer to question, this answer is splitted into individual facts. The facts are converted into self-contained, so the fact can be understood without rest of the facts. The individual facts are retrieved with google search: Facts supported by search results are labelled as supported and rest as non supported. If the fact is not relevant to the question, then the fact is labelled as irrelevant.
- Achieves super-human level performance and measures this with a F1-score. 


---

[What are human values, and how do we align AI to them?](https://arxiv.org/abs/2404.10636)



---

[Large Language Models Need Consultants for Reasoning: Becoming an Expert in a Complex Human System Through Behavior Simulation](https://arxiv.org/abs/2403.18230)

- MEOW (MOsaic Expert Observation Wall): improves LLM reasoning with behaviour simulation. 
- Expert model is trained with simulated data from experience of specific task. Tested in communication game.


---

[A Path Towards Legal Autonomy: An interoperable and explainable approach to extracting, transforming, loading and computing legal information using large language models, expert systems and Bayesian networks](https://arxiv.org/abs/2403.18537)

- Reviews the concept of legal autonomy of LLM agents for the first time: extracting, loading and transforming computing legal information.


---

[A Study of Three Influencer Archetypes for the Control of Opinion Spread in Time-Varying Social Networks](https://arxiv.org/abs/2403.18163)

- Reviews automated agents in social networks for opinion control: opinion inference engine with LLM, content generation using opinion vectors.


---
[]()
---
[]()



---

#### 26th of March 2024

[MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution](https://arxiv.org/abs/2403.17927)

- MAGIS: Resolves Github issues with multi-agent LLMs: Manager, Repository Custodian, Developer and Quality Assurance engineer. 


---

[Depending on yourself when you should: Mentoring LLM with RL agents to become the master in cybersecurity games](https://arxiv.org/abs/2403.17674)

- SecurityBot: role-based multiagent collaborative framework with RL agent as mentors for LLM agent to support cybersecurity operations. Includes modules: profiles, memory, reflection and action using LLMs.
- Collaboration mechanism: cursor for dynamic suggestions taking, aggregator for multiple mentors suggestion ranking & caller for proactive suggestion asking.


---
[Large Language Models Need Consultants for Reasoning: Becoming an Expert in a Complex Human System Through Behavior Simulation](https://arxiv.org/abs/2403.18230)
---
[A Study of Three Influencer Archetypes for the Control of Opinion Spread in Time-Varying Social Networks](https://arxiv.org/abs/2403.18163)


---
[Depending on yourself when you should: Mentoring LLM with RL agents to become the master in cybersecurity games](https://arxiv.org/abs/2403.17674)
---
[OVER-NAV: Elevating Iterative Vision-and-Language Navigation with Open-Vocabulary Detection and StructurEd Representation](https://arxiv.org/abs/2403.17334)



---

[Compressed Federated Reinforcement Learning with a Generative Model](https://arxiv.org/abs/2404.10635)


---

[]()


---

#### 25th of March 2024

[AIOS: LLM Agent Operating System](https://arxiv.org/abs/2403.16971)

- AIOS-architecture ofr LLM agent OS: AIOS SDK, LLM Kernel (Kernel layer), OS Kernel, Agent applications (Application layer), HW layer.
- LLM kernel: Agent scheduler, Context manager, Memory manager, Storage manager, Tool manager and Access manager.


---

[RepairAgent: An Autonomous, LLM-Based Agent for Program Repair](https://arxiv.org/abs/2403.17134)

- RepairAgent: Automated program repair with LLMs with dynamically updated prompt format.


---

[CYGENT: A cybersecurity conversational agent with log summarization powered by GPT-3](https://arxiv.org/abs/2403.17160)

- CYGENT: Fine-tunes LLM for cybersecurity tasks and LLM agent provides/analyzes/summarizes user information from log files, detected events


---


[TwoStep: Multi-agent Task Planning using Classical Planners and Large Language Models](https://arxiv.org/abs/2403.17246)

- TwoStep: Combines classical planning with LLMs (Helper Plan and Main Plan).   




---
[Temporal and Semantic Evaluation Metrics for Foundation Models in Post-Hoc Analysis of Robotic Sub-tasks](https://arxiv.org/abs/2403.17238)
---
[Do LLM Agents Have Regret? A Case Study in Online Learning and Games](https://arxiv.org/abs/2403.16843)



---
[An LLM-Based Digital Twin for Optimizing Human-in-the Loop Systems](https://arxiv.org/abs/2403.16809)


---
[Harnessing the power of LLMs for normative reasoning in MASs](https://arxiv.org/abs/2403.16524)


---
[Norm Violation Detection in Multi-Agent Systems using Large Language Models: A Pilot Study](https://arxiv.org/abs/2403.16517)


---
[Towards Automatic Evaluation for LLMs' Clinical Capabilities: Metric, Data, and Algorithm](https://arxiv.org/abs/2403.16446)


---
[Re2LLM: Reflective Reinforcement Large Language Model for Session-based Recommendation](https://arxiv.org/abs/2403.16427)


---
[RL for Consistency Models: Faster Reward Guided Text-to-Image Generation](https://arxiv.org/abs/2404.03673)


---
[]()



---


#### 24th of March 2024




---
[AgentFL: Scaling LLM-based Fault Localization to Project-Level Context](https://arxiv.org/abs/2403.16362)
---
[Combining Fine-Tuning and LLM-based Agents for Intuitive Smart Contract Auditing with Justifications](https://arxiv.org/abs/2403.16073)


---
[]()

---
[]()

---
[]()

---
[]()

---
[]()

---

#### 23th of March 2024

[When LLM-based Code Generation Meets the Software Development Process](https://arxiv.org/abs/2403.15852)

- LCG: Multi-agent LLM consisting of waterfall, scrum and Test-Driven-Development sw development workflows with CoT and Self-refinement.
- LLM agent includes roles: requirements engineer, architect, developer, tester and scrum master. Uses same prompt, with role-identifier, role-specific instruction and task-information to drive dynamic prompting.


---
[Towards a RAG-based Summarization Agent for the Electron-Ion Collider](https://arxiv.org/abs/2403.15729)

---
[EduAgent: Generative Student Agents in Learning](https://arxiv.org/abs/2404.07963)


---
[]()

---
[]()



---

#### 22th of March 2024


[Can large language models explore in-context?](https://arxiv.org/abs/2403.15371)

- Reviews, if LLMs can explore effectively in-context, similar to Reinforcement learning-like agents.
- Suggest need for external summarization, larger models like GPT-4 and careful prompt engineering.

---

[CoLLEGe: Concept Embedding Generation for Large Language Models](https://arxiv.org/abs/2403.15362)

- CoLLEGe (Concept Learning with Language Embedding Generation): few-shot learning for new-concept acquisition and knowledge augmentation for LLMs.
- Generates concept embedding with CoLLEGe based on two example sentences, where the concept is used, creates a definition-sentence using this concept-embedding and asks LLM to generate the definition of the concept.  


---

[LLM-Driven Agents for Influencer Selection in Digital Advertising Campaigns](https://arxiv.org/abs/2403.15105)

- Influencer Dynamics Simulator (IDS): LLM-agent based influencer selection for digital ad campaigns.
- Includes: Influencer pre-selection, user profile generation, follower behaviour prediction and influencer tracking.


---

[Language Models in Dialogue: Conversational Maxims for Human-AI Interactions](https://arxiv.org/abs/2403.15115)

- Proposes principles for effective human-AI conversation: quantity, quality, relevance and manner, benevolence and transparency.


--- 

[CACA Agent: Capability Collaboration based AI Agent](https://arxiv.org/abs/2403.15137)

- CACA (Capability Collaboration based AI Agent): LLM agent with the following components: profile capability, reception capability, workflow capability, tool capability, tool service, methodology capability, add domain knowledge and planning capability.
- Processes: user request, generate plan, search methodology, get profile, discover tool, invoke service, add domain knowledge and register tool service.

---

[Content Knowledge Identification with Multi-Agent Large Language Models (LLMs)](https://arxiv.org/abs/2404.07960)

---


#### 21st of March 2024

[ReAct Meets ActRe: Autonomous Annotations of Agent Trajectories for Contrastive Self-Training](https://arxiv.org/abs/2403.14589)

- A^3T (Autonomous Annotation Agent Trajectories): Closed-loop self-improvement for LLM agents.
- Autonomous annotation of agent trajectories with ReAct for contrastive self-training. Reduces human-effort of data-collection.
- Agent reasons for actions taken (ActRe-prompting agent).Contrastive self-training uses rewards decisions made based on accumulated successful trajectoriess.
- The model outperforms GPT-4 and matches human average in Webshop-benchmark 




---

[ERD: A Framework for Improving LLM Reasoning for Cognitive Distortion Classification](https://arxiv.org/abs/2403.14255)

- ERD: Three step approach to reason cognitive distortions of user input: extraction, reasoning (CoT, Diagnosis of Thought) and debate between two LLM-agents and one LLM-judge.

---

[PeerGPT: Probing the Roles of LLM-based Peer Agents as Team Moderators and Participants in Children's Collaborative Learning](https://arxiv.org/abs/2403.14227)

- PeerGPT: pedagogical agents in Children collaborative learning with peer agent as team moderator or peer agent as a participant.


---

[RoleInteract: Evaluating the Social Interaction of Role-Playing Agents](https://arxiv.org/abs/2403.13679)

- RoleInteract-benchmark: Measures Sociality skills of role-playing LLM-agents. Conversation memory is one aspect to improve conversational agents. Complex group dynamics are still hard.


---

[Polaris: A Safety-focused LLM Constellation Architecture for Healthcare](https://arxiv.org/abs/2403.13313)

- Polaris: 1T parameter LLM as a co-operative agent for patient friendly conversation with multiple specialist agents like nurses/social workers/nutritionists. Uses iterative co-training to optmize diverse objectives. Uses healthcare-related data, including propietary data.
- Performs on par with human nurses and outperform significantly GPT-4. 


---


#### 20th of March 2024


[Reverse Training to Nurse the Reversal Curse](https://arxiv.org/abs/2403.13799)

- Reverse training: trains LLMs using reverse order to solve the reverse curse, where the LLM struggles to learn: B is a feature of A.
- Reverse curse has been key issue in the current LLM training.

---

[Large Language Models meet Network Slicing Management and Orchestration](https://arxiv.org/abs/2403.13721)

- LLM slices isolated virtual network of a Physical infrastructure. 



---

[Mapping LLM Security Landscapes: A Comprehensive Stakeholder Risk Assessment Proposal](https://arxiv.org/abs/2403.13309)

- Traditional risk assessment framework for LLMs through 10 categories: prompt injection, insecure plugin design, training data poisoning, model denial of service, supply chain vulnerabilities, sensitive information disclosure, insecure output handling, excessive agency, overreliance and model theft.



---


#### 19th of March 2024

[Agent-FLAN: Designing Data and Methods of Effective Agent Tuning for Large Language Models](https://arxiv.org/abs/2403.12881)

- Agent-FLAN (Finetuned LANguage models for aents): finetuning for agentic tasks.
- Llama-2 7B model with Agent-FLAN surpasses by 3.5% existing SOTA models. Works both for tool utilization and agentic tasks.
- Observes: LLMs overfit to specific agentic task formats like JSON, Learning speed of LLMs vary for agentic tasks and current training methods introduce hallucinations.


---

[HYDRA: A Hyper Agent for Dynamic Compositional Visual Reasoning](https://arxiv.org/abs/2403.12884)

- HYDRA (HYper Dynamic Reasoning Agent): multi-stage dynamic compositional visual reasoning, to make hyper-decisions (fast, strategic and efficient decisions).
- Three modules: LLM-Planner, RL agent (controller) and LLM-Reasoner (includes code generator and code executor). Includes Memory (code-, instruction- and feedback-history) and LLM-Textualizer (Uses template to create summary).
- Planner and Reasoner generate instructions/Code with LLM. RL agent interacts with these modules and makes high-level decisions from best instructions based history. HYDRA adjusts actions from feedback received in reasoning. User queries are deconstructed with three sub-questions processed concurrently. The code executor has access to vision foundational models like BLIP, XVLM and GLIP.
- RL agent is based on DQN-algorithm.


---

[Characteristic AI Agents via Large Language Models](https://arxiv.org/abs/2403.12368)

- Characteristics AI: simulates real-life individuals in different situations. Releases Character100-dataset.
  

---


[Embodied LLM Agents Learn to Cooperate in Organized Teams](https://arxiv.org/abs/2403.12482)

- Introduces prompt-based orgnizational structure. Reduces LLM errors related to redundant information and complying any instruction. Includesc communication- and action phases. Criticize-Reflect architecture.


---

[Contextual Moral Value Alignment Through Context-Based Aggregation](https://arxiv.org/abs/2403.12805)

- CMVA-GS: moral value agents with different profiles pass through contextual aggregator.

---

[LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach Combining Predictive Agent Reasoning and Critical Agent Instruction](https://arxiv.org/abs/2403.15464)


---

[The Use of Generative Search Engines for Knowledge Work and Complex Tasks](https://arxiv.org/abs/2404.04268)

---


#### 18th of March 2024

[Multimodal Human-Autonomous Agents Interaction Using Pre-Trained Language and Visual Foundation Models](https://arxiv.org/abs/2403.12273)

- Dual-modality frameworkk: leverages independent LLM/VLM/SR models in order to interact autonomous robots.
- Includes components of visual understanding, LLM and Speech regognition.


---

[EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents](https://arxiv.org/abs/2403.12014)

- EnvGen-framework: Use LLM-agent creates training environment for reasoning, so smaller embodied RL-agents improve their weak skills.
- Benefits from the LLM-agents world knowledge and the small, yet capable RL agents.


---

[From Pixels to Insights: A Survey on Automatic Chart Understanding in the Era of Large Foundation Models](https://arxiv.org/abs/2403.12027)

- Chart understanding task (chart Q&A, captioning, fact-checking, -to-table conversion, factual error correction).


---

[Agent3D-Zero: An Agent for Zero-shot 3D Understanding](https://arxiv.org/abs/2403.11835)

- Agent3D-Zero: 3D scene understanding agent with VLM by selecting and analyzing series of viewpoints for 3D understanding. 


---

#### 17th of March 2024

[Logic Query of Thoughts: Guiding Large Language Models to Answer Complex Logic Queries with Knowledge Graphs](https://arxiv.org/abs/2404.04264)


---


#### 15th of March 2024

[DiPaCo: Distributed Path Composition](https://arxiv.org/abs/2403.10616)

- DiPaCo (DIstributed PAth COmposition): a modlular ML paradigm, where computing is distributed by path. Path refers to sequence of modules defining input-output function.
- Paths are small in relation to the overall model. During both training and deployment, a query is routed to replica of a path (sparsely activated), not the entire model.
- The training phase distributes computation by paths through set of shared modules. The inference phase computes single path.
- First large-scale, more modular and less synchronous learning, when FLOPs are relatively cheap and communication is relatively expensive.
- Exceeds 1B parameter dense Transformer by choosing 256 possible paths with size of 150 million parameters.


---

[PERL: Parameter Efficient Reinforcement Learning from Human Feedback](https://arxiv.org/abs/2403.10704)

- PERL (Parameter Efficient Reinforcement Learning): Compares reward modelling training and RL using LoRA against traditional RLHF. The study focuses on device UI control, such as sending email.
- PERL achieves similar level of performance with less training compute and less memory used.
- Releases self-dialogue: Taskmaster Coffee and Ticketing-datasets and still pending, but planned release of UI automation-dataset called "S-dataset". Unclear, if the NPOV-dataset apart is kept internal. 


---

[AUTONODE: A Neuro-Graphic Self-Learnable Engine for Cognitive GUI Automation](https://arxiv.org/abs/2403.10171)

- AUTONODE (Autonomous User-Interface Transformation through Online Neuro-graphic Operations and Deep Exploration).
- Integrates Dora (Discovery and mapping Opertion for graph Retrieval Agents).


---

[Enhancing Human-Centered Dynamic Scene Understanding via Multiple LLMs Collaborated Reasoning](https://arxiv.org/abs/2403.10107)

- V-HOU Multi-LLMs Collaborated Reasoning: video scene understanding.


---

[Can a GPT4-Powered AI Agent Be a Good Enough Performance Attribution Analyst?](https://arxiv.org/abs/2403.10482)

- LLM agent for performance attrition using CoT and Plan and Solve (PS).

---

[ChatPattern: Layout Pattern Customization via Natural Language](https://arxiv.org/abs/2403.15434)


---

[ExeGPT: Constraint-Aware Resource Scheduling for LLM Inference](https://arxiv.org/abs/2404.07947)

---


#### 14th of March 2024


[Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking](https://arxiv.org/abs/2403.09629)

- Quiet-Star: Extension and generalization of STaR-paper. Improves significantly LLM performance on GSM8K-benchmark.
- Uses "meta-tokens" at the start/end of each thought, to learn when to generate a rationale and when it should make prediction-based on that rationale.


---

[Enhancing Trust in Autonomous Agents: An Architecture for Accountability and Explainability through Blockchain and Large Language Models](https://arxiv.org/abs/2403.09567)

- Blockchain based Autonomous agent not only with explanation, but as well with record auditable interpretation.
- Components: Autonomous agent, blockchain, Non-expert users, Automatic evaluation, Explainability component and Asynchronous task.


---

[VisionGPT-3D: A Generalized Multimodal Agent for Enhanced 3D Vision Understanding](https://arxiv.org/abs/2403.09530)

- Vision-GPT-3D: Multimodal agent optimizing 3d vision understanding by integrating: YOLO-, SAM- and DINO-models.  
- Starts by making a depth map from multiple images, converts the depth map into point cloud, then into mesh and finally into a video.


---

[From Skepticism to Acceptance: Simulating the Attitude Dynamics Toward Fake News](https://arxiv.org/abs/2403.09498)

- Fake news Propagation Simulation (FPS)-framework: identifies LLMs usefulness of LLMs to combat fake news. Reviews trends and controls of fake news using multiple agents under different personas (age/name/education/personality traits) with both long/short-term memory and self-reflection. Early and frequent regulation of fake news helps to limit its propagation impact.
- Dynamic Opinion Agent (DOA) simulates cognitive processes of each agent. Agent Interaction Simulator (AIS) defines how/which agents interact daily and publishes new common knowledge/beliefs to agents. 


---

[LLM-based agents for automating the enhancement of user story quality: An early report](https://arxiv.org/abs/2403.09442)

- ALAS (Autonomous LLM-based Agent System): LLM-based system between different agent profiles to develop and maintain high-quality IT user stories.
- Agent profiles: Product Owner/Requirements Engineer. User story. Task preparation phase: task, sub-tasks, context and vision statement. Task conduction-phase.


---

[USimAgent: Large Language Models for Simulating Search Users](https://arxiv.org/abs/2403.09142)

- USimAgent: generates search interaction sequence through multiple rounds, taking into account context generated in prior rounds, each with steps: reasoning/action, query generation and click behaviour. 


---

[MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training](https://arxiv.org/abs/2403.09611)

- MM1: MLLM training.

---


#### 13th of March 2024

[Gemma: Open Models Based on Gemini Research and Technology](https://arxiv.org/abs/2403.08295)

---

[Scaling Instructable Agents Across Many
Simulated Worlds](https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/sima-generalist-ai-agent-for-3d-virtual-environments/Scaling%20Instructable%20Agents%20Across%20Many%20Simulated%20Worlds.pdf)

- SIMA: The Scalable, Instructable, Multiworld Agent based on image from the screen and text instruction provided by user. SIMA agent uses text encoder, image encoder and video encoder to process the input image and text and output only the embodied action.
- Real-tme, embodied agent generalizes in 3D environment to any human task and coordinated by natural language instructions. Agent trained on multiple games outperformed an agent trained on single game. Performs nearly as well in new unseen game environments.
- Data collection from commercial video game environments, Training of SIMA Agent model with text instruction-actions and human evaluation. 


---

[SOTOPIA-π: Interactive Learning of Socially Intelligent Language Agents](https://arxiv.org/abs/2403.08715)

-  SOTOPIA-π: LLMs with social intelligence engage, act safer and persuade more.
-  Achieves social interaction goal completion capability of GPT-4 using 7B LLM. 
-  Starts by generating social tasks with each character with its own social goal. Continues by collecting this training data using behavioural cloning (expert signal) and self-reinforcement(strongly performing signals from itself). Improve the agent policy with the LLM ratings. Generate SOTOPIA tasks with characters and evaluate their interaction with LLM rating and human rating.  


---

[AutoGuide: Automated Generation and Selection of State-Aware Guidelines for Large Language Model Agents](https://arxiv.org/abs/2403.08978)

- AutoGuide: the LLM-agent receives task-information, in-context examples, current trajectory and "state-aware guidelines"-retrieval.
- The "State-aware retrieval" is in short a navigational instruction of the specific section in the web-page, such as clicking the "Forum"-button leads to page, where you can create a new Forum.


---

[TINA: Think, Interaction, and Action Framework for Zero-Shot Vision Language Navigation](https://arxiv.org/abs/2403.08833)

- TINA (Thinking, Interacting and Action)-framework: a zero-shot Vision-Language Navigation (VLN) based LLM-agent, visual perceptor making observations and a memory.
- Agent inputs include: Task description, Instuction and Memory. Trajectory memorizer summarizes observations/actions to memory. 



---

[System for systematic literature review using multiple AI agents: Concept and an empirical evaluation](https://arxiv.org/abs/2403.08399)

- Systematic Literature Reviews (SLRs)-agent: planner, literature identification, data extraction, data compilation, performance validation. The code includes concrete prompts used with each step.


---

[Hierarchical Auto-Organizing System for Open-Ended Multi-Agent Navigation](https://arxiv.org/abs/2403.08282)

- HAS (Hierarchical Auto-organizing System): Auto-organizes LLM-agents to complete navigation tasks using dynamic maps and auto-organizing-mechanism.
- Centralized planning (planner, describer, critic and deployer) with global multi-modal memory, distributed execution (actor, curriculum, critic and skill) with local-multi-modal memory and multimodal information (vision, audio, object and map) with environment state.


---

[Cultural evolution in populations of Large Language Models](https://arxiv.org/abs/2403.08882)

- Models cultural evolution in LLM-agent population.  


---

[CleanAgent: Automating Data Standardization with LLM-based Agents](https://arxiv.org/abs/2403.08291)

- CleanAgent: a data preparation LLM agent. 


---


#### 12th of March 2024

[NavCoT: Boosting LLM-Based Vision-and-Language Navigation via Learning Disentangled Reasoning](https://arxiv.org/abs/2403.07376)

- NavCoT (Navigational CoT): LLM acts as a world model and a navigational reasoning agent.
- LLM is prompted to forecast the navigational NavCoT: 1. act as world model to imagine the next observation based on instruction, 2. select best aligned candidate observation fitting to the imagination, 3. determine action based on reasoning from prior steps.
- In the Future Imagination-step (FI), the LLM is prompted to imagine the next observation, such as seeing a Patio. Visual Information Filter (VIF) selects from the available options provided by the VLM (image and description of the action towards it), the best matching to the FI. Action Prediction (AP)-step generates action prediction based on the selected option.


---

[WorkArena: How Capable Are Web Agents at Solving Common Knowledge Work Tasks?](https://arxiv.org/abs/2403.07718)

- Introduces two benchmarks WorkArena- and BrowserGym--benchmarks to evaluate LLM-agent interacting with software via browser.
- WorkArena (list, form, knowledge base, service catalog, menus) includes 23k tasks to interact with ServiceNow.
- BrowserGym designs and evaluates web agents in Python environment, which includes html content, raw pixels and acccessibility tree. and  
- Illustrates clear difference in web browsing expertise between GPT-3.5 vs. GPT-4.


---

[Transforming Competition into Collaboration: The Revolutionary Role of Multi-Agent Systems and Language Models in Modern Organizations](https://arxiv.org/abs/2403.07769)

- Multiagent Data and AI based platform framework: data, playground, web app, embedding model, multiagent orchestration (rest of the components interact with), data security/privacy, APIs/plugins, LLM & cache, Cloud provider, cloud DBs, Data Ops, MLOps, LLMOps and data strategy/ethics/LLM governance. The paper offers very little apart from this list, but the list does include quiet many of the components.


---

[DexCap: Scalable and Portable Mocap Data Collection System for Dexterous Manipulation](https://arxiv.org/abs/2403.07788)

- DexCap: a hand motion data capture system.


---

[AesopAgent: Agent-driven Evolutionary System on Story-to-Video Production](https://arxiv.org/abs/2403.07952)

- Aesop-agent: Multimodal content generation agent.
- Includes RAG from database(expert experience/professional knowledge), script generation, image generation, video assembly, utility layer.
- Reviews prompt optimization.


---

#### 11th of March 2024

[RecAI: Leveraging Large Language Models for Next-Generation Recommender Systems](https://arxiv.org/abs/2403.06465)

- RecAI: Recommender systems based on LLMs, where user makes query, the LLM agent makes tool queries to get the correct items.
- Includes Profile memory, info query, item retrieval and item ranker.
- The LLM chain includes: init state, dynamic demo, plan  execute and reflection.
- Refers to planning called Plan-First method, which creates comprehensive execution plan and then strictly follows this plan. The planning input includes: user input, context, tool descriptions and demonstrations for in-context learning to create tool utilization plan.


---

[DriveDreamer-2: LLM-Enhanced World Models for Diverse Driving Video Generation](https://arxiv.org/abs/2403.06845)

- DriveDreamer-2: First world model to generate customized driving videos, including uncommon scenes. 
- LLM generates user-defined driving videos: LLM converts user request into agent based trajectories, which is used to generate HDMap (python script creates Bird Eye View (BEV)) with respecting traffic rules. Unified Multi-View Model (UniMVM) improve temporal and spatial coherence of the generated video.


---

[Academically intelligent LLMs are not necessarily socially intelligent](https://arxiv.org/abs/2403.06591)

- SESI (Situational Evaluation of Social Intelligence)-benchmark: Superficial friendliness is principal reason for errors.
- Reviews: Empathy, Social-cognition, self-presentation, influence and concern.
- Illustrates interesting insight about GPT-4 not being better in this benchmark than GPT-3.5 turbo and Mistral model outperforming Llama 2.


---

#### 10th of March 2024

[TRAD: Enhancing LLM Agents with Step-Wise Thought Retrieval and Aligned Decision](https://arxiv.org/abs/2403.06221)

- TRAD: Thought Retrieval Aligned Decision.
- Includes three sub-processes: Temporal Expansion, Relative Order Mark and History Alignment.


---

[ArgMed-Agents: Explainable Clinical Decision Reasoning with Large Language Models via Argumentation Schemes](https://arxiv.org/abs/2403.06294)

- ArgMed-agent: Generator of the Argumentation Schema (AS), Verifier of the AS and Reasoner as symbolic solver.


---

[Reframe Anything: LLM Agent for Open World Video Reframing](https://arxiv.org/abs/2403.06070)

- RAVA (Reframe Any Video Agen): Perception to interpret user query and video content, Planning to determine aspect ratio/reframin strategies and Execution uses video editing tools to produce final video. 


---

#### 9th of March 2024

[Cached Model-as-a-Resource: Provisioning Large Language Model Agents for Edge Intelligence in Space-air-ground Integrated Networks](https://arxiv.org/abs/2403.05826)

- Model caching optimization on edge devices. Age of Thought (AoT): to measure the relevance/coherence of intermediate thoughts
during CoT inference.


---

#### 8th of March 2024


[RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation](https://arxiv.org/abs/2403.05313)

- Retrieval Augmented Thoughts (RAT): Iterative revising CoTs with retrieval information, which improves LLM reasoning in long-horizon tasks and reduces hallucinations.
- First generates CoT answer, then uses this answers with a verification prompt. The verification prompt requests to verify correctness of the given answer to the question with the separately added information query, for example by using Bing/Google search (authors implement a separate get_content function in their Github code).
- The query is based on the draft answer. The retrieved information is used to revise the draft answer. The next thought is then appended and a new round of revision performed. The process is repeated, until all revised thoughts are obtained and the final answer is provided.
- The github code includes multiple functions to manage inputs and outputs for the LLMs.


---

[FLAP: Flow Adhering Planning with Constrained Decoding in LLMs](https://arxiv.org/abs/2403.05766)

- FLAP (Flow Adhering Planning): Static planning in task oriented dialogs using constrained decoding algorithm based on lookahead heuristics.
- The research is static planning, but the authors plan a follow up research with dynamic planning.
- Aligns suggested plan thoughts using three scale score regards: user intent alignment, permitted flow steps, API selected, API permitted and structrally correct.


---

[Will GPT-4 Run DOOM?](https://arxiv.org/abs/2403.05468)

- Doom-game agent, consisting Python-based Manager module connected to Doom code and three modules: Planner, Vision and Agent.
- Vision module (GPT-4V) receives screenshots from the Managers and provides text description of it. - Planner uses as input the walkthrough and history and outputs a granular plan to be executed. Uses k-level of experts.


---


#### 7th of March 2024

[Acceleron: A Tool to Accelerate Research Ideation](https://arxiv.org/abs/2403.04382)

- Acceleron: LLM agent for research using colleague and mentor personas. Interacts with researcher develop research proposal.
- Introduces concept of "Unanswerability", when LLM should identify when all the retrieved paragraphs are irrelevant.


---


#### 6th of March 2024

[PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion](https://arxiv.org/abs/2403.03788)

- PowerPoint Task Completion-Robustness (PPTC-R)-benchmark for LLMs PowerPoint completion tasks.


---

[SheetAgent: A Generalist Agent for Spreadsheet Reasoning and Manipulation via Large Language Models](https://arxiv.org/abs/2403.03636)

- SheetAgent: LLM-agent to complete spreadsheet tasks by interacting through iterative task reasoning. Introduces SheetRM-benchmark.
- Includes three modules: Planner (generates python code to modify the spreadsheet), Informer (produces SQLs to perceive the spreadsheet despite dynamic range) and Retriever (retrieves instructive examples to improve robustness).
- Includes interesting concept of erroneous code-code repository as Milvus vector database, in order to perform cosine similarity search in case erroneous code.


---

[Exploring LLM-based Agents for Root Cause Analysis](https://arxiv.org/abs/2403.04123)

- Introduces LLM-based Root-Cause-Analysis (RCA) agent based on ReCT.


---


#### 5th of March 2024



[Cradle: Empowering Foundation Agents Towards General Computer Control](https://arxiv.org/abs/2403.03186v3)

- Cradle-framework: introduces MLLM-agent to control GUI using screenshot inputs and outputs executable code to control keyboard/mouse actions(key or button to press/where/duration/speed/location to move). Introduces the term General Computer Control (GCC).
- Includes modules: information gathering/self-reflection/task inference/skill curator/action planning/memory(episodic for retaining information/procedural for skills).
- Uses PyDirectInput instead of pyautogui for keyboard control. Includes low-level wrapper, which uses ctypes in windows and AppleScript in Mac to communicate low-level mouse controls.
- Procedural memory is based on topk matches of the skills (text embeddings).
- Episodic memory consists of short-term (screenshots/task guidance actions/reasoningand long-term summary. Short-term memory includes forgetting factor k set to 5-interactions. 
- The long-term memory includes recurrent information summary to avoid losing track of long-horozon task objective while inside short-horizon task: ongoing task/the past entities met/past behaviours.

---

[Reaching Consensus in Cooperative Multi-Agent Reinforcement Learning with Goal Imagination](https://arxiv.org/abs/2403.03172)

- MAGI (Multi-Agent Goal Imagination)-framework: agents reach consensus (and cooperatively reaching valuable future states) through imagined common goal.
- Future states are modeled with CVAE-based self-supervised generative modelling. Samples a common goal with high-potential value for multi-agent consensus to guide policies of all agents.
- CVAE is self-supervised conditional variational auto-encoder to model the distribution of future states.

---

[Language Guided Exploration for RL Agents in Text Environments](https://arxiv.org/abs/2403.03141)

- Introduces Language Guided Exploration (LGE), which in this study outperforms Behaviour Cloning.
- Explorer: RL agent with LGE outperforms with wide margin behaviour cloning. The key component is the Guide-model (LLM), which provides world knowledge to introduce set of feasible actions and reducing substantially the possible action space.


---

[KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents](https://arxiv.org/abs/2403.03101)

- KnowAgent: LLM-agent to improve planning with explicit action knowledge retrieval. The agent includes Action Knowledge Base (AKB), Planning Path Generation(question, action path, thought and observation) and Kowledgable Self-Learning.
- Introduces term planning hallucinations, which refers to agent generating conflicting or unnecessary action sequences.
- AKB contains information to steer action generation process: action name, definition, rule and knowledge.
- Knowledgable Self-Learning phase improves continuously the understanding and usage of action knowledge


---

[Learning to Use Tools via Cooperative and Interactive Agents](https://arxiv.org/abs/2403.03031)

- ConAgents: Cooperative and interactive agents, which iteratively applies three modules: Grounding, Execution and Observation. 
- Grounding step grounds user query into too definition and target output. Executing defines required tool arguments and completes returned output. Observing addresses long-form data outputs with IterCal-method: LLM agent self-adapts to feedback from tool environment.
- IterCal-method uses a pseudo-schema, which is basically a simplifie human-readable dictionary of the lengthy output returned from the tool used, see the pseudo-schema in the last page of the paper for quick understanding. 


---

[OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following](https://arxiv.org/abs/2403.03017)

- OPEx-agent: Includes Observer, Planner and Executor-roles. Observer-agent processes and interprets sensory inputs, such as vision from the environment. Planner integrates dynamically strategic plans and sub-tasks based on perception. Excutor implements the plans with skills library.
- Embodied Instruction Following (EIF): agents follows task instruction by interacting with the environment through observations in a ego-centric way.
- The agent basically includes, what objects the agent is currently observing, what objects have been found, what observations have been so far made and what previous steps have been completed. In addition, there is known the current objective, thought and action.


---

[Android in the Zoo: Chain-of-Action-Thought for GUI Agents](https://arxiv.org/abs/2403.02713)

- Chain-of-Action-Thought (dubbed CoAT): a novel prompting strategy to allow GUI agents to perceive, reason and decide.
- CoAT includes four parts: Screen context, Action thinking, Action target and Action Result.
- Screen context explains content of the GUI screenshot. Action thinking takes user query, current screen and history to define possible actions to complete goal. Action target refers to GUI element being actioned such as clicking an icon. Action result maps current screen with next action to future observation. 


---

[InjecAgent: Benchmarking Indirect Prompt Injections in Tool-Integrated Large Language Model Agents](https://arxiv.org/abs/2403.02691)

- InjectAgent-benchmark with +1k test cases in 17 tools and 62 attacker tools. Illustrates. Attack Success Rate (ASR) remains high especially in open source models like Llama 2.
- This result is surprising, considering "open source" models are often categorized as safer options over closed models. 


---

[Entropy-Regularized Token-Level Policy Optimization for Large Language Models](https://arxiv.org/abs/2402.06700)

- Entropy-Regularized Token-level Policy Optimization (ETPO).


---

[ChatCite: LLM Agent with Human Workflow Guidance for Comparative Literature Summary](https://arxiv.org/abs/2403.02574)


- ChatCite: Literature summary LLM-agent. Includes Key-Element Extractor and Reflective Incremental Generator.
- Key-Element Extractor: Extracts research questions, methodology, results, conclusions, contributions, innovations and limitations. These are stored in memory.
- Reflective Incremental Generator: Reflective mechnanism, Comparative summarizer, Reflective Evaluator and Rank & Select. Iteratively repeated.


---

#### 4th of March 2024

[Trial and Error: Exploration-Based Trajectory Optimization for LLM Agents](https://arxiv.org/abs/2403.02502)

- Exploration-based Trajectory Optimization (ETO): LLM agent collects failure trajectories to update its policy using failure-success trajectories.
- ETO includes three steps: Explore (SFT-based behavioral cloning LLM agent), Collect Failures (pairs contrastive trajectories from the failures and expert trajectories) and Optimize trajectories (DPO loss on the pairs).


---


#### 2nd of March 2024

[AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks](https://arxiv.org/abs/2403.04783v1)

- AutoDefence: Introduces multi-agent LLM-jailbreaking prevention framework with input agent, defence agent and output agents.
- Defence agent includes prompt analyser agent, intention analyser agent, judge agent and coordinator agent.
- Reduces success rate of prompt attacks.


---

[SceneCraft: An LLM Agent for Synthesizing 3D Scene as Blender Code](https://arxiv.org/abs/2403.01248)

- SceneCraft: LLM agent converts text into Python code for Blender API 3D-scenes. 
- Dual-loop: Inner loop keeps improving scene by writing Blender code, Blender API renders the code and critic-revising this rendered image using Vision-Language Model (VLM).
- Outer loop learns by updating reusable functions to the library.
- The beaty of this approach is, that VLM model revising the end result, makes it very generich approach for self-improvement.


---

#### 1st of March 2024

[Playing NetHack with LLMs: Potential & Limitations as Zero-Shot Agents](https://arxiv.org/abs/2403.00690)

- NetPlay: zero-shot agent, which uses agent loop using GPT-4.
- Constructs prompt including past events, the current observation, a task description with available skills and the desired output format. Retrieve new skill and Execute it. New events are then observed.


---

#### 28th of February 2024

[Human Simulacra: A Step toward the Personification of Large Language Models](https://arxiv.org/abs/2402.18180)

- Creates LLM personification with complete life story to simulate personality and interacting with external world in human-like manner
- Uses multi-agent framework to simulate cognitive functions, memory and psychology-guided evaluation to asses the quality of the human simulation with self-reporting and external observations. 


---

[Prospect Personalized Recommendation on Large Language Model-based Agent Platform](https://arxiv.org/abs/2402.18240)

-  Rec4Agentverse: Recommender agent with three steps: User-Agent Interaction, Agent-Recommender, Agents Collaboration.


---


[Data Interpreter: An LLM Agent For Data Science](https://arxiv.org/abs/2402.18679)

- Data Interpreter: Data scientist LLM agent with Plan, Code and Verify steps. The pipeline is represented as a DAG-structure. 
- Plan Real data adaption using dynamic planning with hierarchical graph structures. Code: Dynamic tool integration to improve code execution. Verify: Logical inconsistency identification through feedback


---


#### 24th of February 2024

[ByteComposer: a Human-like Melody Composition Method based on Language Model Agent](https://arxiv.org/abs/2402.17785)

- ByteComposer: LLM-agent based melody composer with four elements: Conception analysis, Draft composition, Self-evaluation and modification and Aesthetic selection. 


---

#### 23th of February 2024

[Large Multimodal Agents: A Survey](https://arxiv.org/abs/2402.15116)

- Survey on multi-modal AI and LLM agents.


---

[Genie: Generative Interactive Environments](https://arxiv.org/abs/2402.15391)

- Genie: a Foundational World Model. The learning paradigm is unsupervised learning from unlabelled internet video.  The approach scales effectively as compute is increased.
- Includes: Latent Action Model (LAM) for latent action between each video frame in each timestep, 2. Video tokenizer to convert video frames into discrete tokens, 3. Dynamics model to predict next frame 
- The model/datasets are not released, but the approach is explained in the paper with single GPU implementation details by bringing your own data using the dataset creationg instructions provided. 


---

#### 21st of February 2024

[Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping](https://arxiv.org/abs/2402.14083)

-  Searchformer: Transformer model outperforms A* search algorithm in planning.
-  Two step approach, where Transformer excels large action spaces and learns heuristics (strategies to guide search) from the training with the data.
- First step generates synthetic dataset: Imitate A* search by using A* search and recording compute and and optimal plan as text token sequences(task description, search tree dynamics, and final plan) with length of thousands of tokens. This dataset includes search dynamics of A* search itself. Train a Transformer model (Searchformer) to generate the text token sequences with optimal plan for a given task. This leads to a transformer model, which has the A* search coded in the model weights.
- Second step further trains Searchformer using Expert Iteration, which attempts to generate optimal plans to tasks with less steps in the optimal plan. The resulting model solves Sokoban puzzles with 27% less search steps, than A* search algorithm. The idea is to generalize the Transformer model into more generic search beyond A* search.


---

[User-LLM: Efficient LLM Contextualization with User Embeddings](https://arxiv.org/abs/2402.13598)

- User-LLM: generates user embeddings from user data with multi-feature autoregressive transformer and then fine-tunes the LLM using these embeddings with cross-attention.
- The method enables inserting the LLM with long-term user history through compressed user embeddings and short term user context through input prompt.
- Effective approach for LLM personalization and user modelling. Includes good chapter on LLM long context research.


---

[∞Bench: Extending Long Context Evaluation Beyond 100K Tokens](https://arxiv.org/abs/2402.13718)

- Coins prompting technique called: "Context recalling": improves code debug accuracy from +16% (using CoT) to +40% (using context recalling).
- Context recalling prompts the model to first recall the relevant information, before doing further reasoning.
- Introduces long context bencmark: ∞BENCH-benchmark for LLMs with above 100k context window. 


---

[Neeko: Leveraging Dynamic LoRA for Efficient Multi-Character Role-Playing Agent](https://arxiv.org/abs/2402.13717)

- Neeko-agent: Multi-character roleplaying agent with LoRA.
- Includes Pretraining, Multi-character Role-Playing and Incremental Role-Playing with Fusion and Expansion stages.


---


#### 20th of February 2024

[MuLan: Multimodal-LLM Agent for Progressive Multi-Object Diffusion](https://arxiv.org/abs/2402.12741)

- MuLan: Multimodal LLM agent, addresses text2image generation errors through progressive multiobject generation with LLM-based planning and VLM-based feedback control.
- MuLan is training free method.


---

[Large Language Model-based Human-Agent Collaboration for Complex Task Solving](https://arxiv.org/abs/2402.12914)

- ReHAC: uman-agent(LLM) collaboration with RL policy model.


---

#### 19th of February 2024

[AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling](https://arxiv.org/abs/2402.12226)

- AnyGPT: Any-to-Any Multimodal Language Model with any input output between text, speech, image and music.
- Uses only data preprocessing with modality specific tokenizers to tokenize input into discrete tokens and model outputs by de-tokenizing into specific modality outputs.
- Introduces multimodal alignment dataset made of conversations.   


---

[Shall We Talk: Exploring Spontaneous Collaborations of Competing LLM Agents](https://arxiv.org/abs/2402.12327)

- Studies spontaneuous collaboration between competing LLM agents


---

[WorldCoder, a Model-Based LLM Agent: Building World Models by Writing Code and Interacting with the Environment](https://arxiv.org/abs/2402.12275)

- WorldCoder: LLM agent learns World Models (world_model.py) using Python program from interactions with its environment.
- Outperforms baselines from DeepRL- and ReAct-agents in gridworlds-environment.
- Incldues sample code of the world_model.py.


---

[Comprehensive Cognitive LLM Agent for Smartphone GUI Automation](https://arxiv.org/abs/2402.11941)

- CoCo-Agent: GUI control with VLM/LLM/CLIP, which includes Comprehensive Environment Perception (CEP) and Conditional Action Prediction (CAP). Includes information such as GUI screenshot, GUI layout information, user objective and action history.
- Offers SOTA-level performance on GUIs, yet high training cost.  


---

[LLM Agents for Psychology: A Study on Gamified Assessments](https://arxiv.org/abs/2402.12326)

- PsychoGAT: Gamification of psychological assessment traditionally performed with questionaries with superior performance. Includes prompt templates.  


---

[Structured Chain-of-Thought Prompting for Few-Shot Generation of Content-Grounded QA Conversations](https://arxiv.org/abs/2402.11770)

- Structured CoT (SCoT): breakdowns into states for for generating actions for each sub-tasks durign the specific state. 
- For example first state determines, if question is answerable, the next step identifies required steps for the answer and the next state generates the step answer. 


---

#### 18th of February 2024

[LongAgent: Scaling Language Models to 128k Context through Multi-Agent Collaboration](https://arxiv.org/abs/2402.11550)

- LongAgent: Scales LLaMA to 128k context window outperforming GPT-4 through multiagent collaboration using inter-member communication.
- Leader agent selects agent members of team based on task description, agent team collaboratively reason, deduct answer and finally resolve conflict to generate final answer. 


---

[Learning From Failure: Integrating Negative Examples when Fine-tuning Large Language Models as Agents](https://arxiv.org/abs/2402.11651)

- Fine-tuning LLMs with Negative examples enhances performance. 


---

[Modelling Political Coalition Negotiations Using LLM-based Agents](https://arxiv.org/abs/2402.11712)

- Political coalition negotiation with LLM agents.


---

#### 17th of February 2024

[LLM can Achieve Self-Regulation via Hyperparameter Aware Generation](https://arxiv.org/abs/2402.11251)

- Hyperparameter Aware Generation (HAG): the LLM learns to modify automatically its hyperparameters (temperature, top_p, top_k, repetition_penalty) for each user task input.
- Self-regulation of hyperparameters enables the LLM to finetune its responses to different task inputs.
- Self-regulation takes inspiration from the ability of human body to regulate itself based on different factors like temperature, blood pressure, adrealine etc.


---

#### 16th of February 2024

[Robust agents learn causal world models](https://arxiv.org/abs/2402.10877)

- Implies causal understanding is required for robust generalization.
- Causal models can be learned from adaptive agents.


---

#### 15th of February 2024

[Chain-of-Thought Reasoning Without Prompting](https://arxiv.org/abs/2402.10200)

- CoT-Decoding: CoT without prompting. LLMs inherently pose reasoning abilities.
- Uses top-k alternative tokens to uncover CoT paths, which are frequently paths discovered in CoT. 


---

[A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts](https://arxiv.org/abs/2402.09727)

- ReadAgent: very long context management through gist-memories and pagination for web browsing.
- ReadAgent: LLM decided what content to store as episode pagination, LLM compresses page memory as shorter gist memory (see fuzzy-trace theory about memory) and LLM decides the pages to look up per given task and the gist memories related to the context of the task. The agent then retrieves the related page information to complete the task.
- Extends effective context window by 3-20x and keeps failure rate close to 0%, which is significantly less than traversing tree with a MemWalker-like solution.
- Gist-memory improves Web navigation over using raw html inputs, which is by nature a very long context task.


---

[AI Hospital: Benchmarking Large Language Models in a Multi-agent Medical Interaction Simulator](https://arxiv.org/abs/2402.09742)

- AI Hospital: LLM acts with doctor, patient, examiner and physician-roles. Categorises medical information into: subjective, objective and Diagnosis/Treatment. 
- MVME-benchmark (Multi-View Medical Evaluation): evaluates LLMs in symptop collection, recommendation analysis and diagnosis.


---

#### 14th of February 2024

[AgentLens: Visual Analysis for Agent Behaviors in LLM-based Autonomous Systems](https://arxiv.org/abs/2402.08995)

- AgentLens: visual analysis of of LLM based autonomous agents and exploration of their behaviours.
- UI includesOutline view, Agent view and Monitor view. Summarizes raw events, Descriptions of generated behaviours, Behaviour embeddings, Timeline segmentation.
- The behavioural embeddings: enables plotting specific behaviours in time, which is very effective approach. 


---

[Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications](https://arxiv.org/abs/2402.09015)

- AgentEval: framework to verify utility of the LLM tool through automatic criteria creation for a given task to review meeting of user needs. 
- Includes CriticAgent to list criteria of accepted values and QuantifierAgent verifying suggested criteria.


---

[DoRA: Weight-Decomposed Low-Rank Adaptation](https://arxiv.org/abs/2402.09353)

- Next generation LoRA. Get more out from your LLM, while not directly related to agents.


---


#### 13th of February 2024


[GLoRe: When, Where, and How to Improve LLM Reasoning via Global and Local Refinements](https://arxiv.org/abs/2402.10963)

- GLoRe: Presents a Stepwise Outcome-based Reward models. SORM is in contrat to Outcome-Based Reward models (ORMs) and Process-Based Rewrd Model (PRMs), where trained only on synthetic data to approximate future reward of optimal policy V*.
- Uses three step refinement training process: 1. Fine-tune base model for Student policy model, 2. SORM training, 3. Refinement training.

---

[Grounding LLMs For Robot Task Planning Using Closed-loop State Feedback](https://arxiv.org/abs/2402.08546)

- Brain-Body LLM(BB-LLM): Brain-LLM defines high-level plans for robot. The BodyLLM converts them into low-level planned actions as robot commands. 


---

[Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast](https://arxiv.org/abs/2402.08567)

- Agent Smith: "Infectious Jailbraking" Technique, which infects single LLM agent, that then infects with exponential growth rate the remaining agents.
- Concering technique reminding traditional computer virus, because the computational/time/resource expenses of infecting single agent remain low, but includes capability of infecting rest of the agents.


---

[Simulating Human Strategic Behavior: Comparing Single and Multi-agent LLMs](https://arxiv.org/abs/2402.08189)

- Investigation on LLMs capability to simulate human strategic behaviour.
- Compares Multiagent vs. Single LLM agent performance in the Ultimatum game and finds multiagent system more accurately simulating human behaviour.


---

[Large Language Models as Minecraft Agents](https://arxiv.org/abs/2402.08392)

- Develops Minecraft Builder and Architect LLM agents using JSON-format with capacity to ask clarifying questions from the LLM.


---

[PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human Feedback and Preference Alignment](https://arxiv.org/abs/2402.08702)

- PROMST: Optimizes prompts. Includes TaskLLM and PromptLLM. PromptLLM generates new prompt suggestions from existing best prompts and their feedbacks. New candidates are selected by score prediction model. 


---


#### 12th of February 2024

[T-RAG: Lessons from the LLM Trenches](https://arxiv.org/abs/2402.07483)


---


[OS-Copilot: Towards Generalist Computer Agents with Self-Improvement](https://arxiv.org/abs/2402.07456)

- FRIDAY: Self-improving embodied agent to interact with OS.
- OS-Copilot framework: Planner, Configurator to update or retrieve (Declarative memory for user profile and Semantic knowledge/Procedural memory for tools), Actor (Executor / Critic).
- Learns to control and self-improve.


---

[Predictive representations: building blocks of intelligence](https://arxiv.org/abs/2402.06590)

- Successor Representation (SR) may function as versatile building blocks of intelligence.


---

[Secret Collusion Among Generative AI Agents](https://arxiv.org/abs/2402.07510)

- Model capability evaluation framework on Secret collusion.


---


[THE COLOSSEUM: A Benchmark for Evaluating Generalization for Robotic Manipulation](https://arxiv.org/abs/2402.08191)

- THE COLOSSEUM benchmark for robot manipulation generalization through 20 diverse tasks.


---

#### 11th of February 2024

[Self-Correcting Self-Consuming Loops for Generative Model Training](https://arxiv.org/abs/2402.07087)

- Self-Correcting Functions using expert knowledge for generative model training. 


---
 
#### 9th of February 2024

<div id="vstar"> </div>  

--- 

[V-STaR: Training Verifiers for Self-Taught Reasoners](https://arxiv.org/abs/2402.06457)

- V-STaR: Enhancement to STaR-method. Uses during self-improvement not only correct, but as well incorrect solutions generated to train a verifier using DPO, where is judged correctness of the model-generated solutions.
- Iterating V-STaR multiple rounds generates progressively better reasoners and stronger verifiers by increasing GSM8K performance significantly from base STaR-method.
- Addresses the aspect of data efficiency by being able to improve both from correct and incorrect solutions. 


---

[Alphazero-like Tree-Search can Guide Large Language Model Decoding and Training](https://arxiv.org/abs/2309.17179)

- TS-LLM: a tree search guided LLM decoding with learned value function applicable for reasoning tasks.

---

[Feedback Loops With Language Models Drive In-Context Reward Hacking](https://arxiv.org/abs/2402.06627)

- LLMs interacting with the real-world create feedback loops, where the LLMs outputs shape world state, from where next LLMs are trained.
- Such feedback loops can cause In-Context Reward Hacking (ICRH): LLM outputs increase BOTH the objective and the negative side-effects.
- Output-refinement and policy refinement lead to ICRH.


---

[Understanding the Weakness of Large Language Model Agents within a Complex Android Environment](https://arxiv.org/abs/2402.06596)

- AndroidArena benchmark for measuring LLMs capability to control a modern operating system.
- Main failure modes: understanding, reasoning, exploration, and reflection.
  

---

<div id="llmsurveymikolov"> </div>  

[Large Language Models: A Survey](https://arxiv.org/abs/2402.06196)

- Reviews past years LLM research: LLM model families, building of LLMs, using of LLMs, LLM datasets, LLM metrics and future directions and challenges.
- Includes deployment pipelines, vector databases, prompting pipelines and LLM training/inference frameworks


---

[Why Solving Multi-agent Path Finding with Large Language Model has not Succeeded Yet](https://arxiv.org/abs/2401.03630)

- Identifies three reasons on why multi-agent path finding with LLMs does not work: model limitation, lack of understanding and lack of reasoning.


---

#### 8th of February 2024

<div id="interactiveagent"> </div>  


[An Interactive Agent Foundation Model](https://arxiv.org/abs/2402.05929)

- Interactive Agent Foundational Model: A generalist agent. Multi-task, Multi-domain: Healthcare, Gaming AI and Robotics.
- Interactive Agent framework: action encoder, visual encoder and language encoder. Pretrained to predict masked unified tokens for the three modalities: text token, visual token and action/agent token from each separate token per input type. Effectively generalizes between domains.
- Defines term "Agent-based AI" as generating dynamic behaviours grounded on the context understanding of uncertain environment. Defines "Embodied Agent-paradigm principles": Perception, Planning and Interaction.
Agent actions impact directly task plans by not requiring environment feedback to plan next action.
- MUltimodal systems preteained cross-modality grounded with environment hallucinate less by being grounded with the physical/virtual environment and require less size, than models pretrained separately/without grounding.


---

[UFO: A UI-Focused Agent for Windows OS Interaction](https://arxiv.org/abs/2402.07939)

- UI-Focused (UFO) agent: Automatically controlling Windows OS. The system includes two VLM-based agents: AppAgent (Application Selection Agent) and ActAgent (Action Selection Agent).
- AppAgent uses User input, Desktop screenshot, App information, Examples and Memory. It chooses application to complete the task, generates global plan. AppAgent outputs observation, Thoughts, Selected App, Status, Global pla and Comment.
- ActAgent takes as input  User request, Screenshots (highlighted last action, clean, annotated), Control information, Examples and Memory. ActAgent pursues local plans and actions until meeting the goal / receives observations from apps / interacts with memory. Outputs observation, Thoughts, Labeled control operation, Function, Status, Local plan and Comment.
- Control Interaction module grounds actions.


--- 

[Real-World Robot Applications of Foundation Models: A Review](https://arxiv.org/abs/2402.05741)

- A literature review of Robotics Foundationa models.
- Reviews Input/Ourput relationships of models, perception, motion planning and control.

---

[TimeArena: Shaping Efficient Multitasking Language Agents in a Time-Aware Simulation](https://arxiv.org/abs/2402.05733)

- TimeArena: A textual simulation environment for LLM agents to complete tasks as soon as possible.
- 30 real world like tasks from household activities to laboratory work. Illustrates, that GPT-4 lacks temporal awareness such as failing to recognize opportunities in parallel processing.


---

[ScreenAgent: A Vision Language Model-driven Computer Control Agent](https://arxiv.org/abs/2402.07945)

- VLM to control a real computer screen/GUI.
- Includes Planning, Acting and Reflecting phases.


---

[In-Context Principle Learning from Mistakes](https://arxiv.org/abs/2402.05403)

- Learning Principles (LEAP): Intentially guide LLM to make mistakes on few examples to reflect on them and learn task-specific principles.
- Improves MATH reasoning capability. 


---

[Keyframer: Empowering Animation Design using Large Language Models](https://arxiv.org/abs/2402.06071)

- Keyframer: LLM-powered animation generator from SVG images.


---

[Discovering Temporally-Aware Reinforcement Learning Algorithms](https://arxiv.org/abs/2402.05828)

- Reviews Temporally-aware reinforcement learning and Meta-learning.


---

[WebLINX: Real-World Website Navigation with Multi-Turn Dialogue](https://arxiv.org/abs/2402.05930)

- WebLINX: Real-time webpage control with LLMs.
- Filters relevant web page elements


---

[How Well Can LLMs Negotiate? NegotiationArena Platform and Analysis](https://arxiv.org/abs/2402.05863)

- NegotionArena bencbmark: to measure LLMs ability to negotiate. 


---

[Decision Theory-Guided Deep Reinforcement Learning for Fast Learning](https://arxiv.org/abs/2402.06023)

- Decision Theory-guided Deep Reinforcement Learning (DT-guided DRL): addresses cold start problem in RL.
- Promotes more structural and informed exploration strategy.


---


#### 7th of February 2024

[The Future of Cognitive Strategy-enhanced Persuasive Dialogue Agents: New Perspectives and Trends](https://arxiv.org/abs/2402.04631)

- CogAgent: Persuasion LLM agent framework.
- Cognitive strategy mining, Cognitive Strategy Prediction for Dialogue Modelling and Application scenarios (bargaining, counselling, debating etc.)


---

[Can Large Language Model Agents Simulate Human Trust Behaviors?](https://arxiv.org/abs/2402.04559)

- Reviews LLM agents ability to simulate Trust. 


---

[ScreenAI: A Vision-Language Model for UI and Infographics Understanding](https://arxiv.org/abs/2402.04615)

- ScreenAI: a VLM. Screen user interfaces (UIs) understanding, dataset creation with LLMs.


---

#### 6th of February 2024


[Self-Discover: Large Language Models Self-Compose Reasoning Structures](https://arxiv.org/abs/2402.03620)

- Self-Discover: Self-discovers complex reasoning structures outperforming CoT-Self-Consistency in MATH, while being more compute efficient. 
- Select reasoning modules(for exampel CoT, etc), Adapt reasoning modules and Implement reasoning structures as key-value pair as json. 
- Works with multiple LLMs and different types of reasoning scenarios.
 

---

[AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls](https://arxiv.org/abs/2402.04253)

- AnyTool: LLM agent utilizing over 16k APIs.
- API retriever with hierarchical structure with meta-agent, user query solver using candidate APIs and self-reflection mechanism for initial impractical solutions. Uses GPT-4 with function calling. 
- Introduces AnyToolBench-benchmark.
- Meta-agent is linked with multiple category agents each managing collection of tool agents.


---

[Can Generative Agents Predict Emotion?](https://arxiv.org/abs/2402.04232)

- Reviews LLM agents capability to align humans in terms of emotional states, when new events take place.
- LLM agent framework, where time series text memories are stored in graph database, which are summarized. As new events take place, the norm of the past episodic memories is combined with the current context. LLM agents emotional state is measured using pre-existing Positive And Negative Affect Schedule (PANAS)-framework to arrive a PANAS score of the current emotional state. Finally, the new memory is added to the graph database.
- The LLM agent acts in a virtual town with multiple agents interacting for example inviting and assisting a party. Performance is reviewed using pre-existing EmotionBench-benchmark. LLM agents lack to some extent ability to align emotionally like humans.
- Raises interesting concern, that GPT-3.5 may be biased to provide positive answers and therefore struggle to illustrate negative emotions.


---

[S-Agents: self-organizing agents in open-ended environment](https://arxiv.org/abs/2402.04578)

- S-Agents: Tree-of-Agents, where the leader LLM agent leads tree-like structure wiith executor agents.
- Hourglass agent framework: Monitor progress and Hierarchical planning. 
- Monitor progresss: starts with previous plan and perception used to monitor progress against objective. 
- Hierarchical planning: plans long-term (task planner), takes current task and generates actions (action planner) in the environment and agents.


---

[Large Language Models as an Indirect Reasoner: Contrapositive and Contradiction for Automated Reasoning](https://arxiv.org/abs/2402.03667)

- Indirect Reasoning (IR): Uses logic of contrapositives and contradictions for factual reasoning and math proofs.
- Adding IR to factual reasoning increases overall accuracy compared to Direct Reasoning (DR) only or IR only. 


---

[MobileVLM V2: Faster and Stronger Baseline for Vision Language Model](https://arxiv.org/abs/2402.03766)

- Vision Language Model: MobileVLM V2.


---


[QuantAgent: Seeking Holy Grail in Trading by Self-Improving Large Language Model](https://arxiv.org/abs/2402.03755)

- QuantAgent: Includes two LLM agents: Writer and Judge. The Writer-agent retrieves Knowledge Base (KB) and then generates answer based on the KB and submits the answer to real environment for evaluation. The Judge-agent retrieves relevant KB related to the review and it then generates score and feedback used in the next iteration.
- The iteration continues until maximum number of steps is reached or the score is high enough.


---

[Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models](https://arxiv.org/abs/2402.03877)

- Improves LLMs geometric reasoning with self-correction, collaboration and role specialization using geometric tools and four LLM agents.
- Uses LLM agents with four roles: Natural language solver and validator, Geometric tool Solver and Validator.


---

[In-context learning agents are asymmetric belief updaters](https://arxiv.org/abs/2402.03969)

- In-context learning: framing of the problem significantly impacts succesfullness.
- LLMs learn better from better-than-expected outcomes rather than worse-than-expected outcomes. 


---

[Systematic Biases in LLM Simulations of Debates](https://arxiv.org/abs/2402.04049)

- Reviews LLMs capability to generate believable simulation and current LLMs include a simulation bias for political debate. 
- Self-fine tunes LLM to take a specific political stance by using politically-oriented question to reflect answers, which is more effective than prompt-profiling alone.
- Illustrates the difficulty for LLMs to simulate specific human behaviour like a political views.


---

[Prioritizing Safeguarding Over Autonomy: Risks of LLM Agents for Science](https://arxiv.org/abs/2402.04247)

- Takes safety research from LLM safety to LLM agent safety, which is more holistic view.
- Scientific agent: Reviews LLM agent vulnerabilities within science domain: Data Insuffiency, Planning limitation, Tool limitations, LLM limitations and Lack of measurement. 
- Introduces triangle framework: Human regulation (Intent), Agent alignment (Red teaming) and Agent regulation (environmental feedback). 


---

#### 5th of February 2024

[Understanding the planning of LLM agents: A survey](https://arxiv.org/abs/2402.02716)

- LLM-Agent planning: provides a systematic view of LLM-based agents planning, covering recent works aiming to improve planning ability.
- It categorizes existing works into Task Decomposition, Plan Selection, External Module, Reflection and Memory, and provides comprehensive analysis for each direction.
- This survey is the first work that comprehensively analyzes LLM-based agents from the planning abilities.


---


[Chain-of-Feedback: Mitigating the Effects of Inconsistency in Responses](https://arxiv.org/abs/2402.02648)

- Recursive Chain-of-Feedback (R-CoF): Recursively breaks down complex reasoning problems into more easier and more detailed solutions and re-adjusts original reasoning based on the detailed correct reasoning.
- Given a problem, asks LLM to generate answer using multiple reasoning steps, then LLM verifies the incorrect reasoning steps, LLM then recursively asks only to solve the incorrect reasoning steps using same approach. If the new answer is correct, it gets added to the higher level answer and otherwise repeats the recursive LLM call.


---

[Vision-Language Models Provide Promptable Representations for Reinforcement Learning](https://arxiv.org/abs/2402.02651)

-  Promptable Representations for Reinforcement Learning (PR2L): the model asks from VLM about the game tasks, such as in case a spider is visiblle. The VLM responds semantic features or knowledge, which then better help the system to advance in the game by connecting what is seen with what it needs to do. This ensures, that the system actions are grounded with the reality of what is going on in the game. 
-  Initializes RL policy using VLM representation.
-  PR2L was not trained to play Minecraft only, but it still plays at level closed to models specifically trained with Minecraft games.


---

[Guiding Language Model Math Reasoning with Planning Tokens](https://arxiv.org/abs/2310.05707)

- Planning tokens improve LLM reasoning capabilities.
- Add the planning tokens in the LLM generated answer based on CoT in the beginning of each reasoning step, such as planning token related to multiplying done on that reasoning step,


---

[DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models](https://arxiv.org/abs/2402.03300)

- DeepSeekMath: 7B model comparable with math reasoning of a 70B model, close to Gemini Ultra and GPT-4.
- Introduces Group Relative Policy Optimization (GRPO).


---

[LLM Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations of Large Language Models](https://arxiv.org/pdf/2402.02896.pdf)

- Studies LLM agents capability to follow human personality profiles: analytical vs. creative personality.
- Each profile demonstrates different levels of consistency towards its profile in writing style and in a personality test. 


---

[Graph-enhanced Large Language Models in Asynchronous Plan Reasoning](https://arxiv.org/abs/2402.02805)

- Plan Like a Graph (PLaG): asynchronous plan reasoning with LLM: generates time estimations, identify step dependencies, converts the time estimates and dependencies into a graph processor and finally generate answer.
- Creates AsyncHow-benchmark: for asynchronous plan reasoning, requiring ability to correctly add time, correctly comparing time durations and ability to solve constrained reasoning.
- LLMs struggle efficiently completing complex asyncchronous plans without detailed illustration of how to solve the task.


---

[C-RAG: Certified Generation Risks for Retrieval-Augmented Language Models](https://arxiv.org/abs/2402.03181)

---

#### 4th of February 2024


[Understanding the planning of LLM agents: A survey](https://arxiv.org/abs/2402.02716)

- Review studies about the LLM agents planning capabilities.
- Categorizes these planning capabilities into: Task decomposition, Plan selection, External module, Reflection and Memory.
- Identifies development areas in: evaluating efficiency of the planning, revisiting of planning strategies in multimodality and more realistic evaluations.


---

[Solution-oriented Agent-based Models Generation with Verifier-assisted Iterative In-context Learning](https://arxiv.org/abs/2402.02388)

- SAGE: Modelling and Solving stages with Automatic Design and Generation of ABM.
  

---

[LLM-Enhanced Data Management](https://arxiv.org/abs/2402.02643)

- LLMDB: Detailed data management framework with LLMs.
- Components include: Preparation, Request pre-processing, Request parsing, Pipeline executor agent, Vector database and Data/Model management.


---

[Collaborative Agents for Software Engineering](https://arxiv.org/abs/2402.02172)

- CodeAgent: Autonomous Agent, a multi agent code review system.
- SOTA in code review systema.


---

### 3rd of Februry 2024

[More Agents Is All You Need](https://arxiv.org/abs/2402.05120)

- Scaling up LLM-agents increases performance with sampling & majority voting.
- Performance improvements increase and then decrease as difficult level gets harder. Improvements increase in function of number of steps. Prior probability of correct answer increases performance gains.


---

[Affordable Generative Agents](https://arxiv.org/abs/2402.02053)

- Affordable Generative Agents (AGA) framework: agent environment interaction and inter-agent interactions.
- Believable, low cost LLM-agents by replacing repetitive LLM inferences with learned policies. Models social relationships between LLM-agents and compresses auxiliary dialogue information.
- Emergent believable behaviour: LLM-agents generate finite behaviours in limited environments. Defines "mind wandering"-technique in memorory to generate diverse social behaviour by sampling both: highly relevant events and sampling ranly unrelated events. The idea is to randomness & spontaneus responses, like a real person.
- Social memory: relationship, feeling, events summary between the agents.



---

#### 2nd of February 2024


[K-Level Reasoning with Large Language Models](https://arxiv.org/abs/2402.01521)

- K-level of Reasoning: Recursive reasoning process, which improves dynamic reasoning by integrating cognitive hierarchy theory by recursively predicting and responding to the thoughts and actions of rivals.
- In essence, multiple LLM agents take a context, reason on it and make decision in "k-1"-level. The reasoning is then repeated in the "k"-level by integrating the the analysis from "k-1"-level to arrive decision in the "k"-level.


---


#### 1st of February 2024

[Multimodal Embodied Interactive Agent for Cafe Scene](https://arxiv.org/abs/2402.00290v1)

- MEIA (Multimodal Embodied Interactive Agent): Uses Multimodal Environment Memory (MEM) with LLM and VLM, to store egocentric environmental information (object IDs/coordinates as textual memory and visual observations as image memories) to improve significantly task planning and execution.
- MEIA is able to perform various tasks such as seating guidance, order taking and environmental adjustments being robust in zero-shot learning for real world tasks.
- It appears to be the first paper to introduce multimodal memory, which improves significantly performance and increases precision of the planning.
- Includes two measurement metrics: ESR (Executable Success Rate) and SSL (Succcess Rate Weighted by Step Length) with formulas included.
- Uses RGB images (stored in image memory)/depth images/segmentation images. 


---

[Efficient Exploration for LLMs](https://browse.arxiv.org/abs/2402.00396)

- Actively exploration is used to achieve high performance with less feedback.
- Uses double Thompson sampling with eistemic neural network (ENNs) to model reward uncertainty and least amount of queries.
- Gemini Nano is used as baseline model, which output is compared with Best-of-N responses from Gemini Nano based on reward model.


---

[Hello OLMo: A truly open LLM](https://blog.allenai.org/hello-olmo-a-truly-open-llm-43f7e7359222)

- OLMo: First open access data, open weights, open source code LLM.
- The model training data comes with need to agree to AI2's license terms wiith very clearly stated legal implications.


---

[Formal-LLM: Integrating Formal Language and Natural Language for Controllable LLM-based Agents](https://browse.arxiv.org/abs/2402.00798)


- Formal-LLM: Context-Free Grammar (CFG) translates guidance and rules for each relevant task, which LLM text generation must follow when generating the plan.
- Prevents generating invalid plans.   


---

#### 30th of January 2024


[StrokeNUWA: Tokenizing Strokes for Vector Graphic Synthesis](https://arxiv.org/abs/2401.17093)

- StrokeNUWA: Introduces image representations based on vector graphics using "stroke tokens". The approach does not require using raster/pixel representation.
-  Includes components of: Vector-Quantized-Stroke (VQ-Stroke), Scalable Vector Graphics (SVG) compression, Encoder-Decoder LLM for SVG generation and post-processing SVG fixer.
-  Enables 94 times faster inference speed and representing images as more "language like" manner of sequences of strokes.


---

[Efficient Tool Use with Chain-of-Abstraction Reasoning](https://arxiv.org/abs/2401.17464)

- Chain-of-Abstraction (CoA): trains LLMs with decoded reasoning chains using abstract placeholders and then call tools to complete the reasoning chain.
- CoA learns more generic math reasoning and   


---

[Planning, Creation, Usage: Benchmarking LLMs for Comprehensive Tool Utilization in Real-World Complex Scenarios](https://arxiv.org/abs/2401.17167)

- UltraTool Construction-framework includes three key steps: Query collection, Solution Annotation and Manual refinement. 
- UltraTool: benchmarking LLM performance in using tools in real world.
- Reviews tool use performance from planning, tool creation awareness, tool creation, tool usage awareness, tool selection and tool usage.


---

[Can Large Language Models be Trusted for Evaluation? Scalable Meta-Evaluation of LLMs as Evaluators via Agent Debate](https://arxiv.org/abs/2401.16788)

- Scale-Eval: Meta-evaluation framework using agents debates to reach consensus or align with human answer in various task scenarios.


---

[LLaMP: Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation](https://arxiv.org/abs/2401.17244)

- LLaMP: ReAct-agents connected with arXiv, Wikipedia, Material Project-agents. Includes promts and json-formats used with the RAG-pipeline. Reduces hallucinations in material science queries.
  

---


#### 29th of January 2024

[Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual Perception](https://arxiv.org/abs/2401.16158)

- Mobile-Agent: Multimodal Large Language Models (MLLM) for mobile devices, which locates visual/textual, plans, decomposes and executes complex tasks.
- OS agnostic
- Introduces Mobile-Eval benchmark and open sources [code](https://github.com/X-PLUG/MobileAgent).


---

[Beyond Direct Diagnosis: LLM-based Multi-Specialist Agent Consultation for Automatic Diagnosis](https://arxiv.org/abs/2401.16107)

- Patient consultation with muliple agents, starting with general practioner and then LLM agents in specific specialities: surgeon, respiratory doctor, endocrinologist.
- Icludes three stages: Individual practitioner consultation, practitioner group consultation and agent-based groupdecision fusion.

---

[Divide and Conquer: Language Models can Plan and Self-Correct for Compositional Text-to-Image Generation](https://arxiv.org/abs/2401.15688)

- CompAgent: LLM agent is manages the task of the entire image generation.
- The LLM agent is used to plan composition of objects next to each other. Achieves better images for example when prompted to generate image with a red hat next to blue backpack.

---


#### 28th of January 2024

[YODA: Teacher-Student Progressive Learning for Language Models](https://arxiv.org/abs/2401.15670)

- YODA: Hunan-like progressive learning paradigm for LLMs, where student agent learns in fixed dataset by learning first basic questions, then learns to generalize and finally learns harder problems.
- Teacher agent asks then similar questions from the student agent. The teacher agent gradually adds more complex and more generic questions after each iteration and offers feedback to the student agent for the answers provided.
- The approach helps the student agent to learn to solve problems and generalize problems comprehensively, which leads to 10% improvement in MATH benchmark from the original Llama 2. 


---


#### 26th of January 2024

[Turn-taking and Backchannel Prediction with Acoustic and Large Language Model Fusion](https://arxiv.org/abs/2401.14717)

- Reviews how voice-assistant systems should predict and manage: turn-taking, backchanneling and continued speaking.
- Contiying speaking refers to the other party needing to continue listening the current speaker. Backchanneling refers to the current listener needing to produce a short utterance of acceptance without meaning to take over the speaker role. Turn-taking refers to the listered being expected to take over speaking turn from the current speaker.
- Creates fusion model combining both LLM (GPT-2/RedPajama) and HuBERT-acoustic model.


---

#### 24th of January 2024

[Hi-Core: Hierarchical Knowledge Transfer for Continual Reinforcement Learning](https://arxiv.org/abs/2401.15098)

- Hi-Core: Formulates goals as a high-level policy using LLM reasoning and then low-level policy learning towards these high-level goals. Policy library is used to store policies searchable with embeddings based on policy description.
- Makes the important point, that to learn high-level human cognitive skills using transfer learning, we need to represent high-level human knowledge effectively to be able to transfer them into models.


---


#### 23rd of January 2024

[Meta-Prompting: Enhancing Language Models with Task-Agnostic Scaffolding](https://arxiv.org/abs/2401.12954)

- Meta-prompting: LLM coordinate and execute multiple independent queries with their responses to generate final answer.


---


[AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents](https://arxiv.org/abs/2401.12963)

- AutoRT: Fleet of robots use VLM and LLM 


---

[HAZARD Challenge: Embodied Decision Making in Dynamically Changing Environments](https://arxiv.org/abs/2401.12975)

- HAZARD-benchmark made of three dynamic challenges for an embodied agents: flood, fire and wind, which  performance are evaluated in terms of value, steps and damage.
- Builds LLM-based pipeline for embodied agents by providing it task description, agent status and target info. Agent reads environment information, includes observation memory and LLM-based decision maker to select the next action.


---


#### 22th of January 2024


[Memory Matters: The Need to Improve Long-Term Memory in LLM-Agents](https://ojs.aaai.org/index.php/AAAI-SS/article/view/27688)

- Reviews memory management of LLM-agents with useful insights about using different types meta-data in vector db along the word embeddings as long-term memory.
- Identifies in past research example ways of storing: thoughts/skills in vector db, but as well gaps in retrieving information, when different memories may contradict the retrieval. 


---

[OK-Robot: What Really Matters in Integrating Open-Knowledge Models for Robotics](https://arxiv.org/abs/2401.12202)

- OK-robot (Open-Knowledge): 59% success rate in open ended picking and dropping task.
- SOTA level in OVMM-benchmark.

---

[WARM: On the Benefits of Weight Averaged Reward Models](https://arxiv.org/abs/2401.12187)

- Weight Averaged Reward Models (WARM) models.


---

[PsySafe: A Comprehensive Framework for Psychological-based Attack, Defense, and Evaluation of Multi-agent System Safety](https://arxiv.org/abs/2401.11880)

- PySafe: Safety research on LLM agents based on behavioural/psychological-characteristics.


---


#### 21st of January 2024

[AttentionLego: An Open-Source Building Block For Spatially-Scalable Large Language Model Accelerator With Processing-In-Memory Technology](https://arxiv.org/abs/2401.11459)

- AttentionLego: LLM is implemented on Processing-In Memory (PIM) HW.


---

[The Conversation is the Command: Interacting with Real-World Autonomous Robot Through Natural Language](https://arxiv.org/abs/2401.11838) 

- Simplistic robotic control using VLM and LLM: VLM to object textual description and scene comprehension. LLM for reasoning and REM-node to translate commands into robot actions.


---


#### 19th of January 2024

[Tool-LMM: A Large Multi-Modal Model for Tool Agent Learning](https://arxiv.org/abs/2401.10727)

- Tool-LMM: LLM is agent able to process multimodal inputs into APIs of the specific modalities.
- Input modalities include, text, audio/text, text/video and text/image. The LLM text output includes recommendation of the API to be used and model information.


---

[A match made in consistency heaven: when large language models meet evolutionary algorithms](https://arxiv.org/abs/2401.10510)

- Compares and finds multiple similarities between GPT-LLMs and Genetic Algorithm (GA)-evolutionary algorithms.


---

[CivRealm: A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents](https://arxiv.org/abs/2401.10568)

- CivicRealm: RL agent generalization benchmark, based on video game environment with various players and dynamic game space, imperfect information and random variability.


---


#### 18th of January 2024

[Self-Rewarding Language Models](https://arxiv.org/abs/2401.10020)

- Self-rewarding LLMs: Ability for LLM to follow instructions and Ability to create/evaluate new training data (Self-Instruction creation).
- LLLm-as-a-Judge: LLM acts as a reward model and self-reward its own responses.
- Claims to outperform Claude 2/Gemini Pro/GPT-4 0613 with three iterations and ability to keep continuously improving both self-instructions and the reward signal.


---

[R-Judge: Benchmarking Safety Risk Awareness for LLM Agents](https://arxiv.org/abs/2401.10019)

- R-Judge: Safety benchmark for LLM-agents, not LLM models on 27 risk scenarios.


--- 


#### 17th of January 2024

[Large Language Models Are Neurosymbolic Reasoners](https://arxiv.org/abs/2401.09334)

- LLM agent plays text-based game with access to Symbolic module.


---

[ReFT: Reasoning with Reinforced Fine-Tuning](https://arxiv.org/abs/2401.08967)

- Reinforced Fine-Tuning (ReFT): In the initial SFT-step, the model is trained to produce correct answers to mathematical problems.
- In the second step, online RL with PPO is used to prompt multiple CoT responses to learn from them.
- ReFT uses majority voting and reward model reranking. 


---

[Scalable Pre-training of Large Autoregressive Image Models](https://arxiv.org/abs/2401.08541)

- AIM: Visual models, which scale with both compute and data introduced.

---

[What makes for a 'good' social actor? Using respect as a lens to evaluate interactions with language agents](https://arxiv.org/abs/2401.09082)

- LLM agent as as social (automated) actor.
- Identifies what makes a good vs negative social behaviour for LLM agents.


---


#### 16th of January 2024

[Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering](https://arxiv.org/abs/2401.08500)


- AlphaCodium: Improves code solutions through AI code tests.
- Iteratively reasons about code tests and reflects problem, generates AI tests to improve testing.
- Two phases: Preprocessing (to reason new AI tests from ranked solutions feom public tests) and Code iteration (with public and AI tests).


---

[MultiPLY: A Multisensory Object-Centric Embodied Large Language Model in 3D World](https://arxiv.org/abs/2401.08577)

- MultiPLY: Multisensory (temperature, tactile, audio and visuals) embodied agent acts (action tokens such as navigate/select/touch/observe/look around/) in 3D virtual environment.
- The model trained with ultisensory Universe-dataset, performs multiple tasks: navigates, manipulates, uses tools, dialogue,
- Encodes 3D-scenes as object centric representations, generate action token to be taken from current state token (temperature/tactile/sound/object) within the environment to reach new state observation in time. The new state token is fed back to LLM to drive follow up actions.


---

[DoraemonGPT: Toward Understanding Dynamic Scenes with Large Language Models](https://arxiv.org/abs/2401.08392)

- DoramonGPT includes task-related symbolic memory, sub-task/knowledge tools and MCTS planner.
- The task related symbolic memory will choose either the Spatial or Time-dimension as most relevant based on the LLM.   
- DoramonGPT collecta information before reasoning, reasons spatial-temporal video, explores different solutions in a large planning space.


---

[Self-Imagine: Effective Unimodal Reasoning with Multimodal Models using Self-Imagination](https://arxiv.org/abs/2401.08025)

- Self-Imagine: VLM creates HTML code about the text question, renders it as an image and uses the image with the question to answer the question with the VLM.


---

[Application of LLM Agents in Recruitment: A Novel Framework for Resume Screening](https://arxiv.org/abs/2401.08315)

- Automated resume screening, where segments from CV are classified into information types, personal information is removed. T
- The HR grading LLM agent rates these resumes and another HR decision making agent picks preferred application with eplanation, which is then available for the HR professional.


---

[Contrastive Preference Optimization: Pushing the Boundaries of LLM Performance in Machine Translation](https://arxiv.org/abs/2401.08417)

- Contrastive Preference Optimization (CPO): A potential improvement to DPO, applied in machine translation.


---


#### 15th of January 2024

[Exploring the Potential of Large Language Models in Self-adaptive Systems](https://arxiv.org/abs/2401.07534)

- Literature review of Self-Adaptive Systems with LLMs.


---

[A Study on Training and Developing Large Language Models for Behavior Tree Generation](https://arxiv.org/abs/2401.08089)

- LLMs used to generate Behavioural Trees (BT) generation for agents/robots.


---

[When Large Language Model Agents Meet 6G Networks: Perception, Grounding, and Alignment](https://arxiv.org/abs/2401.07764)

-  Least Age-of-Thought (LAoT) model caching algorithm to manage local/global compute/network traffic to avoid model with least valuable thoughts. 


---


#### 14th of January 2024

[CodeAgent: Enhancing Code Generation with Tool-Integrated Agent Systems for Real-World Repo-level Coding Challenges](https://arxiv.org/abs/2401.07339)

- Introduces CodeAgent, a LLM agent able to use tools (search, code navigation and code interpreter) to generate code/create repositories (instructions, code dependencies) better than Github Copilot.
- Introduces CodeAgentBench-dataset.
- Code symbol navigation is key component, to explore: file/module-based parsing and class/function-symbol navigation. 


---

[Small LLMs Are Weak Tool Learners: A Multi-LLM Agent](https://arxiv.org/abs/2401.07324)

-  α-UMi:  Multi-agent LLM, which includes planner/caller and summarizer and tools.


---


#### 12th of January 2024

[ModaVerse: Efficiently Transforming Modalities with LLMs](https://arxiv.org/abs/2401.06395)

- ModaVerse: Introduces Adaptor+Agent framework for training multi-modal LLM able to process content across audio/video/image modalities.
- Introduces Input/Output (I/O) Alignment: LLM generates language aligned meta-responses, which are instructions to activate specific generative models.
- This method is capable of converting variety of modalities, while being very efficient to train.


---

[AntEval: Quantitatively Evaluating Informativeness and Expressiveness of Agent Social Interactions](https://arxiv.org/abs/2401.06509)

- AntEval: a framework to evaluate LLM-agents social interactions with two metrics: Information Exchange Precision and Intention Expresiveness Gap.


---

[Mutual Enhancement of Large Language and Reinforcement Learning Models through Bi-Directional Feedback Mechanisms: A Case Study](https://arxiv.org/abs/2401.06603)

- Investigates bi-directional feedback loop, where LLM agent acts as a teacher, while the RL agent acts as a student.


---

#### 11th of January 2024

[EASYTOOL: Enhancing LLM-based Agents with Concise Tool Instruction](https://arxiv.org/abs/2401.06201)

- EASYTOOL: Creates a cleaned version of any tool/API documentation for LLM agent to use via single "tool instruction".
- Tool documentation is translated into: tool descriptions and tool core functionality. Each are created using specific LLM instructions.
- Significantly improves tool-based LLM agent performance. 


---

[Designing Heterogeneous LLM Agents for Financial Sentiment Analysis](https://arxiv.org/abs/2401.05799)

- Heterogenoeus multi-Agent Discussion (HAD): Multiple agents with each instructions to pay attention to error category types, which form the resulting answer based on shared disussion. The domain of the research is Financial Sentiment Analysis.
- Builds on the conclusion, that LLMs are "resources": similar to Minsky's theory about human mind being built from a [Resource-cloud](#resourcecloud) to be activated/deactivated on the spot.
- Defines  Kernel Theory-Based Design: Kernel theory, Meta-requirements, Meta-designs, Testable hypothesis. 


---

[Evidence to Generate (E2G): A Single-agent Two-step Prompting for Context Grounded and Retrieval Augmented Reasoning](https://arxiv.org/abs/2401.05787)

- Evidence-to-Generation (E2G): Single LLM produces in two-steps answer step-by-step based on evidence from the context/question provided.
- E2G represents context-aware reasoning.


---


#### 10th of January 2024

[Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training](https://arxiv.org/abs/2401.05566)

- Adds backdoors on LLMs.
- Trains deceptive LLMs using data, which "acts" based on being either in training vs inference: demonstrates safe code vs unsafe code.


---

[Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security](https://arxiv.org/abs/2401.05459)

- Reviews systematically "Personal LLM Agents" connected to personal data and devices for personal use.


---


[The Impact of Reasoning Step Length on Large Language Models](https://arxiv.org/abs/2401.04925)

- Adding reasoning steps improvea accuracy unril 5th step.


---

[InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks](https://arxiv.org/abs/2401.05507)

- DABench-benchmark for LLM based data analysis and open sources Data analysis agent : DA Agent.


---


#### 9th of January 2024

[Agent Alignment in Evolving Social Norms](https://arxiv.org/abs/2401.04620)

- EvolutionaryAgent: Evaluates LLM agents based on fitness to social norms using observer LLM within EvolvingSociety-environment.
- LLM agents producing highest social norm ratings, self-envolve and reproduce into new generation LLM agents. Agents either convert into obsolate or survived.
- Agents events are recorded within short term memory with a threshold, which defines when long term and higher-level memories are distilled.
- Defines initial stage of the EnvolvingSociety and the desired direction only.


---

[Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects](https://arxiv.org/abs/2401.03428)

- Reviews LLM Intelligent agents: definitions, frameworks, single/multiple agents, compoments, cognitive features etc.

---

[Metacognition is all you need? Using Introspection in Generative Agents to Improve Goal-directed Behavior](https://arxiv.org/abs/2401.10910)

-  Adds a metacognition to LLM agents for emulating System 1 and System 2 processes. The idea is to let LLMs "think about thinking".
-  The Metacognition module (knowledge about itself, the task and the strategies) gets triggered to ask reflective questions, when the LLM agent is not making significant progress.
-  The metacognition is used throughout the planning, evaluation, monitoring and cognition-steps using reflective questions and then stored in the meta-memory used.


---

<div id="agentbasedai"> </div>  


#### 7th of January 2024

[Agent AI: Surveying the Horizons of Multimodal Interaction](https://arxiv.org/abs/2401.03568)

- Agent AI system: Perceives and acts in different domains and applications.
- Multi-modal generalist agent: Environment and Perception with task-planning and skill observation, Agent learning, Memory, Agent action; Cognition.


--- 


### 4th of January 2024

[LLaVA-ϕ: Efficient Multi-Modal Assistant with Small Language Model](https://arxiv.org/abs/2401.02330)

- LLava-Phi: VLM using Phi-2 as LLM model with CLIP-ViT-L/14 with 336x336 visual encoder.


---

[Self-Contrast: Better Reflection Through Inconsistent Solving Perspectives](https://arxiv.org/abs/2401.02009)

- Self-Contrast: Explores potential paths, Contrasts differences and Summarizes them into checklist to better reason.
- Many LLM agent errors are due to inconsistent feedback.


---

[INTERS: Unlocking the Power of Large Language Models in Search with Instruction Tuning](https://arxiv.org/abs/2401.06532)

- Technique to tune LLM for "search": INstruction Tuning datasEt foR Search (INTERS).

---


#### 3rd of January 2024

[Act as You Learn: Adaptive Decision-Making in Non-Stationary Markov Decision Processes](https://arxiv.org/abs/2401.01841)

- Adaptive MCTS (Ada-MCTS): explores using epistemic & aleatoric uncertanties to adapt risk-aversion behaviour vs performance when spending more time in the environment.


---

[Economics Arena for Large Language Models](https://arxiv.org/abs/2401.01735)

- EconArena: Reviews multiple LLM models jn their ability to act rationally by comparing performance between models and against Nash Equilibrium (NE) rationality.
- Better models act more rational. LLMs are dynamically able to change strategies based on opponent strategy. Game history improves reasoning. Competing with rational opponent helps to achieve NE quicker.


---


#### 2nd of January 2024

[LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning](https://arxiv.org/abs/2401.01325)

- LLMs have built-in capability to manage long context, similar as children manage long context such as books mainly by having seen short context text.
- Self-Extend: No specific training / finetuning required. Plug in 4 lines of code during inference to the attention mechanism, based on LLM with RoPE and FLOOR-operation.


---

<div id="spin"> </div>  

[Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models](https://arxiv.org/abs/2401.01335)

- Self-Play fIne-tuNing (SPIN): Fine-tuning LLMs based on Self-play mechanism, where the main player is the to-be learned LLM from the current iteration and its opponent is the same LLM from the previous iteration.



#### 22th of December 2023

[Pangu-Agent: A Fine-Tunable Generalist Agent with Structured Reasoning](https://arxiv.org/abs/2312.14878)

- Pangu-Agent: Introduces a generic RL-based objective to improve agents intrinsic and extrinsic functions. 

---


#### 21st of December 2023

[AppAgent: Multimodal Agents as Smartphone Users](https://arxiv.org/abs/2312.13771)

- Multimodal VLM agents learn operate popular smartphone apps by creating a knowledge base through: Autonomous exploration and Human demonstrations.
- Includes: Exploration phase and Deployment phase.
- Exploration phase learns smartphone functionalities through trial and error, which are saves records of effects to actions and stops, if the current view is unrelated to the assigned task. Exploration stops, whene task is finished. Alternatively these behaviours are shown through human demonstrations, which keeps the agent exploration streamlined and efficient.
- In deployment phase, the VLM agent has access to the UI screenshot and potential actions. The agent generates a summary of the actions taken and interaction history, which are passed to the next step.


---

[Capture the Flag: Uncovering Data Insights with Large Language Models](https://arxiv.org/abs/2312.13876)

- Exlores two types of Data Science Agents: Explorer agent and Aggregator agent 


---


#### 20th of December 2023

[AgentCoder: Multi-Agent-based Code Generation with Iterative Testing and Optimisation](https://arxiv.org/abs/2312.13010)

- AgentCoder:  Multi-Agent Assistant Code Generation made from Programmer Agent, Test designer Agent and Test executor Agent
- Uses Self-Refine with CoT in a Multi-Agent System.


---

[DSPy Assertions: Computational Constraints for Self-Refining Language Model Pipelines](https://arxiv.org/abs/2312.13382)

- LM Assertions: Integrates with [DSPy](https://github.com/stanfordnlp/dspy), which integrates reasoning, self-improvement, augmentation, retrieval and tools (DSPy is like challenger for Langchain).
- To help runtime self-refinement in LM pipelines with boolean type conditions: Assert (hard or critical condition) and Suggest (soft condition).
- For example a critical condition (hard) is such, that will resul the LM pipeline to halt, if the condition is not met with maximum number of attempts, while Suggest-option still lets the pipeline to continue. 


---

[ASSISTGUI: Task-Oriented Desktop Graphical User Interface Automation](https://arxiv.org/abs/2312.13108)

- ASSISTGUI: Window mouse / keyboard management with LLM.


---

[Generative agents in the streets: Exploring the use of Large Language Models (LLMs) in collecting urban perceptions](https://arxiv.org/abs/2312.13126)

- Explores generative agents in urban environments: includes memory modyke, movement module, visual inference module and a LLM module


---

[dIR -- Discrete Information Retrieval: Conversational Search over Unstructured (and Structured) Data with Large Language Models](https://arxiv.org/abs/2312.13264)

- Discrete Information Retrieval (dIR): Text-queries of SQL databases using LLMs.


---


#### 19th of December 2023

[Large Language Models Play StarCraft II: Benchmarks and A Chain of Summarization Approach](https://arxiv.org/abs/2312.11865)

- Plays Starcraft 2 better than an average player by using Chain of Summarization (CoS), python-sc2 and TextStarCraft II-environment (Observation-to-Text Adapter: and Text-to-Action Adapter).
- Chain of Summarization (CoS): Improves LLMs capability to extract / analyze information using two compnents: Single-frame summarization and Multi-frame summarization.
- TextStarCraft II-environment processes game information into textual format for LLM model defining macro-actions and a rule-based method for micro-actions
- System prompt includes: Situation Overview, Situation Analysis, Strategic Planning, Opponent Strategy, Analysis, Strategic Recommendations, Decision-Making rocess.
- Reduces 10x the need of LLM API calls and improves strategic, analytical and judging capabilities. 


---

#### 19th of December 2023

[Large Language Models Empowered Agent-based Modeling and Simulation: A Survey and Perspectives](https://arxiv.org/abs/2312.11970)

- LLM empowered agent-based modeling and simulation framework: surveys the landscape of utilizing LLMs in agent-based modeling and simulation.
- Framework examines challenges, future directions, motivation for applying LLMs, environment perception, human alignment, action generation, evaluation, cyber, physical, social, and hybrid domains.
- This framework provides a comprehensive overview of recent works in this interdisciplinary field.


---


<div id="humancap"> </div>  

[Large Language Models Empowered Agent-based Modeling and Simulation: A Survey and Perspectives](https://arxiv.org/abs/2312.11970)

- Reviews LLM-based agents on their ability to simulate various human-like capabilities.


---


#### 18th of December 2023

[Agent Assessment of Others Through the Lens of Self](https://arxiv.org/abs/2312.11357)

- Discusses concept of Self-Awareness of Autonomous Agents.


---

[Evaluating Language-Model Agents on Realistic Autonomous Tasks](https://arxiv.org/abs/2312.11671)

- Autonomous Replication and Adaption (ARA) framework: reviews ability of LLM agents to acquire resources, create copies of themselves and adapt to novel situations in the real world.
- Tests LLM-agents using Scaffolding programs to interact with LLMs.
- Defines implications of potentially ARA-level agents.

---

[LLM-ARK: Knowledge Graph Reasoning Using Large Language Models via Deep Reinforcement Learning](https://arxiv.org/abs/2312.11282)

- LLM-ARK: LLM reasons from Knowledge Graphs with DRL.

---

#### 17th of December 2023

[Learning to Act without Actions](https://arxiv.org/abs/2312.10812)

- LAPO (Latent Action Policy).


---

#### 16th of December 2023

[ProTIP: Progressive Tool Retrieval Improves Planning](https://arxiv.org/abs/2312.10332)

- Progressive Tool Retrieval Improves Planning (ProTIP): Mulit-step planning with external tools, where tasks are decomposed without explicit definition of the sub-task.
- Addresses the issue, where single-step tool retrieval does not manage to handle dependencies between the tools.


---

<div id="restreact"> </div>  


#### 15th of December 2023

[ReST meets ReAct: Self-Improvement for Multi-Step Reasoning LLM Agent](https://arxiv.org/abs/2312.10003)

- Self-Imepoving LLM model without any human-assisted data for fine tuning achieving significantly better reasoning results with smaller model, when using the synthetic data to distill smaller model.
- Finetunes LLM with ReST using ReAct-method reasoning-actions.


---

<div id="agenticaisystem"> </div>  


#### 14th od December 2023

[Practices for Governing Agentic AI Systems](https://cdn.openai.com/papers/practices-for-governing-agentic-ai-systems.pdf)

- OpenAI's research on Agentic AI systems with definition of Agentic AI system.
- Includes level of "Agenticness":  the degree of goal complexity, environment complexity, adaptability and independence.

---

[TinyGSM: achieving >80% on GSM8k with small language models](https://arxiv.org/abs/2312.09241)

- First student LLM to learn the Teacher LLM model ( GPT-3.5) performance in mathematical reasoning using synthetic data from the teacher model.  
- TinyGSM: Two 1.3B LLNs with a 1.3B verifier LLM achieves SOTA level 81.5% accuracy on GSM8k, which consists of a high-quality dataset TinyGSM and use of verifier selecting final answer from multiple output generations.


---

[Modeling Complex Mathematical Reasoning via Large Language Model based MathAgent](https://arxiv.org/abs/2312.08926)

-  Planner-Reasoner-Executor-Reflector (PRER) / MathAgent: Planner, Reasoner, Executor and Reflector.
-  Systematic process for solving zero-shot mathematical reasoning with LLM agents.


---

[Rational Sensibility: LLM Enhanced Empathetic Response Generation Guided by Self-presentation Theory](https://arxiv.org/abs/2312.08702)

- Self-Representation with Lamb:  Uses semantic label to set tone for the conversation.


---

[LiFT: Unsupervised Reinforcement Learning with Foundation Models as Teachers](https://arxiv.org/abs/2312.08958)

- LiFT: Outperforms significantly VPT/other models in MineDojo-ennvironment.
- LLM provides task instruction.
- VLM is sed to learn policy and act as a reward model.


---

[LLMind: Orchestrating AI and IoT with LLMs for Complex Task Execution](https://arxiv.org/abs/2312.09007)

- LLMind: Includes coordinator updating short-term memory/retrieving required AI (IoT) modules with ability to define, if script exists for the module and enerates it, if missing. Coordinator retrieves error / output messages from the executed script, which is handled by the script executor.


---

[Holodeck: Language Guided Generation of 3D Embodied AI Environments](https://arxiv.org/abs/2312.09067)

- HoloDeck: Generating 3d embodied environments with LLM: FLoor-wall module, doorway-window module, object selection module and layout design module.


---

[Personalized Path Recourse](https://arxiv.org/abs/2312.08724)

- Personalized Path Recourse (PPR): Personalized path of actions to achieve a certain goal with an agent.


---

[Adaptive parameter sharing for multi-agent reinforcement learning](https://arxiv.org/abs/2312.09009)

-  AdaPS: Maps agents to different regions of brain/shared network based on identity vectors obtained with VAE and clusters agents to K classes.


---

[Auto MC-Reward: Automated Dense Reward Design with Large Language Models for Minecraft](https://arxiv.org/abs/2312.09238)

- RL agent using LLM to act as a Reward designer, Reward critic and a Trajectory designer.


---

[Vision-Language Models as a Source of Rewards](https://arxiv.org/abs/2312.09187)

- VLMs work as reward models and larger scale improves performance of the reward model.


---

[Learning Coalition Structures with Games](https://arxiv.org/abs/2312.09058)

- Coalition Structure Learning (CSL): Learns coalitions of agents via set of games.


---

#### 13rd of December 2025

[KVDirect: Distributed Disaggregated LLM Inference](https://arxiv.org/abs/2501.14743)

- KVDirect: Framework optimizes KV cache transfer to enable distributed disaggregated LLM inference.
- Tensor-centric communication mechanism, custom communication library, dynamic GPU resource scheduling, pull-based KV cache transfer strategy, reduces synchronization overhead.
- KVDirect reduces per-request latency and improves resource utilization in disaggregated LLM inference.


---


#### 12th of December 2023

[Medprompt+](https://github.com/microsoft/promptbase/tree/main)

- Medprompt+ extends Medprompt-method improved by asking additionally if scrapt-pad is needed and increasing number of ensembled calls from 5 to 20.


---

[diff History for Long-Context Language Agents](https://arxiv.org/abs/2312.07540)

- Compresses consecutive text observations from environment with Unix "diff"-command, which leads to 700% improvement in game score, outperforming existing agents by 40%, which use visual observations.
- Similar approach may enable building vastly more generic embodied LLM agents.


---

[Sequential Planning in Large Partially Observable Environments guided by LLMs](https://arxiv.org/abs/2312.07368)

- Neoplanner: builds state space model of the environment by testing different actions, observations and rewards. Builds a graph memory of learnings from all previous trials using Learner agent.
- Model provides anytime best policy given the knowledge at that moment. Balances exploration and exploitation.


---


#### 11th of December 2023

[Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models](https://arxiv.org/abs/2312.06585)

- ReST<sup>EM (Expectation-Maximization)</sup>: LLM generates samples (E-step/Expectation-step) using temperature sampling, filter samples using binary feedback/reward, fine-tune LLM using these feedbacks (M-step/Maximization-step). Repeat few rounds. Improves significantly coding and math benchmark results. 
- Ability to generate multiple correct solutions compared against human-generated data.
- ReST<sup>EM</sup> uses temperature sampling (diverse/creative), compared to [STaR](#star)-method based on greedy sampling (most-likely), where the rationalization-process leads to false-positive solutions.


---


#### 8th of Decembebr 2023

[KwaiAgents: Generalized Information-seeking Agent System with Large Language Models](https://arxiv.org/abs/2312.04889)

- KwaiAgents, an autonomous agent loop including three key components: (KAgentSyst), LLMs (KAgentLLMs) and Benchmarks (KAgentsBench).
- System includes: Memorybank (Knowledge, Conversation and Task), Tool-library (Factuality-aware, Time-aware and Custom tools) used with Memory update, Task plan, Tool execution and Finish & Conclude-steps.
- LLM-component includes templates for LLs, Meta-Agent Tuning (MAT)-framework and LLM services. Benchmarks include both human and LLM-driven profiling.
- MAT includes six key components to generate prompt templates: system profile, instructions/constraints, tool specification, goal placement, memory allocation and output format. 


---


#### 7th of December 2023

[Chain of Code: Reasoning with a Language Model-Augmented Code Emulator](https://arxiv.org/abs/2312.04474)

- Creates answer in two steps: Starts by creating pseudo-code to solve the question, then runs the pseudo-code in code interpreter or LM emulating code, in case no code interpreter is available. 


---

[AVA: Towards Autonomous Visualization Agents through Visual Perception-Driven Decision-Making](https://arxiv.org/abs/2312.04494)

-  Autonomous Visualization Agents (AVAs): User instructions are converted with Visualization agent into actions and the taken actions are converted back to language within visualization tasks.
-  Components include: Visual perception, Action planning and Memory components, working within visualization-perception-action-loop.  


---

[Generating Illustrated Instructions](https://arxiv.org/abs/2312.04552)

- StackedDiffusion: Generates illustrated instructions based on text, which helps to train SOTA level multi modal models preferred over human generated articles.

---

[Fortify the Shortest Stave in Attention: Enhancing Context Awareness of Large Language Models for Effective Tool Use](https://arxiv.org/abs/2312.04455)

- Introduces "Attention Buckets", which enable a 7B open source model to acchieve GPT-4 level tool use performance by compensating attention peaks between parallel processes in specific context.


---


#### 6th of December 2023

[Generative agent-based modeling with actions grounded in physical, social, or digital space using Concordia](https://arxiv.org/abs/2312.03664)

- Concordia-library: Simulation environment made of multiple agents and Grand Master (GM) inspired by the Dungeons and Dragons game.
- Agents consume observations and GM agent actions. Agent produces actions and GM event statements (such as physical grounding). 
- Includes long and short term memory, which include state of the world.


---

[LLM as OS (llmao), Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem](https://arxiv.org/abs/2312.03815)

- AIOS-Agent Ecosystem: Envisions LLMs as OS, Agents as Applications, Natural Language as Programming language and Tools as Devices/Libraries.


---


#### 5th of December 2023


[Visual Program Distillation: Distilling Tools and Programmatic Reasoning into Vision-Language Models](https://arxiv.org/abs/2312.03052)


- Answers visual questions by creating programs, that can review the image such as count number of specific types of objects and use tools.
- Answer is provided with CoT reasoning based on filtered program from many programs executed.


---

[Beyond Isolation: Multi-Agent Synergy for Improving Knowledge Graph Constructio](https://arxiv.org/abs/2312.03022)

- Uses three LLM agents for entity, event and relation extraction to build knowledge graph.


---

[Large Knowledge Model: Perspectives and Challenges](https://arxiv.org/abs/2312.02706)

- Large Knowledge Models: Reviews combination of LLMs (neural representation) and Knowledge graphs (symbolic representation) through usage of knowledge graph embeddings and text embeddings with LLMs. 


---


#### 4th of December 2023

[Exchange-of-Thought: Enhancing Large Language Model Capabilities through Cross-Model Communication](https://arxiv.org/abs/2312.01823)

- Exchange-of-Thought (EoT): Improvement from CoT and Self-Consistency, where thoughts from other LLMs are considered, outperforming in mathematical reasoning the CoT with Self-Consistency
- Proposes four communication paradigms to define the setup of the Exchange-of-Thought: Memory, Report, Relay and Debate. 
- For example in Debate-mode: two LLM agents produce first ansswer the question and the two rationalizations are provided to the third LLM agent in order to debate these solutions in order to provide the right answer.


---

[LLM A*: Human in the Loop Large Language Models Enabled A* Search for Robotics](https://arxiv.org/abs/2312.01797)

-  LLM A*: Includes current node, goal node, optical action and these three make up the plan.
-  The chat-environment with user defines user inputs: Setting up environment, Setting up Action model, Start and Target Nodes, Heuristic and Rules.
-  Demonstrates the possibility of achieving very good path planning results using mobile embodied agents.


---

[Towards Learning a Generalist Model for Embodied Navigation](https://arxiv.org/abs/2312.02010)

- NaviLLM: Embodied navigation with LLMs using schema-based instruction (task, history, observation and output hint), which generalizes well to unseen navigation tasks.
- Uses the following Multi-task learning modules: Visual-Language Navigation, Object localization, Trajectory Summarization and 3D Queestion Summarization.


---

[OpenVoice: Versatile Instant Voice Cloning](https://arxiv.org/abs/2312.01479)

- OpenVoice: Voice cloning almost from instant voice record.


---


#### 29th of Novemebr 2023

[Universal Self-Consistency for Large Language Model Generation](https://arxiv.org/abs/2311.17311)

- Universal Self-Consistency (USC): Uses LLMs to select the most consistent answer among multiple candidates working in mathematical reasoning and code generation and unlike the original Self-Consistency, the method works in open-ended questions.
- This can be used as a more capabale component in the [STaR-method](#star), which generalizes with Q&A with open-ended answers, not only precise answers.


---


#### 28th of Novemebr 2023

[Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine](https://arxiv.org/abs/2311.16452)

- Medprompt: Generalist LLM using MedPrompt outperforms SOTA specialist model.
- Uses SOTA prompt method: CoT, Choice Shuffle and Self-Consistency prompting
- Introduces Choice Shuffle-technique, which inreases diversity of the reasoning paths.
  

---


#### 27th of Novemeber 2023 

<div id="extreme"></div>

[Some intuitions about large language models](https://docs.google.com/presentation/d/1hQUd3pF8_2Gr2Obc89LKjmHL0DlH-uof9M0yFVd3FA4/edit) 

- Jason Wei Blog post / Presentation.
- Learning the relationship from Input to Output is as well Next-word prediction learning.
- Next-word prediction is massively multi-task learning.


---


#### 22th of November 2023

[Building the Future of Responsible AI: A Pattern-Oriented Reference Architecture for Designing Large Language Model based Agents](https://arxiv.org/abs/2311.13148)

- Identifies two types of LLM agents: "Agents-as-workers" and "Agents-as-coordinators".

  
---


#### 21st of November 2023

[System 2 Attention (is something you might need too)](https://arxiv.org/abs/2311.11829)

- System 2 Attention (S2A): Generate interim user question and interim context from the original user input. Finally, generate the final answer by answering to the interim user question from the interim context. 
- Reduces hallucination from irrelevant context by first defining the question and the context and this way separating irrelevant facts from impacting the response generation.


---


#### 20th of November 2023

[Igniting Language Intelligence: The Hitchhiker's Guide From Chain-of-Thought Reasoning to Language Agents](https://arxiv.org/abs/2311.11797)

- Systematic review of research from Chain-of-Thought (CoT) to LLM Agents and identifies gaps in generalization, redundant interactions and customization and more. 


---


#### 17th of November 2023

[A Language Agent for Autonomous Driving](https://arxiv.org/abs/2311.10813)

- Agent-Driver: Uses LLM agent for human-like intelligence for autonomous driving.
- Tool library provides input for: detection, prediction, occupancy and mapping functions. Memory includes commonsense memory and Experience memory. There is apart historical trajectories and ego-states.
- The reasoning engine includes: CoT reasoning, Task planning, Motion planning and Self-Reflection. These lead to actions and again to environment update. 


---


#### 16th of November 2023

[Digital Socrates: Evaluating LLMs through explanation critiques](https://arxiv.org/abs/2311.09613)

- Digital Socrates: evaluates reasoning flaws: giving feedback on why and where? 


---


#### 15th of November 2023

[Divergences between Language Models and Human Brains](https://arxiv.org/abs/2311.09308)

- Reviews differences measured with MEG in human brain vs. language models.
- The study reveeals, that LLMs are less good at social/emotional intelligence and physical commonsense reasoning.
- Finetuning helps to align LLMs to act more in human brain-like manner. 

---

[AutoMix: Automatically Mixing Language Models](https://arxiv.org/abs/2310.12963)

- AutoMix: Use a smaller LLM to generate initial response and uses Meta-Verifier to check the trustworthy in rough scale. If the answer is trustworthy then use the small LLM answer, otherwise consult a larger LLM.
- Uses Incremental Benefit Per Unit Cost (IBC) metric to asses effectiveness of this approach.


---


#### 14th of November 2023

[DeepThought: An Architecture for Autonomous Self-motivated Systems](https://arxiv.org/abs/2311.08547)

- DeepThought: An architecture for cognitive language agents posing agency, self-motivation, and partly meta-cognition.
- Includes supervisor module, Deep Reinforcement Learning module, Attention Schema (long-term memory), Language/Auditory/Vision modules and Embedding store.


---


#### 9th of November 2023

[LLM Augmented Hierarchical Agents](https://arxiv.org/abs/2311.05596)

- Hierchical agent uses LLM to evaluate, when to use specific skill to complete specific sub-level task with long horizon.
- The resulting model works without the need for a LLM after the training.


---

[Prompt Engineering a Prompt Engineer](https://arxiv.org/abs/2311.05661)

- Guide LLM to prompt engineer prompts automatically
- The metaprompt uses: prompt engineering tutorial, two-step task description, step-by-step reasoning template and context specification.


---


#### 8th of November 2023

[ADaPT: As-Needed Decomposition and Planning with Language Models](https://arxiv.org/abs/2311.05772)

- ADaPT: Plans and decomposes dynamically complex tasks with LLMs, if the executor is not able to complete the task.


---


#### 2nd of November 2023

[RoboGen: Towards Unleashing Infinite Data for Automated Robot Learning via Generative Simulation](https://arxiv.org/abs/2311.01455)

- RoboGen: Agent using LLMs to define new tasks to learn, create their simulation environments, train on them to acquire diverse & new skills.
- Agent includes: Task proposal, Scene generation, Training Supervision Generation & Skill learning.


---

<div id="stopvideo"></div>

[Youtube. Adam Kalai presents "Recursive Self-improving Code Generation - talk 2.11.2023](https://www.youtube.com/watch?v=RovcBFlfXpQ)

- Adam Kalai talk on the "Self-Taught Optimizers (STOP): Recursively Self-Improving code generation", which is in essence attempts to build code for letting LLMs themselves improve (their) own code.
- I recommend to check this especially from safety-aspects on the point "sandbox-flag" and to better understand the 

---


#### 1st of November 2023

[Plug-and-Play Policy Planner for Large Language Model Powered Dialogue Agents](https://arxiv.org/abs/2311.00262)

- Introduces plug-and-play dialogue policy planner(PPDPP).
- Dialogues plans using Self-play with three LLM agents: one acting to achieve a goal like buying a product at cheaper price, second to negotiate as seller a higher price and a third LLM scoring performance as reward model.


---

[SAGE: Smart home Agent with Grounded Execution](https://arxiv.org/abs/2311.00772)

- SAGE (Smart home Agent with Grounded Execution).
- Device interaction: Interaction planner, Attribute retriever, API documentation retriever, Device disambiguity, Device command execution.
- Personalization: Long-term memory, User profile & Personalization tool.
- Includes Physical grounding such as light bulbs and External grounding (such as weather forecast) & Personalization.


---

[Efficient Human-AI Coordination via Preparatory Language-based Convention](https://arxiv.org/abs/2311.00416)

- HAPLAN: Human-AI coordination using Conventions. Humans communicate roles & tasksof individuals before starting a task to be completed. Humans create Conventions.
- Builds a Convention (an action-plan) to guide AI/human using task requirements, human preferences, number of agents and other information for a better understanding of tasks & responsibilities of each agent/human.
- Assigns sub-problems to own sessions. Convention is first confirmed with human.


---


#### 31st of October 2023

[Generating Sequences by Learning to Self-Correct](https://arxiv.org/abs/2211.00053)

- Self-Correction: A generative LLM, which includes two modules: Generator and Corrector. 


---

[Autonomous Robotic Reinforcement Learning with Asynchronous Human Feedback](https://arxiv.org/abs/2310.20608)

- Autonomously explores real world
- Guided Expliration for Autonomous Reinforcement learning (GEAR): approaches objective by meeting promising sub-goal close to final target (Goal Selector), but reachable from current position using current policy (Density model).
- Crowdsourced & Occasional comparative feedback regards user objective vs. available correct/incorrect states.


---

[Towards A Natural Language Interface for Flexible Multi-Agent Task Assignment](https://arxiv.org/abs/2311.00153)

- Programs constraints into task assignments system based on natural language using Multi-agent LLMs.


---

[Leveraging Word Guessing Games to Assess the Intelligence of Large Language Models](https://arxiv.org/abs/2310.20499)

- DEEP: Uses agressive (truthfull) & conservative modes (to disguise) to play spy game to asses intelligence of LLMs to describe target word without stating explicitly the word.


---

[Multi-Agent Consensus Seeking via Large Language Models](https://arxiv.org/abs/2310.20151)

- Consensus within multi-agent reason mainly reason and change their numerical value state based on consensus strategy based on average strategy.


---

#### 26th of October 2023

[CompeteAI: Understanding the Competition Behaviors in Large Language Model-based Agents](https://arxiv.org/abs/2310.17512)

- Studies competition of LLM agents and identifies research on competition of LLM agents, as important as co-operation.
- The initial advantage of a LLM agent leads to feedback creating cycle for Matthew's effect.
- LLM Agents can operate in competitive environment. 
- LLM Agents learn to imitate and differentiate with other LLM agents. 


---

#### 25th of October 2023

[PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization](https://arxiv.org/abs/2310.16427)

- PromptAgent: Optimizes prompts using planning algorithms such as MCTS.
- Creates intermediate prompts, updates them based on error feedback, simulates future rewards and searches higher reward paths.
- Prompts generated include: Domain knowledge, Task description, Term clarification, Solution Guidance,Exception handling, Priority & Emphasis, Formatting


---

#### 24th of October 2023

[RCAgent: Cloud Root Cause Analysis by Autonomous Agents with Tool-Augmented Large Language Models](https://arxiv.org/abs/2310.16340)

- Key-value store for observation retrieval, parsed actions are executed by RCAgent or by Expert Agent.


---

[Diverse Conventions for Human-AI Collaboration](https://arxiv.org/abs/2310.15414)

- Mixed-play: generates diverse conventions (arbitrary solutions to reocurring cooperation problems) by randomly switching between self-play (maximize award) and cross-play (Minimize) actions to maxime mixed-play.
- CoMeDi (Cross-play optimized, Mixed-play enforced Diversity) algorithm is explained [](https://www.youtube.com/watch?time_continue=30&v=wm4f0sdKIUA&embeds_referring_euri=https%3A%2F%2Filiad.stanford.edu%2F&source_ve_path=MzY4NDIsMjg2NjY&feature=emb_logo).


---

[Woodpecker: Hallucination Correction for Multimodal Large Language Models](https://arxiv.org/abs/2310.16045)

- Woodpecker: To extract key concepts, formulate questions and validate visual knowledge and generate visual claims using Multimodal Large Language Models (MLLMs) to control hallucinations in LLM responses.


---

[In-Context Learning Creates Task Vectors](https://arxiv.org/abs/2310.15916)

- Training data used with LLMs is compressed into task vectors within LLM. Task vectors are used in 18 tasks.


---

[Instruct and Extract: Instruction Tuning for On-Demand Information Extraction](https://arxiv.org/abs/2310.16040)

- On Demand Information Extraction (ODIE): Extracting information using LLMs from text to present it in structured tabular format.


---


#### 23th of October 2023

---

[Function Vectors in Large Language Models](https://arxiv.org/abs/2310.15213)

- LLMs include Function Vectors (FCs) to trigger functions in different contexts.


---

[LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay](https://arxiv.org/abs/2310.14985)

- Explores social behaviour or LLMs in Avalon-game regards team working and other collaboration.
  

---


#### 20th of October 2023

<div id="toolchain"></div>

[ToolChain*: Efficient Action Space Navigation in Large Language Models with A* Search](https://arxiv.org/abs/2310.13227)

- ToolChain*: Uses A ∗ search algorithm to navigate an action space as a tree-like structure with LLM agent.
- Selects most promising path, Expand follow up actions in the selected path, Update the tree-structure.


--- 

[Democratizing Reasoning Ability: Tailored Learning from Large Language Model](https://arxiv.org/abs/2310.13332)

- Student LM takes an “exam” to gather mistakes it made. Teacher LM generates training data based on the mistakes. Teacher LM customizes each "exam" the feedback. Student LM learns to improve with self-reflection on its mistakes made and the new training data provided by the teacher LM. These steps are repeated until Student LM has reacher Teacher LM capability.


---


#### 19th of October 2023

[AgentTuning: Enabling Generalized Agent Abilities for LLMs](https://arxiv.org/abs/2310.12823)

- AgentTuning: Improves LLM capability by Instruction Tuning to user tasks by using AgentInstruct-dataset to create AgentLM using AgentTuning.


---


#### 18th of October 2023

[Language Agents for Detecting Implicit Stereotypes in Text-to-image Models at Scale](https://arxiv.org/abs/2310.11778)

- Language agent to automatically identify ans quantify extent of generated images.
- Planning and Reasoning. Tool usage: Intent understanding, Instruction generation, Instruction retrieval, Prompt optimization & Stereotype score generation.

---


#### 17th of October 2023

[Set-of-Mark Prompting Unleashes Extraordinary Visual Grounding in GPT-4V](https://arxiv.org/abs/2310.11441)

- Set-of-Mark (SoM)-visual prompting technique to answer questions by partioning image into regions with different level of granularity and insert numbers for each region.
- Studies VLM model prompting techniques. 



---

[The next grand challenge for AI](https://www.ted.com/talks/jim_fan_the_next_grand_challenge_for_ai/transcript)

- Foundational Agent: Agents, which scale in all three axis of: skills, embodiment and realities.  If chatgpt was scaled with data, foundational agents are scaled with realities.


---


#### 16th of October 2023

[Character-LLM: A Trainable Agent for Role-Playing](https://arxiv.org/abs/2310.10158)

- Character-LLM: simulates historical figures using LLMs, which mimick profile / experiences and emotional states of specific individuals.
- Applies "Experience Reconstruction" with detailed experiences and memories.
- Specialises a base model for character generation.
- Evaluates using step-by-step LLM-judge aproach by evaluating one dimension at each step.

---

[OpenAgents: An Open Platform for Language Agents in the Wild](https://arxiv.org/abs/2310.10634)

- OpenAgents-platform: Data agent, Plugin/Tools and Web agent
- Automatic tool selection from over 200 tools


---

[Improving Large Language Model Fine-tuning for Solving Math Problems](https://arxiv.org/abs/2310.10047)

- Introduces multi-task sequential fine-tuning method, where solution generation is improved by including solution evaluation as part of the fine-tuning objective together with the generated solution to provide higher-quality guidance to solution generator.
- Quality and style of the step-by-step solutions used for fine-tuning impact model performance. Solution re-ranking and Majority voting used together are effective way to improve model performance with fine-tuning.


---

[CLIN: A Continually Learning Language Agent for Rapid Task Adaptation and Generalization](https://arxiv.org/abs/2310.10134)

- A Continually Learning Generative Agent from Interactions (CLIN): Memory generator updates memory, Controller manages tasks and Executor converts it into actions towards the goal. 

---

[Theory of Mind for Multi-Agent Collaboration via Large Language Models](https://arxiv.org/abs/2310.10701)

- LLM-based agent manages complex multi-agent collaboration task with performance level comparable with RL agent. 


---

#### 13th of October 2023

[A Zero-Shot Language Agent for Computer Control with Structured Reflection](https://arxiv.org/abs/2310.08740)

- Zero-shot agent plans executable actions in the environment and iteratively progresses by learning from mistakes using  self-reflection and structured thoughts management.
- Better generalization, outperforms best iterative-planning agents


---


#### 12th of October 2023

[AgentCF: Collaborative Learning with Autonomous Language Agents for Recommender Systems](https://arxiv.org/abs/2310.09233)

- AgentCF: LLM agent-based recommender system with Use and Item Agents.
- User & Item Agents interact autonomously and the discrepancies between the two are stored in the memory to help guide better future recommendations.


---

[Octopus: Embodied Vision-Language Programmer from Environmental Feedback](https://arxiv.org/abs/2310.08588)

- Octopus: Uses Vision-Language Model with Reinforcement Learning from Environmental Feedback (RLEF).
- Generates action sequences and executable code.


---

[MemGPT: Towards LLMs as Operating Systems](https://arxiv.org/abs/2310.08560)

- MemGPT: OS-based design with LLM-processor managing its actual context and long term memory and uses functions to make changes and events to manage order of processing data.


---

[Promptor: A Conversational and Autonomous Prompt Generation Agent for Intelligent Text Entry Techniques](https://arxiv.org/abs/2310.08101)

- Promptor: Automatic prompt generation.
- Builds prompts based on: User goals, User Profiles, Data Profile, Contextual nformation & Output constraints
- System prompt includes: instructions, Actions, Facts and Examples.


---

[Towards Robust Multi-Modal Reasoning via Model Selection](https://arxiv.org/abs/2310.08446)

- Dynamic model selection by taking into account input & sub-task dependencies.


---


#### 11th of October 2023

[The Temporal Structure of Language Processing in the Human Brain Corresponds to The Layered Hierarchy of Deep Language Models](https://arxiv.org/abs/2310.07106)

- Evidence about strong correlation between layers activated in Deep Language Models (DLMs) and human brain high-order language areas: auditory,syntactic and semantic areas. 
- Brain and DLMs both process input into multi dimensional vector embeddings, processed as sequences taking into account the context.
- Identifies differences. One difference is, that human brain does not perform straightforward linear interpolation between the previous and current words, suggesting RNNs may better mimick human brain language processing. The other difference is, that humans do not learn only by reading text, but use data from multiple modalities.


---

[Empowering Psychotherapy with Large Language Models: Cognitive Distortion Detection through Diagnosis of Thought Prompting](https://arxiv.org/abs/2310.07146)

- Diagnosis-of-Thought: Cognitive distortion detection through prompting: Subjective assessment, contrastive reasoning and schema analysis.

---

[LangNav: Language as a Perceptual Representation for Navigation](https://arxiv.org/abs/2310.07889)

- Uses BLIP to make imgae caption and DETR for object detection on image views to to obtain text descriptions, which a LLM agent uses to generate navigation instruction.

---

#### 10th of October 2023

[Towards Mitigating Hallucination in Large Language Models via Self-Reflection](https://arxiv.org/abs/2310.06271)

- Self-Reflection: Introduces self-reflection prompting, similar to "Reflection"-prompting. Evaluates via LLM-loom, if the answer knowledge is factual enough and in second loop, if the answer is enough consistent.
- Human reviewers are asked to evaluate sentence in answer in case is generic, fact-inconsistent or fact-consistent. The user is as well asked to categorise answer to be question-inconsistent(inconsistent), tangential (consistent, but not on topic) or answerable (consistent and answers).


---


#### 9th of October 2023

[FireAct: Toward Language Agent Fine-tuning](https://arxiv.org/abs/2310.05915)

- Fine-tuning LLMs with agent trajectories for better autonomous agents.


---


#### 8th of October 2023

[Walking Down the Memory Maze: Beyond Context Limit through Interactive Reading](https://arxiv.org/abs/2310.05029)

- MemWalker: navigates long-context iteratively and construct memory as treelike structure.


---


#### 7th of October 2023

[Crystal: Introspective Reasoners Reinforced with Self-Feedback](https://arxiv.org/abs/2310.04921)

- Introspective reasoning of the knowledge.


---

[Self-Supervised Behavior Cloned Transformers are Path Crawlers for Text Games](https://arxiv.org/abs/2312.04657)

- PathCrawling: Crawl all paths leading to reward (train LLM with these paths) and Evaluate generality to unseen task. Continue crwaling most general paths.


---


#### 6th of October 2023

[Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models](https://arxiv.org/abs/2310.04406)

- Language Agents Tree Search (LATS): Self-Refine, Memory, Reasoning, Decision Making & Planning.
- Uses multiple reasonining paths and learns from experience by integrating external feedback & self-reflection.

---

[BrainSCUBA: Fine-Grained Natural Language Captions of Visual Cortex Selectivity](https://arxiv.org/abs/2310.04420)

- BrainScuba (Semantic Captioning Using Brain Alignments): LLM generates interpretable captions.
- Aligns brain activity pattern with semantic content to generate captions to explain how brain processes visual information.
- Collects brain imaging data fMRI when human views visual stimuli and uses BERT to obtain semantic reprensentation in natural language, which is based on alignment process. This process maps images to voxel-wise brain activations.
  

---


#### 5th of October 2023

[Agent Instructs Large Language Models to be General Zero-Shot Reasoners](https://arxiv.org/abs/2310.03710)

- AgentInstruct: generates instructions for th problem and then solves it using these instructions, improving the Chain of Thought (CoT) zero-shot reasoning.


---


#### 5th of October 2023

[Balancing Autonomy and Alignment: A Multi-Dimensional Taxonomy for Autonomous LLM-powered Multi-Agent Architectures](https://arxiv.org/abs/2310.03659)

- Characteristics of Autonomous Agents: Goal-driven task management, Intelligent Agents with LLMs, Multi-Agents collaboration, Context interaction, Balancing Autonomy vs. Alignment.


---

[DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines](https://arxiv.org/abs/2310.03714)

- DSPy programs (think Langchain as cmparison) help create LLM pipelines, which can outperform few-shot prompting techniques.
- Help improve mathe world problems or answering complex questions and manage chaining / loops.


---


#### 3rd of October 2023

<div id="stop"></div>

[Self-Taught Optimizer (STOP): Recursively Self-Improving Code Generation](https://arxiv.org/abs/2310.02304)

- Self-Taught Optimizer (STOP): Ask LLM to improve initial program by providing improvement candidates and then output best solution.


---

[Lyfe Agents: Generative agents for low-cost real-time social interactions](https://arxiv.org/abs/2310.02172)

- LyfeAgents Brain: Sensory processing, Internal states, Self-monitor, Action selection and Memory.
- Internal states are text based: current goal, memory, recent events and sensory inputs. 
- Cognitive controller selects high-level actions. Action model selects actions until termination condition is reached.
- Self-monitoring maintains and emphasizes recent and novel events towards agent goals
- Memories are clustered and summarized before moving them to long-term storage (vector database)


---

[EcoAssistant: Using LLM Assistant More Affordably and Accurately](https://arxiv.org/abs/2310.03046)

- EcoAssistant: Enables LLM agent to converse with code executor to iteratively produce answers based on code produced. Hierachical structure, where cheaper and weaker LLM is used before trying the stronger and expensive LLM.
- Surpasses GPT-4 10% in performance with 50% less cost.
  

---

[Large Language Models as Analogical Reasoners](https://arxiv.org/abs/2310.01714)

- LLM self-generates examples/knowledge related to the task.


---

[Conceptual Framework for Autonomous Cognitive Entities](https://arxiv.org/abs/2310.06775)

- Conceptual framework for Autonomous entities.


---

[OceanGPT: A Large Language Model for Ocean Science Tasks](https://arxiv.org/abs/2310.02031)

- DoInstruct (Domain Instruction): Automatically gathers large amount of domain specific instruction data for multi-agent collaboration.
- Domain Instruction generation: Agents used as experts in each topic. Instructions are augmented rapidly through agent collaboration, which are annotated and finally inspected for high quality fine-tuning dataset. 
  

---


#### 2nd of October 2023

[Enabling Language Models to Implicitly Learn Self-Improvement](https://arxiv.org/abs/2310.00898)

- ImPlicit Self-ImprovemenT (PIT)-framework: introduces self-improvement, where LLMs self-improve its response quality with human preference data without extensive human annotation.


---


[SmartPlay : A Benchmark for LLMs as Intelligent Agents](https://arxiv.org/abs/2310.01557)

- SmartPlay: a benchmark to test LLM-based agents from 9 perspectives.
- Tests: Reasonning with object dependencies, planning ahead, spatial reasoning, learning from history, and understanding randomness. 


---

[GRID: A Platform for General Robot Intelligence Development](https://arxiv.org/abs/2310.00887)

- GRID: General Robot Intelligence Development
- Solves complex tasks using simulatiom and/or real-world data
- Task specification, robot configuration and sensor/API.
- Foundation Mosaic: a neural architecture.


---


#### 1st of October 2023

[RoleLLM: Benchmarking, Eliciting, and Enhancing Role-Playing Abilities of Large Language Models](https://arxiv.org/abs/2310.00746)

- RoleLLM: Role-profile constructor, Context-based Instruction generarion, Role-based Prompting(RoleGPT), Role-conditioned Instruction-tuning.


---

#### 29th of September 2023

[AutoAgents: A Framework for Automatic Agent Generation](https://arxiv.org/abs/2309.17288)

- AutoAgents: Planner agent receives user input and converts it into a plan. Multiple agent roles take actions in this plan to convert into a result. 
- Observers: Observer agent reviews, if the created agent roles meet the requirements. Plan observer agent reviews, if the plan meets expectations. Action observer reviews, if the action response meets expectations.
- Includes drafting stage (with agent observer and plan observer agents) and Execution stage (with action observer).


---

[Motif: Intrinsic Motivation from Artificial Intelligence Feedback](https://arxiv.org/abs/2310.00166)

- Motif: Trains a reward fucntion/model from pairs of gameplay captions and LLM observations of these game actions. Then train an agent using RL with the reward model.
- Diverse behaviours triggered with the LLM improve in performance in specific domain: for example Gold Collector collects more cold.


---


#### 28th of September 2023

[Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution](https://arxiv.org/abs/2309.16797)

- Promptbreeder uses thinking styles and mutation-prompts and is able to improve mutation/task prompts.


---

#### 24th of September 2023

[Let's reward step by step: Step-Level reward model as the Navigators for Reasoning](https://openreview.net/forum?id=RSQL6xvUYW)

- Heuristic Greedy Search for Process-Supervised Reward Model (HGS-PRM): each new reasoning step generated by the LLM is evaluated by the reward model, if to accept the reasoning step or generate a new one until the reasoning path is identified.
- Creates PRM-Code dataset using Code-LLaMA-7B using Mutating testing-technique. 


---


#### 23th of September 2023
[Natural Language based Context Modeling and Reasoning with LLMs: A Tutorial](https://arxiv.org/abs/2309.15074)

- LLM-driven Context-aware Computing (LCaC) approach.


---


#### 20th of September 2023

[You only look at the screens: Multimodal Chain-of-Action Agents](https://arxiv.org/abs/2309.11436)

- Multimodal Chain-of-Actions Agents (Auto-UI) interacts directly with the UI
- Chain-ofAction technique using series of action histories and future action plans.

---


#### 18th of September 2023

[MindAgent: Emergent Gaming Interaction](https://arxiv.org/abs/2309.09971)

- MindAgent: Planning skills and Tools use(Agent location, Tool state, Agent holdings, Pending dishes, Timer), LLM dispatcher, Memory history (Environment, Agent State, Actions and Feedback) and Action module(Controller, Human actions, Action validator, Action Types/Patterns/Names).
- Introduces CuisineWorld-benchmark, where multiple agents play game simultaneously through multi-agent collaboration.


---


#### 14th of September 2023

<div id="llmagentsurvey"> </div>

[The Rise and Potential of Large Language Model Based Agents: A Survey](https://arxiv.org/abs/2309.07864)

-  A conceptual framework for LLM-based agents with three components brain, perception, and action.


---

[Agents: An Open-source Framework for Autonomous Language Agents](https://arxiv.org/pdf/2309.07870.pdf)

- Multi-agent: Planning, memory, tool usage, multi-agent communication & symbolic control.
- Open source library.


---

<div id="physicalgrounding"> </div>


#### 13th of September 2023

[Physically Grounded Vision-Language Models for Robotic Manipulation](https://arxiv.org/abs/2309.02561)

- PhysObjects dataset for physical grounding.
- VLMs with PhysObjects improves its understanding on physical objects.
- Improves task success rate.


---


#### 12th of September 2023

[Life-inspired Interoceptive Artificial Intelligence for Autonomous and Adaptive Agents](https://arxiv.org/abs/2309.05999)

- Interoceptive AI: monitoring own internal state of the artificial agent.


---

[Textbooks Are All You Need](https://www.youtube.com/watch?v=24O1KcIO3FM)

- Sebastien Bubeck explains the insights from the reserch on Phi-1 regards coding tasks and Phi-1.5. regards reasoning tasks and the models being able to outperform 1000 times larger LLMs.
- The talk highlights, that the key ingredients on Textbook-like training data and then giving then giving Exercises.
- Explains the the key ingredient in "Textbooks are all you need"-paper regards the data, is largerly based on TinyStories-paper, which dataset was used to train a high performing model to generate fluent and consistent stories in English language. 


---



#### 8th of September 2023

<div id="autonomousagentssurvey"> </div>

[Unleashing the Power of Graph Learning through LLM-based Autonomous Agents](https://arxiv.org/abs/2309.04565)

- AutoGraph procedure: data, configuration, searching and tuning agents.

---


#### 28th of August 2023

[RecMind: Large Language Model Powered Agent For Recommendation](https://arxiv.org/abs/2308.14296)

- RecMind: a recommender focused LLm agent with reasoning, planning to sub-tasks, memory & tools.


---

#### 22th of August 2023

[A Survey on Large Language Model based Autonomous Agents](https://arxiv.org/abs/2308.11432)

- Systematic review of LLM based Autonomous Agents.
- Use cases and evaluation strategies and future use cases.


---

#### 21st of August 2023

[AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors](https://arxiv.org/abs/2308.10848)

- AgentVerse: multi-agent collaborarion and individual agents social bjeaviours.


#### 18th of August 2023

<div id="got"></div>

[Graph of Thoughts: Solving Elaborate Problems with Large Language Models](https://arxiv.org/abs/2308.09687)

- Graph-of-Thoughts (GoT): Reasoning with LLM using graph-structure with intermediate steps.
- Introduces Volume-of-Tought metric to inform the scope of information carried by the LLM output.

---

[AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation](https://arxiv.org/abs/2308.08155)

- AutoGen: An open source framework, where LLM agents converse with other LLM agents either one or many, chat with humans and use tools.
- LLM agents are able to create new chats with other LLM agents.

---


[WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct](https://arxiv.org/abs/2308.09583)

- Improves math reasoning with Reinforcement Learning from Evol-Instruct Feedback (RLEIF): Upward and Downward evolution improve instructions by making questions easier or harder based on their difficulty level.


---

#### 17th of August 2023

<div id="rest"></div>

[Reinforced Self-Training (ReST) for Language Modeling](https://arxiv.org/abs/2308.08998)

- Introduces Reinforced Self-Training (ReST).
- Grow step generates data from LLM, Improve step uses this filtered data to fine-tune the LLM. Repeat. 


---

[Never-ending Learning of User Interfaces](https://arxiv.org/abs/2308.08726)

- Never-ending UI Learner: automatically installs apps from an appstore and crawls them to learn difficult training examples


---

#### 3rd of August 2023

[Scaling Relationship on Learning Mathematical Reasoning with Large Language Models](https://arxiv.org/abs/2308.01825)

- Proposes Rejection sampling Fine-Tuning (RFT), which generates reasoning and collects correct ones to augment as fine-tuning dataset. 


---

#### 25th of July 2023

[WebArena: A Realistic Web Environment for Building Autonomous Agents](https://arxiv.org/abs/2307.13854)

- An environment to test Autonomous agents in an environment with tools, external knowledge.

---

#### 20th of July 2023

[Textbooks Are All You Need](https://arxiv.org/abs/2306.11644)

- Addresses LLM training data to be "text-book-like":  clear, self-contained, instructive, and balanced. The method is used in Phi-models.


---

[BuboGPT: Enabling Visual Grounding in Multi-Modal LLMs](https://arxiv.org/abs/2307.08581)

- BuboGPT: Uses Vicuna LLM by receiving text input inserting together visual and audio inputs separately with Q-former. The Vicuna output is then processed using SAM-model for visual grounding.
- Achieves coherent and grounded descriptions

---


#### 16th of July 2023

[Communicative Agents for Software Development](https://arxiv.org/abs/2307.07924)

- ChatDev: Define task and automatically generate SW designing, coding, testing, and documentation using "Chat Chains", where LLM-based chats include different roles for each sub-task: CEO, programmer, CTO etc.
- Includes role-assignment, memory and self-reflection.  


---

[xTrimoPGLM: Unified 100B-Scale Pre-trained Transformer for Deciphering the Language of Protein](https://www.biorxiv.org/content/10.1101/2023.07.05.547496v3)

- Protein Language Model: xTrimoPGLM.

---


#### 14th of July 2023

[Large Language Models Understand and Can be Enhanced by Emotional Stimuli](https://arxiv.org/abs/2307.11760)

- EmotionPrompt: adds to prompt an emotional stimuli, which improves performance by 10.9%.
- An example of an emotional stimuli is to state that the work is important for career. 




#### 23rd of June 2023 

<div id="lili"> </div>

[LLM Powered Autonomous Agents](https://lilianweng.github.io/posts/2023-06-23-agent/)

- Lilian Weng from OpenAI article / blog post
- Covers Planning, Memory and Tool usage of LLM powevered agents


---

#### 8th June 2023

[ToolAlpaca: Generalized Tool Learning for Language Models with 3000 Simulated Cases](https://arxiv.org/pdf/2306.05301.pdf)

- Builds multi-agent simulation environment to generate dataset of using many real world apis. 
- Small models can achieve comparable performance to larger models on tool usage.


---

#### 6th of June 2023

[Enabling Intelligent Interactions between an Agent and an LLM: A Reinforcement Learning Approach](https://arxiv.org/abs/2306.03604)

- When2Ask: RL agent, which learns when to query LLM for high-level plans to complete a task.
- Planner, Actor and Mediator.


---

#### 5th June 2023

[SELFEVOLVE: A Code Evolution Framework via Large Language Models](https://arxiv.org/pdf/2306.02907.pdf)

- Generates intermediate code based on input prompt. 
- Use LLM to act as expert programmer to debug the generated code by receiving errors from Python interpreter.


---

#### 3th June 2023

[Prompt Sapper: LLM-Empowered Software Engineering Infrastructure for AI-Native Services](https://arxiv.org/pdf/2306.02230.pdf)

- Human AI collaborative intelligence methodology & technical practices, where the idea is not to have "full Auto-GPT" from user input to direct resolution by LLM, but rather human reviews steps between.
- Useer inputs objective, LLM asks clarification. Use then  User adds clarifications and LLM constructs AI chain for human to review. Finally LLM executes the AI chain with user acceptabnce tests.


---

#### 3th June 2023

[Auto-GPT for Online Decision Making: Benchmarks and Additional Opinions](https://arxiv.org/pdf/2306.02224.pdf)

- Auto-GPTs outperforms supervised state-of-the-art Imitiation Learning (IL) models with GPT4 in WebShop- and ALFWorld-benchmarks in unknown external environments.
- Additional opinions algorithm improves performance, which takes into account additional opinions from external expert models.


---

#### 2nd of June 2023

- MathChat: Describes a solid conversational MATH problem solving in four step process.
- Describes the prompts used.

---

#### 26th of May 2023

[Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models](https://arxiv.org/abs/2305.16582)

- Graph-of-Thought (GoT) reasoning: To model human thought process as graph instead of chain to improve LLM reasoning capability.


---

[Impossible Distillation: from Low-Quality Model to High-Quality Dataset & Model for Summarization and Paraphrasing](https://arxiv.org/abs/2305.16635)

- Uses low-quality LM to generate High-quality dataset (more diverse and more effective for generalization in unseen domains) to train a high quality model: 770 million parameter model outperforms GPT-3 in multiple tasks evaluated by humans.

---


#### 25th of May 2023

[Voyager: An Open-Ended Embodied Agent with Large Language Models](https://arxiv.org/abs/2305.16291)

- Voyager: open-ended embodied agent with LLM

---

#### 24th May 2023

[Reasoning with Language Model is Planning with World Model](https://arxiv.org/abs/2305.14992)

- RAP (Reasoning via Planning): Uses LLM as both world model and reasoning LLM-agent. Integrates MCTS search planning algorithm.
- Incrementally generates reasoning tree with LLM in domains of plan generation, math reasoning and logical inference.

---

[Gorilla: Large Language Model Connected with Massive APIs](https://arxiv.org/abs/2305.15334)

- Gorilla is a retrieve-aware finetuned LLaMA-7B model for API calls using self-instruct to generate Instruction-API pairs. 


---

[Better speech synthesis through scaling](https://arxiv.org/abs/2305.07243)

- TorToise (TorToise an expressive, multi-voice text-to-speech system): introduces text-to-speech synthesis framework utilizing autoregressive transformer and diffusion decoder with conditioning inputs and CLVP re-ranking for improved speech quality.
- This framework comprises autoregressive transformer for speech token prediction, diffusion decoder for converting tokens to MEL spectrograms, and vocoder for waveform generation from spectrograms.
- TorToise incorporates conditioning MEL from reference audio and CLVP discriminator to enhance speech synthesis expressiveness and enable speaker cloning capabilities.


---


#### 18th of May 2023

[Think Outside the Code: Brainstorming Boosts Large Language Models in Code Generation](https://arxiv.org/abs/2305.10679)

- Brainstorm: uses brainstorming step to generate and select diverse thoughts in code generation.
- Uses three steps: brainstorming, thought selection (trains a thought ranker for this) and writing code.



#### 17th May 2023

<div id="tot"></div>

[Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/abs/2305.10601) 

- Tree of Thoughts (ToT)-technique makes decisions using multiple different reasoning paths, self-evaluating choices to decide next action with ability to look back/forward for global decisions.


---

[Mobile-Env: Building Qualified Evaluation Benchmarks for LLM-GUI Interaction](https://arxiv.org/abs/2305.08144)


---

#### 13th of May 2023

[BabyCatAGI: Fast and Feline](https://yoheinakajima.com/babycatagi-fast-and-feline/)

- BabyCatAGI: a modified BabyAGI by replacing  task manager in BabyBeeAGI with task creation agent running once.
- Uses Intelligent Agent Tool to combines tools to extract only relevant information to next step such as looping web search and scraping results to pull only specific part to another task.


### 12th of May 2023

[TinyStories: How Small Can Language Models Be and Still Speak Coherent English?](https://arxiv.org/abs/2305.07759)

- A breakthrough paper, where synthetic data generated by Teacher-Student LLM is used to train a high-performing model to generate fluent and consistent English stories.
- Demonstrated the effectiveness of synthetic data in smaller LLMs challenging large SOTA models in domain of English language.
- Uses GPT-4 to grade content generated by the models as if created by student and being graded by the GPT-4 teacher.

---

### 9th of May 2023

[ImageBind: One Embedding Space To Bind Them All](https://arxiv.org/abs/2305.05665)

- ImageBind: a joint embedding space for images, text, audio, depth, thermal and IMU data modalities-

---

#### 3rd of May 2023

[Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings](https://arxiv.org/abs/2305.02317)

- Introduces Visual Chain of Thought (VCoT) for data augmentation, where between reasoning steps multimodal data is infilled to obtain better reasoning results.


---

#### 30th of April 2023

[BabyBeeAGI: Task Management and Functionality Expansion on top of BabyAGI](https://yoheinakajima.com/babybeeagi-task-management-and-functionality-expansion-on-top-of-babyagi/)

- BabyBeeAGI: a modified from BabyAGI tracking statuses of tasks, task dependencies, identification of required new tasks, assigning tools and results in json-format.


---

<div id="consciousnesstest"> </div>  

# 26 of April 2023

["Inside OpenAI [Entire Talk" by Stanford eCorner](https://www.youtube.com/watch?si=nMlyq1_d0r9JQkJ0&v=Wmo2vR7U9ck&feature=youtu.be)

- Interview of Ilya Sustskever, where defined a way to perform "a consciousness test" from a very controlled dataset, see "minute 15".
 
---

#### 21st of April 2023

[Improving Grounded Language Understanding in a Collaborative Environment by Interacting with Agents Through Help Feedback](https://arxiv.org/abs/2304.10750)

- LLM agent self-help with LLM to complete IGLU tasks using clarifying questions.
- 
---

#### 13th of April 2023

[RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment](https://arxiv.org/abs/2304.06767)

- RAFT-finetuning: Samples batch lf data from LLM, reward function scores them, high reward examples are filtered as data to finetune the LLM.


---

#### 11th of April 2023

[ChemCrow: Augmenting large-language models with chemistry tools](https://arxiv.org/abs/2304.05376)

- Uses LLM and chemistry tools to plan and execute different chemical tasks. 
- Tools include web and literature search, Python, human-tool to interact with the end user and various molecule tools, safety tools and chemical reaction tools.

---

[Teaching Large Language Models to Self-Debug](https://arxiv.org/abs/2304.05128)

- The model generates new code together with code explanation. The code is then executed and this executed code is sent back as feedback together with the code explanation. This feedback

---

#### 7th of April 2023

[ChatPipe: Orchestrating Data Preparation Program by Optimizing Human-ChatGPT Interactions](https://arxiv.org/abs/2304.03540)

- ChatPipe - Iterative, data preparation program with ChatGPT using 1. Operation Recommendation, 2.   Program generation, 3. Version management. 
- Recommends next data preparation opration. Easily roll-back to previous program for version control.


---

#### 6th April 2023

[Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/abs/2304.03442)

- Enable believable human behavior: observation, planning, and reflection.
- An agent wants to throw a Valentine’s Day party. The agents autonomously spread invitations, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. 
- [GPTeam](https://github.com/101dotxyz/GPTeam) is inspired by this approach.


---

#### 31 March 2023

[CAMEL: Communicative Agents for "Mind" Exploration of Large Scale Language Model Society](https://arxiv.org/abs/2303.17760)

- CAMEL attempts to facilitate autonomous cooperation among communicative agents through role-playing framework.
- The approach manages complete tasks with minimal human input.


---

#### 30th of March 2023

[Self-Refine: Iterative Refinement with Self-Feedback](https://arxiv.org/abs/2303.17651)

- Self-Refine refers to Iterative refinement with self-feedback: use the LLM to get Feedback to original output, which is passed back to LLM to Refine a new output.
- The concept is best understood here in the blog by : [Self-Refine: Iterative Refinement with Self-Feedback](https://selfrefine.info/) with GIFs and code examples.
- Improves base-model performance in tasks like math reasoning and code generation. 


---

[HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace](https://arxiv.org/abs/2303.17580)

- A LLM (such as ChatGPT) accesses HuggingFace community to look AI models to complete the given task. 
- It can read multi modalities by outsourcing tasks like image recognition to the specific image model. 


---

[DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents](https://arxiv.org/abs/2303.17071)

- Dialog-Enabled Resolving Agents (DERA) uses two roles: Researcher and Decider to perform discussion between these two agents.
- Researcher role processes information and Decider role uses judgement.


---

#### 29th of March 2023

[TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs](https://arxiv.org/abs/2303.16434)

- Multimodal conversational foundation model (MCFM). MCFM generates a textual solution outline, then API selector chooses most relevant API from collection of APIs (with API name, parameter list, description, usage example and example when combining it with another API). 
- MCFM generates action code using recommended API and the API call is executed. Finally, output is provided back to developer.


---


#### 28th March 2023 

[Task-driven Autonomous Agent Utilizing GPT-4, Pinecone, and LangChain for Diverse Applications](https://yoheinakajima.com/task-driven-autonomous-agent-utilizing-gpt-4-pinecone-and-langchain-for-diverse-applications/)

- Task-driven autonomous agent, with vector database and Langchain. BabyAGI includes: Execution, creation and prioritization
- Takes objective, pulls an item from task queue and moves it to execution agent with access to memory.  


---

[Sparks of Artificial General Intelligence: Early experiments with GPT-4](https://arxiv.org/abs/2303.12712)

- Raises an argument, that GPT-4 model capabilities should be reviewed as an early and incomplete version of Artificial General Intelligence (AGI) systems due the multiple metrics comparing against human level-performance.
- Raises the argument, that LLMs need to move beyond "next-word prediction" to overcome linear reasoning limitation, which often is possible to solve as incremental tasks with few iterations.


---

#### 20th March 2023

[Reflexion: Language Agents with Verbal Reinforcement Learning](https://arxiv.org/abs/2303.11366)

- Reflexion agents reflect on task feedback, use it from memory to make better decisions and new attempts.

---

[Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference](https://arxiv.org/abs/2303.04673)

- EcoOptiGen: Hyperparameter tuning of LLMs.


---

[Improving Multimodal Interactive Agents with Reinforcement Learning from Human Feedback](https://arxiv.org/abs/2211.11602)


---


#### 27th of February 2023

[Reward Design with Language Models](https://arxiv.org/abs/2303.00001)

- LLM-RL: framework uses a LLM as a proxy reward function to train reinforcement learning (RL) agents.
- User specifies objective with natural language prompt, LLM evaluates agent's behavior, and framework is agnostic to RL algorithm.
- This approach simplifies reward design and enables training of agents aligned with user objectives.


---


#### 8th of December 2022

[LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models](https://arxiv.org/abs/2212.04088)

- LLM-Planner: Uses LLM for few-shot planning with embodied agents based on natural language and visual perception of the environment.
- Improves planning with physical grounding to create and update plans.
- Includes task introduction/goal instruction/step-by-step instructions/plan list//object list/retrieval message (next plan).

---

#### 20th of October 2022

[Large Language Models Can Self-Improve](https://arxiv.org/abs/2210.11610)

- Demonstrates LLM is able to Self-Improve with only unlabeled datasets using CoT and Self-Consistency Prompting and then fine-tune the LLM using these self-generated solutions as target outputs.
- This research by Google, effectively performs Self-Recursive Learning not only during Inference time (such as CoT or In-Context Learning alone), but training as well.


---

#### 12th October 2022

[Interactive Language: Talking to Robots in Real Time](https://arxiv.org/abs/2210.06407)

- Interactive Language: introduces a framework for real-time language-instructable robots, with Teleoperated Data Collection, Hindsight Language Relabeling, Language Conditioned Behavioral Cloning (LCBC), Robot Policy, Real-time Language Guidance, ResNet CNN, CLIP Text Encoder, Vision-Language Transformer, Temporal Transformer, and Policy MLP.
- Interactive Language framework uses behavioral cloning on large language-annotated dataset for training real-time language-guided robot policy.
- This framework facilitates interactive robot control for complex manipulation tasks and demonstrates high success rate on diverse language commands.


---


#### 31st of August 2022

<div id="emerging"></div>

[Emergent Abilities of Large Language Models](https://openreview.net/forum?id=yzkSU5zdwD)

-  Defines officially the term  "Emergent Abilities": "An ability is emergent if it is not present in smaller models but is present in larger models."
-  Emergent abilities were detected already with GPT-3, but here its clearly defined as ability detected only after specific scale.
-  Identifies a list of Emerging abilities not detected in specific smaller model, but identfied in a larger model.
-  I like the paper, because increasing number of task patterns are learned using single learning objective of next-word prediction as scale increases.


---

<div id="generalistagent"></div>

#### 12th of May 2022

[A Generalist Agent](https://arxiv.org/abs/2205.06175)

- Gato: A multi-modal, multi-task, multi-embodiment generalist policy agent.
- Learns to play Atari, caption images, chat, stack blocks with robot arm, etc. 
- Includes text tokens, image patch tokens, agent timesteps and action tokens.
- Argues, that "a generalist agent that can adapt to new embodiments and learn new tasks with few data."

---

#### 19th of April 2022

<div id="worldmodel2"></div>


[Deep learning, reinforcement learning, and world models](https://www.sciencedirect.com/science/article/pii/S0893608022001150)

- Reviews Deep learning, Reinforcement learning and World models.
- Claims humans use World model as simulators in the brain, learned through senso-motory interaction with the environment. It is possible to learn world model using deep generative models.




<div id="star"></div>

---


#### 28th of March 2022

[STaR: Bootstrapping Reasoning With Reasoning](https://arxiv.org/abs/2203.14465)

- Introduces the concept: "Self-Taught Reasoner" (STaR) or *, where LLM improves its reasoning by learning from its own reasoning: model is asked to generate rationalizations to questions. If rationalization derives wrong answer to question, the rationalization is repeated by giving it as well the correct answer. All rationalizations leading to correct answer are used for fine-tuning the LLM model. This process is repeated and each iteration improves the LLMs capability of reasoning.
- The paper does not refer to Self-Recursive Learning, but we could argue it as an example of this process in the context of reasoning.


---

#### 21st of March 2022

<div id="selfconsistency"></div>

[Self-Consistency Improves Chain of Thought Reasoning in Language Models](https://arxiv.org/abs/2203.11171)

- Enables reasoning with LLMs using CoT and Self-Consistency, where multiple, different reasoning paths are used to vote the most consistent answer.
- Improves reasoning and math problem solving.


---

[Chain of Hindsight Aligns Language Models with Feedback](https://arxiv.org/abs/2302.02676)

- Chain of Hindsight (CoH): Humans learn from feedback, which is converted sequences of sentences, ranked with human preferences and used to fine-tune the LLM.

---

#### 7th of March 2022

[Shared computational principles for language processing in humans and deep language models](https://www.nature.com/articles/s41593-022-01026-4)

- Provides evidence  about three computational principles, shared both by Deep Language Models (DLMs) and human brain to process language.
- The three principles are: continuous next-word prediction, contextual embeddings and surprise prediction error.

  
---

#### 28th of January 2022

<div id="cot"></div>

[Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903)

- Defines Chain-of-Thought (CoT).
- CoT is one Emerging Ability not present in smaller models, but present in larger models.
- CoT can be seen as Self-Recursive Learning, where the LLM improves its own output by having LLM use intermediate steps to solve complex task.
- The approach effectively demonstrates the LLMs capability to perform Self-Recursive Learning, altough its not integrated back as training data of the model.

---

#### 12th April 2021

[Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401)

- RAG (Retrieval-Augmented Generation): introduces retrieval-augmented generation models, with Query Encoder, Retriever, Document Index, and Generator, for knowledge-intensive NLP tasks.
- RAG framework combines parametric memory (pre-trained seq2seq model) and non-parametric memory (Wikipedia index) to improve generation quality.
- RAG models achieve state-of-the-art results on open domain question answering tasks, outperforming parametric and task-specific architectures.


---

<div id="languageagentdefinition"></div>


#### 26th of March 2021


[Alignment of Language Agents](https://arxiv.org/abs/2103.14659)

- Defines Language Agent. 



---

<div id="qstar"></div>

#### 8th of February 2021

[A* Search Without Expansions: Learning Heuristic Functions with Deep Q-Networks](https://arxiv.org/abs/2102.04518)

- Q* search algorithm: Better version of A* search algoirthm, because reduces computation time and number of nodes to be computed.

---

#### 28th of May 2020 

<div id="multitask"></div>

[Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165)

- Applies first-time the term of LLMs ability to learn a task from contextual information: "In-Context Learning".
- This ability is another example of Self-Recursive Learning, altough its not integrated back as training data of the model.
- This paper as well identified the capability of LLMs to learn multiple tasks by having been only trained to predict the next word. See Jason Wei´s presentation included below, where he covers the "Massively Multi-task learning" of LLMs and I think it helps to gain better insight about LLMs, rather than thinking them as simply "statistical models". 

---

#### 22th of May 2020

[Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401)

- Defines Retrieval-Augmented Generation (RAGs).

---

#### 12th of November 2020

<div id="rewardisenough">  </div>

[Reward is enough](https://www.sciencedirect.com/science/article/pii/S0004370221000862)

- Reward is sufficient to drive intelligent behaviours instead of requiring special formulations.
- Agents could learn to obtain various intelligent behaviours through trial and error experiences to maximize reward.
- Sophisticated intelligence may emerge from simple objective, think what an animal is able to learn to do just by being in hungry.


---


#### 24th of November 2019

[Multi-Agent Reinforcement Learning: A Selective Overview of Theories and Algorithms](https://arxiv.org/abs/1911.10635)

- MARL: Introduces Multi-Agent Reinforcement Learning (MARL).


<div id="resourcecloud">  </div>

#### 28th of July 2005

[The Emotion Machine. Draft.](https://web.media.mit.edu/~minsky/eb1.html)

- Human mind consists according to Minsky, from Cloud of Resources turnable on/off.
- Important theory, because LLM agents can construct such resources, observed in a human brain, altough years after this theory.

---


<div id="autonomousagentdefinition">  </div>

#### 12th of August 1996 

[Is it an Agent, or Just a Program?: A Taxonomy for Autonomous Agents.](https://www.researchgate.net/publication/221457111_Is_it_an_Agent_or_Just_a_Program_A_Taxonomy_for_Autonomous_Agents)

- "Autonomous agent is a system situated within and a part of an environment that senses that environment and acts on it, over time, in pursuit of its own agenda and so as to effect what it senses in the future."
- Definition includes: 1. Operate within an environment, 2. Sense and Act, 3. Over time, 4. Control its own agenda (Autonomous).
- Studies the multiple previous definitions of Agents / Autonomous Agents, although the perspective is +27 years ago and prior to LLMs. 

---


[Prediction and Adaptation in an Evolving Chaotic Environment](https://arxiv.org/abs/adap-org/9306005)

- Defines the concept of "Predictive Agent" as adaptive predictors.

---

[A Learning Algorithm that
Mimics Human Learning](https://www.santafe.edu/research/results/working-papers/a-learning-algorithm-that-mimics-human-learning)

- Reviews Artificial Agents learning like humans.

---

<div id="astarssearch">  </div>

#### 24th of November 1967


[A formal Basis for the Heuristic Determination of Minimum Cost Paths](https://ai.stanford.edu/%7Enilsson/OnlinePubs-Nils/General%20Essays/roboticsandai.pdf)

- A* search algorithm.
- Defines the A* search algorithm for the first time, widely used in RL as planning algorithm.



---

## Citation


How to cite my work?



```
@misc{MaattaAutonomousAgents2023,
  author = {Teemu Maatta},
  title = {Autonomous Agents},
  year = {2023},
  howpublished = {\url{https://github.com/tmgthb/Autonomous-Agents}},
  note = {Accessed: YYYY-MM-DD}
}

```

---



[Back to top](#topofthepage)
